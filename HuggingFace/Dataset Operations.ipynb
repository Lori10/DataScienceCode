{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d8e95d",
   "metadata": {},
   "source": [
    "In this notebook we will show some methods that can be applied to HuggingFace dataset to perform different data transformation manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d3d46",
   "metadata": {},
   "source": [
    "* Load your own custom dataset using the HuggingFace load_dataset (as a HuggingFace DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6683a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"train.csv\", \"test\": \"test.csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5e58c",
   "metadata": {},
   "source": [
    "* Load a dataset from the HuggingFace dataset Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f6bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\loriz\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad\", split='train')\n",
    "squad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086f26b",
   "metadata": {},
   "source": [
    "* Use features attribute to get an overview about the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc61bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'title': Value(dtype='string', id=None),\n",
       " 'context': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None),\n",
       " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e799cf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'answer_start': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad.features['answers'].feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d08914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f196fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6cf7c8",
   "metadata": {},
   "source": [
    "* Using shuffle method we can shuffle the dataset by setting a particular seed value to reproduce same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15c8957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5727cc873acd2414000deca9',\n",
       " 'title': 'Oklahoma',\n",
       " 'context': 'Oklahoma is the 20th largest state in the United States, covering an area of 69,898 square miles (181,035 km2), with 68,667 square miles (177847 km2) of land and 1,281 square miles (3,188 km2) of water. It is one of six states on the Frontier Strip and lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near-west by Texas.',\n",
       " 'question': 'Where does Oklahoma rank by land area?',\n",
       " 'answers': {'text': ['20th'], 'answer_start': [16]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_shuffled = squad.shuffle(seed=666)\n",
    "squad_shuffled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551863f7",
   "metadata": {},
   "source": [
    "* We can split the data into train and test and it automatically randomly select different examples. This method does not include stratify parameter for stratified train test split. Instead we should use train_test_split method of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e9e596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 78839\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 8760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = squad.train_test_split(test_size=0.1, shuffle=True, seed=10)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e55e6e",
   "metadata": {},
   "source": [
    "* Using select method we can select particular examples/rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9eb14f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select examples with these indices\n",
    "indices = [0, 10, 20, 40, 80]\n",
    "examples = squad.select(indices)\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d92f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select first 2 examples\n",
    "examples = squad.select(range(0,2))\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40780206",
   "metadata": {},
   "source": [
    "* Usually we use shuffle with select to select randomly select some examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a295b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = squad.shuffle().select(range(5))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a5b0e",
   "metadata": {},
   "source": [
    "* Using filter method we can select examples that satisfy some conditions. It applies a function to each example for each split. We should define the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2688720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615cae6ca1f34a62945b1fd6656aa347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '56de0fef4396321400ee2583',\n",
       " 'title': 'Lighting',\n",
       " 'context': 'Lighting or illumination is the deliberate use of light to achieve a practical or aesthetic effect. Lighting includes the use of both artificial light sources like lamps and light fixtures, as well as natural illumination by capturing daylight. Daylighting (using windows, skylights, or light shelves) is sometimes used as the main source of light during daytime in buildings. This can save energy in place of using artificial lighting, which represents a major component of energy consumption in buildings. Proper lighting can enhance task performance, improve the appearance of an area, or have positive psychological effects on occupants.',\n",
       " 'question': 'What is used a main source of light for a building during the day?',\n",
       " 'answers': {'text': ['Daylighting'], 'answer_start': [245]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_filtered = squad.filter(lambda x : x[\"title\"].startswith(\"L\"))\n",
    "squad_filtered[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2776",
   "metadata": {},
   "source": [
    "* Rename_column can be used to give the columns new names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabfa974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'passages', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_squaed = squad.rename_column(\"context\", \"passages\")\n",
    "new_squaed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c06f2c",
   "metadata": {},
   "source": [
    "* With remove_columns method we can remove specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7821bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_squad = squad.remove_columns([\"id\", \"title\"])\n",
    "n_squad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05429d33",
   "metadata": {},
   "source": [
    "* We may have nested columns in our data (nested dictionaries). Using flatten we can flatten our data to convert nested columns into normal columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "564c19fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5fd2c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]},\n",
       " {'text': ['a copper statue of Christ'], 'answer_start': [188]},\n",
       " {'text': ['the Main Building'], 'answer_start': [279]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['answers'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "261dd189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers.text', 'answers.answer_start'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_squad = squad.flatten()\n",
    "fl_squad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7403cbf",
   "metadata": {},
   "source": [
    "* Using map method we apply a function (either built in or implemented by us) to each example/row for each split (train/test/validation). It returns something (value, array etc) for each example as a dictionary. In the dataset we ll have these new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "393e32be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bad533cfa24600823173643ba29d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87599 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['egypt',\n",
       " 'ann_arbor,_michigan',\n",
       " 'rule_of_law',\n",
       " 'samurai',\n",
       " 'group_(mathematics)']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase_title(example):\n",
    "    return {\"title\": example[\"title\"].lower()}\n",
    "\n",
    "squad_lowercase = squad.map(lowercase_title)\n",
    "# Peek at random sample\n",
    "squad_lowercase.shuffle(seed=42)[\"title\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504c92d",
   "metadata": {},
   "source": [
    "* Using batched=True and batch_size parameter we can perform paralell computing. This function will be applied for several examples in paralell (batch_size examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ec9fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac7ede1415442e896b5bc7ef9f85a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'attention_mask', 'context', 'id', 'input_ids', 'question', 'title'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_title(example):\n",
    "    return tokenizer(example[\"title\"])\n",
    "\n",
    "tokenized_data = squad.map(tokenize_title, batched=True, batch_size=500)\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77226862",
   "metadata": {},
   "source": [
    "* We can convert HuggingFace data into pandas DataFrame to perform more advanced operation and visualization. We can use set_format('pandas') or to_pandas methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8b73014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\loriz\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad\", split='train')\n",
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6662cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the output format to pandas.DataFrame\n",
    "squad.set_format(\"pandas\")\n",
    "squad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aeb68a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad.__getitem__(0)\n",
    "\n",
    "squad.set_format(\"pandas\")\n",
    "\n",
    "squad.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42322735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = squad.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a17d9",
   "metadata": {},
   "source": [
    "Now we can perform different operations using pandas on our pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed8f1aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New_York_City            817\n",
       "American_Idol            802\n",
       "Beyoncé                  758\n",
       "Frédéric_Chopin          697\n",
       "Queen_Victoria           680\n",
       "                        ... \n",
       "Great_Plains              47\n",
       "Tristan_da_Cunha          44\n",
       "Pitch_(music)             36\n",
       "Matter                    24\n",
       "Myocardial_infarction     22\n",
       "Name: title, Length: 442, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How are languages distributed across regions?\n",
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394813ba",
   "metadata": {},
   "source": [
    "* But we should make sure to switch again to HuggingFace Dataset before Tokenizing the data since the TOkenizer expects the dataset to be of type Dataset. Eitherwise we face issue like this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "058ad60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f66e64f8484338b4f40f3a3ab83740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87599 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# Tokenize the `text` column\n",
    "squad.map(lambda x : tokenizer(x[\"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262313d0",
   "metadata": {},
   "source": [
    "* TO bring the dataframe back to dataset object we use reset_format method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cbd7b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbd7888a9bd478eaeb7cc18f9865f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87599 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset back to Arrow format\n",
    "squad.reset_format()\n",
    "# Now we can tokenize!\n",
    "squad.map(lambda x : tokenizer(x[\"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc514e",
   "metadata": {},
   "source": [
    "* Using Dataset.from_pandas we can convert from Pandas DataFrame into HuggingFace Dataset.\n",
    "* Using datasets.DatasetDict({\"train\":train_dataset,\"test\":test_dataset}) we can build a DatasetDict using Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7196cadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['a'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "train_df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05507409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['a'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({\"a\": [4, 5, 6]})\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "509c241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['a'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['a'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset_dict = datasets.DatasetDict({\"train\":train_dataset,\"validation\":val_dataset})\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ec8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c238e5ac",
   "metadata": {},
   "source": [
    "* When we download a dataset, it is stored in a cache directory locally to avoid redownloading it again. Using cache_files we can get the directory names for each split. Since there is .arrow extension the data is stored as Arrow table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e33edd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e9bf1cfbbb41598654cc29eb5ad1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f499668cf2480e830036ad23741034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/866 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset allocine_dataset/allocine (download: 63.54 MiB, generated: 109.12 MiB, post-processed: Unknown size, total: 172.66 MiB) to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\allocine_dataset\\allocine\\1.0.0\\91f700d606838c22c5c370846746e60503219d0c1f16ed96bfd1fa19a73458eb...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f89a0b7174748a0fbc519210c5d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/66.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset allocine_dataset downloaded and prepared to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\allocine_dataset\\allocine\\1.0.0\\91f700d606838c22c5c370846746e60503219d0c1f16ed96bfd1fa19a73458eb. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f78fdf099ba41b79341ad470f4b9d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': [{'filename': 'C:\\\\Users\\\\loriz\\\\.cache\\\\huggingface\\\\datasets\\\\allocine_dataset\\\\allocine\\\\1.0.0\\\\91f700d606838c22c5c370846746e60503219d0c1f16ed96bfd1fa19a73458eb\\\\allocine_dataset-train.arrow'}],\n",
       " 'validation': [{'filename': 'C:\\\\Users\\\\loriz\\\\.cache\\\\huggingface\\\\datasets\\\\allocine_dataset\\\\allocine\\\\1.0.0\\\\91f700d606838c22c5c370846746e60503219d0c1f16ed96bfd1fa19a73458eb\\\\allocine_dataset-validation.arrow'}],\n",
       " 'test': [{'filename': 'C:\\\\Users\\\\loriz\\\\.cache\\\\huggingface\\\\datasets\\\\allocine_dataset\\\\allocine\\\\1.0.0\\\\91f700d606838c22c5c370846746e60503219d0c1f16ed96bfd1fa19a73458eb\\\\allocine_dataset-test.arrow'}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"allocine\")\n",
    "raw_datasets.cache_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d39e35",
   "metadata": {},
   "source": [
    "* If dataset is small we can save it into JSON or CSV format. If its huge we should save it in Arrow or Parquet format. Arrow is great if we plan to reuse the data in the future while Parquest are designed for long-term storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94179352",
   "metadata": {},
   "source": [
    "* When we save in Arrow format we use save_to_disk function. Each split and its metadata is stored in a separate directory. We should specify the directory name\n",
    "* When we reload the data, we use load_from_disk function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73a770d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets.save_to_disk(\"my-arrow-datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4fda9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 160000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "arrow_datasets_reloaded = load_from_disk(\"my-arrow-datasets\")\n",
    "arrow_datasets_reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a7c3f",
   "metadata": {},
   "source": [
    "* If we want to store the data in CSV format, we use to_csv function. We should loop over each split and save it as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0aa0943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbccf02ff1344bc79bf8165b4412af65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540eda664db6431b8aeca792c716c3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2761c287507d479d89cb168386604ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in raw_datasets.items():\n",
    "    dataset.to_csv(f\"my-dataset-{split}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b50a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5139732793baa2f3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\csv\\default-5139732793baa2f3\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e413e19a0a9541599730e3f8a28ee60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd5b8ec0eaf490b8bae7d4571b374f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\csv\\default-5139732793baa2f3\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bb6f53320943399311d8e4a097a357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 160000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the saved csv data \n",
    "data_files = {\n",
    "    \"train\": \"my-dataset-train.csv\",\n",
    "    \"validation\": \"my-dataset-validation.csv\",\n",
    "    \"test\": \"my-dataset-test.csv\",\n",
    "}\n",
    "\n",
    "csv_datasets_reloaded = load_dataset(\"csv\", data_files=data_files)\n",
    "csv_datasets_reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b49804",
   "metadata": {},
   "source": [
    "* To save data in JSON or PARQUET format, we should loop over each split and save it into a specific directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad194ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcd5272dc354e07828e6454ee1cc780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b75f67ae7a44009abe3afb5a0344f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b374e0e29fd4641bde234bff1f6ae48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save in JSON Lines format\n",
    "for split, dataset in raw_datasets.items():\n",
    "    dataset.to_json(f\"my-dataset-{split}.jsonl\")\n",
    "\n",
    "# Save in Parquet format\n",
    "for split, dataset in raw_datasets.items():\n",
    "    dataset.to_parquet(f\"my-dataset-{split}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87b8ea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c03988952e6b6818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\json\\default-c03988952e6b6818\\0.0.0\\c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3111e6277b41b6b5c8799d96d93437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98115977fc624fe4aa33c38cafee411b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\json\\default-c03988952e6b6818\\0.0.0\\c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c4b0b0349c4a69abf3f642bbad4c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f1d8613dd327676c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\parquet\\default-f1d8613dd327676c\\0.0.0\\1638526fd0e8d960534e2155dc54fdff8dce73851f21f031d2fb9c2cf757c121...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74334669607b43f9a058eda0c373b574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba944a36a444ad1bb54971b6b457948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:\\Users\\loriz\\.cache\\huggingface\\datasets\\parquet\\default-f1d8613dd327676c\\0.0.0\\1638526fd0e8d960534e2155dc54fdff8dce73851f21f031d2fb9c2cf757c121. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9669d17f984552b3d24cfcf59da84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload the saved data\n",
    "\n",
    "json_data_files = {\n",
    "    \"train\": \"my-dataset-train.jsonl\",\n",
    "    \"validation\": \"my-dataset-validation.jsonl\",\n",
    "    \"test\": \"my-dataset-test.jsonl\",\n",
    "}\n",
    "\n",
    "parquet_data_files = {\n",
    "    \"train\": \"my-dataset-train.parquet\",\n",
    "    \"validation\": \"my-dataset-validation.parquet\",\n",
    "    \"test\": \"my-dataset-test.parquet\",\n",
    "}\n",
    "\n",
    "# Reload with the `json` script\n",
    "json_datasets_reloaded = load_dataset(\"json\", data_files=json_data_files)\n",
    "# Reload with the `parquet` script\n",
    "parquet_datasets_reloaded = load_dataset(\"parquet\", data_files=parquet_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b83380d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 160000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_datasets_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b504c085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 160000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_datasets_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa28db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

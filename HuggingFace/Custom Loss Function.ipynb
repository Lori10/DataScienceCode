{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3694567",
   "metadata": {},
   "source": [
    "* In this notebook we will define a custom loss function for token classification task. We want to find named entities in python code, so we may want to weight more words like np, pd etc. Thats why we build a new loss function.\n",
    "* For each sample, we count how many key_tokens (np, pd etc) appear in that sequence (sample). That frequency will be the weight for that sample. Then we multiply the weight with the sample's loss and compute weighted mean over all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525c2f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.6.2-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.9/65.9 KB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\anaconda3\\lib\\site-packages (from accelerate) (1.8.1+cpu)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\lib\\site-packages (from accelerate) (1.22.3)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda3\\lib\\site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda3\\lib\\site-packages (from torch>=1.4.0->accelerate) (4.0.1)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lask (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lask (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lask (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lask (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lask (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lask (c:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e7421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278a58f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232a777b8afe46948f669c8de740cbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/265 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9274a1d17654f409ed99cdc8e6ccb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/771k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b0ad902d2d4e26b963080fb35e0d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d8b4f6661b4935b96d244d5b19a6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d394b0c6569040d6a2663343bfd32816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ae1adc9f014f71b212c0fa4a19f33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/938 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bfa028e6274e94be8d532423e0e221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"huggingface-course/codeparrot-ds\")\n",
    "\n",
    "# get the input id of key tokens using the pretrained Tokenizer\n",
    "keytoken_ids = []\n",
    "for keyword in [\n",
    "    \"plt\",\n",
    "    \"pd\",\n",
    "    \"sk\",\n",
    "    \"fit\",\n",
    "    \"predict\",\n",
    "    \" plt\",\n",
    "    \" pd\",\n",
    "    \" sk\",\n",
    "    \" fit\",\n",
    "    \" predict\",\n",
    "]:\n",
    "    ids = tokenizer([keyword]).input_ids[0]\n",
    "    keytoken_ids.append(ids[0])\n",
    "\n",
    "batch = tokenizer([\"import numpy as np\"], return_tensors=\"pt\")\n",
    "model = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15119ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "def keytoken_weighted_loss(inputs, logits, keytoken_ids, alpha=1.0):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduce=False)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "    # Calculate and scale weighting\n",
    "    weights = torch.stack([(inputs == kt).float() for kt in keytoken_ids]).sum(\n",
    "        axis=[0, 2]\n",
    "    )\n",
    "    weights = alpha * (1.0 + weights)\n",
    "    # Calculate weighted average\n",
    "    weighted_loss = (loss_per_sample * weights).mean()\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a68bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "logits = model(batch[\"input_ids\"]).logits\n",
    "loss = keytoken_weighted_loss(batch[\"input_ids\"], logits, keytoken_ids)\n",
    "accelerator.backward(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d13915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        input_ids = inputs.get(\"input_ids\")\n",
    "        outputs = model(input_ids)\n",
    "        loss = keytoken_weighted_loss(input_ids, outputs.logits, keytoken_ids)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc059f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the first hidden layer we must specify the nr of features/dimensions.\n",
    "* In each layer we must specify the nr of neurons, the parameters initializer (for weights and bias) and activation function.\n",
    "* We compile the model and specify the optimizer which determines how the weights updation will happen, loss function that needs to be minimized and the metrics which we will use for model evaluation.\n",
    "* Batch Size specifies the nr of trainig examples that would be processed at a time. Ex batch_size=36 means take 36 perform 1 step of Gradient Descent (forward and backward propagation) using 36 training examples than do the weights updation. Then take next 36 training examples, perform 1 step of Gradient Descent and do the weights updation using the previous weights.\n",
    "* 1 epoch means processing 1 time the entire training set using Gradient Descent. Nr of batches = total_nr_training_examples / batch_size OR by setting a specific parameter 1 epoch = specific nr of GD iterations.\n",
    "* After training for a particular nr of epochs we check if the loss and performance metric. If loss is decreasing all the time, it may still decrease if we train for more epochs, so we increase the nr of epochs to train the NN more in order to get a smaller loss (better model).\n",
    "* When we fit the model, we must specify the training set, either specify a validation set where we validate the model, or we can split the training set into training and validation set using validation_split, batch_size (how many training examples to proceeed with Gradient Descent at a time), and the nr of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('datasets/Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 13)\n",
      "(2000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Encode categorical features\n",
    "X_train = pd.get_dummies(X_train, columns=['Geography', 'Gender'])\n",
    "X_test = pd.get_dummies(X_test, columns=['Geography', 'Gender'])\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Build Artificial Neural Network (Build a base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7435 - val_loss: 0.4657 - val_accuracy: 0.7845\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.7974 - val_loss: 0.4465 - val_accuracy: 0.8005\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4402 - accuracy: 0.8050 - val_loss: 0.4331 - val_accuracy: 0.8080\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4295 - accuracy: 0.8124 - val_loss: 0.4204 - val_accuracy: 0.8135\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4142 - accuracy: 0.8198 - val_loss: 0.3989 - val_accuracy: 0.8415\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8359 - val_loss: 0.3793 - val_accuracy: 0.8470\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3777 - accuracy: 0.8416 - val_loss: 0.3661 - val_accuracy: 0.8550\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8454 - val_loss: 0.3623 - val_accuracy: 0.8485\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3618 - accuracy: 0.8472 - val_loss: 0.3521 - val_accuracy: 0.8570\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 0s 960us/step - loss: 0.3573 - accuracy: 0.8500 - val_loss: 0.3497 - val_accuracy: 0.8585\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 0s 989us/step - loss: 0.3541 - accuracy: 0.8514 - val_loss: 0.3484 - val_accuracy: 0.8585\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3517 - accuracy: 0.8549 - val_loss: 0.3456 - val_accuracy: 0.8590\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3499 - accuracy: 0.8555 - val_loss: 0.3444 - val_accuracy: 0.8580\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 0s 994us/step - loss: 0.3486 - accuracy: 0.8574 - val_loss: 0.3431 - val_accuracy: 0.8590\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3476 - accuracy: 0.8584 - val_loss: 0.3432 - val_accuracy: 0.8610\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3470 - accuracy: 0.8587 - val_loss: 0.3428 - val_accuracy: 0.8620\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8585 - val_loss: 0.3418 - val_accuracy: 0.8620\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8585 - val_loss: 0.3416 - val_accuracy: 0.8630\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3446 - accuracy: 0.8595 - val_loss: 0.3414 - val_accuracy: 0.8610\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3441 - accuracy: 0.8591 - val_loss: 0.3381 - val_accuracy: 0.8635\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 0s 990us/step - loss: 0.3433 - accuracy: 0.8616 - val_loss: 0.3392 - val_accuracy: 0.8640\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.8610 - val_loss: 0.3381 - val_accuracy: 0.8610\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8606 - val_loss: 0.3389 - val_accuracy: 0.8620\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3414 - accuracy: 0.8630 - val_loss: 0.3373 - val_accuracy: 0.8630\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8633 - val_loss: 0.3381 - val_accuracy: 0.8645\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8645 - val_loss: 0.3410 - val_accuracy: 0.8585\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8643 - val_loss: 0.3349 - val_accuracy: 0.8670\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3385 - accuracy: 0.8610 - val_loss: 0.3362 - val_accuracy: 0.8610\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 0s 971us/step - loss: 0.3377 - accuracy: 0.8630 - val_loss: 0.3381 - val_accuracy: 0.8615\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 0s 994us/step - loss: 0.3374 - accuracy: 0.8618 - val_loss: 0.3375 - val_accuracy: 0.8620\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3366 - accuracy: 0.8641 - val_loss: 0.3364 - val_accuracy: 0.8655\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3359 - accuracy: 0.8644 - val_loss: 0.3345 - val_accuracy: 0.8610\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3354 - accuracy: 0.8649 - val_loss: 0.3347 - val_accuracy: 0.8615\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8645 - val_loss: 0.3334 - val_accuracy: 0.8630\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8650 - val_loss: 0.3361 - val_accuracy: 0.8600\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8644 - val_loss: 0.3336 - val_accuracy: 0.8630\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8625 - val_loss: 0.3327 - val_accuracy: 0.8635\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.8644 - val_loss: 0.3314 - val_accuracy: 0.8630\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8649 - val_loss: 0.3322 - val_accuracy: 0.8665\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8634 - val_loss: 0.3305 - val_accuracy: 0.8655\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.8650 - val_loss: 0.3330 - val_accuracy: 0.8635\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.8656 - val_loss: 0.3311 - val_accuracy: 0.8655\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8639 - val_loss: 0.3312 - val_accuracy: 0.8635\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.8625 - val_loss: 0.3325 - val_accuracy: 0.8655\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8644 - val_loss: 0.3328 - val_accuracy: 0.8650\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8650 - val_loss: 0.3306 - val_accuracy: 0.8640\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3314 - accuracy: 0.8651 - val_loss: 0.3313 - val_accuracy: 0.8635\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8652 - val_loss: 0.3309 - val_accuracy: 0.8625\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8660 - val_loss: 0.3312 - val_accuracy: 0.8610\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8659 - val_loss: 0.3300 - val_accuracy: 0.8620\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from keras import initializers\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(6, kernel_initializer = 'he_uniform', bias_initializer=initializers.Zeros(),\n",
    "                     activation='relu', input_dim = X_train.shape[1]))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(6, kernel_initializer = 'he_uniform', bias_initializer=initializers.Zeros(),\n",
    "                     activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'glorot_uniform', bias_initializer=initializers.Zeros(),\n",
    "                     activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 16, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nr of parameters of first hidden layer : nr_neurons_current_layer * nr_features (weights) + 6*1 (bias) = 6 * 13 = 78 + 6*1 = 84 <br>\n",
    "Nr of parameters of second hidden layer : nr_neurons * nr_neurons_previous_layer - 1 (weights) + 6*1(bias) = 6 * 6 + 6 = 36 + 6 = 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAviElEQVR4nO3deZxU5Z3v8c+vqqt63+lmXxVQUERBFLeYGEWM4zIxaoxJTCYxTvaZxInOHbPdm0lyJ5MYMzHGJN5ETTQuwZi4EY0b7oCoICgIDTTN0jQ0vW9Vv/vHKZqmKbDBLqq76/t+vepVVafOqfodEvnyPM95nmPujoiISG+hdBcgIiIDkwJCRESSUkCIiEhSCggREUlKASEiIkkpIEREJCkFhEg/MLPfmtn/6eO+VWb2wff6PSKppoAQEZGkFBAiIpKUAkIyRqJr51oze93Mms3sN2Y23MweMbNGM3vczEp77H+Bma0ws3oze8rMju7x2fFmtjRx3B+BnF6/db6ZLUsc+7yZzTjEmj9rZmvMbIeZPWhmoxLbzcx+YmbbzGxX4pyOSXx2npm9mahtk5l9/ZD+wCTjKSAk03wYOBuYAvwD8Ajw78Awgv8evgxgZlOAu4CvAhXAw8BfzCxqZlHgAeAOoAy4N/G9JI49AbgN+BxQDvwSeNDMsg+mUDP7APB94FJgJLAeuDvx8TnAGYnzKAEuA+oSn/0G+Jy7FwLHAH8/mN8V2U0BIZnmZ+6+1d03Ac8CL7n7q+7eDiwAjk/sdxnwkLv/zd07gR8BucApwMlABLjR3Tvd/T7glR6/8Vngl+7+krvH3P13QHviuIPxMeA2d1+aqO96YK6ZTQA6gULgKMDcfaW7b04c1wlMM7Mid9/p7ksP8ndFAAWEZJ6tPV63JnlfkHg9iuBf7AC4exzYCIxOfLbJ917pcn2P1+OBryW6l+rNrB4YmzjuYPSuoYmglTDa3f8O/A/wc2Crmd1qZkWJXT8MnAesN7OnzWzuQf6uCKCAENmfGoK/6IGgz5/gL/lNwGZgdGLbbuN6vN4IfM/dS3o88tz9rvdYQz5Bl9UmAHe/yd1nAdMJupquTWx/xd0vBCoJusLuOcjfFQEUECL7cw/wITM7y8wiwNcIuomeB14AuoAvm1mWmf0jMKfHsb8CrjGzkxKDyflm9iEzKzzIGv4AfMrMZibGL/6ToEusysxOTHx/BGgG2oBYYozkY2ZWnOgaawBi7+HPQTKYAkIkCXd/C7gS+BmwnWBA+x/cvcPdO4B/BK4CdhKMV/ypx7GLCcYh/ifx+ZrEvgdbwxPADcD9BK2WI4DLEx8XEQTRToJuqDqCcRKAjwNVZtYAXJM4D5GDZrphkIiIJKMWhIiIJKWAEBGRpBQQIiKSlAJCRESSykp3Af1p2LBhPmHChHSXISIyaCxZsmS7u1ck+2xIBcSECRNYvHhxussQERk0zGz9/j5TF5OIiCSlgBARkaQUECIiktSQGoNIprOzk+rqatra2tJdSkrl5OQwZswYIpFIuksRkSFiyAdEdXU1hYWFTJgwgb0X3xw63J26ujqqq6uZOHFiussRkSFiyHcxtbW1UV5ePmTDAcDMKC8vH/KtJBE5vIZ8QABDOhx2y4RzFJHDKyMC4kDcna0NbTS2daa7FBGRASXjA8LM2N7YTmNbV0q+v76+nptvvvmgjzvvvPOor6/v/4JERPoo4wMCIBw2uuKpuS/G/gIiFjvwTb4efvhhSkpKUlKTiEhfDPmrmPoiKxSiKxZPyXdfd911vPPOO8ycOZNIJEJBQQEjR45k2bJlvPnmm1x00UVs3LiRtrY2vvKVr3D11VcDe5YNaWpqYv78+Zx22mk8//zzjB49mj//+c/k5uampF4Rkd0yKiC+85cVvFnTsM/2ts4YDuRGwgf9ndNGFfGtf5i+389/8IMfsHz5cpYtW8ZTTz3Fhz70IZYvX959Oeptt91GWVkZra2tnHjiiXz4wx+mvLx8r+9YvXo1d911F7/61a+49NJLuf/++7nySt1FUkRSK6MCYn/MjHiKuph6mzNnzl5zFW666SYWLFgAwMaNG1m9evU+ATFx4kRmzpwJwKxZs6iqqjostYpIZsuogNjfv/Q372qlrqmD6aOKUn65aH5+fvfrp556iscff5wXXniBvLw8zjzzzKRzGbKzs7tfh8NhWltbU1qjiAhokBqAcMiIu5OKRkRhYSGNjY1JP9u1axelpaXk5eWxatUqXnzxxf4vQETkEGVUC2J/skJBTsbiccKhgx+HOJDy8nJOPfVUjjnmGHJzcxk+fHj3Z+eeey633HILM2bMYOrUqZx88sn9+tsiIu+FuR+evvfDYfbs2d77hkErV67k6KOPPuBxDa2dVNU1c2RlAXnRwZuZfTlXEZGezGyJu89O9pm6mAi6mICUzYUQERmMFBBAViIgYjEFhIjIbgoIgpnUoBaEiEhPCgggbIaZ0RVPzWxqEZHBSAFBMFEuK2TE1IIQEemmgEgIh4wujUGIiHRTQCSkqgVxqMt9A9x44420tLT0c0UiIn2jgEgIh1Kz5LcCQkQGq8E7K6yfZYVDdLX3/02Dei73ffbZZ1NZWck999xDe3s7F198Md/5zndobm7m0ksvpbq6mlgsxg033MDWrVupqanh/e9/P8OGDePJJ5/s99pERA4kswLiketgyxtJP6qIxSnuiuPZYYyDWLBvxLEw/wf7/bjnct8LFy7kvvvu4+WXX8bdueCCC3jmmWeora1l1KhRPPTQQ0CwRlNxcTE//vGPefLJJxk2bNhBnaaISH9QF1PC7khI5TD1woULWbhwIccffzwnnHACq1atYvXq1Rx77LE8/vjjfOMb3+DZZ5+luLg4hVWIiPRNZrUgDvAv/eaWDjbsaGHK8EJyDuHGQX3h7lx//fV87nOf2+ezJUuW8PDDD3P99ddzzjnn8M1vfjMlNYiI9JVaEAm7l9vo70tdey73PW/ePG677TaampoA2LRpE9u2baOmpoa8vDyuvPJKvv71r7N06dJ9jhUROdwyqwVxAOEeS373p57Lfc+fP58rrriCuXPnAlBQUMCdd97JmjVruPbaawmFQkQiEX7xi18AcPXVVzN//nxGjhypQWoROey03HdCZyzOys0NjC7Jpbwg+133H4i03LeIHCwt990HWvJbRGRvCoiEkBlhrcckItItIwKir91og3k9pqHUVSgiA8OQD4icnBzq6ur69BdoVig0KJf8dnfq6urIyclJdykiMoQM+auYxowZQ3V1NbW1te+6b11TO7G407598P1Fm5OTw5gxY9JdhogMIUM+ICKRCBMnTuzTvtfe+xrPrq7jxX8/K8VViYgMfEO+i+lglBVE2dHSof58ERFSHBBmdq6ZvWVma8zsuiSfn2lmu8xsWeLxzb4emwpleVE6uuI0d8QOx8+JiAxoKetiMrMw8HPgbKAaeMXMHnT3N3vt+qy7n3+Ix/arsvwoADubOyjIHvK9byIiB5TKFsQcYI27r3X3DuBu4MLDcOwh2x0Qdc0dqf4pEZEBL5UBMRrY2ON9dWJbb3PN7DUze8TMph/ksZjZ1Wa22MwW9+VKpQPp2YIQEcl0qQyIZHfd6T36uxQY7+7HAT8DHjiIY4ON7re6+2x3n11RUXGotQJqQYiI9JTKgKgGxvZ4Pwao6bmDuze4e1Pi9cNAxMyG9eXYVFALQkRkj1QGxCvAZDObaGZR4HLgwZ47mNkIM7PE6zmJeur6cmwqFGRnEQmbWhAiIqTwKiZ37zKzLwKPAWHgNndfYWbXJD6/BbgE+Gcz6wJagcs9mISQ9NhU1bqbmVGWH2VHc3uqf0pEZMBL6bWciW6jh3ttu6XH6/8B/qevxx4OpXlRdjR3Hu6fFREZcDSTupfyArUgRERAAbGP0rwoO1vUghARUUD0Up4fpa5JLQgREQVEL6X5URrauuiMDb77QoiI9CcFRC/lu+dCtOhSVxHJbAqIXkq7J8tpHEJEMpsCopc9y21oHEJEMpsCopfy/GxALQgREQVEL6X5EQDNhRCRjKeA6KU0L+hi0mxqEcl0CoheIuEQRTlZakGISMZTQCRRXpDNDs2mFpEMp4BIojQvohaEiGQ8BUQSZfnZGoMQkYyngEiiLF8tCBERBUQSZfnZ7GzuJLh3kYhIZlJAJFGWH6EjFqepvSvdpYiIpI0CIokyzaYWEVFAJFOWmE2t9ZhEJJMpIJLY3YLY0awlv0UkcykgkijrXm5DASEimUsBkURZgQJCREQBkUR+NEw0HGKH7ionIhlMAZGEmVGWH2VHkwJCRDKXAmI/yvKjui+1iGQ0BcR+lOVHqdMYhIhkMAVERzP89V9gxYK9NpflR9mpgBCRDKaAiOTBmifg1Tv32qwWhIhkOgWEGUy/GNY+BS07ujeX5UdpbOuiMxZPX20iImmkgACYfhHEu2DVX7s3leYHcyHUzSQimUoBATByJpROgBUPdG8qTwSE5kKISKZSQEDSbqbS3cttaC6EiGQoBcRu0y8Gj8HKvwBQXqAWhIhkNgXEbiNmQNmk7stdS7Vgn4hkOAXEbmYw7SJY9ww011GaF9wTQgEhIplKAdHT7m6mVX8hKxyiODeigBCRjKWA6GnEsVB2RHc3U3l+VAEhIhlLAdHT7quZ1j0Dzdspy4+yqb413VWJiKSFAqK36ReDx2Hlg7z/qEpe3VDPW1sa012ViMhhl9KAMLNzzewtM1tjZtcdYL8TzSxmZpf02FZlZm+Y2TIzW5zKOvcyfDqUHwkrFvCxk8aRGwnzm0VrD9vPi4gMFCkLCDMLAz8H5gPTgI+a2bT97PdD4LEkX/N+d5/p7rNTVec+dnczVS2iJL6LS2aN4YFXa6htbD9sJYiIDASpbEHMAda4+1p37wDuBi5Mst+XgPuBbSms5eD06Gb61KkT6IzHuePF9emuSkTksEplQIwGNvZ4X53Y1s3MRgMXA7ckOd6BhWa2xMyu3t+PmNnVZrbYzBbX1tb2Q9lA5TQYNgVWLGBSRQFnHTWcO19cT1tnrH++X0RkEEhlQFiSbd7r/Y3AN9w92d+8p7r7CQRdVF8wszOS/Yi73+rus919dkVFxXsquNvubqb1z0HjVj5z+kR2NHfwp6Wb+uf7RUQGgVQGRDUwtsf7MUBNr31mA3ebWRVwCXCzmV0E4O41iedtwAKCLqvDZ9pF3d1MJ00s45jRRfxm0Vri8d4ZJyIyNKUyIF4BJpvZRDOLApcDD/bcwd0nuvsEd58A3Ad83t0fMLN8MysEMLN84BxgeQpr3Vfl0TBsKrx2NwZ89vRJvFPbzNNv91M3lojIAJeygHD3LuCLBFcnrQTucfcVZnaNmV3zLocPBxaZ2WvAy8BD7v5oqmpNygzmfBY2LYaqRZx37EhGFOXwa13yKiIZwtyHTpfJ7NmzffHifpwy0dkGP50BFUfBJx/klqff4QePrOLhL5/OtFFF/fc7IiJpYmZL9jeVQDOpDySSA3O/COuehurFfPTEceRFw/xm0bp0VyYiknIKiHcz+9OQWwrP/IjivAiXzh7Lg69tYltDW7orExFJKQXEu8kugJM/D28/Alve4FOnTqAr7tz+gibOicjQpoDoizmfhWghPPvfjC/P55xpw7njxfXs1FLgIjKEKSD6IrcU5nwGVjwA21fzL2dPoam9ix8tfCvdlYmIpEyfAsLMvmJmRRb4jZktNbNzUl3cgHLyFyArBxb9hKNGFPGJueP5w8sbeL26Pt2ViYikRF9bEJ929waCCWsVwKeAH6SsqoGooAJmXQWv/xF2rudfzp5CeX423/zzCs2uFpEhqa8BsXtdpfOA/+fur5F8raWh7ZQvAQbP/ZSinAj/ft5RLNtYz71LNr7roSIig01fA2KJmS0kCIjHEstgxFNX1gBVPBpmXgGv3gmNW7j4+NGcOKGUHzyyivoWDViLyNDS14D4J+A64ER3bwEiBN1Mmee0f4F4Fzz/M8yM7154DA1tGrAWkaGnrwExF3jL3evN7ErgP4BdqStrACubCMdeAotvg6Zajh5ZxMdPHs/vX9rAG9WZ+UciIkNTXwPiF0CLmR0H/BuwHrg9ZVUNdGdcC11t8NyNAN0D1jf8ebkGrEVkyOhrQHR5sKrfhcBP3f2nQGHqyhrghk2GGZfBK7+Gxi0U50a4fn4wYH3fkup0Vyci0i/6GhCNZnY98HHgITMLE4xDZK73/RvEOmHRTwD4xxMSA9aPrqKhrTPNxYmIvHd9DYjLgHaC+RBbCO4t/V8pq2owKJsUXNG0+P/Brk2YGTecP40dzR3cu1itCBEZ/PoUEIlQ+D1QbGbnA23unrljELudcW1wW9JFPwZgxpgSZo8v5Y4XqjQWISKDXl+X2riU4M5uHwEuBV4ys0tSWdigUDoeTvg4LPkd1G8A4BOnTKCqroWnV+vWpCIyuPW1i+l/EcyB+KS7fwKYA9yQurIGkdO/Ftye9JkfAXDu9BFUFGZz+/NV6a1LROQ96mtAhNx9W4/3dQdx7NBWPCZYo2nZ72HHOqJZIa6YM46n3q6lantzuqsTETlkff1L/lEze8zMrjKzq4CHgIdTV9Ygc9q/QigLngnG7T920jjCZtz5om4qJCKDV18Hqa8FbgVmAMcBt7r7N1JZ2KBSNBJm/xO8dhfUvUNlUQ7zjx3JPYs30tLRle7qREQOSZ+7idz9fnf/V3f/F3dfkMqiBqXTvhrcL+KpYBX0T84dT0NbFw+8WpPeukREDtEBA8LMGs2sIcmj0cwaDleRg0JBZXBr0jfuhZ1VzBpfyrSRRdz+QhXBJHQRkcHlgAHh7oXuXpTkUejuRYeryEFj9qcBh1UPY2ZcdcoEVm1p5OV1O9JdmYjIQdOVSP2pdAJUHA1vPwrABTNHUZIX4XcvVKW1LBGRQ6GA6G9T5sH656BtFzmRMJfNHstjK7ayeVdruisTETkoCoj+NnV+cEOhNU8AcOXJ44m784eXNqS5MBGRg6OA6G9jToTcMnj7MQDGluVx1lHDuevlDbR3xdJcnIhI3ykg+lsoDJPPgdULIR4EwidPGc/2pg4eXb4lzcWJiPSdAiIVpp4LrTtg48sAnHrEMCoLs3nkDQWEiAweCohUOOIDwdIbbz8CQChknD1tOE+/XUtbp7qZRGRwUECkQk4xjD+1exwCYN70EbR2xnjmbS0DLiKDgwIiVabOh9pVsGMdACdPKqcwJ4uFb25Nc2EiIn2jgEiVKfOC58SkuWhWiLOOquSJlVvpisXTWJiISN8oIFKlbBIMm9odEBB0M+1s6eTlKi29ISIDnwIilabMg6rnoC1Y1/B9UyvIzgqxcIW6mURk4FNApNLU+RDvhHeCWdV50SxOn1zBwhVbtMKriAx4CohUGjMHckt7Xc00nJpdbbyxaVcaCxMReXcKiFQKZ8GRZ+81q/qDRw8nHDIeW6FJcyIysKU0IMzsXDN7y8zWmNl1B9jvRDOLmdklB3vsgDf1XGipg+pXACjNjzJnQhmPaRxCRAa4lAWEmYWBnwPzgWnAR81s2n72+yHw2MEeOygccVZiVnXPq5mGs2ZbE+/UNqWxMBGRA0tlC2IOsMbd17p7B3A3cGGS/b4E3A9sO4RjB77cEhg3F97aExDnTB8BoG4mERnQUhkQo4GNPd5XJ7Z1M7PRwMXALQd7bI/vuNrMFpvZ4traAbqMxdT5ULsSdlYBMKoklxljitXNJCIDWioDwpJs631t543AN9y99wp2fTk22Oh+q7vPdvfZFRUVB1/l4TDl3OB51cPdm+ZNH8FrG+vZsqstTUWJiBxYKgOiGhjb4/0YoKbXPrOBu82sCrgEuNnMLurjsYNH+RFQOR1WPti9ad704QAsfFPdTCIyMKUyIF4BJpvZRDOLApcDD/bcwd0nuvsEd58A3Ad83t0f6Muxg860C2HDi9CwGYAjKwuZVJGvcQgRGbBSFhDu3gV8keDqpJXAPe6+wsyuMbNrDuXYVNV6WEy7EHBY9dfuTfOmj+DFtTuob+lIX10iIvuR0nkQ7v6wu09x9yPc/XuJbbe4e+9Badz9Kne/70DHDmqVRwWL97355+5N86aPIBZ3nli57QAHioikh2ZSH07TL4L1z0FTEAgzRhczqjiHP782eIdXRGToUkAcTtMuBI93dzOFQsYls8fy7OpaNu5oSXNxIiJ7U0AcTpXToPxIWPFA96bLTgwu1rp38cb9HCQikh4KiMPJLGhFVC2C5u0AjC7J5cwpFfxx8UbdaU5EBhQFxOE27ULwGKx6qHvT5XPGsbWhnSffGqAzwUUkIykgDrcRM6B0wl5XM33gqEoqC7O5++UN6atLRKQXBcThtrubad3T0BLcmzoSDnHp7LE8+dY2aupb01ygiEhAAZEO0y6EeBe89Uj3pstOHIsD92iwWkQGCAVEOow6AYrH7tXNNLYsj9OOHMY9r2wkFtf9qkUk/RQQ6bC7m+mdv0PbnntTXzFnHDW72njmbQ1Wi0j6KSDSZdpFEO/c60ZCH5w2nGEF2fxBg9UiMgAoINJl9CwoGr1XN1MkHOIjs8fw91XbdJ8IEUk7BUS6hEJw9AWw5nFoa+jefPmJY4nFXTOrRSTtFBDpNO1CiLXD6oXdm8aX53PqkeXc/cpG4hqsFpE0UkCk09iToHAULPntXps/Omccm+pbeXbN9vTUJSKCAiK9QiGY+wWoehY2vNS9+ZxpIyjPj3LHC1Xpq01EMp4CIt1mfwryyuGZ/9u9KZoV4qpTJvD4ym38fdXWNBYnIplMAZFu0fygFbHmcdi0tHvz1e+bxJThBfzHguU0tnWmsUARyVQKiIHgxM9CTgk886PuTdlZYX744Rlsbmjj/z76VvpqE5GMpYAYCHKK4OR/hrcegi3LuzcfP66UT50ykTteXM/L63aksUARyUQKiIHipM9BtBCe+a+9Nn993hTGlOZy3f2v09YZS1NxIpKJFBADRW4pzPlsMLO6dk+XUl40ix/84wzWbm/mpidWp7FAEck0CoiBZO4XIJILz/73XptPmzyMj8wawy+fWcuKml37OVhEpH8pIAaS/GEw+9Pwxr1Q985eH/3Hh6ZRlh/l3+57XfeuFpHDQgEx0JzyZQhFYNGP99pcnBfhuxdMZ0VNA796dl2aihORTKKAGGgKh8OsT8Jrd0P93st+zz92JOdOH8FP/vY2jy7fnKYCRSRTKCAGolO/Ahj87VvQufey3z/88AyOGV3E53+/lLt03wgRSSEFxEBUPCYIiRV/gptPglUPgwcruxbnRbjzMydxxpQKrv/TG/z8yTW4a9VXEel/CoiB6qwb4OMPQDgb7v4o/P4S2B5c5poXzeJXn5jNhTNH8V+PvcX//utKLQ0uIv1OATGQHfF++OfnYN5/wsaX4ea5sPAGaG8kEg7xk0tnctUpE7jtuXV87d7X6NTVTSLSjxQQA104EsyP+NISmHEpPH8T3HwKtOwgFDK+9Q/T+NrZU1jw6iauvn2xFvYTkX6jgBgsCirhopvhk3+Fhk3w+LcAMDO+dNZkvnfxMTz9di3zf/qs1m0SkX6hgBhsJp4Op3wRlt4OVYu6N3/spPHce81cQmZcdusL/PDRVXR0qctJRA6dAmIwet91UDIe/vLVvS6DnTW+jIe/cjqXzhrLL556h4tvfo7VWxvTV6eIDGoKiMEomgfn/wTqVu8z47ogO4sfXjKDX358Fpt3tXH+zxbx2+fW6SonETloCojB6sizYMZl8OyPYduqfT6eN30Ej371dE45opxv/+VNzv/ZIh5bsUVzJkSkzxQQg9m8/4TsAvjLVyC+73hDZWEOt111Ij+57DhaOrr43B1LOO+mRTy6fLNaFCLyrhQQg1n+sMQciRdh6W+T7mJmXHz8GB7/1/fx40uPo70zxjV3LuW8m57lkTcUFCKyfzaUuhxmz57tixcvTncZh5c73H4B1CyDL7wMRSMPuHss7vzltRpu+vtq1tY2M64sj0tmjeHDs8YwuiT38NQsIgOGmS1x99lJP1NADAF178AvToEp8+DS2/t0SCzuPPTGZu56aQMvrK3DDE47chiXzBrDvOkjyImEU1y0iAwEaQsIMzsX+CkQBn7t7j/o9fmFwP8G4kAX8FV3X5T4rApoBGJA1/5OoKeMDQgI7kL3xHdhxLEw82Nw7KWQX96nQzfuaOG+JdXct6SaTfWtFOZkMf+YEbxvSiWnHllOSV40xcWLSLqkJSDMLAy8DZwNVAOvAB919zd77FMANLu7m9kM4B53PyrxWRUw29239/U3Mzog4jFY8lt49Q6oeTW46dCUeXD8lXDkB4MlO97tK+LOi2vruHdJNY+v3EpjWxdmMGNMCWdMHsbpkys4flwJkbCGrkSGinQFxFzg2+4+L/H+egB3//4B9r/N3Y9OvK9CAXFotq6AZX+A1/8IzbWQXwETToORM2HkccEjr+yAX9EVi/Na9S6eXV3LM2/XsmxjPXGHvGiYY0YVM2NMMTPGlnDcmGLGleVhZofn3ESkX6UrIC4BznX3zyTefxw4yd2/2Gu/i4HvA5XAh9z9hcT2dcBOwIFfuvut+/mdq4GrAcaNGzdr/fr1KTmfQSnWCav/FtzjetPive9QVzwORs6AyecEiwBGDjxAvau1kxfe2c6La3fwWnU9K2oaupfyKMmLcOzoYo6oKGBCeR7jh+UzsTyf0aW5am2IDHDpCoiPAPN6BcQcd//SfvY/A/imu38w8X6Uu9eYWSXwN+BL7v7MgX5TLYh30bIDtrwOm18LHpuWwM4qyC2DWVfBiZ+B4tF9+qrOWJy3tjTyevUuXq+uZ3nNLtbVNtPcEeveJytkjCnNZVRJLsOLchhelMOIomxGFAevx5XlUV6QnZpzFZE+GRRdTIl91gEn9u5WMrNvA03u/qMD/aYC4iC5w/rn4aVfwKqHwEIw7UI46Z9h7ImH8HXO9qYO1tc1s257M+vrWlhX18zm+la2NrSzrbGNztje/38rz48yeXgBU4YXMnl4IVMqC5hYkU95fjbhkLqtRFLtQAGRlcLffQWYbGYTgU3A5cAVvQo7EngnMUh9AhAF6swsHwi5e2Pi9TnAd1NYa2YygwmnBo+d6+HlW2HpHbD8fqg4CkbP2jNuMeLYYA2oA36dUVGYTUVhNrMn7DvGEY87O1o62LKrja0Nbazb3szqrU28va2RPy3dRFN7V/e+4ZBRnh+lsiibysIcKgqyqSzK7m6JDE+8HlagIBFJlVRf5noecCPBZa63ufv3zOwaAHe/xcy+AXwC6ARagWvdfZGZTQIWJL4mC/iDu3/v3X5PLYh+0N4Er90Fbz8Gm5cFg9wQtC6GTd0zyD1yRhAaOcX98rPuzuZdbby9tZENO1rYlmhx1Da2sy3xqGtqp/fE75BBRWE2pXlRSvIi3c8leVFKciOMKA66ssaW5VGeH9Vgukgvmignh8YdGmoSYxbLgtnam5dB09Y9+5RODMJi+DHBpbTxrmBdqHhX8PAYRPIguygIk5zEc3YRFI0Olgvp41/aXbE4dc0dbG1oC1ohje1sawhaIztbOqlv6aC+pZOdLZ3sau3YpzsrLxpmXFkeY0rzGFGcTWFOhKKcCIU5WRTlRijKyaIsP8rY0jxK8iIKE8kICgjpX41bE4Pdy2Dz68HrnVX77heKBC2PWPv+vyu3DCqmBo9hU6FiSnCFVTgSPEK7n7MgKxvC0T4FirvT3BFjc30rG3a0sGFHCxt3tCaeW9je1M6u1k669rMWVWFOFuPL8xhXlse4snzGluVSUZDNsMLs4Lkgm9yoZpvL4KeAkNTrbA1aHKGsxKPH5a3xGLQ3QNsuaNv9XA+7qqF2FdS+HTy39uFWqRYKWiSRvODS3Ehe0Co59iNwwieCEOkjd6etM05DWyeNbZ3sau1ie1M7GxOBsmFHCxvqWti4s2Wf1ghAfjRMeUE2hTlZ5GdnUZCdRV40TEF28H5USS5ThxcyZXgBFYXZQYtk4yvgcRh3Up/rFEklBYQMDs3bg6BoqAnmcMQ7E89dwXOsIwiizlbobNnzqN8QdIMVjYEzvgYzr4Ss/lseJBZ3tjW2sb2xg+1N7dQ2tbO9qZ3tjR3UNbfT1NZFU3sXzR1dNLfHaG4P3rckLvkNEefi3Ff5XNZDTOlcRdzCrJrzfaKzPsaY0lyteyVppYCQoc0d1j4JT34fql8OuqjO+DrMvCLonnKHhk2wbSVsezN49jhUHg2V02H4tGA8pHfXVVcHNNYELZ3W+mCspXhsn8dMtu/cScPzv2PY8l9T1LqRLeER3BY7jzNiL3FaeAU3dF7FHbFzGJGYEzKmNJeKomyGF+Z0X701PPGs7ixJFQWEZAZ3WPMEPPWfwSTAknFQODIIhPaGPfsVjgQs+Mt/t+ziIDAKKqFxcxAKjVsIJvL3UDQaxp0M4+YGz5XTgu2NW4IQ2lUdPHZWwYoFQbfZ6Nlw6pfhqPNxC7G9voHIgn+iZMPfeH7CF1iQfxkbdrRQvbOV2sZ2OmL73vxpWEE248vzGF+Wx6QSY1bsNY5oXEwkKwsrqCRUWElW0XAixSPJKqrECkdCSKEi704BIZnFPVhi5PmberQUjg7+Mq84as86VK0797Qqtr4ZPDfXBiFQPBaKxyQeo4OrrjYthQ0vBI/GzcF3RPKhqy24WqunaAFMOhNO+RKMPWnfVkesEx74PLxxD5z6Vfjgt8EMd6e+pTNxaW8bWxva2drQRsPmtVRufYqjG19gVuwNsq2TFs8mRohCa93nj6CNKNVZ46nLn0xr2VGERhxD4fiZjBg5imEF2VoCRbopIET6k3sw7rHhxaClkl3QI1RGB69zit+9Kyoeh4e/Botvg9mfhvP+Oxjc72wNAmvzq8HYSvXiILwASifSNXkeW0ecyersY2noCtHZ1kSoaRuhlu2EW2uJttWSs2sdJY2rGdvxDqXsaT2tj1fyVPw4XonOYX3hCZQUFQYTEQuzKc+PUpof3eu5JC9CTiRMVsje/bLf2reDFYUh6N4bccyh/xnLYaOAEBmo3OHxb8NzNwYtjY7mxBhJokWSWxrMZj/yLJhyLpQf2ecxkN3a62uoe+dVWjYuI6fmJYZvf5FIvJ12y+a1rON4yo/n762T6Yw72XSSTSdRusi2DkLEWecjWe/DiYRDez0KssOU5IQ4w15lfstfOLplMV0WLCuf5Z1sKZjG65UXsqr8bDqyCsgKG0U5EYpzE4+8Pa9L8iJkZ6lLLB0UECID3XM/hVd+A8MmJ2aqz4RRMw9qULzPOtugahGsfiyYMV//7isgt4UL2Jo/lZrcKWzKncqmyATG17/IqTseoCK2hVor5147h9vbz6QtBheHF3F5+Emmhqpp8Wweip/Mg7G5rImPZgulOPt2ceVHw5TmRynLj1KSF6UsMSO+LNGiKc2LUJYXfJYTCREyIxwyzIKlWUJm3ZcYS98pIEQkOXfY/nbiJlNZkJUTzCXJyg5eQ9Ci2T2TfuuKvSc+jj8V5lwNR31o35tSuQddcEt/B2/cD53NweZwNu2F42guGEd9zli2R8eyPvtIVjOeujZjR0sHO5s72NHSQX1zJ4091ujqi6KcYA7KiOIcJuV38r72JxnZuYHa8hPZVnEKndEijGDtsHCI7lZNSV6E4twoxbkRollJxmjiseDPqmlrj0ute1x2nTcMps5/13utDDQKCBHpH7HOYK7K1hXB8ip9HWdobwruSbJjbeKxbs/rrrZgn1BWcCHBqOODx/BjoH0XXXVVtG9fR6yuitCuDUSaNtGaM5ytFXPZOuwUtpXMpCsUJeZOQ2sXW+qbKN78ArN2/pW5HS8QpYtWj5JrHXR5iCU+hSdjM3kyPpO3fCywbwstNxJiUtZ2ZthajrXVTPN3mBpfSy5tB/7jsSw2lZ7EmspzWFd+Jh2RQkIGedlZFGSHyY9mUZCTRUE0RH68ifZQDq3xLFo74rR1xmjtjNHeFac8P8q48uDS51R3vSkgRGRgisdh18ZEC+XVPY+2XXvvF4pAyVgoGR9cWVb3TjDnJd4FWbkwfi4c8YFgpv6yP0BDdTB+M+My2o+9gh35k4hsXkr2uifIXvcE0e3LAYjllhMLZePxGB6PBa0EjxGKdxCNB2HQaVE25RxJVfZRrItOYROV7OwMs7Mji7qOELVtWdR3hplkNZwffonzwy8wxrbT7lk8E5/Bi/GjKbNGRlkdo6yOkdQxwnYQtWCcqc0jNJDPLs+ngTwaPY8wMfKtjTzaKQq1UxBqJ9dbacsqoibnSKqjR1AVncS60CQ2hkaSlx3lF1fOOqT/CRQQIjJ4uAfzSLa9GfwlXzI+mLsS6tXt094IVc8FkyTfeRK2vwVYMKB//JUw9bz9L73SUANrHoeNLyWWiAmDhfc8hyPBBQGjTwhaNe9yT/fOWJz2rnjQdYUTqllCeOWfyVr5ANZYg4ey6MofQUf+KFpyRtCcM5ymSDlR7yA31kh2VyPZXQ1EOhsJdzTQ6WGayaExns3Orih1nRFq28KUxHcylfVMoposgoBpJ5v12ZOZct2iQxqvUkCIyNDXUBOs1VU4It2V7BGPQ0tdMC7RnxMXu9qh9i3Yuhy2LIeORrjgZ4f0Vem6YZCIyOFTNCrdFewrFIKCiv7/3qzsYOmXkTP6/7t70HRKERFJSgEhIiJJKSBERCQpBYSIiCSlgBARkaQUECIikpQCQkREklJAiIhIUkNqJrWZ1QLvvnZxcsOA7f1YzmCh884sOu/M0pfzHu/uSWfzDamAeC/MbPH+ppsPZTrvzKLzzizv9bzVxSQiIkkpIEREJCkFxB63pruANNF5Zxadd2Z5T+etMQgREUlKLQgREUlKASEiIkllfECY2blm9paZrTGz69JdTyqZ2W1mts3MlvfYVmZmfzOz1Ynn0nTW2N/MbKyZPWlmK81shZl9JbF9qJ93jpm9bGavJc77O4ntQ/q8dzOzsJm9amZ/TbzPlPOuMrM3zGyZmS1ObDvkc8/ogDCzMPBzYD4wDfiomU1Lb1Up9Vvg3F7brgOecPfJwBOJ90NJF/A1dz8aOBn4QuJ/46F+3u3AB9z9OGAmcK6ZnczQP+/dvgKs7PE+U84b4P3uPrPH/IdDPveMDghgDrDG3de6ewdwN3BhmmtKGXd/BtjRa/OFwO8Sr38HXHQ4a0o1d9/s7ksTrxsJ/tIYzdA/b3f3psTbSOLhDPHzBjCzMcCHgF/32Dzkz/sADvncMz0gRgMbe7yvTmzLJMPdfTMEf5kClWmuJ2XMbAJwPPASGXDeiW6WZcA24G/unhHnDdwI/BsQ77EtE84bgn8ELDSzJWZ2dWLbIZ97VgoKHEwsyTZd9zsEmVkBcD/wVXdvMEv2P/3Q4u4xYKaZlQALzOyYNJeUcmZ2PrDN3ZeY2ZlpLicdTnX3GjOrBP5mZqvey5dleguiGhjb4/0YoCZNtaTLVjMbCZB43pbmevqdmUUIwuH37v6nxOYhf967uXs98BTB+NNQP+9TgQvMrIqgy/gDZnYnQ/+8AXD3msTzNmABQTf6IZ97pgfEK8BkM5toZlHgcuDBNNd0uD0IfDLx+pPAn9NYS7+zoKnwG2Clu/+4x0dD/bwrEi0HzCwX+CCwiiF+3u5+vbuPcfcJBP89/93dr2SInzeAmeWbWeHu18A5wHLew7ln/ExqMzuPoM8yDNzm7t9Lb0WpY2Z3AWcSLAG8FfgW8ABwDzAO2AB8xN17D2QPWmZ2GvAs8AZ7+qT/nWAcYiif9wyCAckwwT8E73H375pZOUP4vHtKdDF93d3Pz4TzNrNJBK0GCIYP/uDu33sv557xASEiIslleheTiIjshwJCRESSUkCIiEhSCggREUlKASEiIkkpIEQGADM7c/fKoyIDhQJCRESSUkCIHAQzuzJxn4VlZvbLxIJ4TWb232a21MyeMLOKxL4zzexFM3vdzBbsXoffzI40s8cT92pYamZHJL6+wMzuM7NVZvZ7y4QFo2RAU0CI9JGZHQ1cRrAg2kwgBnwMyAeWuvsJwNMEM9QBbge+4e4zCGZy797+e+DniXs1nAJsTmw/Hvgqwb1JJhGsKySSNpm+mqvIwTgLmAW8kvjHfS7Bwmdx4I+Jfe4E/mRmxUCJuz+d2P474N7EWjmj3X0BgLu3ASS+72V3r068XwZMABal/KxE9kMBIdJ3BvzO3a/fa6PZDb32O9D6NQfqNmrv8TqG/vuUNFMXk0jfPQFcklhrf/e9fscT/Hd0SWKfK4BF7r4L2Glmpye2fxx42t0bgGozuyjxHdlmlnc4T0Kkr/QvFJE+cvc3zew/CO7YFQI6gS8AzcB0M1sC7CIYp4BgaeVbEgGwFvhUYvvHgV+a2XcT3/GRw3gaIn2m1VxF3iMza3L3gnTXIdLf1MUkIiJJqQUhIiJJqQUhIiJJKSBERCQpBYSIiCSlgBARkaQUECIiktT/B64x2NkFg0U0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Plot the results during training (loss and metric)\n",
    "\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8620\n",
      "Test Loss : 0.3300362825393677\n",
      "Test Accuracy : 0.8619999885559082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      1595\n",
      "           1       0.71      0.54      0.61       405\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.80      0.74      0.76      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "AUC Score : 0.7403150276713495\n"
     ]
    }
   ],
   "source": [
    "# Model Performance on TEST SET\n",
    "\n",
    "print('.')\n",
    "loss_test, accuracy_test = classifier.evaluate(X_test, y_test)\n",
    "print(f'Test Loss : {loss_test}')\n",
    "print(f'Test Accuracy : {accuracy_test}')\n",
    "\n",
    "test_pred_prob = classifier.predict(X_test)\n",
    "test_pred = np.where(test_pred_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, test_pred)\n",
    "print(f'AUC Score : {auc_score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8674\n",
      "Train Loss : 0.32794228196144104\n",
      "Train Accuracy : 0.8673750162124634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      6368\n",
      "           1       0.76      0.51      0.61      1632\n",
      "\n",
      "    accuracy                           0.87      8000\n",
      "   macro avg       0.82      0.73      0.77      8000\n",
      "weighted avg       0.86      0.87      0.86      8000\n",
      "\n",
      "AUC Score : 0.7339531604098926\n"
     ]
    }
   ],
   "source": [
    "# Model Performance on TRAINING SET\n",
    "\n",
    "print('.')\n",
    "loss_train, accuracy_train = classifier.evaluate(X_train, y_train)\n",
    "# Train Loss corresponds to the loss of last epoch\n",
    "print(f'Train Loss : {loss_train}')\n",
    "\n",
    "# Train Accuracy correspons to the accuracy of last epoch\n",
    "print(f'Train Accuracy : {accuracy_train}')\n",
    "\n",
    "train_pred_prob = classifier.predict(X_train)\n",
    "train_pred = np.where(train_pred_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_train, train_pred))\n",
    "\n",
    "auc_score_train = roc_auc_score(y_train, train_pred)\n",
    "print(f'AUC Score : {auc_score_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Train Model for more epochs, plot the results and evaluate new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will use the same classifier so we will take the weights that we got after training for 50 epochs, use those weights to train for more epochs. We are not going to start training from beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8668 - val_loss: 0.3307 - val_accuracy: 0.8635\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8661 - val_loss: 0.3311 - val_accuracy: 0.8630\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8645 - val_loss: 0.3339 - val_accuracy: 0.8605\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8651 - val_loss: 0.3300 - val_accuracy: 0.8655\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8637 - val_loss: 0.3323 - val_accuracy: 0.8625\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8658 - val_loss: 0.3337 - val_accuracy: 0.8600\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8662 - val_loss: 0.3356 - val_accuracy: 0.8595\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8636 - val_loss: 0.3304 - val_accuracy: 0.8600\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8666 - val_loss: 0.3329 - val_accuracy: 0.8595\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8652 - val_loss: 0.3332 - val_accuracy: 0.8585\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8659 - val_loss: 0.3317 - val_accuracy: 0.8605\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8649 - val_loss: 0.3331 - val_accuracy: 0.8610\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - 1s 1ms/step - loss: 0.3293 - accuracy: 0.8655 - val_loss: 0.3317 - val_accuracy: 0.8615\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8654 - val_loss: 0.3315 - val_accuracy: 0.8620\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8650 - val_loss: 0.3329 - val_accuracy: 0.8600\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8661 - val_loss: 0.3306 - val_accuracy: 0.8610\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8668 - val_loss: 0.3306 - val_accuracy: 0.8590\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8684 - val_loss: 0.3326 - val_accuracy: 0.8610\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8665 - val_loss: 0.3333 - val_accuracy: 0.8590\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8680 - val_loss: 0.3341 - val_accuracy: 0.8565\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8681 - val_loss: 0.3291 - val_accuracy: 0.8610\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8658 - val_loss: 0.3297 - val_accuracy: 0.8615\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8668 - val_loss: 0.3294 - val_accuracy: 0.8610\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8676 - val_loss: 0.3317 - val_accuracy: 0.8615\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8683 - val_loss: 0.3307 - val_accuracy: 0.8630\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8658 - val_loss: 0.3282 - val_accuracy: 0.8620\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8665 - val_loss: 0.3308 - val_accuracy: 0.8605\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8666 - val_loss: 0.3301 - val_accuracy: 0.8610\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8665 - val_loss: 0.3313 - val_accuracy: 0.8610\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8673 - val_loss: 0.3292 - val_accuracy: 0.8615\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8680 - val_loss: 0.3300 - val_accuracy: 0.8605\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8655 - val_loss: 0.3293 - val_accuracy: 0.8590\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8661 - val_loss: 0.3312 - val_accuracy: 0.8620\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8652 - val_loss: 0.3298 - val_accuracy: 0.8610\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8677 - val_loss: 0.3284 - val_accuracy: 0.8615\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8666 - val_loss: 0.3289 - val_accuracy: 0.8635\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8677 - val_loss: 0.3289 - val_accuracy: 0.8620\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8673 - val_loss: 0.3284 - val_accuracy: 0.8605\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8675 - val_loss: 0.3315 - val_accuracy: 0.8620\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8668 - val_loss: 0.3298 - val_accuracy: 0.8585\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8659 - val_loss: 0.3280 - val_accuracy: 0.8605\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8675 - val_loss: 0.3297 - val_accuracy: 0.8625\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8689 - val_loss: 0.3327 - val_accuracy: 0.8565\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8687 - val_loss: 0.3307 - val_accuracy: 0.8615\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8680 - val_loss: 0.3331 - val_accuracy: 0.8570\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8680 - val_loss: 0.3291 - val_accuracy: 0.8595\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8665 - val_loss: 0.3316 - val_accuracy: 0.8580\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8673 - val_loss: 0.3313 - val_accuracy: 0.8600\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8671 - val_loss: 0.3298 - val_accuracy: 0.8605\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8662 - val_loss: 0.3281 - val_accuracy: 0.8620\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 16, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABq2ElEQVR4nO2dZ3gc1dmw70e9Wt1VtiXLso2xLXdjMDa9hF4CJLSQQkgCIXlDQnr5SPLmTUhCEgikQEJLgDh0CM0B21Tb2JZ7lWRLlmyrW73t+X6cHWm12jIr7WpVzn1dunZ35szMGXt3nvN0UUphMBgMBoNdIsI9AYPBYDAML4zgMBgMBkNAGMFhMBgMhoAwgsNgMBgMAWEEh8FgMBgCwggOg8FgMASEERwGgx9E5O8i8lObY0tE5JxQz8lgCCdGcBgMBoMhIIzgMBhGCSISFe45GEYGRnAYRgROE9E3RWSbiDSJyMMiMk5E/iMiDSLyloikuYy/VER2ikidiLwjIie57FsgIpudxz0NxLld62IR2eo89n0RmWdzjheJyBYROSEipSLyY7f9K5znq3Pu/4xze7yI/FpEDolIvYi869x2hoiUefh3OMf5/scislpEnhCRE8BnRGSpiHzgvEaFiNwvIjEux58sIm+KSI2IHBOR74rIeBFpFpEMl3GLRKRSRKLt3LthZGEEh2EkcRVwLjADuAT4D/BdIBP9Xf8qgIjMAP4JfA3IAl4FXhKRGOdD9HngcSAd+JfzvDiPXQg8AnwRyAD+BLwoIrE25tcE3ASkAhcBXxKRy53nneKc7x+cc5oPbHUedy+wCDjVOadvAQ6b/yaXAaud13wS6AK+jv43WQ6cDXzZOYdk4C3gNWAiMB1Yo5Q6CrwDXONy3huAp5RSHTbnYRhBGMFhGEn8QSl1TCl1BFgPfKSU2qKUagOeAxY4x10LvKKUetP54LsXiEc/mE8BooH7lFIdSqnVwEaXa3wB+JNS6iOlVJdS6lGgzXmcT5RS7yiltiulHEqpbWjhtcq5+3rgLaXUP53XrVZKbRWRCOCzwJ1KqSPOa77vvCc7fKCUet55zRal1MdKqQ+VUp1KqRK04LPmcDFwVCn1a6VUq1KqQSn1kXPfo2hhgYhEAp9CC1fDKMQIDsNI4pjL+xYPn5Oc7ycCh6wdSikHUApMcu47onpX/zzk8n4q8A2nqadOROqAyc7jfCIiy0TkbaeJpx64Db3yx3mOgx4Oy0Sbyjzts0Op2xxmiMjLInLUab76uY05ALwAzBaRaWitrl4ptaGfczIMc4zgMIxGytECAAAREfRD8whQAUxybrOY4vK+FPiZUirV5S9BKfVPG9f9B/AiMFkplQI8BFjXKQXyPBxTBbR62dcEJLjcRyTazOWKe/nrB4E9QL5SagzalOdvDiilWoFn0JrRjRhtY1RjBIdhNPIMcJGInO107n4DbW56H/gA6AS+KiJRInIlsNTl2L8Atzm1BxGRRKfTO9nGdZOBGqVUq4gsBT7tsu9J4BwRucZ53QwRme/Uhh4BfiMiE0UkUkSWO30q+4A45/Wjge8D/nwtycAJoFFEZgFfctn3MjBeRL4mIrEikiwiy1z2PwZ8BrgUeMLG/RpGKEZwGEYdSqm9aHv9H9Ar+kuAS5RS7UqpduBK9AOyFu0Pedbl2E1oP8f9zv0HnGPt8GXg/4lIA/BDtACzznsY+ARaiNWgHeMFzt13AdvRvpYa4P+ACKVUvfOcf0VrS01ArygrD9yFFlgNaCH4tMscGtBmqEuAo8B+4EyX/e+hnfKbnf4RwyhFTCMng8FgFxH5L/APpdRfwz0XQ/gwgsNgMNhCRJYAb6J9NA3hno8hfBhTlcFg8IuIPIrO8fiaERoGo3EYDAaDISCMxmEwGAyGgBgVRc8yMzNVTk5OuKdhMBgMw4qPP/64Sinlnhs0OgRHTk4OmzZtCvc0DAaDYVghIoc8bTemKoPBYDAEhBEcBoPBYAgIIzgMBoPBEBCjwsfhiY6ODsrKymhtbQ33VEJKXFwc2dnZREebfjsGgyE4jFrBUVZWRnJyMjk5OfQuhDpyUEpRXV1NWVkZubm54Z6OwWAYIYxaU1VraysZGRkjVmgAiAgZGRkjXqsyGAyDy6gVHMCIFhoWo+EeDQbD4DKqBYfBYDAEwrayOp7ZWEplg93OvSMTIzjCRF1dHX/84x8DPu4Tn/gEdXV1wZ+QwWDwy3ee3c63/r2NpT9/i2se+oCH3y3mSF1LuKc16BjBESa8CY6uri6fx7366qukpqaGaFYGg8Ebxxta2Vl+guuXTeHOs/M50drBPS/v4rRf/JdL73+XJz/ymGQ9Ihm1UVXh5tvf/jYHDx5k/vz5REdHk5SUxIQJE9i6dSu7du3i8ssvp7S0lNbWVu68805uvfVWoKd8SmNjIxdeeCErVqzg/fffZ9KkSbzwwgvEx8eH+c4MhpHJun1VAHxq6RTmTErha+fMoLiqidd3HuWlwnK+99wOpmclsWxaRphnGnqM4AB+8tJOdpWfCOo5Z08cw48uOdnr/l/84hfs2LGDrVu38s4773DRRRexY8eO7rDZRx55hPT0dFpaWliyZAlXXXUVGRm9v5D79+/nn//8J3/5y1+45ppr+Pe//80NN9wQ1PswGAyatfsqyUyKZfaEMd3bcjMTuW1VHp85NYeVv3ybe9/YyzNfXD7ig1KMqWqIsHTp0l65Fr///e8pKCjglFNOobS0lP379/c5Jjc3l/nz5wOwaNEiSkpKBmm2BsPoosuhWL+/klUzsoiI6CsU4qIjueOs6WwsqWXd/qowzHBwMRoH+NQMBovExMTu9++88w5vvfUWH3zwAQkJCZxxxhkeczFiY2O730dGRtLSMvqcdAbDYFBYVkddcwerZvapMN7NtUum8NDaIn79xl5W5meOaK3DaBxhIjk5mYYGzx046+vrSUtLIyEhgT179vDhhx8O8uwMBoMra/dWEiFw+vRMr2NioiK485x8tpXV8/rOY4M4u8HHCI4wkZGRwWmnncacOXP45je/2WvfBRdcQGdnJ/PmzeMHP/gBp5xySphmOTx4ZVsFZbXN4Z6GYQTzzr5KCiankpYY43PclQsmMS0rkd+8uZcux8hty21MVWHkH//4h8ftsbGx/Oc///G4z/JjZGZmsmPHju7td911V9DnNxyoaWrnK//YzA2nTOGnl88N93QMI5Capna2ldVx59n5fsdGRUbw9XNmcMc/t/DytnIumz9pEGY4+BiNwzCs2VhSA8C2svowz8QepTXNPL/lSLinYQiA9fsrUQrOmDnW1viL5k5g1vhkfvvmPjq6HCGeXXgwgsMwrNlQrAXH7ooTtHX6Tp4MN51dDr705Md87emtNLZ1hns6Bpus3VtJWkI0cyel2BofESF847yZlFQ38+zmshDPLjyEVHCIyAUisldEDojItz3sTxGRl0SkUER2isgtLvtSRWS1iOwRkd0isty5fb6IfCgiW0Vkk4gsDeU9GIY2G0tqiI4UOroUuys8BxvYob3Twdp9lTz+QQlKhcY2/dgHh9hxROcLFVc2heQahuDicCjW7a/k9PwsIj2E4XrjnJPGUjA5ld+vOTDkFzT9IWSCQ0QigQeAC4HZwKdEZLbbsK8Au5RSBcAZwK9FxPI+/Q54TSk1CygAdju3/xL4iVJqPvBD52fDKKSprZOd5Se4pGAioAvQBUJLexev7zzK/zy9lcU/fZObH9nAD17Y2f1wDyYV9S38+o295I9NAuBgZWPQr2EIPjvLT1DV2M4ZPsJwPSEifPO8mRypa+GfHx0O0ezCRyid40uBA0qpIgAReQq4DNjlMkYByaIDnpOAGqBTRMYAK4HPACil2oF2l2Os1M0UoDyE92AYwmw+XEuXQ3H5/Ems3VtJYWk9LPd/XElVE798fQ9v76mkpaOL1IRozjt5PPOyU/jhCzvZf7yBudn2zBJ2+cmLu+hSioduXMR5v11H0RASHK0dXTy14TCfWjaF2KjIcE9nSLF233EATs8PTHAAnDY9g1OmpXP/2wc45qGablSEcP2yqYxPiRvwPAebUAqOSUCpy+cyYJnbmPuBF9EP/2TgWqWUQ0SmAZXA30SkAPgYuFMp1QR8DXhdRO5Fa0ynerq4iNwK3AowZcqUYN2TYQixobiGCIGFU9OYl51iW+P41et7eWdvJVctmsSFcyawNDed6MgIOroc3PPyLvYfD+5D/a1dx3ht51G+dcFM8rKSmJwWz8EhZKr66/oi7n1jHxNS4zn/5PHhns6QYu2+SuZMGkNWcqz/wW6ICHdfMIubHt7Aw+uL++xv73LQ0aX49oWzgjHVQSWUPg5PBkF34/H5wFZgIjAfuN+pbUQBC4EHlVILgCbA8pF8Cfi6Umoy8HXgYU8XV0r9WSm1WCm1OCsr8NVCqOlvWXWA++67j+Zmk7ewobiGOZNSSIqNYl52KgcqG/06nR0OxQdF1VwwZzw/vXwup03PJDpS/wyiIyPIzUxk/7HgCY7m9k5+9OJOZo5L5gunTwMgLytpyJiq6ps7+NO6IsCYz9ypb+lg8+E6zphhL5rKEwumpLH9J+ez72cX9vlbkpPGBweHZ3mSUAqOMmCyy+ds+pqVbgGeVZoDQDEwy3lsmVLqI+e41WhBAnAz8Kzz/b/QJrFhhxEcA6Ots4utpXUsyUkHoGByCkrBjiO+w3L3HG2gpqmd0/I8ZwDnj03mwPH+O9ndue+t/Rypa+HnV87pFlB5Y5MoqmoaEglif1lfRENrJ/HRkRw8PnS0oKHAeweq6HIon2VGBsKpeZlsP1JPfUtHSM4fSkIpODYC+SKS63R4X4c2S7lyGDgbQETGATOBIqXUUaBURGY6x51Nj2+kHFjlfH8W0Lf63zDAtaz6N7/5TX71q1+xZMkS5s2bx49+9CMAmpqauOiiiygoKGDOnDk8/fTT/P73v6e8vJwzzzyTM888M8x3ET62l9XT1unoFhzzslMB/w7y950rvOV5nktfTx+bxOGaZlo7Bh4Js6v8BA+/W8ynlk5m0dT07u15WYm0dzo4Uhve2mJVjW088l4xF82bwIIpqSHVOGqb2nnyo0M4AhCW/9leQXFV+ITZO3uPkxwXxYLJqSE5/6l5GTgUfFRUHZLzh5KQ+TiUUp0icjvwOhAJPKKU2ikitzn3PwTcA/xdRLajTVt3K6Us3e0O4Emn0ClCaycAXwB+JyJRQCtOP8aA+M+34ej2AZ+mF+PnwoW/8Lrbtaz6G2+8werVq9mwYQNKKS699FLWrVtHZWUlEydO5JVXXgF0DauUlBR+85vf8Pbbb5OZ6b1uzkhngzPxb0lOGgCZSbFMSo2n0E8i4AcHq8nNTGRique+JfnjknAoKKpsYvbEMR7H2KHLofjuc9tJS4jm7gt627Dzsnoiq6ZkJPT7GgPlwXcO0trRxdfPmcGj75fw/NYjKKVCUpzv35vL+Okru5mWmeRVaLtypK6FLz25mUmp8bx0xwrS/ZT6CDZKKdbuq+T0/EyiIkOzvp4/JZW46AjeP1jNecPMtxTSPA6l1KtKqRlKqTyl1M+c2x5yCg2UUuVKqfOUUnOVUnOUUk+4HLvV6aOYp5S6XClV69z+rlJqkVKqQCm1TCn1cSjvYTB44403eOONN1iwYAELFy5kz5497N+/n7lz5/LWW29x9913s379elJSghvpM5zZWFzD9LFJZCT1OC0LJvt2kHd2OfiouIZTfTy48scmA7B/gOaqf2w4zNbSOr5/0WxSE3o/9FwFR7g4Wt/K4x8e4sqF2Uwfm0ReViINrZ1UNbb7P7gfWPf60jZ7QZAvF+pxlQ1t3PnUlkE36+091sCxE22smhE6/2hsVCRLctK7teDhhKlVBT41g8FAKcV3vvMdvvjFL/bZ9/HHH/Pqq6/yne98h/POO48f/vCHYZjh0KLLodh0qJaL503stX1ediqvbj9KTVO7xxXqtiP1NLZ1cqoX/wZATmYCEQIHBhBZ1d7p4A9r9rMsN53L5k/ssz8tMYa0hOiwRlb94b/7UUp111/Kc8kv6U8EkT8s/8l/tlfwk0tP7vb3eOPFwnIKJqdy3ZLJfOfZ7dz31j6+cd5Mn8cEk3f2VgKwagCOcTucmpfJ/722h8qGtpD8u4cKU3IkTLiWVT///PN55JFHaGzUD6sjR45w/PhxysvLSUhI4IYbbuCuu+5i8+bNfY4djew5eoKG1k6W5qb12j7PmXvhTet4/4Be2Z0yLd3jftCrwJyMgUVWvbytnOMNbXz5zOlezT7hjKw6XN3M0xtLuXbJZCana1PZtBBrQQcrG5mYEkdtcwfvHvC9wj5Y2cjO8hNcWjCR65ZM5pOLsvnDfw+wZrfvUuUfH6oJWh2wtXsrmTU+OeQ5FqdN19rvcNM6jOAIE65l1d98800+/elPs3z5cubOncvVV19NQ0MD27dvZ+nSpcyfP5+f/exnfP/73wfg1ltv5cILLxy1zvGNxZZ/o7cAmDspBRHvBQ/fP1jNSRPG9DJveWL62KR+m6qUUvx1fTH5Y5NYme9ds8nLSgpbEuB9a/YRGSHccVZPtdcJY+JCFllV29ROdVM7158ylTFxUby01be56qXCckTg4nkTEBHuuXwOJ08cw9ef3srh6r7RhCdaO/jec9u56sEP+NrTWwOuIOBOa0cXHx+q5XQf/3/B4uSJKSTHRfHBweHlIDemqjDiXlb9zjvv7PU5Ly+P888/v89xd9xxB3fccUdI5zaU2VhSy6TUeLLTejuWk+OimZaZ6PHB0drRxaZDtdx4ylS/588fl8R/9xynvdNBTFRga6sPi2rYVXGCX1w516eTOW9sIk9vaqe+uYOUhOiArjEQDhxv4PktR/jcilzGjelZTUdECNOyEkOicRRV6XPOGp/MhXMm8Mr2Clo7uoiL7pulrpTipcJyluWmd88vLjqSh25YxMV/eJfbnviYZ798avexb+46xg+e38HxhlZuOS2H57cc4d439vHYZ/sfpb+1tI72LgfLcv078QdKZIRwyrQM3h9mgsNoHIZhhVKKDSU13dFU7hRkp1JYVt+nUOHmQ7W0dzp8OsYt8scm0+lQHKoOfPX98LtFZCTGcPkC330Yuh3kVYOrdfz2zf3ER0dy26o8j3MKheCwtJi8rCQuKZhIY1snb+857nHsrooTHKxs6q4/ZjE5PYH7rp3P7qMn+P7zO6hsaOMrT27mC49tIjUhmme/fBo/uuRkbluVx7p9ld1Vk/uDpdEu9vIdCzan5WVwuKaZ0prhk5tlBIdhWFFS3UxlQxtLcj37KQomp1LZ0MbRE717tL9/sJrICGGpl+Ncme50FAdaeqSospG3dh/nhlOmelxNu9ItOIJc3sQXO8vreWV7BZ9dkevRXJeXlcSRupag5LC4crCqkZjICLLT4lmel0FmUqzX6KqXCiuIihAunDOhz74zZ43ljrPyWf1xGSt/+TZv7jrGXefN4KU7VjDfmWtx0/IcspJjuff1vf2ucryhpIaZ45L7RMOFilOd7Wj9mau2HK7lr+uLKAljbovFqBYcoSqfPZQYafdorQaX5ngWAJaDvLC0t5/j/YNVzMtOITnOv1koLysJEQJ2kD/yXjExkRHcYMMclp0WT3SkDGpk1W/e2MeYuCg+7yx94k7e2ESUIuhJdwePN5GTmUBUZASREcJFc8ezZvdxGlp7Z0xbZqoV+Zle8zbuPDufi+ZNYOHUVF6983RuPyu/V4RWfEwkd5w1nQ0lNazfH7jDubPLweZDtSzJHRxtAyB/bBKZSbG858NB3t7p4PZ/bOGnr+zmjHvf4YL71nHfW/vYc/REWH7jo1ZwxMXFUV1dPeIerK4opaiuriYubvhV3/TGhpIa0hNjurUCd06aMIaoCOnl52ho7aCwrN6WmQr0w2dyWkJADvLapnZWf1zG5Qsm2gqrjIqMICcjND4FT2w+XMuaPcf54qo8UuI9C89pmaGJrCqqbOzWsAAunT+Rtk4Hb7lFSW0+XMeRuhYumdc3hNkiMkJ44NMLefLzp3j9Dly3ZAqTUuO5943AtY5dFSdoau9i6SD4NyxEhFPztJ/D23yf3niYI3Ut/PLqefzw4tmMiYvmd2v2c8F96znz3nd44O0Dg/osG7XO8ezsbMrKyqisrAz3VEJKXFwc2dnZ4Z5G0NhYUsPiqWleHc9x0ZHMmpBMoYvg2FhSQ5dDea1P5Yn8sUkB5XL8Y8NhWjscfG6F59W8J/KyktgXxLpYvrj39b1kJsXwmVNzvI7JzUxEhKBGVrV3OjhU08wn5vaYnhZMTmNSajwvbi3nigU9382XCsuJiYrgvJPHDeiaMVER3HlOPt9avY03dh0LqOLvBj8abag4NS+DFwvLOVjZyHRnEqpFS3sXf/jvAZbkpPHJRdmICJ9dkUtlQxtv7jrGC1uP8KvX9zJ3UgorQ5iw6MqoFRzR0dHk5uaGexqGADh2opVD1c1+I6PmZafyUmE5DociIkJ470A1MVERLJxq3/wwfVwS6/dX0dnl8Ftyor3TwaPvl3B6fiYzxyf7HOtK3thE3tp9jI4uh9+EuIHw/oEq3j9YzQ8unk1irPeffHxMJJNS44OqcRyu0cUcp2Uldm+LiBAuLpjAw+uLqW1qJy0xhi6H4uVtFZw1c6wtc6I/rlwwiYfeOchv3tjHOSeNs929b2NJDZPT4we9R8ZpTj/Heweq+wiOJz48xPGGNv7wqQW9FkxZybF8etkUrlo0iRX/9zYPv1s8aIJj1JqqDMOPDV7yN9wpyE6hobWTEmdU1PsHq1k0Jc2vw9qV/LHJtHc5OGwj0sVK+PvcisAWInlZSXQ6lK1r9BelFL96Yy8TUuK4fpn/vjTBjqyyfDiupiqAS+ZNpNOh+M+OowB8WFRNVWMbl3rItO8PUZERfO3cGew91sDLNsucKKXYWFLr9/sVCianJ5CdFt8nEbCxrZMH1x7k9PxMlk3zbD6LjYrk5uVTWbuvkn3HBkeDNYLDMGzYWFJDQkwkJ/spPthTKbeemqZ2dlec6M7QtUu+zcgq14S/QOsaDUZk1dt7j7PlcB13nJVvS3DqxMSmgKrY+sISQq4aB8DJE8cwLSuRl5w1qV4qLCcxJpKzZgWvxMfFcycwa3wy9721n84uh6251jS1s8xG5F0oODUvgw+LanrV5Xrk3WJqmtr9llv59LKpxEVH8Mi7fRtGhQIjOAzDhg3FNSyamubXdJQ/Nom46AgKy+q6QxyXB+DfgJ7aTf78HFbC3+dW5AZcVdZ6mIYqssrhUNz7+j6mpCfwycX2/Fx5YxNp6ejqE87cXw4eb2LcmNg+5icR4ZJ5E/mwuJrSmmb+s+Mo5508PiCt0B8REcI3zptJcVUT/95c5nf8huJawL9GGypOm55JfUsHu8p1z/u65nb+sq6Ic2eP6w439kZ6YgxXLczm2S1HqGrs26Y22BjB4YN39h7n3tf3hnsaBnSnur3HGmz9qKMiI5gzMYVtZfW8f7CKxJjI7jBduyTFRjEpNZ79flT/h98tIt1Gwp8nkuOiGZscG7LIqv/sOMquihN87Zx82z6UYEdWHXSLqHLlkoKJKAXfeXY79S0dXFLQN3djoJxz0lgKJqfyu7f209bpOz9lY0kNmUkx5GYm+hwXKpZP61236s/rimhs7+Qb582wdfxnV+TS3ungiQ8PhWyOFkZw+GBDcQ33v31g2NWRGYk8tO4gSsGZM+2ZMgomp7KzvJ71+6tYNi2jX85nXbPK+wO0rLaZNXuOc/2yKf1eKYcqW7vLofjNm3uZPjaJy+bbF2p5Y51aUBDMZ0opDlY29jFTWUwfm8TsCWN490AVqQnRrJgefMeuiPCNc2dQXt/Ki35qZG0ormFJTnpI+pHYYeyYOKaPTeK9g9VUNrTxt/dKuHjeRGaNt9cXJi8ribNmjeXxDw4FPYnTHSM4fHDHWflMSU/ge89v97taGcr8Z3uF35aqQ5m9Rxv4y7oiPrkom7k2NYd52Sm0dmjntt38DXeskFxvvSBWf6zNH9csnuxxvx3yxiZy8HhjQDH4Sin2H2vgwXcOOiNu+pqVnt9yhIOVTfzPuTNsRxQBZCXFkhwXFRTzWWVjGw2tnV41DqDbGX7hnPEB1wWzy+n5mcwan8zD7xZ7/Xc+UtfCkboWW5UFQslpeRlsLK7hd2v20d7l4Ovn5Ps/yIXPr8iluqndr5AcKEZw+CA+JpJ7Lp9DUWUTf1pbFO7p9AulFN/69zb+77U94Z5Kv3A4O+klx0XxnU+cZPu4AqeDHLy3ifVH/rgk2ry0eO1yKP61qYwV0zO7S5P3h7ysJE60dlLd5LuBklKK7WX1/Or1PZz9m7Wc+9t1/N9re/j+8ztY9vM1XP3g+/x1fRGlNc20dzq4b80+Tp44hgsC7CwnIkHTgoq8RFS5cvn8Scwcl8z1y/xn2/cXK+9hz9EG3jvg2XrgreLyYLM8L5OWji6e+PAwVy2c1F3u3v7xGZw0YQx/fbcopAmBozaPwy6rZmRx8bwJ3P/2AS4pmBg2+2d/qW/poKG1k4+Kamhu7yQhZnj9lz+9qZSPD9Xyq6vnBdQ+dGpGAinx0UQInGRT1XfHykw+UNnQp8XreweqOFLXwrcvnOXpUNu4RlZleqgf5XAo7luzn39/XMaRuhZnNdV0bjk1h/NOHk9dcwev7TjKazuP8tNXdvPTV3aTnRZPWW0Lf/vMHCIC0DZc5/Sen54ZdrCET56XDG+A8SlxvP71lQO+lj8umz+RX762l4ffLWKFh3LpG0pqSI6N4qQJ/W8XHAxOmZaOCERFCF89OzBtA7SQ/PyKXL7xr0LW768KWV6H0Ths8MOLZxMbGcH3n98+7EqUlNbo1XJ7l4MPi4aXr6ayoY3/fXU3y3LTuXpRYNnvIsJVC7P59LIp/Xp4AkzPcraR9VCz6umNpaQmRA84y9lfZNVL28r5/Zr9TMtK5JdXz2PT987hyc+fwo3Lcxg3Jo6Z45O585x8/nPn6bxz1xl858JZZCXHcuGc8Zwxs38PjWlZiRw90UpjW2e/7wt0RFV8dCQTxoS/5E1sVCQ3LZ/K23srOeAhW39jcQ0Lp6YFZNYLBakJMVxWMJGvnDm9T9sAu1xSMJGxybH8NYShuUZw2GDsmDi+deEs3jtQzQshth0Gm9LanuQyqx3mcOFnr+yipaOLn13hu7eFN354yWy+eX7/NYKUBB315O4gr2lq541dR7lyQTaxUQMLH52YEk9cdIRH01Bnl4P73trPrPHJPHrLUq5ZPJk0H1pXTmYiX1yVx3NfPo0Hb1jUbyevpQUNtNHUwcpGcjMT+y24g831y6YQGxXBw++W9Npe09TO/uONYfdvWNx33QK+do69SCpPxERFcNPyqazbV8neo6FJCDSCwybXL53C/Mmp3PPyLuqafdujhxJWjf+lOems3Td8BMe7+6t4fms5X1qV57WY3WCQP65vZNWzm8vo6FJcu6T/TnGLiAhhWqZnn8Kzm49QXKUd3IP58J1uRVYFQXD4MlMNNhlJsVy5cBLPbi6jxsWntLHEWZ9qiAiOYBDqhEAjOGwSESH8/Iq51LV0hNXRXNXYxgNvH6DDRiYswOGaZlITorm4YAKHqpuHRC1/f7R2dPH957eTk5HAl8+cHta55I9N5sCxhm4TpVKKZzaVMn9yakB1qXyRNzap25Fs0dbZxe/W7KcgO4VzZw/MHBYoU9ITiYyQARU7bO3o4khdC3leQnHDxWdPy6Wt08GTLrkOG4triImKCDjXZyhjJQQ+tzU0CYFGcATA7Ilj+OxpOfxzQymbSvrfYay/dHQ5+PKTm/nV63vZfKjW1jGltS1MTkvoLofxzl7PndeGEn98+wAl1c389PK5Qc0k7g/TxybR1N5FRb0Oed1SWse+Y41B0TYs8rISKa1t7hV7/9SGUo7UtfCN82YOel5BTFQEU9MTBqRxFFc1oZTviKpwkD8umTNmZvHoB4e6Q+w3lNQwPzt1wGbHocZnV+QSExnB9hCE4odUcIjIBSKyV0QOiMi3PexPEZGXRKRQRHaKyC0u+1JFZLWI7BGR3SKy3GXfHc7z7hSRX4byHtz52jkzmJgSx3ef226r/k0w+eVre7oL/dlttlNW08zk9HimZiSSm5k45M1VBysbeXDtQS6fP9Fj9Mtg416z6ukNpSTERPZpbToQpmUloRTdRRlb2ru4/+0DLM1N5/Qw/RtMy+qrBbnyyraKPgX5XOmOqBpiggPgcytyqWps48Wt5TS1dbKz/MSIMlNZ5GUlsfF759hOmg2EkAkOEYkEHgAuBGYDnxKR2W7DvgLsUkoVAGcAvxYRy/v3O+A1pdQsoADY7TzvmcBlwDyl1MnAvaG6B08kxkbxrQtmse9YI1tL6wbtuq9sq+Av64u5ftkUYqIibAkOh0NRVtvSnWewakYWHxRVhzyrdCA8/sEhRITvXeT+VQkP+eOsyKoGGts6eWlbORfNnUCSj/LkgWKZcyzT0GMflFDZ0MZdYdA2XOdUXNXkMflxz9ET3PnUFr7xTKFXk+nB402IMCTD11dMz2TmOJ0QuPlwLV0O5bUV8XAnPiY0WlQoNY6lwAGlVJFSqh14Cv3Ad0UByaJ/HUlADdApImOAlcDDAEqpdqVUnfOYLwG/UEq1OfcNuu3FWgVuGCRz1YHjDXxrdSELpqTyo0tOJicjgSIbguN4QxvtXQ4mp/UIjtYOR7fWMtRw7clgp4veYJCeGENGYgwHjjfyyrZymtu7uG5p8MxU0Ls+VENrBw+uPcjKGVlhXQXnZSXR3uWgrLZ3yXeHQ/HdZ7cTIUJFfWt3WXR3DlY2MjElPmQProEgInzudJ0Q+Ps1+4kQWDglNdzTGlaEUnBMAkpdPpc5t7lyP3ASUA5sB+5USjmAaUAl8DcR2SIifxURa+kyAzhdRD4SkbUissTTxUXkVhHZJCKbgt3lLyMpluljk7qzTUNJU1sntz2xmbjoSP54/UJioiLIzUy0pXFYobiWxnHKtAxioiKGrLkq2D0ZgoVVs+rpjaVMH5vEwinB7Uft2kDp4XeLqWvu4C6bhe1CRZ6XyKqnNpay+XAdP71iDtMyE/nres8ZykMtosqdSwsmkpkUw8aSWmZPHBOU5lGjiVAKDk86tvs37HxgKzARmA/c79Q2ooCFwINKqQVAE2D5SKKANOAU4JvAM+JBn1dK/VkptVgptTgrK/jZk0ty0tl0qNZrHaNgYJULKaps5A+fWsCElHhAx+sfrm72e+3D1U7BkaaPi4+JZFluul8HeVFlo9cHQigJRU+GYJA/LontZfVsPlzHtYsnh8R8lDc2icLSOh5eX8z5J4/r7ikSLrq1IJfIqsqGNn7xn92cMi2dTy7K5pYVuWwrq2eTW6CGw6EoqmwachFVrsRFR3LjKTkALM0ZvP7iI4VQCo4ywFWnz0ZrFq7cAjyrNAeAYmCW89gypdRHznGr0YLEOq91zAbAAQy6B3FpbhoNrZ3sOXoiZNd45L0SXtlWwTfPn8Wp03tucVpmIu1dDsrr+tZQcqW0thkRmOQUHABnzBzLwcqm7vwOdzq7HHz1qS389JXdg+rDae90hKQnQzCwugFGRwpXLAy8fLod8rISKaluprG9k/8513fTnsEgzWmiK6rq0Th++souWjsc3QmZVy2cRGpCNH9d37uO29ETrbR0dA1Jx7grN5wyhYLsFC6aF/xy7iOdUAqOjUC+iOQ6Hd7XAS+6jTkMnA0gIuOAmUCRUuooUCoi1i/obGCX8/3zwFnOY2YAMcDAC+sEyNJcvUoJlblq8+Fa/vfV3Zw3exy3rZrWa1+uczXoz89RWtPCuOS4XmGGVljuuv2ezVWPfXCIHUdOECG6rMZgsX5/Zch6MgwUK7LqnJPGeawnFQysYnaXFkwMWn7IQJmWlditcazfX8kLW8u57Yy8boGQEBPF9cum8MauYxyq7vkuDuWIKlcykmJ54fYVLAqgF71BEzLBoZTqBG4HXkdHRD2jlNopIreJyG3OYfcAp4rIdmANcLdSyhICdwBPisg2tBnr587tjwDTRGQH2uF+swpDAalJqfFMSo1nY4m9fIpAscI+772moI9pxIpUKfYTZ19a28wUt8qteVmJZKfFeyw/UlHfwq/f2MuqGVlctTCblwp1uOJg8GJhOSnxoenJMFDmZKdQkJ3CF1ZO8z+4n5yal8HJE8fwP+eG17fhilUlt7Wjix88v4PczES+fEZerzE3Lc8hKkL423sl3dusXh5D2VRlGBghLZWqlHoVeNVt20Mu78uB87wcuxVY7GF7O3BDUCfaT5bkpPHugWqUUkG3e++sqKdgcipjPDjtMpNiSI6N8usgL6tp5hS3kuIiwqoZWTy/5QjtnY5ePRB+/OJOOh2Key6bQ2VjK//6uIxXtlVwTRCT3TzR0t7Fm7uOcdn8iSHryTAQxsRF88LtK0J6jbysJF756ukhvUag5GUl8VRTKT97ZTcl1c088bllfcyI48bEccm8iTyzqZSvnzuDlPhoDlY2kRwbNWQi4wzBZ+j9SocRS3LTqWpso6Tas7+gv7R3Oth7tIGTJ3ougSAi5GYl+jRVtXV2UXGitTsU15VVM7Joau9i06EeM9tbu47x+s5j3HlOPlMyElg4JY3pY5N4elPozVVr9hyjub2LS+YNrWiq0Y4VWfX4h4e4YsEkrwmZn12RS3N7F09tOAxoU9W0sUlhy0ExhB4jOAbAMmecvS0/x9Z/wvHdts6771gDHV2KOZO89wbwF5JbXteKUnhsMnTq9EyiI6U7LLe5vZMfvbiTGeOS+MLp2hwjIly7eDIfH6r1WIbaFYdD8cd3DvDMplJq/TQk8sRLheVkJceybJqJbhlKWD6KlPhovneR9yZacyalsHxaBo++X0JHl2PIR1QZBo4RHAMgLyuJ9MQY/4mASsGLd8CHf7R13p3luraMN40DtOA4UtfiNQvcipqa7BJRZZEUG8Xiqemsdfo57ntrP0fqWvj5FXN79ea+YuEkoiPFr5P86U2l/PK1vXxr9TYW/+wtPv2XD3n8gxKOnejb0tSdE60dvL23kovmTgh7LwRDb7LTEjhlWjo/vXyO36CAz5+eS3l9K6s/LuPoidYh7xg3DAwjOAaAiLB4apr/TOy2BnB0QO0h3+Oc7Cw/QVJsFFN9tCTNzUxEKV391hNW8p975zqLM2ZmsedoA2/vOc7D7xbzqaWTWezWNjMzKZZzThrHvzdrf4gnXJstvXT7Cr60Ko9jJ1r5wQs7WfbzNVz5x/d4c9cxr/fxxs5jtHc6hlzSnwEiI4Snbl1uqy7XmTPHMi0zkV86K0cbjWNkYwTHAFmam87hmmbfq+tmZ+e9OnuCY8eRemZPHOOzB4OVoOWtEF1pTQsxkRGMS/bcfW2Vszvcl5/cTFpCNHdf4Lnh0bVLJlPT1M6a3Z4f/q7NluZmp3DX+TNZ840zeOt/VnLXeTOob+ngi49vYvXHZR6Pf7GwnOy0eBZMTvV6r4ahT0SEcMuKXGqbO4ChH4prGBhGcAwQq56QT62j2bmvvgwcvgsMdjkUuypOMMeHmQogJ1NrEt78HKU1zUxKi/cqfGaOS2b8mDhaOrr4/kWzSU3w3Fnu9PwsJqbE8ZQHc5WvZkvTxyZz+1n5vHzH6Zw2PZO7/lXIEx/2FpzVjW28d6CKSwomGkfqCMBKCIyMEK+armFkYATHAJk9YQyJMZHdXcQ8Ymkcjk44ccTn+YoqG2ntcHDyRO+OcYDkuGgyk2IprvKcy1Fa20y2B/+GhYhw86k5XLlwEpf5MBNFRghXL57Muv2VHHHJVLfbbCk+JpK/3LSYs2eN5fvP7+Bhl45kr+44SpdDmWiqEUJCTBT/c+4MLi2YOOJ6Wxh6YwTHAImKjGChPz+HJTjAr59jZ7kuYTJnkv9uZNMyEymp8uLjqGn2GFHlypfOyOM318z3u9r/5KJsAFZv6jE3BdJsKS46kgdvWMSFc8Zzz8u7eODtA4COppo+NomTJgyNTGnDwLlpeQ6/vXZ+uKdhCDFGcASBJTnp7D3WQL3TvuvO3uKSng+1JR7HWOw4Uk9sVIQt52Jupudcjsa2TmqbOzzmcPSHyekJrJieyTObSnE4FAeOB95sKSYqgj98agGXz5/Ir17fy/ef387GkhoumWfMVAbDcMMIjiCwNDcdpeiVUGfR1NbJhzv20aki6FJCV02Jz3PtKK/npAljiIr0/1+Tm5VIVWMbJ1p7CywrFNe93MhAuHbJZI7UtfDugSq+99x24qMjA262FBUZwa+vmc+1iyfzxIeHUYohWZvKYDD4JqQlR0YL8yenEh0pbCip4eyTxvXa99s39zGtrZbW+DTq2oXYI/vxVo1JKcXO8hNcarMtqVWzqqSqqVcZbitEd3K6dx9HoJw7exxpCdF8a/U2jp5o5edXzO1XSYnICOF/r5xLRlIMlQ1t3cX9DAbD8MFoHEEgLjqSedmpffwcO8vr+dv7JcxL7yI+dSxlaixtlcVezqJDaBtaO235N0D7OKBvZFVP8l/wNI7YqEiuWJDN0ROtLJqaxnUDqF8VESF864JZ/OqTBUGbn8FgGDyM4AgSS3PT2V5WT0u7Drftcii++9wO0hKimTWmncjETFoSs4lv8pzPANpMBfgNxbWYkpGASN9cjrLaFpJio0hNCG5Xs5uWT2Vedgr/e+VcnzkmBoNhZGMER5BYmpNOp0OxpVSXWX/yo0MUltbxg4tnE9VaC/FpJI7LI0PVcKzacyn2HUfqiYoQZoy3Z76JjYokOy3eo8aRnRYfdKdzTmYiL96+ghnjTBSUwTCaMYIjSCycmoYIbCyu5diJVn712l5WTM/U/oqWGkjIYFKuzs7evK3Q4zl2lJ8gf1xyQDHwuZlJfQWHhz4cBoPBECyM4AgSKfHRzBo/hg0l1fy/l3fR1uXgp5fPQZTSmeMJGUx0Co7i/bv6HK+UYueReub4SfxzZ5qzSq7Vy0opRWlNi98cDoPBYOgvRnAEkWW56XxYVMMr2yq448zp5GQmQls9qC5IyEDScgCoKz9AZ1fvooHHTrRR3dRu2zFukZuZSGNbJ5WNbQBUNbbT0tHlsSquwWAwBAMjOILIkpx0uhyKvKxEbrX6hFt1qhIyIGkcXRGxZHYepbCsrtexO444HeM+enB4oqeNrDZXWVVxjcZhMBhChREcQWTF9EwWTU3jl1cX9PgprHIjCRkgAqlTmCrHu3thWOwor0cETprQP8FRUu0UHDVGcBgMhtBiBEcQSUmI5t9fOpVFU9N6NnYLDl1FNzI9h/zYat7Z5yY4jpxgWmYiCTGB5WROTI0nJjKiu/RIWa0uRBjMHA6DwWBwxQiOUOOqcQCk5TBJHWdbWT1VTr8EwK7y+oD9G6AzsadmJHSbqg5XN5OZFEt8jKlOajAYQoMRHKGmj+CYSmxXI2No5N39VYDuS1Fe32o78c8d1/7jpbXNQS01YjAYDO4YwRFqmqshMhZinNVuU6cCMDehjnf2Hgd6SqmfHKBj3CI3K5FD1c10OZQWHMZMZTAYQkhIBYeIXCAie0XkgIh828P+FBF5SUQKRWSniNzisi9VRFaLyB4R2S0iy92OvUtElIjYq+sdLpqrtX/DyuJO04LjnAmtrNtfhcOhukuNnDyhfxrHtMxE2rscHK5ppryu1WgcBoMhpIRMcIhIJPAAcCEwG/iUiLjX4f4KsEspVQCcAfxaRKwepr8DXlNKzQIKgN0u554MnAscDtX8g0ZzbY+ZCro1jiUp9dQ0tbP9SD07y08wOT2elH7Wlsp19h9//2AVXQ5lNA6DwRBSQqlxLAUOKKWKlFLtwFPAZW5jFJAsuqhSElADdIrIGGAl8DCAUqpdKVXnctxvgW85jx/aWBqHRXwqxKUyPboaEVi7r9KZMd4/bQN6QnKtEF9TbsRgMISSUAqOSUCpy+cy5zZX7gdOAsqB7cCdSikHMA2oBP4mIltE5K8ikgggIpcCR5RSngs+ORGRW0Vkk4hsqqys9DU0tDRX99Y4ANKmEtdUxrxJKbyyrYKS6uZ+RVRZZCbFkBwbxQcHtSPe5HAYDIZQYktwiMi/ReQiEQlE0HgqzequIZwPbAUmAvOB+53aRhSwEHhQKbUAaAK+LSIJwPeAH/q7uFLqz0qpxUqpxVlZ3lonDQKeBEfqVKg9xKqZY9l7rAGA2QHWqHJFRMjNSqShrZPICGFCStxAZmwwGAw+sSsIHgQ+DewXkV+IyCwbx5QBrt1+stGahSu3AM8qzQGgGJjlPLZMKfWRc9xqtCDJA3KBQhEpcZ5zs4iMt3kfg4ujC1pqPWoc1B1mVX7P9oGYqqDHXDUhJc5W21mDwWDoL7aeMEqpt5RS16Mf3iXAmyLyvojcIiLePLobgXwRyXU6vK8DXnQbcxg4G0BExgEzgSKl1FGgVERmOsedjXaib1dKjVVK5SilctACZqFz/NCjpQ5QnjWOrjbmp7aSEh/NuDGx/WrD6oolOIxj3GAwhBrb9S1EJAO4AbgR2AI8CawAbkZHRPVCKdUpIrcDrwORwCNKqZ0icptz/0PAPcDfRWQ72rR1t1KqynmKO4AnnUKnCK2dDC/ck/8s0nIBiKw/zK0rp9HZNXAfvyU4jGPcYDCEGluCQ0SeRZuQHgcuUUpVOHc9LSKbvB2nlHoVeNVt20Mu78uB87wcuxVY7GteTq1j6OJWp6obZy4HdYf4ypnLCQbdGofJ4TAYDCHGrsZxv1Lqv552KKV8PtxHNd40jhSn66f2UNAuNWNcMmfOzOKMmWODdk6DwWDwhF0v6kkikmp9EJE0EflyaKY0hNj5HLz4VVD9NCV5ExzRcZA8AeqCJzjioiP52y1LBxTWazAMOp1t8OaPoKnK/1jDkMGu4PiCawKeUqoW+EJIZjSUqCmCzY/CR3/q3/GW4IhP77svdSrUlvR7agbDiKDkXXjvPij8Z7hnYggAu4IjwpndDXSXE4nxMX5kcNrXYeYn4I3vweEPAz++pQai4iHGg8M6LSeopiqDYVhydJt+LV4X3nkYAsKu4HgdeEZEzhaRs4B/Aq+FblpDhIgIuPxB7ZP412eg8XhgxzfX9DVTWaRNhRNHoLN9wNM0GIYtFc4CEIfeh66O8M7FYBu7guNu4L/Al9CFCdega0WNfOJT4dondE7G6s9CV6f9Y93rVLmSOhVQUF/qeb/BMBqoKISYZGhvhCObwz0bg03sJgA6lFIPKqWuVkpdpZT6k1KqK9STGzKMnwOX3Acl62HNT+wf56nciIVLSK7BMCpprdd+xEU3A2LMVcMIu7Wq8p29MXaJSJH1F+rJDSkKroPFn4P3fw+73BPgveBTcOToV+PnMIxWjm7Xr9POgPFzoXhtWKdjsI9dU9Xf0PWqOoEzgcfQyYCjiwv+FyYtgue/DFX7/Y/3JTiSJ0BEtImsMoxeKpyO8QkFkLsSSjdAR0t452SwhV3BEa+UWgOIUuqQUurHwFmhm9YQJSoWrnkMomLg6Rt9O7a7OrQq7k1wRERC6mRjqhptVBTC2l/1PzdoJFFRqBdQSWMhdxV0tUHpR/6PM4Qdu4Kj1VlSfb+I3C4iVwCjM0U5JRvO+xlU7oZjO7yPa6nVr96c49BdXt0wivjgAXj7p1BuHMFUFGptA2DqcoiIMn6OYYJdwfE1IAH4KrAIXezw5hDNaegzcYF+rT7gfYy3rHFX0qYajWM0oRQUOe34m0efpbcX7c1QtbdHcMQmazNwkfFzDAf8Cg5nst81SqlGpVSZUuoWZ2RVPzLiRgjpuSCRULXP+xhvBQ5dScvR49oagjo9wxClaj80HoW4VNi+Gtqbwj2j8HFsJygHjJ/Xsy13pdbEWuvDNy+DLfwKDmfY7SLXzPFRT1Ssfuj7FBw1+tWXxpHqDMk15qrRgRU1dMH/QnsD7Hw+rNMJK0ediX+WxgHaz6EcOhnQMKSxa6raArwgIjeKyJXWXygnNuTJnOE7ssquqQqMuWq0ULwWUqZAwacgYzpsGcXmqopCXcMtJbtnW/YSiIozfo5hgF3BkQ5UoyOpLnH+XRyqSQ0LMvO1j8PhJQ/SV4FDi9Qc/Wo0jpGPwwHF62HaShCBBTfC4Q+g0ofWOpKxHOOuhozoOJi8zAiOYYDdzPFbPPx9NtSTG9JkzoCudu/aQnMNxCTpH4M3EtL1GKNxjHyOboPWOm2OAa11RESNTq2jsx2O7eptprKYtkpHKzZWDv68DLaxmzn+NxF5xP0v1JMb0mTm69cqL5FVvupUWYg4q+SWBHNmhqGItYrOOV2/Jo+DGRfocuKjrdBl5R5wdMCEeX33WYK1ZP3gzsmdj/7Uv4rYowS7pqqXgVecf2uAMUBjqCY1LMicoV+9Och9ZY27kpaj6/UYRjbFayFzJoyZ0LNt4U3QVAn7Rn6h6V5YFXEnzO+7b8J8XfQwnOaqjlZ4/buw+bHwzWGIY6t1rFLq366fReSfwFshmdFwISFdC4aBCo7MGfrB0dUBkdHBnaNhaNDZDoc+gPmf7r0972xInqjNVbMvDc/cwoFVETctt+++yCjIOS28dauO7wJHpwkL9oFdjcOdfGBKMCcyLPEVWRWI4HB0Ggf5SKZ8M3Q06TwFVyKjtDA58BbUHwnP3MJBRaE2U0V4efzkrtJaeF2YWg5YzaVa6sJz/WGAXR9Hg4icsP6Al9A9OkY3mfk+NA4fTZx6ncOPycsw/ClaCwjkrOi7b8ENOndh6z8GfVphwdGlnd/jPfg3LCwBGy4/h2VKMxqHV+xGVSUrpca4/M1wN1+NSjJnQHNVT7KfRWebTvDyFYrbfY7p+tUIjpFL8Tq9wvYULJGeq1fYWx7TIbsjneoD0NHsOaLKYuxsvegKV/mRbsFRF57rDwPsahxXiEiKy+dUEbncxnEXiMheETkgIt/2sD9FRF4SkUIR2Skit7hdY7WI7BGR3SKy3Ln9V85t20TkORFJtXMPISHDGVnlXrOqO2vchuCIS4GkcfbKtBuGH+3NULahJ1rIEwtvgrrDo6MfRYWHjHF3IiK01lG8bvCrCHd1wFFn8VJjqvKKXR/Hj5RS3XqbUqoO+JGvA5w1rh4ALgRmA58Skdluw74C7FJKFQBnAL8WkRjnvt8BrymlZgEFwG7n9jeBOUqpecA+4Ds27yH4dIfkumkLLTbKjfQ6zwyjcYxUSj/U+T6+BMesi3X9qtGQ01FRqLPDLROtN3JXQkO570KioaBqny7vnp6nrQaBtIoeRdgVHJ7G+YvIWgocUEoVKaXagaeAy9zGKCDZWQcrCagBOkVkDLASeBhAKdXuFFYopd5QSln/mx8C2YSL1KkQGdP3oW+n3Igrlq9kJPZoeO/3sOfVcM8ifBSv04l+U07xPiY6DuZdC7tf6mv2HKpsfsx+J0xXKgph3BwdGOALS9AWvWP/3KUb4d3fBj4nV6zmUpafpe3EwM4XTk5UwONXQNnHQT+1XcGxSUR+IyJ5IjJNRH4L+JvNJMA1LKLMuc2V+4GTgHJgO3CnUsoBTAMqgb+JyBYR+auIJHq4xmeB/3i6uIjcKiKbRGRTZWWIslAjo/TKxN3MFLDgmKHtqdZxI4UtT8CbP4D3fhfumYSPorW6BlNsku9x867RmsnB/w7OvAbKO/8Hr34zsBW5UvrB7Cnxz530aTAmOzAH+Xv3wVs/0eam/lJRCNEJkL1Yfx7Ofo7idfr75E9I9wO7guMOoB14GngGaEGbmXzhqZqu+5L6fGArMBGYD9zv1DaigIXAg0qpBUAT0MtHIiLfQ7eyfdLTxZVSf1ZKLVZKLc7KyvIz1QHgKbIqUMGR4cXkNZypKIRXvgESoXtLjwbHrzstdVCxtW8YricmLoDYlOHh5+hshxNHdIn4A2/aP662BNrqffs3LEScfo719r47ji6nkFHQcNT+nNypKNT9z63f7nD2cxSvhfg0GDc36Ke2G1XVpJT6tvUgVkp9Vynlr5lAGTDZ5XM2WrNw5RbgWaU5ABQDs5zHlimlrD6Sq9GCBAARuRldZPF6pcJs38mcoX8QrqucQJzj4N1XMlxpqdWtdRMy4Jwf6xyGmoPhntXgc+g9HWprR3BEROpw3eFQ4K++lO41YCDZ1XYc465MW6X9hb46bbqe2wqfPeH+mLGJw6FzOMbP00ErMHw1DqX0dynndO/5MgPAblTVm67RSyKSJiKv+zlsI5AvIrlOh/d1gLtR9DBwtvOc44CZQJFS6ihQKiIznePOBnY5x12AziG5VCnVbGf+ISUzXyfw1RT3bGuu1qtHu5ngKZO1w3AkRFY5HPDsrfrHe81jOjsaeh4ao4nidRAVr01VdshdqRchQz0Z1CrKOWkx7Hvd/gq/olD7e8a6x8h4warrZUeYuo45UWbv/O7UFEF7oxZscal623DN5agt1gLezqKlH9gVRZmWcxpAKVWLn57jTgf27cDr6IioZ5RSO0XkNhG5zTnsHuBUEdmOroF1t1KqyrnvDuBJEdmGNmP93Ln9fiAZeFNEtorIQzbvITR40hbsFDh0JSJCm6tGgsax/l7Y/4ZuVpS9GLJmQmSsNtmMNorXaad4VKy98daPfKhrHZZgO+v7oLrsJy9WFMLYk+z/e6RM0n1L7Jjvitdqnwj0X+NwbS5laRzD1VRl5cBMOyMkp7frNXGIyBSl1GEAEcmhr7+iD0qpV4FX3bY95PK+HDjPy7FbgcUetk+3OefBwZN/wm65EVcy86F8S/DmFQ4OvAVv/1xHCC35vN4WGQ3jZo8+jaPxuK55NO8a+8eMPQkSs7TgWHhj6OY2UOoOQUS0FnRTTtVhxCu+3ru3hjtK6e/AjAsCu1buKtj2tO9ablYtsIU3wdYn+1++paJQR0lmzdLVe2H4ahzF6yB5gha8IcCuxvE94F0ReVxEHgfWEs78iaFE3Bj9H+RqZuqv4Kg7pCtzDkfqDsO/P6/NEBff1/shMqFAR9OMxHBjb1haQyCmgm6HcBgS3wKhtgRSJ2u/zMIbtYnn0Hu+j2mo0FUW7Po3LHJXavORr0VV2UbobNE+kTGTtOO+P1QU6u9vVIyOrIqIHp4+Dsu/kbvStzAfAHad46+hV/970ZFV30BHVhmgb2RVc01gpirQTnblGJ4l1jta4ZmbdGTLtY9DTELv/RMK9A+w7nBYpjdgWut16GnlXvvHHFij/VyeSof7IneVjlYKhdnyyGYdruqta6Vdag/pHCaA2ZdB7BjY7Cd5sWyjfu2P4ADf5UeK1+novamnwZiJ/RMclkZkhQqLaHOVXVPV0R1a2x4KAv/4Li2kfSWdDhC7zvHPo30Q33D+PQ78OGSzGm5kzoDq/T1fGrsFDnudYxhHVr12t14RXvEQZOT13W89LIajucrhgOe+BBv+DP+8zp7pYv9bukHT3Kv0qjwQQuXnaDiq5//ub+Dg2wM7V90hSHMKjphEmHs17Hre+0O2uQZe/772QQQqOBLSdXisLz9H8Tp93vhU7Rfpj4+jvlRHA7rOLz7Vvqlqx2pY+3/Q1hD4tYNNt7Z7esguYddUdSewBDiklDoTWIBO0DOA9nO01uumPB0tOvw0UI3DskUOt8iqLU/Cx3+HFf8Dsy7yPGbsySCRw1NwvHcf7H2lp57U81/2vaqsPQT//hyMOxnO+1ng10vLgZQpwc3n6OqAf31GP9TiUnVBxf7S1qhNsZbGAbp/emerfni64+iCZ7+gtahrH/PdStkbuaugdIP+bbnT3qS1GWt1PWaSFpKBJgFaGeOuGmJcin1TlZW71TQEHotFa3Wvk9TQdb6wKzhalVKtACISq5Tagw6dNUBvbaE7hyNAjSMmUYflVg8jwVFRCK/8j/7RnvV97+Oi47TDcbgJjqJ34L/3wJyr4ZLfw7n3wJ6XtTDxhGWyU8qzyc4OIjDNSnwboEnJ4s0fwuEP4NI/wPzrdQmYpir/x3nCCsVNcxEcExfoJDNPOR1rf6mDJi78P5i0qH/XzF2l60eVftR33+EPtCPb0tTGTKJfSYAVhXpxM+7knm1xqfY1Dut3399/12DR1an9TdNCZ6YC+4KjzJnH8Tw6DPYF+ibzjV5ce2oEmjXuSsb04WOqck3yu/oR/yaZCQU9DXKGA/VlsPqz+v/2kt/pB/opX4KTr4Q1/8+zzf0/39Rhx1f+SZfM6C+5q/RK9+j2/p/DYsez8OEfYekXtUlp4Y36QVv4VP/OZ4XipuX0bBPR560o7L042PeGNt8UfBoW3UK/mbpc5394Mt8VrdVObKsW2BhnVaNA/RwVhTp0PDq+Z1sgPo5uwRFmjaOiUNfXClH+hoVd5/gVSqk6pdSPgR+giw9eHsJ5DS/GTNJRGFX7ByY4rI6CQ8HB5gv3JL/ETP/HTCiAxmMDKwcxWHS2wTM36zDPa5/oqTMlolftGflaqLiGfW5+TP+d/g2YeeHArh9I4psvju+BF26H7KVw3k/1trEn6YTEzY/173tWW6JfU3N6b5/7SZ2vYznJa0u0iWrcHLjo1wOL7olN1tqKp3+P4nUweanW2EH7OKB/gsO9uVQgPo6hYqoqfke/5gwBweGKUmqtUupFZ8VbAzgT+KYHQXDk69DDhorgzi/YuCf52WE4Ochf+w4c2QSXP9BjhrSITdLCpLMV/uUULuVb4JW7dLLVmd8b+PXHTIDMmQPzc7Q1wDM3anPZNY/qEFOLhTdB1d6eSKdAqDsEMUl9fXgJ6bpv+vZnerRRpbRfoz8mO3dyV+qosFaXarUttfr75Lq6HjNRvwbiIG84pn0w7o77uFSt+dkRsENGcKzTPsWkENbno/89xw3uWD01+uvjsM4BQ9tc5SnJzw7j5wAy9AVH4VOw6WE49as61NQTWTPgsgf0g/flr2m/RmIWXPVw4FFU3shdqZPaOvuxPlMKXvgKVB+Eq//W8zC1OPkKiE6EzY8Gfm4rFNeTBrHgRr1Cf/g8bZa88s8DM9m5krtSZ6kfer9nW8m7gOoddho7Rgu2QJIALRNqH8GRossJtfspy+dw9PTgCafg6GyDwx+G3EwF9jPHDf7IzIcd/3bWyZGeWjcBncMSHPtDVipgQPhK8vNHbLIO1fUnOCr3woa/wAW/sF8Oes092jxkV/vxRvVBeOlr2lR0ts8+ZXDy5VB2O3xwv7axf/Y1eyY7u+SuhI1/gSMfaxu/O0pp/4EnraGtUTeQOvf/eQ7JjE2GOVdq/8cFv9Cf7VJ3qLd/w5Wc0/W+qn2w8pswM8AscV9kL9X13IrX9Zy3eJ02Ebs63UUCTwK0yuGMd6siG5+qX1vrfZfFb63TOVgQXsFRukFrwoMgOIzGESwy8wGlm8nEp/avBn7yeL1aGoohuf6S/OxgZZD7Yu0v9QPTTkVU0D6T9ffCpr8FPh93StbrDORLfmfv/++cn2in7xUPDVxouZOzAhDvfo4PH4R3/lc362mp7f3n6IDlt2utyRsLb9Zh4zuetT8npXon/7kTEaFDkJd9Cc4IcmGJ6DiYvKy3+a5oLUxZ3tsMB4EnAVYU6r46cWN6b7dbIde1+VY4o6qsRMic00J+KaNxBAtLWzjyMaT0symhiOf+HkMBK8nvun94TvKzw4QCrZV5y6xvrtFd8ECbDybO939OSxAFwwRmrRZTJvseZxEZBZfcN/DreiIhXWcxF6+DM+7uve/QB7pB1syL4Lon++d4zl6sQ6Q3PwaLbrZ3THO1FjbeNA6Aky7Wf6Fg2iod0dZUpU1IVXthwfV9x6VMggN77J+3otBzqLDdCrmWfyM6MbwaR/E6HRptCbwQYjSOYJGeB4iON++Pf8PCiqwaSnQn+X3de5KfHfw5yLf/S//7RUTZFwRWRdPK3drGOxAaK/WPzn0FGy5yV0LZBmh36R7QcEwn86VOgSse7H+0koh2kh/ZBMd22TvGiqhK86JxhBrLl1GyXue5gGezTCBJgM012gTrKaPdMlX5C8m1BEfWzPAJjrZG/X85CGYqMIIjeMQk6MJvMEDBka/9JG2NwZnXQKnY5kzyWwln+kjys4MV7uhJKCilV78T5muThF3BYY1zdOoaPQOhqVI7uYcKuWfodrKlH+rPXR2w+ha9Ar72iYGvLOddp/0zW/zUmbLoDsUNk+CYMF87v4vW6rDTuNS+IbQQWBKgN8c4BGCqsgTHLC2IAmmnGywOf6B/AyGsT+WKERzBxDJXDVTjAKg+MPD5DJSWWnj6BohPh6seGXjv4oR0XU7DUyJg+Rbt11h4kzNZcIe9H2BFoVbPrfcDYagJjimn9E58e+vHOiv40t/3znDuL4kZWoMsfMqetmZljYewlIVPIqN0IcPidc7udis8R7EFkgRomTrHexIcqfrVrqkqayageiKsBpPitbok/ORlg3I5IziCidWbI9A6VZ7OEW7B4XDAs1/sSfILVlz4hHmeH/BbHtfd8uZerQVHZ4v/8iuWmeGkS3Ul2gELjqrgRkYNlNgk3WWvaC3sfF5HcC35QmA9Pvyx8Eb9oNvziv+xtYcgIdN3hFGoyV2p2xDXHfa+ug4kCbCiUPu0Ej0s9uw2c2qp0RFflkANh7mqaK2OPAtGzowNjOAIJlay2EA0jvRpOjIi3A7y9b+G/a/rJL/JNluf2mHCfC0UXRO52pth+2od4hqX4mLS8hOBZZXkmDjfKZAGWNJkqGkcoB3CFVt1Xkb2Ejj/534PCez8Z+oHpx1zla9Q3MHCtQaTt3pMVt6KnVwOTxnjFhGR2jRmR+NIyIAkZ1PUxuP+rxtMmmv0byHE9alcMYIjmATDVBUdp23I4RQcJe/B2z+DudcEluRnB8uW7Bpuu+sFXV9ngbPrXeYMvYLzp0FY+8cX6PMes2ne8oSjSz8AhprgyF2pcwSi4uCTjwbfcR8RqQsfHnzbf7+U2kPhc4xbZJ2ktZ6kcT2/N3esJEB/2eNtjXoR46vUu5U97gsrStD67gx2SO7B/6ITIQfHMQ5GcASXSYv0w3agkj/ckVU7n9O1fy65L/gdxCZ4cJBvfkxHpU09VX+OjNI1juwIjjHZ2swwoUAnP/VX4DbXAGroCY7spboO1LWP95hggs3cTwJKl5HxhqNL96wIl2PcIiICVt2tEwy9fTe7kwDLfJ/r6HZA9XwnPWGn0GFztfYDdguOQTRVnajQJXIypve/+nA/MIIjmMQkwFV/GbjzMDNfr4QcjuDMK1CObtPqu1U4Lpgkj9erRcusVLUfDr+vbe3u7WaPbvP9b1BR2LNaHGgtLOvHPpR8HKA1jKv+2iNUQ0FGnhbAvooqnjiio3bCrXEALLsVln7B95gxE/1rHN0RVfO9j7FT6NAyVcWl6mCGwRIcVp+V9kYdZeetJ3sIMIJjKJI5Q6+e60sH/9qOLr0SC7RTWyBMKOh5wG95XPdBKPh03zFtJ6CuxPM53M0MGdN1+Yl+Cw6nXTpxbP+OH8509zpf711QW+XUw61x2MVOJ8CKQq0lJI/3PsZOMydLcEREaDPaYAmON36gQ7Uv/YOuejyIGMExFOluDBUGc1X1Aeho9q2+D5QJBVC5RzvIt/4DZlwAyePcxvjI+QCnj0T1CI6ISG3e6m/PD8suPdRMVYPFtFU6OshbqRdPDZyGMnaSAC2N1Zc51l8zp65Obcqy/JqJWYPj49i+Gj56EJbdpiMRBxkjOIYi4aySaz2oQ61xqC5497d6dbbwpr5jxs72nUHePU8XAWfVwuqPiW+omqoGC3+9zmsP6Wg/u+VYwo2/JMCOVr148fc9j0/17eNordPX6RYcg6BxHN8DL35V52yce09or+WFkAoOEblARPaKyAER+baH/Ski8pKIFIrIThG5xWVfqoisFpE9IrJbRJY7t6eLyJsist/5mhbKewgLCRkQnxY+wREVp/tBhAor/PGD+yFpPEw/p++YqFitfvsSHIlZkDyhZ9uEAmhvgNriwOfUVKkFVX+qGo8ExkzUOUTeeoDUHdJ+kEG0ow8If0mAx3dpn40/wRGXoutzedNcuvvvOHO3ErNCKzhaT+ik3JgE+OTfw1YeJ2SCQ0QigQeAC4HZwKdEZLbbsK8Au5RSBcAZwK9FxPqX+B3wmlJqFlAA7HZu/zawRimVD6xxfh5ZiIQvsqqiUGclDzRL3BepU/QDuqtdF6nzdi1Lg/DUSMeTmaHbvLU18Dk1VWr7dMQoVsJzV+p+F54ekrUlw8dMBf6TAO1q1v6yx90bt4VScFh9VmqKPPdZGURC+StZChxQShU5uwU+Bbh3xlFAsogIkATUAJ0iMgZYiW5Ri1KqXSlV5zzmMsDqQPMoI7WFbWa+Ltxnp1Ab6C/2C7fr6rz9RSn9oA6lmQr0w966xoIbvI8bXwDNVX2dnB2tcHx333lmnaRrL/XHQd5UNXr9Gxa5K3WEzpHNfff5Kqc+FPGXBFhRqLUJf/fkL3vcvXFbYqb2Efpr/tQfNv4Vdr8I5/zIc5+VQSSUgmMS4BoWVObc5sr9wElAObAduFMp5QCmAZXA30Rki4j8VUSs2NBxSqkKAOerxzAYEblVRDaJyKbKyjC3c+wPMy/Sq5k3f+h/rFLw/Jd1hNJT1/c/c7W2BNrqvWfSBpOlt+p4fF8d4ryF2B7fpX0k7vOMioFxs/uXQd5UOXr9Gxbe/BwdLbq16nDSOPwlAVoh5/7ylFybOXnCXeOwssdDoXXsfE43m/LVZ2WQCKXg8PQ/4m5zOB/YCkwE5gP3O7WNKGAh8KBSagHQRIAmKaXUn5VSi5VSi7OyhuFKctYnYOkX4cM/+m+28959sOdlXceopQ5Wf7Z/GdS+KoUGm5MuhjO/63uMt3azvswMVqivnT7RrgzFciODTUK6fjC5+znqnOu/4aRx+EoC7OrQRTTtfM+7TVW1nvd78nFA8COrHA69IJq8LPhJuf0glIKjDHANwchGaxau3AI8qzQHgGJglvPYMqXUR85xq9GCBOCYiEwAcL4OcmGYQeS8n+rM4Rdu15EUnihaq5vbnHwlfOJXcPFvdb+CNT8J/HoVhdpBPNbdFRUmYhK1r8c9xLaiUBc19FQ3afw8HVZa7ydr2J3Gyp7V4mgmd5VuQdrR0rOtOxQ3JyxT6jfekgCr9um+L74S/yy6S6v70DiiEyA6Xn+2tNZgaxy1xTrwYzAWdTYIpeDYCOSLSK7T4X0d8KLbmMPA2QAiMg6YCRQppY4CpSJihfacDVjNFl4ErJZlNwMvhO4WwkxUDFzzqI6geOZGaGvovb/+iNYuMvJ1EpAIzP8ULP4svP972OX+z+2HikLtJ4iOC949DBTXZEGLikLtCPe08rIeBoH4OdqbdOTMaDdVgRYcXW1Q+lHPtnA3cOovKZM8+zg8hXJ7w18zp+aa3rXpQlV2pLsu2yCYkW0QMsGhlOoEbgdeR0dEPaOU2ikit4nIbc5h9wCnish2dITU3UopS8e7A3hSRLahzVhWWdBfAOeKyH7gXOfnkcuYiXD1Izox74Wv9JhgOtvhXzfrDPNrn+hd6vqCX+i6Nc9/2X5kllI9D+ShxIR5OjKm0flD7OqAYzu9r7zGnazzDQJJBBztyX+uTF2utc4iF3NVbYkO0U4a5/WwIcmYSdB4rG+AScU2rSVkTPd/Dn/NnJqre7dRSAiRxlFRqAM/BjlD3Bsh7TmulHoVeNVt20Mu78uB87wcuxVY7GF7NU4tZdSQuxLO/hG89SP44AE49XZ443tQtlFXTM1yqxIaFau3/2klPH0jfGGN/7pTDUf1l32IqMLdWPM5WqjzPbrNDF7mGZOgc1AC0TiM4OghNlkvOlwd5HWHdAj1ELCtB0R3EmBF7/pxFYXal+OpCZQ70fEQGevbVOWqccQkaKd8sH0cFYVaaETFBve8/WQUB60PM067E2ZdrKOsXvsubPgzLL9d97DwROpkuPphnR374lf9O4sHI2O8P7j35rAzT2/Norwx2rPG3cldCeWbex6Wwy0U16I7CdDFz+FwaG00kO+5rwq57oIDgp893m0NGDq/TSM4hgsicPkfIT0XPnwAppwK5/zY9zF5Z8FZ34Mdq+Hjv/seW1EIiK73NJSIT9VOWUsQVBT6NzNMKNCrzIZj9q7RLTiMxgFoP4dy6GRAGBoNnPqDpyTAmiKdqxLIQ9hXhVx3Hwfo75G/kHhHF7x0Z08zMl+cOKIDPozgMPSLuBS47h+68c4n/2av/MOKb+jIrPd+51vrqCjUD+NwtgX1hquD3I6Zodu8ZdPPYQmOBKNxALrTYFScNle11OmH5nBzjIPnJMCj/XAye2vm1NWh8576CI6x/k1VNUV6MbfpEf/XH4LWACM4hhtZM7Xm4asUtCsREbDkczqcr+Rd7+MCVd8Hk/Hz9Pxbau2VfB8/V7/aNVc1VWq79CD1ax7yRMfpfIGitT2huMPRVOUpCbCiECJjIGuW/fN4M1V1Z42n995ux1Rl1aHz1QPFoqJQB3yMO9n/2EHCCI7RwEmX6h+Rt77STdW698dQFRxWiO2uF7SZwd9qMS4F0nIDExzGv9Gbaavg+E4o26Q/D0eNw1MSYEWhzlMKpDigN1NVi1u5EYvELF0qx1eVZktwVB/w3xu9olDnM4WisVo/MYJjNBCToNuD7nrB88rp6NBThXthhQhvfsz52cY8PeV/eKOpcnQ2cPJFrrP98ZYn9Otw1DigdxJgf53M3po5WVnj8e4aR5b2EbV4yTYHHSYf4Qxq9ad1DEb9uAAxgmO0sPBGnfOx/V9993UnF80d3DnZJWksJE/UBRztmhkmFGgzi68fr4UpcNiXCfO1llq+WT84rUS44YZrEmB9mf4+BJqrZDVzcvcRutepsrCTPV61Hyafoo/1JTgaj0ND+ZBJ/LMwgmO0MGG+FgzWqt2Vim06zt3dVjuUsFZcds0ME9zCeH1hTFV9iYyCqafp98MxosrCNQmw28k8P7BzxKdqDcK9coNXweEne1wpbarKmgE5p+vaYN4CV6zvr9E4DGFBBBbcpJ3g5Vt77xtiMeIesQSB3dXieJuRVQ6H0Ti8YVXLHa5mKuidBFhRqPvbB+pk9pY97l7g0MKf4Giq0ufKnKH/jU8c0VFWnrB6ywwxa4ARHKOJeZ/UWbCuTvLWE1BzcBgIjoLer/5IytIPDXch6U5rnS7RbgRHX6Y5/RzD0TFu4ZoEWFGooxKtgoR28dbMqbkGYpL7ZnP7q5BrOcYz82HaGfq9t86LR7fpQI8hZio0gmM0EZ8Gsy+Dbf/qqX5qJSAFqr4PNrkrYf4NMOsS+8eMOxkq9/oeY7LGvZN1EpzyZZhzdbhn0n+sJMD6sp4eHIHirZmTe50qi4R0HT7b5CUJsFtwzND9aMZM6l0bzJUhag0wgmO0sfBGnbRkVc61TDlDzPnWh9hkuPwBSA6g0F7mDKje7zss0srwNRpHXyIi4IL/hYnzwz2T/mMlAZZv0eaq/jyEvTVz8lRuBHRyakKGd1NV1X6Iitc93EV0BFvJ+r7f05ZaXWByqBUexQiO0cfUFVr1tZzkFYWQND6wB/JwIWO6jiSrL/U+xpQbGdlYSYD7XtOf+yM4uk1Vdb23exMc4Ow97sVUVb1ffzet/va5K/W5ju/qPa7bGmA0DkO4iYjQfb4PvQvVB4esKhwUMp1Vg32Vlrd+3KaJ08jESgKsPqA/98fJ7NNU5U1w+Mger9qn/RsW3S173cxVVkTV+KH3+zSCYzQy/3ptg93wF109d8QLjn3exzRV6n+L+LTBmZNh8LHMVel5EDcm8ONjxwDiwVRV60fj8CA4Olp1teFMl1YIKZO0BuKez1FRqIVe0tDTho3gGI2MmQD558HGv+j49CFoQw0KiZnazFDtS+Oo1D9+O70ZDMMTy0He3+95RIQWOK6mqs423co1wcuCw5upquYgoHprHKC1jpL3oKuzZ9sQtgYYwTFaWXgTOJxf0iH65RwwInpl59NUVWn8GyMdKyR3IN9zK3vcorvAoQ9TVdsJrWG44hpR5UruSi2Iyrfoz+1NeuwQDVoxgmO0kn+ers8UnwYpk8M9m9CROcOPqarKhOKOdIIhOOJTe/s4vGWNW1iLkWY3raPK6Wtx7yeT4+bnOLoDUEN2UWcEx2glMhou/AWc8d3h1xI0EDKn65IT3jq4NR03GsdIJ/88WHQLTFne/3O4Fzr0KzicwRbuDZ2q9umFmnsJ/8QMGDfXRXAMzVIjFkZwjGbmXAXLbg33LEKLZRKwomrcMeVGRj5jJsAl9wWeMe5KH1OVTY3D3c/hHlHlSu5KOPyRNm9VbNWNxSzH/hDDCA7DyMZXSG5Hq7ZDG1OVwR/uzZz8Cg4PFXKV0t9Dd/+GxbRV0NUGpR85HePzhqw1wAgOw8gmLUf3PfDk57Dsz6YXh8Ef7s2cLOe4tzBuT4UOT5RDR5N3jWPKcl2E8cCbcHz3kDVTgREchpFOZLSuB+RJcJiscYNd4lKhs0WH4YLWOOJS9PfLEzGJuqyIq+DwFlHVfY0xMGkhbH5cRzyOVsEhIheIyF4ROSAi3/awP0VEXhKRQhHZKSK3uOwrEZHtIrJVRDa5bJ8vIh9a20VkaSjvwTAC8BaSa9mfjeAw+KO7tLpT6/CVNQ7axOSey2H52bwJDtB1qywn/GgUHCISCTwAXAjMBj4lIrPdhn0F2KWUKgDOAH4tIq5des5USs1XSi122fZL4CdKqfnAD52fDQbvZEzX/Q5ck6vAVMY12McySVl+Dn+CA/qWHanap8uwJ/moC2eVH4lN0TXlhiih1DiWAgeUUkVKqXbgKeAytzEKSBYRAZKAGsDt190HBVh1A1KA8uBN2TAiyZwBjg7dStYVY6oy2MW9mVNLTd9e4+64lx2xIqp8ObwnL9M9c8bPHbKOcYCoEJ57EuBalrQMWOY25n7gRfTDPxm4Vill1RZWwBsiooA/KaX+7Nz+NeB1EbkXLfhO9XRxEbkVuBVgypQpA74ZwzDGtWZVRl7P9sbj2g4dkxieeRmGD+7NnJprYKyfToJJWT0VbkGbS3NO931MdBycd8+Q77oYSo3Dk7h0b6x7PrAVmAjMB+4XEUubOE0ptRBt6vqKiDh1OL4EfF0pNRn4OvCwp4srpf6slFqslFqclWVWlKOaTGeWrruD3MrhGMIrO8MQwb1CrrcmTq5YGodSul/5iSPeI6pcWfZFmHnBgKYbakIpOMoA11oW2fQ1K90CPKs0B4BiYBaAUqrc+XoceA5t+gK4GXjW+f5fLtsNBs/Ep+mQ2z6Co9L4Nwz26G7mVAftzdDRbMPHkaVNpK119hzjw4hQCo6NQL6I5Dod3tehzVKuHAbOBhCRccBMoEhEEkUk2bk9ETgP2OE8phxwNkPmLMBHBTuDwYmnyCpT4NBgF1cfR4ufAocWrtnjVSNLcITMx6GU6hSR24HXgUjgEaXUThG5zbn/IeAe4O8ish1t2rpbKVUlItOA57TPnCjgH0opZwsvvgD8TkSigFacfgyDwSeZ03va5Vo0VY3ckvKG4BIVq/1hLXX+s8YtXLPHq/bpvi/pQzdSKhBC6RxHKfUq8Krbtodc3pejtQn344oAj0HMSql3gUXBnalhxJM5Q68Um6p1QTmljMZhCAwre9y24HDJHq/ap6sYRMWGcoaDhskcN4wO3LsBttZr+7MRHAa7WBVy/fXisOglOHzUqBqGGMFhGB1Y0SyW4DA5HIZAsSrk2tU4rP0Nx7Rz3E5E1TDBCA7D6CBlMkTFeRAcJqrKYBOrmVNzNSA9kVbeiIzWSYLlW3TVW6NxGAzDjIhIXXrECos0GochUFxNVfGp9vrUJ2bB4Q/1eyM4DIZhSMZ0Y6oy9B9XU5U/M5VFYpbuJQ6QYUxVBsPwI3MG1Jbo0thW1VK7DwCDIS4FWk/oRYdtweE0hcan62i+EYIRHIbRQ+YMUA5dKbepUv+YvfVTMBjciU8FFNQeCkzjgBFlpgIjOAyjCdfIKpPDYQgUq9Bhfan/OlUW3YJj5JipwAgOw2giw6XYoVXg0GCwi1V2BBW4qcpoHAbDMCU2CcZk67pBjcdNKK4hMFzDb42pymAYRWRON6YqQ//o1jiwLzimrYJlX4JcP304hhlGcBhGF5kzoHKvjsc3gsMQCJaPA+wLjrgUuPAXI65ZmBEchtFF5gzoaNLvjanKEAj9MVWNUIzgMIwuXKNbjMZhCISYJBBntri/fuMjHCM4DKMLVyelERyGQBDp8XPYDccdoRjBYRhdJE/QK0eApLHhnYth+BGXohsyufo7RiFGcBhGFyI9+RzGx2EIlPhUbaaKGN2PztF994bRSeYMiIyB2DHhnolhuBGXMurNVBDi1rEGw5Bk2Rche7HWPgyGQFh+u66QO8oxgsMw+sherP8MhkDJPzfcMxgSGFOVwWAwGALCCA6DwWAwBIQRHAaDwWAIiJAKDhG5QET2isgBEfm2h/0pIvKSiBSKyE4RucVlX4mIbBeRrSKyye24O5zn3SkivwzlPRgMBoOhNyFzjotIJPAAcC5QBmwUkReVUrtchn0F2KWUukREsoC9IvKkUqrduf9MpVSV23nPBC4D5iml2kTEZHEZDAbDIBJKjWMpcEApVeQUBE+hH/iuKCBZRARIAmqATj/n/RLwC6VUG4BS6nhwp20wGAwGX4RScEwCSl0+lzm3uXI/cBJQDmwH7lRKOZz7FPCGiHwsIre6HDMDOF1EPhKRtSKyxNPFReRWEdkkIpsqKyuDcT8Gg8FgILSCw1N2lXL7fD6wFZgIzAfuFxErnfc0pdRC4ELgKyKy0rk9CkgDTgG+CTzj1Fh6X0ipPyulFiulFmdlmWJ2BoPBECxCmQBYBkx2+ZyN1ixcuQVtdlLAAREpBmYBG5RS5aBNUSLyHNr0tc553medx2wQEQeQCXhVKz7++OMqETnUz/vIBKr8jhp5mPsefYzWezf37Z2pnjaGUnBsBPJFJBc4AlwHfNptzGHgbGC9iIwDZgJFIpIIRCilGpzvzwP+n/OY54GzgHdEZAYQg5+bV0r1W+UQkU1KqVGXZmzue/QxWu/d3HfghExwKKU6ReR24HUgEnhEKbVTRG5z7n8IuAf4u4hsR5u27lZKVYnINOA5pwUqCviHUuo156kfAR4RkR1AO3CzU/swGAwGwyAQ0lpVSqlXgVfdtj3k8r4crU24H1cEFHg5ZztwQ3BnajAYDAa7mMxx//w53BMIE+a+Rx+j9d7NfQeIGCuPwWAwGALBaBwGg8FgCAgjOAwGg8EQEEZw+MBfkcaRgog8IiLHnZFq1rZ0EXlTRPY7X9PCOcdQICKTReRtEdntLJh5p3P7iL53EYkTkQ0uxUV/4tw+ou/bQkQiRWSLiLzs/Dzi79tT0diB3LcRHF5wKdJ4ITAb+JSIzA7vrELG34EL3LZ9G1ijlMoH1jg/jzQ6gW8opU5CVyL4ivP/eKTfextwllKqAF2x4QIROYWRf98WdwK7XT6Plvs+Uyk13yV3o9/3bQSHd+wUaRwRKKXWoQtMunIZ8Kjz/aPA5YM5p8FAKVWhlNrsfN+AfphMYoTfu9I0Oj9GO/8UI/y+AUQkG7gI+KvL5hF/317o930bweEdO0UaRzLjlFIVoB+wwIguXy8iOcAC4CNGwb07zTVbgePAm0qpUXHfwH3AtwCHy7bRcN+eisb2+75DmgA4zLFTpNEwAhCRJODfwNeUUic81MwccSiluoD5IpKKrtIwJ8xTCjkicjFwXCn1sYicEebpDDanKaXKnf2L3hSRPQM5mdE4vGOnSONI5piITABwvo7IviciEo0WGk8qpZ51bh4V9w6glKoD3kH7uEb6fZ8GXCoiJWjT81ki8gQj/76tKh1W/yKraGy/79sIDu90F2kUkRh0kcYXwzynweRF4Gbn+5uBF8I4l5DgLMf/MLBbKfUbl10j+t5FJMupaSAi8cA5wB5G+H0rpb6jlMpWSuWgf8//VUrdwAi/bxFJFJFk6z26zNMOBnDfJnPcByLyCbRN1CrS+LPwzig0iMg/gTPQZZaPAT9CVyF+BpiCrmL8SaWUuwN9WCMiK4D16CZils37u2g/x4i9dxGZh3aGRqIXj88opf6fiGQwgu/bFaep6i6l1MUj/b6torHOj1bR2J8N5L6N4DAYDAZDQBhTlcFgMBgCwggOg8FgMASEERwGg8FgCAgjOAwGg8EQEEZwGAwGgyEgjOAwGIY4InKGVcnVYBgKGMFhMBgMhoAwgsNgCBIicoOzz8VWEfmTs5Bgo4j8WkQ2i8gaEclyjp0vIh+KyDYRec7qhSAi00XkLWevjM0ikuc8fZKIrBaRPSLypIyGglqGIYsRHAZDEBCRk4Br0cXk5gNdwPVAIrBZKbUQWIvOygd4DLhbKTUPnblubX8SeMDZK+NUoMK5fQHwNXRvmGnouksGQ1gw1XENhuBwNrAI2OhUBuLRReMcwNPOMU8Az4pICpCqlFrr3P4o8C9nPaFJSqnnAJRSrQDO821QSpU5P28FcoB3Q35XBoMHjOAwGIKDAI8qpb7Ta6PID9zG+arx48v81Obyvgvz2zWEEWOqMhiCwxrgame/A6uf81T0b+xq55hPA+8qpeqBWhE53bn9RmCtUuoEUCYilzvPESsiCYN5EwaDHcyqxWAIAkqpXSLyfXSXtQigA/gK0AScLCIfA/VoPwjoMtYPOQVDEXCLc/uNwJ9E5P85z/HJQbwNg8EWpjquwRBCRKRRKZUU7nkYDMHEmKoMBoPBEBBG4zAYDAZDQBiNw2AwGAwBYQSHwWAwGALCCA6DwWAwBIQRHAaDwWAICCM4DAaDwRAQ/x+y8bGTDOIRcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8620\n",
      "Test Loss : 0.32807016372680664\n",
      "Test Accuracy : 0.8619999885559082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1595\n",
      "           1       0.71      0.53      0.61       405\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.80      0.74      0.76      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "AUC Score : 0.7384728511165294\n"
     ]
    }
   ],
   "source": [
    "# Model Performance on TEST SET\n",
    "\n",
    "print('.')\n",
    "loss_test, accuracy_test = classifier.evaluate(X_test, y_test)\n",
    "print(f'Test Loss : {loss_test}')\n",
    "print(f'Test Accuracy : {accuracy_test}')\n",
    "\n",
    "test_pred_prob = classifier.predict(X_test)\n",
    "test_pred = np.where(test_pred_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, test_pred)\n",
    "print(f'AUC Score : {auc_score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8690\n",
      "Train Loss : 0.3240715265274048\n",
      "Train Accuracy : 0.8690000176429749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      6368\n",
      "           1       0.78      0.50      0.61      1632\n",
      "\n",
      "    accuracy                           0.87      8000\n",
      "   macro avg       0.83      0.73      0.76      8000\n",
      "weighted avg       0.86      0.87      0.86      8000\n",
      "\n",
      "AUC Score : 0.7308724997536703\n"
     ]
    }
   ],
   "source": [
    "# Model Performance on TRAINING SET\n",
    "\n",
    "print('.')\n",
    "loss_train, accuracy_train = classifier.evaluate(X_train, y_train)\n",
    "print(f'Train Loss : {loss_train}')\n",
    "print(f'Train Accuracy : {accuracy_train}')\n",
    "\n",
    "train_pred_prob = classifier.predict(X_train)\n",
    "train_pred = np.where(train_pred_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_train, train_pred))\n",
    "\n",
    "auc_score_train = roc_auc_score(y_train, train_pred)\n",
    "print(f'AUC Score : {auc_score_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Hyperparameter Tuning using RandomSearch of KerasTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomSearch a hyperparameter tuning technique which randomly select n different combinations of hyperparameters, trains the model using those hyperparameters on training data and evaluates it on validation data. The number of hyperparameter combinations is chosen by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 10)):\n",
    "        model.add(layers.Dense(units=hp.Int(f'units_{i}',\n",
    "                                            min_value=6,\n",
    "                                            max_value=30,\n",
    "                                            step=5),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy', # direction='max' to maximize\n",
    "    max_trials=20,\n",
    "    directory='directory1',\n",
    "    project_name='Project_Name1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">num_layers (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units_0 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units_1 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.75 - ETA: 0s - loss: 0.6245 - accuracy: 0.80 - ETA: 0s - loss: 0.6174 - accuracy: 0.80 - ETA: 0s - loss: 0.6122 - accuracy: 0.80 - ETA: 0s - loss: 0.6114 - accuracy: 0.79 - ETA: 0s - loss: 0.6070 - accuracy: 0.79 - 1s 3ms/step - loss: 0.6045 - accuracy: 0.7948 - val_loss: 0.5744 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.6111 - accuracy: 0.78 - ETA: 0s - loss: 0.5642 - accuracy: 0.81 - ETA: 0s - loss: 0.5688 - accuracy: 0.80 - ETA: 0s - loss: 0.5699 - accuracy: 0.79 - ETA: 0s - loss: 0.5654 - accuracy: 0.79 - ETA: 0s - loss: 0.5616 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7948 - val_loss: 0.5382 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.93 - ETA: 0s - loss: 0.5442 - accuracy: 0.79 - ETA: 0s - loss: 0.5391 - accuracy: 0.79 - ETA: 0s - loss: 0.5397 - accuracy: 0.79 - ETA: 0s - loss: 0.5358 - accuracy: 0.79 - ETA: 0s - loss: 0.5313 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7948 - val_loss: 0.5173 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.78 - ETA: 0s - loss: 0.4965 - accuracy: 0.81 - ETA: 0s - loss: 0.5081 - accuracy: 0.80 - ETA: 0s - loss: 0.5095 - accuracy: 0.80 - ETA: 0s - loss: 0.5153 - accuracy: 0.79 - ETA: 0s - loss: 0.5185 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7948 - val_loss: 0.5029 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.84 - ETA: 0s - loss: 0.4999 - accuracy: 0.79 - ETA: 0s - loss: 0.5106 - accuracy: 0.79 - ETA: 0s - loss: 0.5078 - accuracy: 0.79 - ETA: 0s - loss: 0.5018 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7948 - val_loss: 0.4917 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.81 - ETA: 0s - loss: 0.4971 - accuracy: 0.78 - ETA: 0s - loss: 0.4817 - accuracy: 0.79 - ETA: 0s - loss: 0.4871 - accuracy: 0.79 - ETA: 0s - loss: 0.4867 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7948 - val_loss: 0.4826 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.84 - ETA: 0s - loss: 0.4648 - accuracy: 0.80 - ETA: 0s - loss: 0.4737 - accuracy: 0.80 - ETA: 0s - loss: 0.4769 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7948 - val_loss: 0.4746 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.84 - ETA: 0s - loss: 0.4578 - accuracy: 0.80 - ETA: 0s - loss: 0.4648 - accuracy: 0.80 - ETA: 0s - loss: 0.4765 - accuracy: 0.79 - ETA: 0s - loss: 0.4694 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7948 - val_loss: 0.4677 - val_accuracy: 0.7995\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.87 - ETA: 0s - loss: 0.4673 - accuracy: 0.79 - ETA: 0s - loss: 0.4757 - accuracy: 0.78 - ETA: 0s - loss: 0.4698 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7948 - val_loss: 0.4613 - val_accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.84 - ETA: 0s - loss: 0.4562 - accuracy: 0.79 - ETA: 0s - loss: 0.4427 - accuracy: 0.80 - ETA: 0s - loss: 0.4525 - accuracy: 0.79 - ETA: 0s - loss: 0.4539 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7948 - val_loss: 0.4553 - val_accuracy: 0.7995\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5594 - accuracy: 0.68 - ETA: 0s - loss: 0.4530 - accuracy: 0.79 - ETA: 0s - loss: 0.4446 - accuracy: 0.79 - ETA: 0s - loss: 0.4479 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7948 - val_loss: 0.4498 - val_accuracy: 0.7995\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.75 - ETA: 0s - loss: 0.4376 - accuracy: 0.80 - ETA: 0s - loss: 0.4445 - accuracy: 0.79 - ETA: 0s - loss: 0.4459 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7948 - val_loss: 0.4451 - val_accuracy: 0.7995\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.78 - ETA: 0s - loss: 0.4361 - accuracy: 0.79 - ETA: 0s - loss: 0.4398 - accuracy: 0.79 - ETA: 0s - loss: 0.4350 - accuracy: 0.79 - ETA: 0s - loss: 0.4329 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7950 - val_loss: 0.4414 - val_accuracy: 0.7995\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.87 - ETA: 0s - loss: 0.4467 - accuracy: 0.78 - ETA: 0s - loss: 0.4366 - accuracy: 0.78 - ETA: 0s - loss: 0.4309 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7965 - val_loss: 0.4382 - val_accuracy: 0.7985\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.65 - ETA: 0s - loss: 0.4560 - accuracy: 0.77 - ETA: 0s - loss: 0.4483 - accuracy: 0.78 - ETA: 0s - loss: 0.4267 - accuracy: 0.80 - ETA: 0s - loss: 0.4263 - accuracy: 0.80 - ETA: 0s - loss: 0.4296 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7990 - val_loss: 0.4353 - val_accuracy: 0.8010\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.78 - ETA: 0s - loss: 0.4368 - accuracy: 0.80 - ETA: 0s - loss: 0.4292 - accuracy: 0.80 - ETA: 0s - loss: 0.4307 - accuracy: 0.80 - ETA: 0s - loss: 0.4242 - accuracy: 0.80 - ETA: 0s - loss: 0.4219 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8075 - val_loss: 0.4328 - val_accuracy: 0.8135\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.81 - ETA: 0s - loss: 0.4153 - accuracy: 0.82 - ETA: 0s - loss: 0.4130 - accuracy: 0.82 - ETA: 0s - loss: 0.4160 - accuracy: 0.81 - ETA: 0s - loss: 0.4172 - accuracy: 0.81 - ETA: 0s - loss: 0.4182 - accuracy: 0.81 - ETA: 0s - loss: 0.4184 - accuracy: 0.81 - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8148 - val_loss: 0.4303 - val_accuracy: 0.8185\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.84 - ETA: 0s - loss: 0.4007 - accuracy: 0.82 - ETA: 0s - loss: 0.4144 - accuracy: 0.81 - ETA: 0s - loss: 0.4107 - accuracy: 0.81 - ETA: 0s - loss: 0.4169 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8177 - val_loss: 0.4279 - val_accuracy: 0.8210\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.84 - ETA: 0s - loss: 0.4136 - accuracy: 0.81 - ETA: 0s - loss: 0.4119 - accuracy: 0.82 - ETA: 0s - loss: 0.4269 - accuracy: 0.81 - ETA: 0s - loss: 0.4215 - accuracy: 0.81 - ETA: 0s - loss: 0.4194 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8215 - val_loss: 0.4260 - val_accuracy: 0.8205\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.84 - ETA: 0s - loss: 0.3952 - accuracy: 0.82 - ETA: 0s - loss: 0.4052 - accuracy: 0.81 - ETA: 0s - loss: 0.4035 - accuracy: 0.81 - ETA: 0s - loss: 0.4112 - accuracy: 0.81 - ETA: 0s - loss: 0.4144 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8228 - val_loss: 0.4242 - val_accuracy: 0.8230\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.84 - ETA: 0s - loss: 0.3903 - accuracy: 0.83 - ETA: 0s - loss: 0.4255 - accuracy: 0.82 - ETA: 0s - loss: 0.4282 - accuracy: 0.81 - ETA: 0s - loss: 0.4220 - accuracy: 0.82 - ETA: 0s - loss: 0.4117 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8252 - val_loss: 0.4226 - val_accuracy: 0.8245\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.81 - ETA: 0s - loss: 0.4085 - accuracy: 0.82 - ETA: 0s - loss: 0.4080 - accuracy: 0.82 - ETA: 0s - loss: 0.4148 - accuracy: 0.82 - ETA: 0s - loss: 0.4146 - accuracy: 0.82 - ETA: 0s - loss: 0.4076 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8275 - val_loss: 0.4208 - val_accuracy: 0.8250\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.75 - ETA: 0s - loss: 0.4393 - accuracy: 0.81 - ETA: 0s - loss: 0.4151 - accuracy: 0.82 - ETA: 0s - loss: 0.4117 - accuracy: 0.82 - ETA: 0s - loss: 0.4047 - accuracy: 0.83 - ETA: 0s - loss: 0.4038 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8305 - val_loss: 0.4192 - val_accuracy: 0.8275\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.84 - ETA: 0s - loss: 0.4246 - accuracy: 0.80 - ETA: 0s - loss: 0.4051 - accuracy: 0.82 - ETA: 0s - loss: 0.4144 - accuracy: 0.82 - ETA: 0s - loss: 0.4046 - accuracy: 0.82 - ETA: 0s - loss: 0.4022 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8318 - val_loss: 0.4173 - val_accuracy: 0.8255\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.87 - ETA: 0s - loss: 0.4027 - accuracy: 0.83 - ETA: 0s - loss: 0.3976 - accuracy: 0.83 - ETA: 0s - loss: 0.3896 - accuracy: 0.84 - ETA: 0s - loss: 0.3951 - accuracy: 0.84 - ETA: 0s - loss: 0.4070 - accuracy: 0.83 - ETA: 0s - loss: 0.3993 - accuracy: 0.83 - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8320 - val_loss: 0.4154 - val_accuracy: 0.8270\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.87 - ETA: 0s - loss: 0.4333 - accuracy: 0.81 - ETA: 0s - loss: 0.4047 - accuracy: 0.82 - ETA: 0s - loss: 0.3995 - accuracy: 0.82 - ETA: 0s - loss: 0.3985 - accuracy: 0.82 - ETA: 0s - loss: 0.3964 - accuracy: 0.83 - ETA: 0s - loss: 0.3935 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8323 - val_loss: 0.4136 - val_accuracy: 0.8255\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.87 - ETA: 0s - loss: 0.3682 - accuracy: 0.84 - ETA: 0s - loss: 0.3990 - accuracy: 0.83 - ETA: 0s - loss: 0.3902 - accuracy: 0.83 - ETA: 0s - loss: 0.3821 - accuracy: 0.84 - ETA: 0s - loss: 0.3911 - accuracy: 0.83 - ETA: 0s - loss: 0.3925 - accuracy: 0.83 - ETA: 0s - loss: 0.3965 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8347 - val_loss: 0.4119 - val_accuracy: 0.8265\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.84 - ETA: 0s - loss: 0.3659 - accuracy: 0.83 - ETA: 0s - loss: 0.3914 - accuracy: 0.82 - ETA: 0s - loss: 0.3841 - accuracy: 0.83 - ETA: 0s - loss: 0.3938 - accuracy: 0.83 - ETA: 0s - loss: 0.3946 - accuracy: 0.83 - ETA: 0s - loss: 0.3962 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8367 - val_loss: 0.4103 - val_accuracy: 0.8260\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.84 - ETA: 0s - loss: 0.4141 - accuracy: 0.80 - ETA: 0s - loss: 0.3983 - accuracy: 0.82 - ETA: 0s - loss: 0.3925 - accuracy: 0.83 - ETA: 0s - loss: 0.4012 - accuracy: 0.83 - ETA: 0s - loss: 0.3964 - accuracy: 0.83 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3919 - accuracy: 0.8367 - val_loss: 0.4089 - val_accuracy: 0.8280\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.90 - ETA: 0s - loss: 0.3725 - accuracy: 0.84 - ETA: 0s - loss: 0.3841 - accuracy: 0.84 - ETA: 0s - loss: 0.3883 - accuracy: 0.83 - ETA: 0s - loss: 0.3920 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8390 - val_loss: 0.4072 - val_accuracy: 0.8295\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.90 - ETA: 0s - loss: 0.3815 - accuracy: 0.84 - ETA: 0s - loss: 0.3806 - accuracy: 0.84 - ETA: 0s - loss: 0.3877 - accuracy: 0.83 - ETA: 0s - loss: 0.3872 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8392 - val_loss: 0.4054 - val_accuracy: 0.8300\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.68 - ETA: 0s - loss: 0.3871 - accuracy: 0.85 - ETA: 0s - loss: 0.3836 - accuracy: 0.84 - ETA: 0s - loss: 0.3897 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8423 - val_loss: 0.4037 - val_accuracy: 0.8315\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.78 - ETA: 0s - loss: 0.4025 - accuracy: 0.82 - ETA: 0s - loss: 0.3848 - accuracy: 0.84 - ETA: 0s - loss: 0.3824 - accuracy: 0.84 - ETA: 0s - loss: 0.3837 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8417 - val_loss: 0.4020 - val_accuracy: 0.8325\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.87 - ETA: 0s - loss: 0.3832 - accuracy: 0.83 - ETA: 0s - loss: 0.3760 - accuracy: 0.84 - ETA: 0s - loss: 0.3782 - accuracy: 0.84 - ETA: 0s - loss: 0.3806 - accuracy: 0.84 - ETA: 0s - loss: 0.3806 - accuracy: 0.84 - ETA: 0s - loss: 0.3771 - accuracy: 0.84 - ETA: 0s - loss: 0.3796 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8422 - val_loss: 0.4006 - val_accuracy: 0.8320\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.87 - ETA: 0s - loss: 0.3717 - accuracy: 0.84 - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - ETA: 0s - loss: 0.3762 - accuracy: 0.83 - ETA: 0s - loss: 0.3778 - accuracy: 0.84 - ETA: 0s - loss: 0.3801 - accuracy: 0.84 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8422 - val_loss: 0.3988 - val_accuracy: 0.8325\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.81 - ETA: 0s - loss: 0.3865 - accuracy: 0.83 - ETA: 0s - loss: 0.3819 - accuracy: 0.83 - ETA: 0s - loss: 0.3801 - accuracy: 0.84 - ETA: 0s - loss: 0.3733 - accuracy: 0.84 - ETA: 0s - loss: 0.3700 - accuracy: 0.84 - ETA: 0s - loss: 0.3743 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3767 - accuracy: 0.8435 - val_loss: 0.3974 - val_accuracy: 0.8345\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.81 - ETA: 0s - loss: 0.4050 - accuracy: 0.82 - ETA: 0s - loss: 0.3881 - accuracy: 0.84 - ETA: 0s - loss: 0.3790 - accuracy: 0.84 - ETA: 0s - loss: 0.3739 - accuracy: 0.84 - ETA: 0s - loss: 0.3755 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8448 - val_loss: 0.3960 - val_accuracy: 0.8370\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.84 - ETA: 0s - loss: 0.3493 - accuracy: 0.86 - ETA: 0s - loss: 0.3645 - accuracy: 0.85 - ETA: 0s - loss: 0.3552 - accuracy: 0.85 - ETA: 0s - loss: 0.3585 - accuracy: 0.85 - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - ETA: 0s - loss: 0.3711 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3725 - accuracy: 0.8462 - val_loss: 0.3942 - val_accuracy: 0.8375\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.93 - ETA: 0s - loss: 0.3483 - accuracy: 0.86 - ETA: 0s - loss: 0.3646 - accuracy: 0.85 - ETA: 0s - loss: 0.3637 - accuracy: 0.85 - ETA: 0s - loss: 0.3648 - accuracy: 0.85 - ETA: 0s - loss: 0.3678 - accuracy: 0.85 - ETA: 0s - loss: 0.3706 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3704 - accuracy: 0.8477 - val_loss: 0.3930 - val_accuracy: 0.8395\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.78 - ETA: 0s - loss: 0.3582 - accuracy: 0.84 - ETA: 0s - loss: 0.3616 - accuracy: 0.84 - ETA: 0s - loss: 0.3656 - accuracy: 0.84 - ETA: 0s - loss: 0.3625 - accuracy: 0.84 - ETA: 0s - loss: 0.3662 - accuracy: 0.84 - ETA: 0s - loss: 0.3670 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8480 - val_loss: 0.3918 - val_accuracy: 0.8390\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.81 - ETA: 0s - loss: 0.3748 - accuracy: 0.84 - ETA: 0s - loss: 0.3712 - accuracy: 0.83 - ETA: 0s - loss: 0.3832 - accuracy: 0.83 - ETA: 0s - loss: 0.3756 - accuracy: 0.84 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - ETA: 0s - loss: 0.3663 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3667 - accuracy: 0.8477 - val_loss: 0.3905 - val_accuracy: 0.8400\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.96 - ETA: 0s - loss: 0.3509 - accuracy: 0.86 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3695 - accuracy: 0.84 - ETA: 0s - loss: 0.3703 - accuracy: 0.84 - ETA: 0s - loss: 0.3597 - accuracy: 0.84 - ETA: 0s - loss: 0.3635 - accuracy: 0.84 - ETA: 0s - loss: 0.3650 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8492 - val_loss: 0.3892 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.90 - ETA: 0s - loss: 0.3780 - accuracy: 0.84 - ETA: 0s - loss: 0.3618 - accuracy: 0.84 - ETA: 0s - loss: 0.3715 - accuracy: 0.84 - ETA: 0s - loss: 0.3657 - accuracy: 0.84 - ETA: 0s - loss: 0.3631 - accuracy: 0.84 - ETA: 0s - loss: 0.3600 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3631 - accuracy: 0.8510 - val_loss: 0.3878 - val_accuracy: 0.8410\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.90 - ETA: 0s - loss: 0.3794 - accuracy: 0.84 - ETA: 0s - loss: 0.3691 - accuracy: 0.84 - ETA: 0s - loss: 0.3619 - accuracy: 0.84 - ETA: 0s - loss: 0.3597 - accuracy: 0.84 - ETA: 0s - loss: 0.3620 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8518 - val_loss: 0.3862 - val_accuracy: 0.8425\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3521 - accuracy: 0.86 - ETA: 0s - loss: 0.3583 - accuracy: 0.85 - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8522 - val_loss: 0.3848 - val_accuracy: 0.8435\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.93 - ETA: 0s - loss: 0.3770 - accuracy: 0.84 - ETA: 0s - loss: 0.3766 - accuracy: 0.84 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - ETA: 0s - loss: 0.3617 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8540 - val_loss: 0.3833 - val_accuracy: 0.8415\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.87 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3537 - accuracy: 0.85 - ETA: 0s - loss: 0.3618 - accuracy: 0.84 - ETA: 0s - loss: 0.3574 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8537 - val_loss: 0.3819 - val_accuracy: 0.8435\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.90 - ETA: 0s - loss: 0.3620 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3598 - accuracy: 0.84 - ETA: 0s - loss: 0.3625 - accuracy: 0.84 - ETA: 0s - loss: 0.3592 - accuracy: 0.84 - ETA: 0s - loss: 0.3566 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8543 - val_loss: 0.3807 - val_accuracy: 0.8445\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.87 - ETA: 0s - loss: 0.3645 - accuracy: 0.84 - ETA: 0s - loss: 0.3508 - accuracy: 0.86 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8555 - val_loss: 0.3795 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.78 - ETA: 0s - loss: 0.3714 - accuracy: 0.85 - ETA: 0s - loss: 0.3625 - accuracy: 0.85 - ETA: 0s - loss: 0.3522 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3495 - accuracy: 0.8563 - val_loss: 0.3788 - val_accuracy: 0.8465\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.90 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3432 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8565 - val_loss: 0.3775 - val_accuracy: 0.8475\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.96 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3446 - accuracy: 0.85 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8568 - val_loss: 0.3769 - val_accuracy: 0.8460\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.96 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3469 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8572 - val_loss: 0.3760 - val_accuracy: 0.8465\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.96 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - ETA: 0s - loss: 0.3422 - accuracy: 0.85 - ETA: 0s - loss: 0.3441 - accuracy: 0.85 - ETA: 0s - loss: 0.3448 - accuracy: 0.86 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8590 - val_loss: 0.3754 - val_accuracy: 0.8470\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.84 - ETA: 0s - loss: 0.3335 - accuracy: 0.85 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8583 - val_loss: 0.3749 - val_accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.90 - ETA: 0s - loss: 0.3498 - accuracy: 0.85 - ETA: 0s - loss: 0.3424 - accuracy: 0.85 - ETA: 0s - loss: 0.3382 - accuracy: 0.85 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3406 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8582 - val_loss: 0.3739 - val_accuracy: 0.8475\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.84 - ETA: 0s - loss: 0.3334 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3427 - accuracy: 0.8597 - val_loss: 0.3731 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.81 - ETA: 0s - loss: 0.3487 - accuracy: 0.84 - ETA: 0s - loss: 0.3315 - accuracy: 0.85 - ETA: 0s - loss: 0.3431 - accuracy: 0.85 - ETA: 0s - loss: 0.3464 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8585 - val_loss: 0.3724 - val_accuracy: 0.8485\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.85 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8597 - val_loss: 0.3720 - val_accuracy: 0.8495\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.78 - ETA: 0s - loss: 0.3595 - accuracy: 0.85 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8598 - val_loss: 0.3716 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.84 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - ETA: 0s - loss: 0.3363 - accuracy: 0.85 - ETA: 0s - loss: 0.3420 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8592 - val_loss: 0.3709 - val_accuracy: 0.8520\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.71 - ETA: 0s - loss: 0.3275 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8595 - val_loss: 0.3705 - val_accuracy: 0.8505\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.75 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3546 - accuracy: 0.84 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3378 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8595 - val_loss: 0.3704 - val_accuracy: 0.8525\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.81 - ETA: 0s - loss: 0.3756 - accuracy: 0.84 - ETA: 0s - loss: 0.3494 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3406 - accuracy: 0.85 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8612 - val_loss: 0.3699 - val_accuracy: 0.8520\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.84 - ETA: 0s - loss: 0.3537 - accuracy: 0.85 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8602 - val_loss: 0.3700 - val_accuracy: 0.8510\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.87 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - ETA: 0s - loss: 0.3336 - accuracy: 0.85 - ETA: 0s - loss: 0.3346 - accuracy: 0.85 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8610 - val_loss: 0.3690 - val_accuracy: 0.8525\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.87 - ETA: 0s - loss: 0.3359 - accuracy: 0.85 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3390 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8610 - val_loss: 0.3687 - val_accuracy: 0.8530\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.87 - ETA: 0s - loss: 0.3522 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3448 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - ETA: 0s - loss: 0.3391 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8607 - val_loss: 0.3684 - val_accuracy: 0.8535\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.84 - ETA: 0s - loss: 0.3140 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8600 - val_loss: 0.3680 - val_accuracy: 0.8545\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.84 - ETA: 0s - loss: 0.3403 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8600 - val_loss: 0.3676 - val_accuracy: 0.8545\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.87 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3380 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8610 - val_loss: 0.3675 - val_accuracy: 0.8545\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.93 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8608 - val_loss: 0.3671 - val_accuracy: 0.8550\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.84 - ETA: 0s - loss: 0.3618 - accuracy: 0.83 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8615 - val_loss: 0.3673 - val_accuracy: 0.8550\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.85 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8615 - val_loss: 0.3668 - val_accuracy: 0.8560\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.75 - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8622 - val_loss: 0.3663 - val_accuracy: 0.8560\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.84 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - ETA: 0s - loss: 0.3374 - accuracy: 0.85 - ETA: 0s - loss: 0.3323 - accuracy: 0.85 - ETA: 0s - loss: 0.3314 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8617 - val_loss: 0.3662 - val_accuracy: 0.8575\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.87 - ETA: 0s - loss: 0.3574 - accuracy: 0.84 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8623 - val_loss: 0.3657 - val_accuracy: 0.8570\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.78 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.85 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8625 - val_loss: 0.3656 - val_accuracy: 0.8570\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2388 - accuracy: 0.90 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.87 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8628 - val_loss: 0.3652 - val_accuracy: 0.8565\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.81 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - ETA: 0s - loss: 0.3252 - accuracy: 0.87 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8627 - val_loss: 0.3649 - val_accuracy: 0.8555\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2937 - accuracy: 0.90 - ETA: 0s - loss: 0.3418 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3434 - accuracy: 0.85 - ETA: 0s - loss: 0.3384 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8637 - val_loss: 0.3649 - val_accuracy: 0.8560\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.87 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3352 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3347 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8628 - val_loss: 0.3650 - val_accuracy: 0.8560\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.87 - ETA: 0s - loss: 0.3442 - accuracy: 0.85 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8632 - val_loss: 0.3644 - val_accuracy: 0.8570\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.81 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8643 - val_loss: 0.3640 - val_accuracy: 0.8555\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.81 - ETA: 0s - loss: 0.3622 - accuracy: 0.84 - ETA: 0s - loss: 0.3515 - accuracy: 0.84 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8638 - val_loss: 0.3642 - val_accuracy: 0.8560\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.90 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8642 - val_loss: 0.3643 - val_accuracy: 0.8565\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.78 - ETA: 0s - loss: 0.3314 - accuracy: 0.86 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - ETA: 0s - loss: 0.3406 - accuracy: 0.85 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8638 - val_loss: 0.3638 - val_accuracy: 0.8570\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.93 - ETA: 0s - loss: 0.3097 - accuracy: 0.87 - ETA: 0s - loss: 0.3114 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8652 - val_loss: 0.3635 - val_accuracy: 0.8535\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.71 - ETA: 0s - loss: 0.3490 - accuracy: 0.85 - ETA: 0s - loss: 0.3336 - accuracy: 0.85 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8645 - val_loss: 0.3632 - val_accuracy: 0.8555\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.93 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8643 - val_loss: 0.3629 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.78 - ETA: 0s - loss: 0.3459 - accuracy: 0.85 - ETA: 0s - loss: 0.3347 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8638 - val_loss: 0.3634 - val_accuracy: 0.8570\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.84 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8637 - val_loss: 0.3633 - val_accuracy: 0.8570\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.78 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3205 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8640 - val_loss: 0.3628 - val_accuracy: 0.8565\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.90 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3205 - accuracy: 0.86 - ETA: 0s - loss: 0.3240 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8632 - val_loss: 0.3628 - val_accuracy: 0.8565\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.90 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - ETA: 0s - loss: 0.3348 - accuracy: 0.85 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8645 - val_loss: 0.3623 - val_accuracy: 0.8580\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4393 - accuracy: 0.81 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - ETA: 0s - loss: 0.3216 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3361 - accuracy: 0.85 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8635 - val_loss: 0.3623 - val_accuracy: 0.8570\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.87 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8657 - val_loss: 0.3622 - val_accuracy: 0.8570\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.1764 - accuracy: 0.93 - ETA: 0s - loss: 0.3127 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8650 - val_loss: 0.3619 - val_accuracy: 0.8575\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.84 - ETA: 0s - loss: 0.3512 - accuracy: 0.84 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3314 - accuracy: 0.86 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8647 - val_loss: 0.3615 - val_accuracy: 0.8590\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.87 - ETA: 0s - loss: 0.3094 - accuracy: 0.87 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8647 - val_loss: 0.3615 - val_accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ad5730a6d23b2cbcaaa03e629bc4c00d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859000027179718</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.21 - ETA: 0s - loss: 0.6645 - accuracy: 0.61 - ETA: 0s - loss: 0.5977 - accuracy: 0.71 - ETA: 0s - loss: 0.5645 - accuracy: 0.74 - ETA: 0s - loss: 0.5473 - accuracy: 0.74 - ETA: 0s - loss: 0.5311 - accuracy: 0.75 - 1s 4ms/step - loss: 0.5189 - accuracy: 0.7625 - val_loss: 0.4542 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.81 - ETA: 0s - loss: 0.4130 - accuracy: 0.80 - ETA: 0s - loss: 0.4251 - accuracy: 0.79 - ETA: 0s - loss: 0.4343 - accuracy: 0.79 - ETA: 0s - loss: 0.4425 - accuracy: 0.79 - ETA: 0s - loss: 0.4404 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7948 - val_loss: 0.4306 - val_accuracy: 0.8005\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.84 - ETA: 0s - loss: 0.4197 - accuracy: 0.79 - ETA: 0s - loss: 0.4263 - accuracy: 0.78 - ETA: 0s - loss: 0.4197 - accuracy: 0.79 - ETA: 0s - loss: 0.4117 - accuracy: 0.80 - ETA: 0s - loss: 0.4126 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8122 - val_loss: 0.4033 - val_accuracy: 0.8255\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.96 - ETA: 0s - loss: 0.3822 - accuracy: 0.83 - ETA: 0s - loss: 0.3751 - accuracy: 0.84 - ETA: 0s - loss: 0.3787 - accuracy: 0.84 - ETA: 0s - loss: 0.3761 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8452 - val_loss: 0.3728 - val_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.84 - ETA: 0s - loss: 0.3662 - accuracy: 0.84 - ETA: 0s - loss: 0.3549 - accuracy: 0.84 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8543 - val_loss: 0.3637 - val_accuracy: 0.8495\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 1.00 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8565 - val_loss: 0.3586 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.90 - ETA: 0s - loss: 0.3490 - accuracy: 0.85 - ETA: 0s - loss: 0.3365 - accuracy: 0.85 - ETA: 0s - loss: 0.3381 - accuracy: 0.85 - ETA: 0s - loss: 0.3369 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8590 - val_loss: 0.3581 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.81 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8605 - val_loss: 0.3573 - val_accuracy: 0.8505\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.87 - ETA: 0s - loss: 0.3403 - accuracy: 0.86 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - ETA: 0s - loss: 0.3353 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8660 - val_loss: 0.3629 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.81 - ETA: 0s - loss: 0.3216 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8635 - val_loss: 0.3540 - val_accuracy: 0.8520\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.75 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.87 - ETA: 0s - loss: 0.3275 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8673 - val_loss: 0.3608 - val_accuracy: 0.8515\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.90 - ETA: 0s - loss: 0.3017 - accuracy: 0.88 - ETA: 0s - loss: 0.3150 - accuracy: 0.87 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8668 - val_loss: 0.3599 - val_accuracy: 0.8490\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.81 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8658 - val_loss: 0.3556 - val_accuracy: 0.8510\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.81 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3543 - accuracy: 0.85 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8662 - val_loss: 0.3562 - val_accuracy: 0.8515\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.90 - ETA: 0s - loss: 0.3090 - accuracy: 0.88 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8662 - val_loss: 0.3571 - val_accuracy: 0.8530\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.90 - ETA: 0s - loss: 0.3094 - accuracy: 0.87 - ETA: 0s - loss: 0.3392 - accuracy: 0.85 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8678 - val_loss: 0.3563 - val_accuracy: 0.8520\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.90 - ETA: 0s - loss: 0.2998 - accuracy: 0.88 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3126 - accuracy: 0.87 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8678 - val_loss: 0.3595 - val_accuracy: 0.8505\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.87 - ETA: 0s - loss: 0.3272 - accuracy: 0.87 - ETA: 0s - loss: 0.3135 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8713 - val_loss: 0.3606 - val_accuracy: 0.8510\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.90 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - ETA: 0s - loss: 0.3427 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3205 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8697 - val_loss: 0.3607 - val_accuracy: 0.8535\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.90 - ETA: 0s - loss: 0.2712 - accuracy: 0.90 - ETA: 0s - loss: 0.2965 - accuracy: 0.88 - ETA: 0s - loss: 0.2945 - accuracy: 0.88 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3173 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8713 - val_loss: 0.3596 - val_accuracy: 0.8505\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.81 - ETA: 0s - loss: 0.3196 - accuracy: 0.85 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3134 - accuracy: 0.86 - ETA: 0s - loss: 0.3103 - accuracy: 0.87 - ETA: 0s - loss: 0.3161 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8697 - val_loss: 0.3555 - val_accuracy: 0.8585\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.84 - ETA: 0s - loss: 0.3395 - accuracy: 0.85 - ETA: 0s - loss: 0.3338 - accuracy: 0.85 - ETA: 0s - loss: 0.3187 - accuracy: 0.86 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - ETA: 0s - loss: 0.3170 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8718 - val_loss: 0.3584 - val_accuracy: 0.8520\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.84 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3210 - accuracy: 0.87 - ETA: 0s - loss: 0.3078 - accuracy: 0.88 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8730 - val_loss: 0.3606 - val_accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.71 - ETA: 0s - loss: 0.2902 - accuracy: 0.88 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.3055 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8720 - val_loss: 0.3577 - val_accuracy: 0.8555\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.84 - ETA: 0s - loss: 0.2830 - accuracy: 0.88 - ETA: 0s - loss: 0.3100 - accuracy: 0.87 - ETA: 0s - loss: 0.3014 - accuracy: 0.88 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - ETA: 0s - loss: 0.3097 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8742 - val_loss: 0.3583 - val_accuracy: 0.8520\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.93 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8738 - val_loss: 0.3665 - val_accuracy: 0.8530\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.84 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.3033 - accuracy: 0.87 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8730 - val_loss: 0.3597 - val_accuracy: 0.8550\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3009 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8730 - val_loss: 0.3581 - val_accuracy: 0.8565\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.93 - ETA: 0s - loss: 0.2869 - accuracy: 0.89 - ETA: 0s - loss: 0.2957 - accuracy: 0.88 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8743 - val_loss: 0.3586 - val_accuracy: 0.8565\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.90 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8757 - val_loss: 0.3677 - val_accuracy: 0.8550\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.87 - ETA: 0s - loss: 0.3048 - accuracy: 0.87 - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.3059 - accuracy: 0.87 - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8732 - val_loss: 0.3654 - val_accuracy: 0.8540\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.81 - ETA: 0s - loss: 0.3070 - accuracy: 0.87 - ETA: 0s - loss: 0.3106 - accuracy: 0.86 - ETA: 0s - loss: 0.2995 - accuracy: 0.87 - ETA: 0s - loss: 0.2995 - accuracy: 0.87 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8772 - val_loss: 0.3585 - val_accuracy: 0.8560\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.96 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - ETA: 0s - loss: 0.3008 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - ETA: 0s - loss: 0.3005 - accuracy: 0.87 - ETA: 0s - loss: 0.3016 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8732 - val_loss: 0.3598 - val_accuracy: 0.8530\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2881 - accuracy: 0.90 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8788 - val_loss: 0.3703 - val_accuracy: 0.8545\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.71 - ETA: 0s - loss: 0.2902 - accuracy: 0.87 - ETA: 0s - loss: 0.3097 - accuracy: 0.86 - ETA: 0s - loss: 0.3053 - accuracy: 0.86 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.3008 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8742 - val_loss: 0.3615 - val_accuracy: 0.8570\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - ETA: 0s - loss: 0.2698 - accuracy: 0.89 - ETA: 0s - loss: 0.2900 - accuracy: 0.88 - ETA: 0s - loss: 0.2870 - accuracy: 0.88 - ETA: 0s - loss: 0.2904 - accuracy: 0.88 - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8775 - val_loss: 0.3651 - val_accuracy: 0.8515\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.87 - ETA: 0s - loss: 0.2868 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.2976 - accuracy: 0.87 - ETA: 0s - loss: 0.2996 - accuracy: 0.87 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - 1s 3ms/step - loss: 0.2994 - accuracy: 0.8790 - val_loss: 0.3611 - val_accuracy: 0.8620\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.87 - ETA: 0s - loss: 0.2884 - accuracy: 0.88 - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - ETA: 0s - loss: 0.2936 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8762 - val_loss: 0.3587 - val_accuracy: 0.8605\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.90 - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - ETA: 0s - loss: 0.2904 - accuracy: 0.88 - ETA: 0s - loss: 0.2885 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2979 - accuracy: 0.8773 - val_loss: 0.3684 - val_accuracy: 0.8560\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.93 - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - ETA: 0s - loss: 0.2914 - accuracy: 0.87 - ETA: 0s - loss: 0.2917 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8775 - val_loss: 0.3640 - val_accuracy: 0.8560\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.84 - ETA: 0s - loss: 0.2998 - accuracy: 0.88 - ETA: 0s - loss: 0.2923 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8793 - val_loss: 0.3700 - val_accuracy: 0.8565\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.93 - ETA: 0s - loss: 0.2646 - accuracy: 0.89 - ETA: 0s - loss: 0.2683 - accuracy: 0.89 - ETA: 0s - loss: 0.2758 - accuracy: 0.88 - ETA: 0s - loss: 0.2811 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8785 - val_loss: 0.3642 - val_accuracy: 0.8590\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.81 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.2802 - accuracy: 0.88 - ETA: 0s - loss: 0.2892 - accuracy: 0.88 - ETA: 0s - loss: 0.2941 - accuracy: 0.87 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8773 - val_loss: 0.3651 - val_accuracy: 0.8535\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.90 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - ETA: 0s - loss: 0.2896 - accuracy: 0.87 - ETA: 0s - loss: 0.2939 - accuracy: 0.87 - ETA: 0s - loss: 0.2942 - accuracy: 0.87 - ETA: 0s - loss: 0.2950 - accuracy: 0.87 - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8797 - val_loss: 0.3664 - val_accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.93 - ETA: 0s - loss: 0.3248 - accuracy: 0.85 - ETA: 0s - loss: 0.2842 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.87 - ETA: 0s - loss: 0.2882 - accuracy: 0.88 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8783 - val_loss: 0.3655 - val_accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.84 - ETA: 0s - loss: 0.2852 - accuracy: 0.89 - ETA: 0s - loss: 0.2851 - accuracy: 0.88 - ETA: 0s - loss: 0.2887 - accuracy: 0.88 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - ETA: 0s - loss: 0.2892 - accuracy: 0.88 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8807 - val_loss: 0.3653 - val_accuracy: 0.8590\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.84 - ETA: 0s - loss: 0.3004 - accuracy: 0.86 - ETA: 0s - loss: 0.2930 - accuracy: 0.87 - ETA: 0s - loss: 0.2925 - accuracy: 0.87 - ETA: 0s - loss: 0.2931 - accuracy: 0.87 - ETA: 0s - loss: 0.2926 - accuracy: 0.87 - ETA: 0s - loss: 0.2914 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8798 - val_loss: 0.3714 - val_accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.93 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.2877 - accuracy: 0.88 - ETA: 0s - loss: 0.2885 - accuracy: 0.88 - ETA: 0s - loss: 0.2917 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8803 - val_loss: 0.3641 - val_accuracy: 0.8595\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.90 - ETA: 0s - loss: 0.2834 - accuracy: 0.89 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2813 - accuracy: 0.88 - ETA: 0s - loss: 0.2860 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8817 - val_loss: 0.3691 - val_accuracy: 0.8555\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.87 - ETA: 0s - loss: 0.3138 - accuracy: 0.86 - ETA: 0s - loss: 0.2703 - accuracy: 0.87 - ETA: 0s - loss: 0.2753 - accuracy: 0.87 - ETA: 0s - loss: 0.2709 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - ETA: 0s - loss: 0.2832 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8820 - val_loss: 0.3628 - val_accuracy: 0.8615\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.90 - ETA: 0s - loss: 0.2663 - accuracy: 0.88 - ETA: 0s - loss: 0.2764 - accuracy: 0.88 - ETA: 0s - loss: 0.2793 - accuracy: 0.88 - ETA: 0s - loss: 0.2816 - accuracy: 0.88 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.2866 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8835 - val_loss: 0.3647 - val_accuracy: 0.8595\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.84 - ETA: 0s - loss: 0.2801 - accuracy: 0.88 - ETA: 0s - loss: 0.2778 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.87 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - ETA: 0s - loss: 0.2869 - accuracy: 0.88 - ETA: 0s - loss: 0.2887 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8813 - val_loss: 0.3654 - val_accuracy: 0.8545\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.87 - ETA: 0s - loss: 0.2797 - accuracy: 0.89 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2799 - accuracy: 0.89 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2914 - accuracy: 0.88 - ETA: 0s - loss: 0.2888 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8838 - val_loss: 0.3739 - val_accuracy: 0.8565\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.62 - ETA: 0s - loss: 0.2875 - accuracy: 0.88 - ETA: 0s - loss: 0.2956 - accuracy: 0.87 - ETA: 0s - loss: 0.2936 - accuracy: 0.87 - ETA: 0s - loss: 0.2932 - accuracy: 0.87 - ETA: 0s - loss: 0.2910 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8837 - val_loss: 0.3701 - val_accuracy: 0.8595\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.90 - ETA: 0s - loss: 0.2413 - accuracy: 0.90 - ETA: 0s - loss: 0.2526 - accuracy: 0.89 - ETA: 0s - loss: 0.2697 - accuracy: 0.89 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.2856 - accuracy: 0.88 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8823 - val_loss: 0.3647 - val_accuracy: 0.8575\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.93 - ETA: 0s - loss: 0.2733 - accuracy: 0.88 - ETA: 0s - loss: 0.2824 - accuracy: 0.87 - ETA: 0s - loss: 0.2658 - accuracy: 0.88 - ETA: 0s - loss: 0.2773 - accuracy: 0.88 - ETA: 0s - loss: 0.2804 - accuracy: 0.88 - ETA: 0s - loss: 0.2837 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8812 - val_loss: 0.3742 - val_accuracy: 0.8515\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.87 - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - ETA: 0s - loss: 0.2896 - accuracy: 0.87 - ETA: 0s - loss: 0.2831 - accuracy: 0.87 - ETA: 0s - loss: 0.2835 - accuracy: 0.87 - ETA: 0s - loss: 0.2811 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8805 - val_loss: 0.3728 - val_accuracy: 0.8560\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.93 - ETA: 0s - loss: 0.2582 - accuracy: 0.89 - ETA: 0s - loss: 0.2682 - accuracy: 0.88 - ETA: 0s - loss: 0.2721 - accuracy: 0.88 - ETA: 0s - loss: 0.2763 - accuracy: 0.88 - ETA: 0s - loss: 0.2774 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8838 - val_loss: 0.3723 - val_accuracy: 0.8605\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.84 - ETA: 0s - loss: 0.2872 - accuracy: 0.87 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2830 - accuracy: 0.88 - ETA: 0s - loss: 0.2841 - accuracy: 0.88 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - ETA: 0s - loss: 0.2838 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8835 - val_loss: 0.3659 - val_accuracy: 0.8585\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.90 - ETA: 0s - loss: 0.2764 - accuracy: 0.89 - ETA: 0s - loss: 0.2843 - accuracy: 0.89 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2776 - accuracy: 0.88 - ETA: 0s - loss: 0.2793 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8855 - val_loss: 0.3712 - val_accuracy: 0.8540\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.87 - ETA: 0s - loss: 0.2803 - accuracy: 0.88 - ETA: 0s - loss: 0.2841 - accuracy: 0.88 - ETA: 0s - loss: 0.2809 - accuracy: 0.88 - ETA: 0s - loss: 0.2869 - accuracy: 0.88 - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - ETA: 0s - loss: 0.2832 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8868 - val_loss: 0.3744 - val_accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.87 - ETA: 0s - loss: 0.2637 - accuracy: 0.89 - ETA: 0s - loss: 0.2658 - accuracy: 0.89 - ETA: 0s - loss: 0.2620 - accuracy: 0.89 - ETA: 0s - loss: 0.2669 - accuracy: 0.88 - ETA: 0s - loss: 0.2701 - accuracy: 0.88 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8847 - val_loss: 0.3675 - val_accuracy: 0.8635\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.1963 - accuracy: 0.90 - ETA: 0s - loss: 0.2745 - accuracy: 0.88 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2913 - accuracy: 0.87 - ETA: 0s - loss: 0.2853 - accuracy: 0.87 - ETA: 0s - loss: 0.2878 - accuracy: 0.87 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8828 - val_loss: 0.3777 - val_accuracy: 0.8580\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.87 - ETA: 0s - loss: 0.2499 - accuracy: 0.90 - ETA: 0s - loss: 0.2608 - accuracy: 0.89 - ETA: 0s - loss: 0.2731 - accuracy: 0.89 - ETA: 0s - loss: 0.2788 - accuracy: 0.88 - ETA: 0s - loss: 0.2752 - accuracy: 0.89 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8850 - val_loss: 0.3702 - val_accuracy: 0.8625\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.96 - ETA: 0s - loss: 0.2551 - accuracy: 0.89 - ETA: 0s - loss: 0.2714 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.88 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - ETA: 0s - loss: 0.2795 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8862 - val_loss: 0.3734 - val_accuracy: 0.8540\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.81 - ETA: 0s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8848 - val_loss: 0.3742 - val_accuracy: 0.8585\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.87 - ETA: 0s - loss: 0.2514 - accuracy: 0.90 - ETA: 0s - loss: 0.2572 - accuracy: 0.89 - ETA: 0s - loss: 0.2670 - accuracy: 0.89 - ETA: 0s - loss: 0.2711 - accuracy: 0.88 - ETA: 0s - loss: 0.2800 - accuracy: 0.88 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8860 - val_loss: 0.3769 - val_accuracy: 0.8615\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.93 - ETA: 0s - loss: 0.2750 - accuracy: 0.88 - ETA: 0s - loss: 0.2847 - accuracy: 0.88 - ETA: 0s - loss: 0.2798 - accuracy: 0.89 - ETA: 0s - loss: 0.2741 - accuracy: 0.88 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.2778 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8867 - val_loss: 0.3732 - val_accuracy: 0.8600\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.96 - ETA: 0s - loss: 0.2809 - accuracy: 0.87 - ETA: 0s - loss: 0.2652 - accuracy: 0.89 - ETA: 0s - loss: 0.2630 - accuracy: 0.88 - ETA: 0s - loss: 0.2636 - accuracy: 0.89 - ETA: 0s - loss: 0.2703 - accuracy: 0.88 - ETA: 0s - loss: 0.2716 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8882 - val_loss: 0.3748 - val_accuracy: 0.8580\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.96 - ETA: 0s - loss: 0.2681 - accuracy: 0.88 - ETA: 0s - loss: 0.2866 - accuracy: 0.88 - ETA: 0s - loss: 0.2826 - accuracy: 0.88 - ETA: 0s - loss: 0.2774 - accuracy: 0.88 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2773 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8877 - val_loss: 0.3811 - val_accuracy: 0.8585\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.90 - ETA: 0s - loss: 0.2698 - accuracy: 0.89 - ETA: 0s - loss: 0.2555 - accuracy: 0.89 - ETA: 0s - loss: 0.2626 - accuracy: 0.89 - ETA: 0s - loss: 0.2646 - accuracy: 0.89 - ETA: 0s - loss: 0.2745 - accuracy: 0.88 - ETA: 0s - loss: 0.2763 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8860 - val_loss: 0.3825 - val_accuracy: 0.8565\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.93 - ETA: 0s - loss: 0.2633 - accuracy: 0.89 - ETA: 0s - loss: 0.2675 - accuracy: 0.89 - ETA: 0s - loss: 0.2730 - accuracy: 0.88 - ETA: 0s - loss: 0.2736 - accuracy: 0.88 - ETA: 0s - loss: 0.2673 - accuracy: 0.89 - ETA: 0s - loss: 0.2722 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8880 - val_loss: 0.3809 - val_accuracy: 0.8560\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.87 - ETA: 0s - loss: 0.2482 - accuracy: 0.90 - ETA: 0s - loss: 0.2610 - accuracy: 0.89 - ETA: 0s - loss: 0.2587 - accuracy: 0.89 - ETA: 0s - loss: 0.2673 - accuracy: 0.89 - ETA: 0s - loss: 0.2713 - accuracy: 0.89 - ETA: 0s - loss: 0.2736 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8897 - val_loss: 0.3993 - val_accuracy: 0.8530\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.96 - ETA: 0s - loss: 0.2824 - accuracy: 0.88 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - ETA: 0s - loss: 0.2667 - accuracy: 0.89 - ETA: 0s - loss: 0.2687 - accuracy: 0.89 - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8880 - val_loss: 0.3886 - val_accuracy: 0.8580\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.87 - ETA: 0s - loss: 0.2788 - accuracy: 0.88 - ETA: 0s - loss: 0.2758 - accuracy: 0.88 - ETA: 0s - loss: 0.2673 - accuracy: 0.89 - ETA: 0s - loss: 0.2717 - accuracy: 0.88 - ETA: 0s - loss: 0.2707 - accuracy: 0.89 - ETA: 0s - loss: 0.2715 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8892 - val_loss: 0.3786 - val_accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.93 - ETA: 0s - loss: 0.2501 - accuracy: 0.89 - ETA: 0s - loss: 0.2626 - accuracy: 0.89 - ETA: 0s - loss: 0.2757 - accuracy: 0.88 - ETA: 0s - loss: 0.2732 - accuracy: 0.88 - ETA: 0s - loss: 0.2772 - accuracy: 0.88 - ETA: 0s - loss: 0.2735 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8890 - val_loss: 0.3824 - val_accuracy: 0.8610\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.78 - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - ETA: 0s - loss: 0.2660 - accuracy: 0.89 - ETA: 0s - loss: 0.2692 - accuracy: 0.89 - ETA: 0s - loss: 0.2700 - accuracy: 0.89 - ETA: 0s - loss: 0.2728 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8887 - val_loss: 0.3758 - val_accuracy: 0.8580\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.90 - ETA: 0s - loss: 0.2350 - accuracy: 0.90 - ETA: 0s - loss: 0.2667 - accuracy: 0.89 - ETA: 0s - loss: 0.2717 - accuracy: 0.89 - ETA: 0s - loss: 0.2667 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8883 - val_loss: 0.3872 - val_accuracy: 0.8560\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.84 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2783 - accuracy: 0.88 - ETA: 0s - loss: 0.2739 - accuracy: 0.89 - ETA: 0s - loss: 0.2747 - accuracy: 0.89 - ETA: 0s - loss: 0.2739 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8913 - val_loss: 0.3932 - val_accuracy: 0.8560\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.87 - ETA: 0s - loss: 0.2826 - accuracy: 0.88 - ETA: 0s - loss: 0.2564 - accuracy: 0.90 - ETA: 0s - loss: 0.2679 - accuracy: 0.89 - ETA: 0s - loss: 0.2657 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8908 - val_loss: 0.3856 - val_accuracy: 0.8615\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2643 - accuracy: 0.90 - ETA: 0s - loss: 0.2732 - accuracy: 0.87 - ETA: 0s - loss: 0.2684 - accuracy: 0.88 - ETA: 0s - loss: 0.2723 - accuracy: 0.88 - ETA: 0s - loss: 0.2701 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8872 - val_loss: 0.3821 - val_accuracy: 0.8580\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.81 - ETA: 0s - loss: 0.2551 - accuracy: 0.89 - ETA: 0s - loss: 0.2628 - accuracy: 0.89 - ETA: 0s - loss: 0.2664 - accuracy: 0.89 - ETA: 0s - loss: 0.2676 - accuracy: 0.89 - ETA: 0s - loss: 0.2708 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8930 - val_loss: 0.3797 - val_accuracy: 0.8575\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.93 - ETA: 0s - loss: 0.2555 - accuracy: 0.90 - ETA: 0s - loss: 0.2574 - accuracy: 0.89 - ETA: 0s - loss: 0.2682 - accuracy: 0.88 - ETA: 0s - loss: 0.2639 - accuracy: 0.88 - ETA: 0s - loss: 0.2650 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8885 - val_loss: 0.3831 - val_accuracy: 0.8545\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2031 - accuracy: 0.96 - ETA: 0s - loss: 0.2402 - accuracy: 0.90 - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - ETA: 0s - loss: 0.2467 - accuracy: 0.90 - ETA: 0s - loss: 0.2556 - accuracy: 0.89 - ETA: 0s - loss: 0.2595 - accuracy: 0.89 - ETA: 0s - loss: 0.2679 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2667 - accuracy: 0.8923 - val_loss: 0.3822 - val_accuracy: 0.8550\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.87 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.2578 - accuracy: 0.90 - ETA: 0s - loss: 0.2576 - accuracy: 0.89 - ETA: 0s - loss: 0.2597 - accuracy: 0.89 - ETA: 0s - loss: 0.2606 - accuracy: 0.89 - ETA: 0s - loss: 0.2662 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8922 - val_loss: 0.3886 - val_accuracy: 0.8570\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.84 - ETA: 0s - loss: 0.2550 - accuracy: 0.89 - ETA: 0s - loss: 0.2422 - accuracy: 0.90 - ETA: 0s - loss: 0.2557 - accuracy: 0.89 - ETA: 0s - loss: 0.2624 - accuracy: 0.89 - ETA: 0s - loss: 0.2630 - accuracy: 0.89 - ETA: 0s - loss: 0.2652 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8903 - val_loss: 0.3820 - val_accuracy: 0.8610\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 1.00 - ETA: 0s - loss: 0.2529 - accuracy: 0.90 - ETA: 0s - loss: 0.2619 - accuracy: 0.89 - ETA: 0s - loss: 0.2637 - accuracy: 0.89 - ETA: 0s - loss: 0.2590 - accuracy: 0.89 - ETA: 0s - loss: 0.2583 - accuracy: 0.89 - ETA: 0s - loss: 0.2654 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8912 - val_loss: 0.3926 - val_accuracy: 0.8625\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.81 - ETA: 0s - loss: 0.2441 - accuracy: 0.90 - ETA: 0s - loss: 0.2577 - accuracy: 0.89 - ETA: 0s - loss: 0.2587 - accuracy: 0.89 - ETA: 0s - loss: 0.2683 - accuracy: 0.88 - ETA: 0s - loss: 0.2643 - accuracy: 0.88 - ETA: 0s - loss: 0.2676 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2674 - accuracy: 0.8903 - val_loss: 0.4018 - val_accuracy: 0.8490\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.78 - ETA: 0s - loss: 0.2622 - accuracy: 0.89 - ETA: 0s - loss: 0.2580 - accuracy: 0.89 - ETA: 0s - loss: 0.2596 - accuracy: 0.89 - ETA: 0s - loss: 0.2623 - accuracy: 0.89 - ETA: 0s - loss: 0.2638 - accuracy: 0.89 - ETA: 0s - loss: 0.2658 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8928 - val_loss: 0.3835 - val_accuracy: 0.8555\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.96 - ETA: 0s - loss: 0.2591 - accuracy: 0.88 - ETA: 0s - loss: 0.2654 - accuracy: 0.88 - ETA: 0s - loss: 0.2626 - accuracy: 0.89 - ETA: 0s - loss: 0.2540 - accuracy: 0.89 - ETA: 0s - loss: 0.2603 - accuracy: 0.89 - ETA: 0s - loss: 0.2644 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8927 - val_loss: 0.3830 - val_accuracy: 0.8580\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.93 - ETA: 0s - loss: 0.2644 - accuracy: 0.89 - ETA: 0s - loss: 0.2651 - accuracy: 0.89 - ETA: 0s - loss: 0.2680 - accuracy: 0.89 - ETA: 0s - loss: 0.2664 - accuracy: 0.89 - ETA: 0s - loss: 0.2645 - accuracy: 0.89 - ETA: 0s - loss: 0.2646 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8915 - val_loss: 0.3870 - val_accuracy: 0.8530\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.90 - ETA: 0s - loss: 0.2511 - accuracy: 0.89 - ETA: 0s - loss: 0.2460 - accuracy: 0.90 - ETA: 0s - loss: 0.2526 - accuracy: 0.89 - ETA: 0s - loss: 0.2502 - accuracy: 0.89 - ETA: 0s - loss: 0.2532 - accuracy: 0.89 - ETA: 0s - loss: 0.2579 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8933 - val_loss: 0.3855 - val_accuracy: 0.8595\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.84 - ETA: 0s - loss: 0.2684 - accuracy: 0.89 - ETA: 0s - loss: 0.2642 - accuracy: 0.89 - ETA: 0s - loss: 0.2692 - accuracy: 0.89 - ETA: 0s - loss: 0.2674 - accuracy: 0.89 - ETA: 0s - loss: 0.2646 - accuracy: 0.89 - ETA: 0s - loss: 0.2641 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8932 - val_loss: 0.3859 - val_accuracy: 0.8580\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.87 - ETA: 0s - loss: 0.2330 - accuracy: 0.89 - ETA: 0s - loss: 0.2587 - accuracy: 0.89 - ETA: 0s - loss: 0.2691 - accuracy: 0.88 - ETA: 0s - loss: 0.2681 - accuracy: 0.88 - ETA: 0s - loss: 0.2679 - accuracy: 0.88 - ETA: 0s - loss: 0.2656 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8902 - val_loss: 0.3918 - val_accuracy: 0.8575\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.90 - ETA: 0s - loss: 0.2519 - accuracy: 0.90 - ETA: 0s - loss: 0.2667 - accuracy: 0.89 - ETA: 0s - loss: 0.2641 - accuracy: 0.89 - ETA: 0s - loss: 0.2673 - accuracy: 0.89 - ETA: 0s - loss: 0.2660 - accuracy: 0.89 - ETA: 0s - loss: 0.2632 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8948 - val_loss: 0.3925 - val_accuracy: 0.8600\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.90 - ETA: 0s - loss: 0.2480 - accuracy: 0.90 - ETA: 0s - loss: 0.2575 - accuracy: 0.90 - ETA: 0s - loss: 0.2592 - accuracy: 0.89 - ETA: 0s - loss: 0.2521 - accuracy: 0.90 - ETA: 0s - loss: 0.2537 - accuracy: 0.89 - ETA: 0s - loss: 0.2602 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8943 - val_loss: 0.3947 - val_accuracy: 0.8530\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.96 - ETA: 0s - loss: 0.2527 - accuracy: 0.89 - ETA: 0s - loss: 0.2743 - accuracy: 0.88 - ETA: 0s - loss: 0.2670 - accuracy: 0.89 - ETA: 0s - loss: 0.2596 - accuracy: 0.89 - ETA: 0s - loss: 0.2627 - accuracy: 0.89 - ETA: 0s - loss: 0.2608 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8978 - val_loss: 0.3960 - val_accuracy: 0.8600\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.93 - ETA: 0s - loss: 0.2347 - accuracy: 0.91 - ETA: 0s - loss: 0.2502 - accuracy: 0.90 - ETA: 0s - loss: 0.2506 - accuracy: 0.90 - ETA: 0s - loss: 0.2544 - accuracy: 0.90 - ETA: 0s - loss: 0.2581 - accuracy: 0.89 - ETA: 0s - loss: 0.2619 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8937 - val_loss: 0.3940 - val_accuracy: 0.8560\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - ETA: 0s - loss: 0.2423 - accuracy: 0.89 - ETA: 0s - loss: 0.2493 - accuracy: 0.89 - ETA: 0s - loss: 0.2535 - accuracy: 0.89 - ETA: 0s - loss: 0.2672 - accuracy: 0.89 - ETA: 0s - loss: 0.2663 - accuracy: 0.89 - ETA: 0s - loss: 0.2634 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8933 - val_loss: 0.3927 - val_accuracy: 0.8575\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.2494 - accuracy: 0.90 - ETA: 0s - loss: 0.2486 - accuracy: 0.90 - ETA: 0s - loss: 0.2622 - accuracy: 0.89 - ETA: 0s - loss: 0.2630 - accuracy: 0.89 - ETA: 0s - loss: 0.2619 - accuracy: 0.89 - ETA: 0s - loss: 0.2593 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8962 - val_loss: 0.3983 - val_accuracy: 0.8505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 111e8a0254257662065566ec0086786e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8650000095367432</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7021 - accuracy: 0.37 - ETA: 0s - loss: 0.6909 - accuracy: 0.54 - ETA: 0s - loss: 0.6750 - accuracy: 0.64 - ETA: 0s - loss: 0.6610 - accuracy: 0.69 - ETA: 0s - loss: 0.6462 - accuracy: 0.72 - 0s 2ms/step - loss: 0.6442 - accuracy: 0.7307 - val_loss: 0.5923 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.84 - ETA: 0s - loss: 0.5976 - accuracy: 0.77 - ETA: 0s - loss: 0.5837 - accuracy: 0.78 - ETA: 0s - loss: 0.5723 - accuracy: 0.78 - ETA: 0s - loss: 0.5612 - accuracy: 0.78 - ETA: 0s - loss: 0.5515 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7948 - val_loss: 0.5088 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.84 - ETA: 0s - loss: 0.5078 - accuracy: 0.79 - ETA: 0s - loss: 0.5022 - accuracy: 0.79 - ETA: 0s - loss: 0.4981 - accuracy: 0.79 - ETA: 0s - loss: 0.4997 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7948 - val_loss: 0.4849 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.75 - ETA: 0s - loss: 0.4906 - accuracy: 0.79 - ETA: 0s - loss: 0.4935 - accuracy: 0.79 - ETA: 0s - loss: 0.4872 - accuracy: 0.79 - ETA: 0s - loss: 0.4824 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7948 - val_loss: 0.4728 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.65 - ETA: 0s - loss: 0.4676 - accuracy: 0.80 - ETA: 0s - loss: 0.4650 - accuracy: 0.80 - ETA: 0s - loss: 0.4681 - accuracy: 0.79 - ETA: 0s - loss: 0.4669 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7948 - val_loss: 0.4622 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.81 - ETA: 0s - loss: 0.4691 - accuracy: 0.79 - ETA: 0s - loss: 0.4619 - accuracy: 0.79 - ETA: 0s - loss: 0.4551 - accuracy: 0.79 - ETA: 0s - loss: 0.4529 - accuracy: 0.79 - ETA: 0s - loss: 0.4565 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7948 - val_loss: 0.4525 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3687 - accuracy: 0.84 - ETA: 0s - loss: 0.4463 - accuracy: 0.79 - ETA: 0s - loss: 0.4496 - accuracy: 0.79 - ETA: 0s - loss: 0.4508 - accuracy: 0.79 - ETA: 0s - loss: 0.4490 - accuracy: 0.79 - ETA: 0s - loss: 0.4444 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7983 - val_loss: 0.4439 - val_accuracy: 0.8035\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.71 - ETA: 0s - loss: 0.4607 - accuracy: 0.78 - ETA: 0s - loss: 0.4439 - accuracy: 0.80 - ETA: 0s - loss: 0.4418 - accuracy: 0.80 - ETA: 0s - loss: 0.4417 - accuracy: 0.80 - ETA: 0s - loss: 0.4361 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8040 - val_loss: 0.4388 - val_accuracy: 0.8095\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.68 - ETA: 0s - loss: 0.4398 - accuracy: 0.79 - ETA: 0s - loss: 0.4215 - accuracy: 0.81 - ETA: 0s - loss: 0.4200 - accuracy: 0.81 - ETA: 0s - loss: 0.4256 - accuracy: 0.81 - ETA: 0s - loss: 0.4295 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8062 - val_loss: 0.4349 - val_accuracy: 0.8130\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.78 - ETA: 0s - loss: 0.4277 - accuracy: 0.81 - ETA: 0s - loss: 0.4213 - accuracy: 0.81 - ETA: 0s - loss: 0.4256 - accuracy: 0.81 - ETA: 0s - loss: 0.4282 - accuracy: 0.80 - ETA: 0s - loss: 0.4220 - accuracy: 0.81 - ETA: 0s - loss: 0.4260 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8145 - val_loss: 0.4319 - val_accuracy: 0.8145\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.81 - ETA: 0s - loss: 0.4630 - accuracy: 0.79 - ETA: 0s - loss: 0.4339 - accuracy: 0.80 - ETA: 0s - loss: 0.4306 - accuracy: 0.80 - ETA: 0s - loss: 0.4271 - accuracy: 0.81 - ETA: 0s - loss: 0.4240 - accuracy: 0.81 - ETA: 0s - loss: 0.4202 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8198 - val_loss: 0.4297 - val_accuracy: 0.8165\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.71 - ETA: 0s - loss: 0.4239 - accuracy: 0.82 - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - ETA: 0s - loss: 0.4191 - accuracy: 0.82 - ETA: 0s - loss: 0.4158 - accuracy: 0.82 - ETA: 0s - loss: 0.4209 - accuracy: 0.81 - ETA: 0s - loss: 0.4179 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8210 - val_loss: 0.4279 - val_accuracy: 0.8160\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3850 - accuracy: 0.83 - ETA: 0s - loss: 0.3973 - accuracy: 0.83 - ETA: 0s - loss: 0.4055 - accuracy: 0.82 - ETA: 0s - loss: 0.4117 - accuracy: 0.82 - ETA: 0s - loss: 0.4142 - accuracy: 0.82 - ETA: 0s - loss: 0.4132 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8213 - val_loss: 0.4261 - val_accuracy: 0.8180\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.87 - ETA: 0s - loss: 0.3916 - accuracy: 0.83 - ETA: 0s - loss: 0.4102 - accuracy: 0.82 - ETA: 0s - loss: 0.4058 - accuracy: 0.82 - ETA: 0s - loss: 0.4047 - accuracy: 0.82 - ETA: 0s - loss: 0.4124 - accuracy: 0.82 - ETA: 0s - loss: 0.4117 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8230 - val_loss: 0.4245 - val_accuracy: 0.8215\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.90 - ETA: 0s - loss: 0.4472 - accuracy: 0.81 - ETA: 0s - loss: 0.4313 - accuracy: 0.82 - ETA: 0s - loss: 0.4257 - accuracy: 0.82 - ETA: 0s - loss: 0.4163 - accuracy: 0.82 - ETA: 0s - loss: 0.4105 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8253 - val_loss: 0.4239 - val_accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.81 - ETA: 0s - loss: 0.4203 - accuracy: 0.81 - ETA: 0s - loss: 0.4197 - accuracy: 0.81 - ETA: 0s - loss: 0.4170 - accuracy: 0.82 - ETA: 0s - loss: 0.4074 - accuracy: 0.82 - ETA: 0s - loss: 0.4095 - accuracy: 0.82 - ETA: 0s - loss: 0.4061 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8260 - val_loss: 0.4218 - val_accuracy: 0.8255\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.84 - ETA: 0s - loss: 0.3976 - accuracy: 0.83 - ETA: 0s - loss: 0.4007 - accuracy: 0.81 - ETA: 0s - loss: 0.4109 - accuracy: 0.81 - ETA: 0s - loss: 0.4062 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8285 - val_loss: 0.4203 - val_accuracy: 0.8265\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.78 - ETA: 0s - loss: 0.4368 - accuracy: 0.80 - ETA: 0s - loss: 0.4156 - accuracy: 0.81 - ETA: 0s - loss: 0.4068 - accuracy: 0.82 - ETA: 0s - loss: 0.4053 - accuracy: 0.82 - ETA: 0s - loss: 0.4008 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8290 - val_loss: 0.4186 - val_accuracy: 0.8255\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.90 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.4037 - accuracy: 0.82 - ETA: 0s - loss: 0.3984 - accuracy: 0.83 - ETA: 0s - loss: 0.3962 - accuracy: 0.83 - ETA: 0s - loss: 0.3989 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8320 - val_loss: 0.4172 - val_accuracy: 0.8230\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.81 - ETA: 0s - loss: 0.3918 - accuracy: 0.83 - ETA: 0s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.4075 - accuracy: 0.82 - ETA: 0s - loss: 0.3969 - accuracy: 0.83 - ETA: 0s - loss: 0.3984 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8330 - val_loss: 0.4159 - val_accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.87 - ETA: 0s - loss: 0.3848 - accuracy: 0.84 - ETA: 0s - loss: 0.4004 - accuracy: 0.83 - ETA: 0s - loss: 0.3951 - accuracy: 0.83 - ETA: 0s - loss: 0.3869 - accuracy: 0.84 - ETA: 0s - loss: 0.3938 - accuracy: 0.83 - ETA: 0s - loss: 0.3921 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8358 - val_loss: 0.4143 - val_accuracy: 0.8220\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.78 - ETA: 0s - loss: 0.4015 - accuracy: 0.82 - ETA: 0s - loss: 0.4028 - accuracy: 0.82 - ETA: 0s - loss: 0.3979 - accuracy: 0.83 - ETA: 0s - loss: 0.3940 - accuracy: 0.83 - ETA: 0s - loss: 0.3925 - accuracy: 0.83 - ETA: 0s - loss: 0.3934 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8373 - val_loss: 0.4126 - val_accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.90 - ETA: 0s - loss: 0.3701 - accuracy: 0.85 - ETA: 0s - loss: 0.3831 - accuracy: 0.84 - ETA: 0s - loss: 0.3859 - accuracy: 0.84 - ETA: 0s - loss: 0.3872 - accuracy: 0.84 - ETA: 0s - loss: 0.3906 - accuracy: 0.83 - ETA: 0s - loss: 0.3908 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8378 - val_loss: 0.4115 - val_accuracy: 0.8225\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.81 - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.3909 - accuracy: 0.84 - ETA: 0s - loss: 0.3860 - accuracy: 0.84 - ETA: 0s - loss: 0.3889 - accuracy: 0.84 - ETA: 0s - loss: 0.3883 - accuracy: 0.83 - ETA: 0s - loss: 0.3885 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8398 - val_loss: 0.4098 - val_accuracy: 0.8185\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.93 - ETA: 0s - loss: 0.3657 - accuracy: 0.86 - ETA: 0s - loss: 0.3805 - accuracy: 0.84 - ETA: 0s - loss: 0.3855 - accuracy: 0.84 - ETA: 0s - loss: 0.3916 - accuracy: 0.83 - ETA: 0s - loss: 0.3906 - accuracy: 0.83 - ETA: 0s - loss: 0.3856 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8402 - val_loss: 0.4090 - val_accuracy: 0.8255\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.87 - ETA: 0s - loss: 0.3821 - accuracy: 0.84 - ETA: 0s - loss: 0.3880 - accuracy: 0.83 - ETA: 0s - loss: 0.3908 - accuracy: 0.83 - ETA: 0s - loss: 0.3887 - accuracy: 0.83 - ETA: 0s - loss: 0.3910 - accuracy: 0.83 - ETA: 0s - loss: 0.3838 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8400 - val_loss: 0.4073 - val_accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.75 - ETA: 0s - loss: 0.3951 - accuracy: 0.84 - ETA: 0s - loss: 0.3873 - accuracy: 0.84 - ETA: 0s - loss: 0.3800 - accuracy: 0.84 - ETA: 0s - loss: 0.3830 - accuracy: 0.83 - ETA: 0s - loss: 0.3817 - accuracy: 0.83 - ETA: 0s - loss: 0.3785 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8410 - val_loss: 0.4055 - val_accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.93 - ETA: 0s - loss: 0.3974 - accuracy: 0.82 - ETA: 0s - loss: 0.3893 - accuracy: 0.83 - ETA: 0s - loss: 0.3922 - accuracy: 0.83 - ETA: 0s - loss: 0.3883 - accuracy: 0.83 - ETA: 0s - loss: 0.3823 - accuracy: 0.83 - ETA: 0s - loss: 0.3787 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8413 - val_loss: 0.4043 - val_accuracy: 0.8245\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.81 - ETA: 0s - loss: 0.3794 - accuracy: 0.83 - ETA: 0s - loss: 0.3685 - accuracy: 0.84 - ETA: 0s - loss: 0.3855 - accuracy: 0.83 - ETA: 0s - loss: 0.3828 - accuracy: 0.83 - ETA: 0s - loss: 0.3777 - accuracy: 0.84 - ETA: 0s - loss: 0.3765 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8427 - val_loss: 0.4024 - val_accuracy: 0.8255\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.81 - ETA: 0s - loss: 0.3759 - accuracy: 0.84 - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - ETA: 0s - loss: 0.3707 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3690 - accuracy: 0.84 - ETA: 0s - loss: 0.3706 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8445 - val_loss: 0.4008 - val_accuracy: 0.8270\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.81 - ETA: 0s - loss: 0.3736 - accuracy: 0.84 - ETA: 0s - loss: 0.3791 - accuracy: 0.84 - ETA: 0s - loss: 0.3715 - accuracy: 0.84 - ETA: 0s - loss: 0.3721 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8455 - val_loss: 0.3998 - val_accuracy: 0.8265\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.81 - ETA: 0s - loss: 0.3737 - accuracy: 0.83 - ETA: 0s - loss: 0.3747 - accuracy: 0.83 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3733 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8472 - val_loss: 0.3980 - val_accuracy: 0.8305\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.90 - ETA: 0s - loss: 0.3938 - accuracy: 0.83 - ETA: 0s - loss: 0.3683 - accuracy: 0.84 - ETA: 0s - loss: 0.3644 - accuracy: 0.85 - ETA: 0s - loss: 0.3605 - accuracy: 0.85 - ETA: 0s - loss: 0.3671 - accuracy: 0.84 - ETA: 0s - loss: 0.3698 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8472 - val_loss: 0.3968 - val_accuracy: 0.8300\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.93 - ETA: 0s - loss: 0.3788 - accuracy: 0.82 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - ETA: 0s - loss: 0.3700 - accuracy: 0.84 - ETA: 0s - loss: 0.3705 - accuracy: 0.84 - ETA: 0s - loss: 0.3686 - accuracy: 0.84 - ETA: 0s - loss: 0.3670 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8472 - val_loss: 0.3956 - val_accuracy: 0.8325\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - ETA: 0s - loss: 0.3692 - accuracy: 0.84 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8495 - val_loss: 0.3941 - val_accuracy: 0.8320\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.81 - ETA: 0s - loss: 0.4000 - accuracy: 0.82 - ETA: 0s - loss: 0.3818 - accuracy: 0.83 - ETA: 0s - loss: 0.3864 - accuracy: 0.83 - ETA: 0s - loss: 0.3785 - accuracy: 0.84 - ETA: 0s - loss: 0.3657 - accuracy: 0.84 - ETA: 0s - loss: 0.3636 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8485 - val_loss: 0.3929 - val_accuracy: 0.8345\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.81 - ETA: 0s - loss: 0.3599 - accuracy: 0.83 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - ETA: 0s - loss: 0.3599 - accuracy: 0.84 - ETA: 0s - loss: 0.3665 - accuracy: 0.84 - ETA: 0s - loss: 0.3621 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8498 - val_loss: 0.3917 - val_accuracy: 0.8370\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.84 - ETA: 0s - loss: 0.3533 - accuracy: 0.86 - ETA: 0s - loss: 0.3640 - accuracy: 0.84 - ETA: 0s - loss: 0.3591 - accuracy: 0.85 - ETA: 0s - loss: 0.3575 - accuracy: 0.85 - ETA: 0s - loss: 0.3623 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8503 - val_loss: 0.3903 - val_accuracy: 0.8365\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.75 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3494 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - ETA: 0s - loss: 0.3593 - accuracy: 0.85 - ETA: 0s - loss: 0.3594 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8517 - val_loss: 0.3897 - val_accuracy: 0.8355\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.93 - ETA: 0s - loss: 0.3608 - accuracy: 0.84 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3574 - accuracy: 0.84 - ETA: 0s - loss: 0.3585 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8525 - val_loss: 0.3879 - val_accuracy: 0.8370\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.87 - ETA: 0s - loss: 0.3460 - accuracy: 0.87 - ETA: 0s - loss: 0.3543 - accuracy: 0.85 - ETA: 0s - loss: 0.3505 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - ETA: 0s - loss: 0.3545 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8535 - val_loss: 0.3870 - val_accuracy: 0.8380\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.84 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8542 - val_loss: 0.3859 - val_accuracy: 0.8375\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.81 - ETA: 0s - loss: 0.3587 - accuracy: 0.86 - ETA: 0s - loss: 0.3678 - accuracy: 0.85 - ETA: 0s - loss: 0.3568 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.86 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8538 - val_loss: 0.3848 - val_accuracy: 0.8405\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.71 - ETA: 0s - loss: 0.3793 - accuracy: 0.84 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - ETA: 0s - loss: 0.3585 - accuracy: 0.84 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8540 - val_loss: 0.3841 - val_accuracy: 0.8390\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.81 - ETA: 0s - loss: 0.3567 - accuracy: 0.84 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3484 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8538 - val_loss: 0.3833 - val_accuracy: 0.8400\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.81 - ETA: 0s - loss: 0.3712 - accuracy: 0.85 - ETA: 0s - loss: 0.3803 - accuracy: 0.83 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3545 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8548 - val_loss: 0.3825 - val_accuracy: 0.8395\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3596 - accuracy: 0.84 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3543 - accuracy: 0.85 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - ETA: 0s - loss: 0.3458 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8553 - val_loss: 0.3826 - val_accuracy: 0.8415\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.81 - ETA: 0s - loss: 0.3693 - accuracy: 0.85 - ETA: 0s - loss: 0.3711 - accuracy: 0.84 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8565 - val_loss: 0.3809 - val_accuracy: 0.8410\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.84 - ETA: 0s - loss: 0.3458 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.85 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8562 - val_loss: 0.3802 - val_accuracy: 0.8420\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.93 - ETA: 0s - loss: 0.3469 - accuracy: 0.85 - ETA: 0s - loss: 0.3624 - accuracy: 0.84 - ETA: 0s - loss: 0.3563 - accuracy: 0.84 - ETA: 0s - loss: 0.3522 - accuracy: 0.84 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8572 - val_loss: 0.3801 - val_accuracy: 0.8420\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3439 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8578 - val_loss: 0.3787 - val_accuracy: 0.8425\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.84 - ETA: 0s - loss: 0.3154 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.85 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - ETA: 0s - loss: 0.3441 - accuracy: 0.85 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3446 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8585 - val_loss: 0.3782 - val_accuracy: 0.8435\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.81 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - ETA: 0s - loss: 0.3390 - accuracy: 0.85 - ETA: 0s - loss: 0.3418 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8587 - val_loss: 0.3781 - val_accuracy: 0.8440\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.90 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3379 - accuracy: 0.86 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8580 - val_loss: 0.3771 - val_accuracy: 0.8435\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 1.00 - ETA: 0s - loss: 0.3592 - accuracy: 0.84 - ETA: 0s - loss: 0.3462 - accuracy: 0.84 - ETA: 0s - loss: 0.3387 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8590 - val_loss: 0.3791 - val_accuracy: 0.8440\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.87 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3396 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8573 - val_loss: 0.3778 - val_accuracy: 0.8445\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.81 - ETA: 0s - loss: 0.3530 - accuracy: 0.84 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.85 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8602 - val_loss: 0.3761 - val_accuracy: 0.8435\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.90 - ETA: 0s - loss: 0.3626 - accuracy: 0.84 - ETA: 0s - loss: 0.3537 - accuracy: 0.84 - ETA: 0s - loss: 0.3413 - accuracy: 0.85 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8590 - val_loss: 0.3759 - val_accuracy: 0.8450\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.87 - ETA: 0s - loss: 0.3629 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - ETA: 0s - loss: 0.3399 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8593 - val_loss: 0.3754 - val_accuracy: 0.8460\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.87 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3355 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8582 - val_loss: 0.3752 - val_accuracy: 0.8455\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.81 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.87 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8605 - val_loss: 0.3747 - val_accuracy: 0.8465\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.78 - ETA: 0s - loss: 0.3364 - accuracy: 0.85 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3432 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8610 - val_loss: 0.3773 - val_accuracy: 0.8445\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.87 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8617 - val_loss: 0.3760 - val_accuracy: 0.8440\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.93 - ETA: 0s - loss: 0.2998 - accuracy: 0.88 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8602 - val_loss: 0.3742 - val_accuracy: 0.8470\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.81 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - ETA: 0s - loss: 0.3495 - accuracy: 0.85 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - ETA: 0s - loss: 0.3383 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8617 - val_loss: 0.3739 - val_accuracy: 0.8480\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.93 - ETA: 0s - loss: 0.3408 - accuracy: 0.85 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - ETA: 0s - loss: 0.3372 - accuracy: 0.85 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8617 - val_loss: 0.3747 - val_accuracy: 0.8445\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.87 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8632 - val_loss: 0.3737 - val_accuracy: 0.8495\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.87 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3408 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8633 - val_loss: 0.3744 - val_accuracy: 0.8445\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.90 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8617 - val_loss: 0.3744 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.87 - ETA: 0s - loss: 0.3605 - accuracy: 0.85 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8625 - val_loss: 0.3736 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.96 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.85 - ETA: 0s - loss: 0.3314 - accuracy: 0.85 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8633 - val_loss: 0.3725 - val_accuracy: 0.8480\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.87 - ETA: 0s - loss: 0.3169 - accuracy: 0.87 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8657 - val_loss: 0.3723 - val_accuracy: 0.8485\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 1.00 - ETA: 0s - loss: 0.2939 - accuracy: 0.88 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8647 - val_loss: 0.3719 - val_accuracy: 0.8510\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.81 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8643 - val_loss: 0.3741 - val_accuracy: 0.8460\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.78 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3423 - accuracy: 0.85 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8652 - val_loss: 0.3718 - val_accuracy: 0.8490\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.93 - ETA: 0s - loss: 0.3243 - accuracy: 0.85 - ETA: 0s - loss: 0.3213 - accuracy: 0.85 - ETA: 0s - loss: 0.3304 - accuracy: 0.85 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8653 - val_loss: 0.3717 - val_accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.87 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8643 - val_loss: 0.3715 - val_accuracy: 0.8505\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.81 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8647 - val_loss: 0.3713 - val_accuracy: 0.8505\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.90 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8645 - val_loss: 0.3716 - val_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.87 - ETA: 0s - loss: 0.3008 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - ETA: 0s - loss: 0.3119 - accuracy: 0.87 - ETA: 0s - loss: 0.3120 - accuracy: 0.87 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8660 - val_loss: 0.3715 - val_accuracy: 0.8500\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.84 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.87 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8660 - val_loss: 0.3707 - val_accuracy: 0.8505\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.85 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3266 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8655 - val_loss: 0.3714 - val_accuracy: 0.8485\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.84 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.86 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8667 - val_loss: 0.3706 - val_accuracy: 0.8500\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.87 - ETA: 0s - loss: 0.3440 - accuracy: 0.86 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8653 - val_loss: 0.3706 - val_accuracy: 0.8505\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.84 - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - ETA: 0s - loss: 0.3173 - accuracy: 0.87 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8665 - val_loss: 0.3702 - val_accuracy: 0.8515\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2923 - accuracy: 0.90 - ETA: 0s - loss: 0.3351 - accuracy: 0.85 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - ETA: 0s - loss: 0.3198 - accuracy: 0.87 - ETA: 0s - loss: 0.3233 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8692 - val_loss: 0.3703 - val_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.93 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - ETA: 0s - loss: 0.3187 - accuracy: 0.87 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8660 - val_loss: 0.3700 - val_accuracy: 0.8500\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8680 - val_loss: 0.3704 - val_accuracy: 0.8505\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.78 - ETA: 0s - loss: 0.3177 - accuracy: 0.86 - ETA: 0s - loss: 0.3222 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.87 - ETA: 0s - loss: 0.3210 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8672 - val_loss: 0.3700 - val_accuracy: 0.8515\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.81 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8683 - val_loss: 0.3695 - val_accuracy: 0.8520\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.96 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8675 - val_loss: 0.3709 - val_accuracy: 0.8490\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.87 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.2991 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3216 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8655 - val_loss: 0.3701 - val_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.78 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3194 - accuracy: 0.86 - ETA: 0s - loss: 0.3237 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8687 - val_loss: 0.3692 - val_accuracy: 0.8520\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.90 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3162 - accuracy: 0.86 - ETA: 0s - loss: 0.3166 - accuracy: 0.87 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8670 - val_loss: 0.3691 - val_accuracy: 0.8510\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3141 - accuracy: 0.87 - ETA: 0s - loss: 0.3185 - accuracy: 0.87 - ETA: 0s - loss: 0.3169 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8677 - val_loss: 0.3693 - val_accuracy: 0.8510\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.75 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3298 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8692 - val_loss: 0.3709 - val_accuracy: 0.8505\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.84 - ETA: 0s - loss: 0.3100 - accuracy: 0.87 - ETA: 0s - loss: 0.3157 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8675 - val_loss: 0.3688 - val_accuracy: 0.8530\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3406 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8690 - val_loss: 0.3691 - val_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.90 - ETA: 0s - loss: 0.3441 - accuracy: 0.85 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - ETA: 0s - loss: 0.3186 - accuracy: 0.87 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8688 - val_loss: 0.3688 - val_accuracy: 0.8505\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.90 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8663 - val_loss: 0.3690 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ae5c6b05ba6be669fbf51c274bb18ca7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8539999723434448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.56 - ETA: 0s - loss: 0.5005 - accuracy: 0.77 - ETA: 0s - loss: 0.4700 - accuracy: 0.79 - ETA: 0s - loss: 0.4460 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8157 - val_loss: 0.3921 - val_accuracy: 0.8455\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.81 - ETA: 0s - loss: 0.3726 - accuracy: 0.85 - ETA: 0s - loss: 0.3579 - accuracy: 0.85 - ETA: 0s - loss: 0.3718 - accuracy: 0.84 - ETA: 0s - loss: 0.3678 - accuracy: 0.84 - ETA: 0s - loss: 0.3675 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8468 - val_loss: 0.3605 - val_accuracy: 0.8495\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.81 - ETA: 0s - loss: 0.3709 - accuracy: 0.83 - ETA: 0s - loss: 0.3545 - accuracy: 0.84 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - ETA: 0s - loss: 0.3484 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8560 - val_loss: 0.3569 - val_accuracy: 0.8565\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.90 - ETA: 0s - loss: 0.3736 - accuracy: 0.83 - ETA: 0s - loss: 0.3441 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.85 - ETA: 0s - loss: 0.3446 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8590 - val_loss: 0.3597 - val_accuracy: 0.8540\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.81 - ETA: 0s - loss: 0.3584 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3495 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8622 - val_loss: 0.3572 - val_accuracy: 0.8560\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 1.00 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - ETA: 0s - loss: 0.3232 - accuracy: 0.87 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8617 - val_loss: 0.3486 - val_accuracy: 0.8545\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4560 - accuracy: 0.78 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.87 - ETA: 0s - loss: 0.3285 - accuracy: 0.87 - ETA: 0s - loss: 0.3343 - accuracy: 0.87 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8622 - val_loss: 0.3647 - val_accuracy: 0.8475\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.84 - ETA: 0s - loss: 0.3622 - accuracy: 0.84 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8620 - val_loss: 0.3457 - val_accuracy: 0.8580\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.75 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8623 - val_loss: 0.3492 - val_accuracy: 0.8585\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.78 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8635 - val_loss: 0.3512 - val_accuracy: 0.8635\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.81 - ETA: 0s - loss: 0.3417 - accuracy: 0.84 - ETA: 0s - loss: 0.3369 - accuracy: 0.85 - ETA: 0s - loss: 0.3344 - accuracy: 0.85 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8603 - val_loss: 0.3465 - val_accuracy: 0.8580\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.87 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - ETA: 0s - loss: 0.3275 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3386 - accuracy: 0.85 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8630 - val_loss: 0.3538 - val_accuracy: 0.8595\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.93 - ETA: 0s - loss: 0.3259 - accuracy: 0.85 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8663 - val_loss: 0.3478 - val_accuracy: 0.8590\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.84 - ETA: 0s - loss: 0.3611 - accuracy: 0.84 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3362 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - ETA: 0s - loss: 0.3314 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8652 - val_loss: 0.3561 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.90 - ETA: 0s - loss: 0.2939 - accuracy: 0.88 - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8668 - val_loss: 0.3508 - val_accuracy: 0.8575\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.87 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8658 - val_loss: 0.3511 - val_accuracy: 0.8550\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.96 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - ETA: 0s - loss: 0.3171 - accuracy: 0.86 - ETA: 0s - loss: 0.3149 - accuracy: 0.86 - ETA: 0s - loss: 0.3147 - accuracy: 0.86 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8642 - val_loss: 0.3496 - val_accuracy: 0.8545\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.90 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3143 - accuracy: 0.86 - ETA: 0s - loss: 0.3197 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8653 - val_loss: 0.3508 - val_accuracy: 0.8575\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.93 - ETA: 0s - loss: 0.3583 - accuracy: 0.85 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - ETA: 0s - loss: 0.3378 - accuracy: 0.85 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8667 - val_loss: 0.3625 - val_accuracy: 0.8610\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.87 - ETA: 0s - loss: 0.2707 - accuracy: 0.89 - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - ETA: 0s - loss: 0.3170 - accuracy: 0.86 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8660 - val_loss: 0.3540 - val_accuracy: 0.8555\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - ETA: 0s - loss: 0.3187 - accuracy: 0.86 - ETA: 0s - loss: 0.3186 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8668 - val_loss: 0.3470 - val_accuracy: 0.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.75 - ETA: 0s - loss: 0.3315 - accuracy: 0.85 - ETA: 0s - loss: 0.3538 - accuracy: 0.84 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3288 - accuracy: 0.85 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8638 - val_loss: 0.3583 - val_accuracy: 0.8560\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.96 - ETA: 0s - loss: 0.3001 - accuracy: 0.88 - ETA: 0s - loss: 0.2964 - accuracy: 0.88 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3149 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8693 - val_loss: 0.3505 - val_accuracy: 0.8555\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.86 - ETA: 0s - loss: 0.3170 - accuracy: 0.86 - ETA: 0s - loss: 0.3179 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8687 - val_loss: 0.3558 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.93 - ETA: 0s - loss: 0.3112 - accuracy: 0.86 - ETA: 0s - loss: 0.3033 - accuracy: 0.86 - ETA: 0s - loss: 0.3134 - accuracy: 0.86 - ETA: 0s - loss: 0.3124 - accuracy: 0.86 - ETA: 0s - loss: 0.3067 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8662 - val_loss: 0.3571 - val_accuracy: 0.8505\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.84 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3271 - accuracy: 0.85 - ETA: 0s - loss: 0.3189 - accuracy: 0.86 - ETA: 0s - loss: 0.3163 - accuracy: 0.86 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8682 - val_loss: 0.3541 - val_accuracy: 0.8570\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.93 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.86 - ETA: 0s - loss: 0.3212 - accuracy: 0.86 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8657 - val_loss: 0.3559 - val_accuracy: 0.8495\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.84 - ETA: 0s - loss: 0.3098 - accuracy: 0.87 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.85 - ETA: 0s - loss: 0.3174 - accuracy: 0.86 - ETA: 0s - loss: 0.3145 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8675 - val_loss: 0.3717 - val_accuracy: 0.8490\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.81 - ETA: 0s - loss: 0.3000 - accuracy: 0.88 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3015 - accuracy: 0.87 - ETA: 0s - loss: 0.3023 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3160 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8690 - val_loss: 0.3635 - val_accuracy: 0.8560\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.93 - ETA: 0s - loss: 0.3149 - accuracy: 0.88 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8678 - val_loss: 0.3532 - val_accuracy: 0.8560\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.71 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - ETA: 0s - loss: 0.3150 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8710 - val_loss: 0.3468 - val_accuracy: 0.8610\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.87 - ETA: 0s - loss: 0.3089 - accuracy: 0.87 - ETA: 0s - loss: 0.3141 - accuracy: 0.86 - ETA: 0s - loss: 0.3153 - accuracy: 0.86 - ETA: 0s - loss: 0.3144 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8688 - val_loss: 0.3657 - val_accuracy: 0.8550\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.93 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3129 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8702 - val_loss: 0.3586 - val_accuracy: 0.8530\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.90 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3091 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8702 - val_loss: 0.3673 - val_accuracy: 0.8510\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.81 - ETA: 0s - loss: 0.3211 - accuracy: 0.87 - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - ETA: 0s - loss: 0.3063 - accuracy: 0.87 - ETA: 0s - loss: 0.3096 - accuracy: 0.86 - ETA: 0s - loss: 0.3091 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8685 - val_loss: 0.3664 - val_accuracy: 0.8580\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.78 - ETA: 0s - loss: 0.3171 - accuracy: 0.86 - ETA: 0s - loss: 0.3057 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3098 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8692 - val_loss: 0.3630 - val_accuracy: 0.8570\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.90 - ETA: 0s - loss: 0.3210 - accuracy: 0.85 - ETA: 0s - loss: 0.3111 - accuracy: 0.86 - ETA: 0s - loss: 0.3134 - accuracy: 0.86 - ETA: 0s - loss: 0.3088 - accuracy: 0.86 - ETA: 0s - loss: 0.3068 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8683 - val_loss: 0.3596 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 1.00 - ETA: 0s - loss: 0.2747 - accuracy: 0.88 - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.3034 - accuracy: 0.87 - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - ETA: 0s - loss: 0.3074 - accuracy: 0.87 - ETA: 0s - loss: 0.3094 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8725 - val_loss: 0.3657 - val_accuracy: 0.8510\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.81 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3114 - accuracy: 0.87 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8737 - val_loss: 0.3690 - val_accuracy: 0.8560\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.71 - ETA: 0s - loss: 0.2671 - accuracy: 0.87 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8740 - val_loss: 0.3783 - val_accuracy: 0.8485\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.87 - ETA: 0s - loss: 0.3026 - accuracy: 0.89 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8720 - val_loss: 0.3636 - val_accuracy: 0.8565\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.84 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - ETA: 0s - loss: 0.3124 - accuracy: 0.86 - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8747 - val_loss: 0.3620 - val_accuracy: 0.8545\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 1.00 - ETA: 0s - loss: 0.2806 - accuracy: 0.88 - ETA: 0s - loss: 0.2932 - accuracy: 0.88 - ETA: 0s - loss: 0.2977 - accuracy: 0.88 - ETA: 0s - loss: 0.3017 - accuracy: 0.87 - ETA: 0s - loss: 0.3048 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8740 - val_loss: 0.3729 - val_accuracy: 0.8515\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.93 - ETA: 0s - loss: 0.2853 - accuracy: 0.89 - ETA: 0s - loss: 0.3035 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.2991 - accuracy: 0.87 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8765 - val_loss: 0.3849 - val_accuracy: 0.8570\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.87 - ETA: 0s - loss: 0.3321 - accuracy: 0.85 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.2990 - accuracy: 0.88 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8755 - val_loss: 0.3776 - val_accuracy: 0.8560\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.90 - ETA: 0s - loss: 0.2974 - accuracy: 0.86 - ETA: 0s - loss: 0.2950 - accuracy: 0.87 - ETA: 0s - loss: 0.2874 - accuracy: 0.87 - ETA: 0s - loss: 0.2979 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3048 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8748 - val_loss: 0.3702 - val_accuracy: 0.8520\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.81 - ETA: 0s - loss: 0.2922 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3033 - accuracy: 0.87 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8743 - val_loss: 0.3771 - val_accuracy: 0.8510\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.90 - ETA: 0s - loss: 0.2871 - accuracy: 0.87 - ETA: 0s - loss: 0.2870 - accuracy: 0.88 - ETA: 0s - loss: 0.3016 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8742 - val_loss: 0.3849 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.78 - ETA: 0s - loss: 0.3165 - accuracy: 0.85 - ETA: 0s - loss: 0.3017 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.3001 - accuracy: 0.87 - ETA: 0s - loss: 0.3017 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8757 - val_loss: 0.3815 - val_accuracy: 0.8510\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.87 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - ETA: 0s - loss: 0.3034 - accuracy: 0.87 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.2984 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8748 - val_loss: 0.3891 - val_accuracy: 0.8505\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.93 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2844 - accuracy: 0.88 - ETA: 0s - loss: 0.2879 - accuracy: 0.88 - ETA: 0s - loss: 0.2945 - accuracy: 0.88 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8775 - val_loss: 0.3703 - val_accuracy: 0.8505\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.93 - ETA: 0s - loss: 0.2925 - accuracy: 0.87 - ETA: 0s - loss: 0.2933 - accuracy: 0.87 - ETA: 0s - loss: 0.2950 - accuracy: 0.87 - ETA: 0s - loss: 0.2957 - accuracy: 0.87 - ETA: 0s - loss: 0.2963 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8770 - val_loss: 0.3837 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.78 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2892 - accuracy: 0.88 - ETA: 0s - loss: 0.2915 - accuracy: 0.88 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8770 - val_loss: 0.3828 - val_accuracy: 0.8490\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.96 - ETA: 0s - loss: 0.2853 - accuracy: 0.89 - ETA: 0s - loss: 0.2749 - accuracy: 0.89 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - ETA: 0s - loss: 0.2900 - accuracy: 0.88 - ETA: 0s - loss: 0.2961 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8782 - val_loss: 0.3767 - val_accuracy: 0.8495\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.87 - ETA: 0s - loss: 0.2866 - accuracy: 0.88 - ETA: 0s - loss: 0.2970 - accuracy: 0.87 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.3835 - val_accuracy: 0.8495\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.84 - ETA: 0s - loss: 0.2909 - accuracy: 0.87 - ETA: 0s - loss: 0.2885 - accuracy: 0.87 - ETA: 0s - loss: 0.2868 - accuracy: 0.87 - ETA: 0s - loss: 0.2916 - accuracy: 0.88 - ETA: 0s - loss: 0.2962 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8788 - val_loss: 0.3952 - val_accuracy: 0.8540\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.87 - ETA: 0s - loss: 0.2944 - accuracy: 0.87 - ETA: 0s - loss: 0.2893 - accuracy: 0.87 - ETA: 0s - loss: 0.2897 - accuracy: 0.87 - ETA: 0s - loss: 0.2896 - accuracy: 0.87 - ETA: 0s - loss: 0.3002 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8788 - val_loss: 0.3945 - val_accuracy: 0.8535\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.93 - ETA: 0s - loss: 0.2743 - accuracy: 0.88 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - ETA: 0s - loss: 0.2931 - accuracy: 0.88 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8783 - val_loss: 0.4032 - val_accuracy: 0.8530\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.96 - ETA: 0s - loss: 0.2816 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2919 - accuracy: 0.87 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - ETA: 0s - loss: 0.2901 - accuracy: 0.88 - ETA: 0s - loss: 0.2926 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8803 - val_loss: 0.4096 - val_accuracy: 0.8490\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.93 - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2858 - accuracy: 0.88 - ETA: 0s - loss: 0.2879 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8795 - val_loss: 0.4089 - val_accuracy: 0.8505\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.87 - ETA: 0s - loss: 0.2850 - accuracy: 0.88 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - ETA: 0s - loss: 0.2926 - accuracy: 0.87 - ETA: 0s - loss: 0.2873 - accuracy: 0.88 - ETA: 0s - loss: 0.2950 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8808 - val_loss: 0.4093 - val_accuracy: 0.8500\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.93 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - ETA: 0s - loss: 0.3022 - accuracy: 0.86 - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - ETA: 0s - loss: 0.2968 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8782 - val_loss: 0.4017 - val_accuracy: 0.8510\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.96 - ETA: 0s - loss: 0.2846 - accuracy: 0.87 - ETA: 0s - loss: 0.2936 - accuracy: 0.87 - ETA: 0s - loss: 0.2941 - accuracy: 0.87 - ETA: 0s - loss: 0.2956 - accuracy: 0.87 - ETA: 0s - loss: 0.2934 - accuracy: 0.87 - ETA: 0s - loss: 0.2932 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8802 - val_loss: 0.4125 - val_accuracy: 0.8430\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.81 - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.2745 - accuracy: 0.88 - ETA: 0s - loss: 0.2842 - accuracy: 0.88 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8793 - val_loss: 0.4060 - val_accuracy: 0.8535\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.87 - ETA: 0s - loss: 0.2842 - accuracy: 0.87 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2850 - accuracy: 0.88 - ETA: 0s - loss: 0.2852 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8812 - val_loss: 0.4173 - val_accuracy: 0.8470\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.90 - ETA: 0s - loss: 0.2825 - accuracy: 0.88 - ETA: 0s - loss: 0.2907 - accuracy: 0.88 - ETA: 0s - loss: 0.2825 - accuracy: 0.88 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2852 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8817 - val_loss: 0.4112 - val_accuracy: 0.8495\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.90 - ETA: 0s - loss: 0.2737 - accuracy: 0.88 - ETA: 0s - loss: 0.2669 - accuracy: 0.89 - ETA: 0s - loss: 0.2675 - accuracy: 0.89 - ETA: 0s - loss: 0.2776 - accuracy: 0.88 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8803 - val_loss: 0.4235 - val_accuracy: 0.8480\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.87 - ETA: 0s - loss: 0.2968 - accuracy: 0.88 - ETA: 0s - loss: 0.2802 - accuracy: 0.88 - ETA: 0s - loss: 0.2843 - accuracy: 0.87 - ETA: 0s - loss: 0.2856 - accuracy: 0.87 - ETA: 0s - loss: 0.2842 - accuracy: 0.88 - ETA: 0s - loss: 0.2885 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8783 - val_loss: 0.4438 - val_accuracy: 0.8415\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.81 - ETA: 0s - loss: 0.2960 - accuracy: 0.87 - ETA: 0s - loss: 0.2911 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - ETA: 0s - loss: 0.2804 - accuracy: 0.88 - ETA: 0s - loss: 0.2907 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8817 - val_loss: 0.4104 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.75 - ETA: 0s - loss: 0.3173 - accuracy: 0.86 - ETA: 0s - loss: 0.3014 - accuracy: 0.87 - ETA: 0s - loss: 0.2953 - accuracy: 0.87 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.2930 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8820 - val_loss: 0.4361 - val_accuracy: 0.8445\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.87 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.2770 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - ETA: 0s - loss: 0.2844 - accuracy: 0.88 - ETA: 0s - loss: 0.2869 - accuracy: 0.88 - ETA: 0s - loss: 0.2866 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8822 - val_loss: 0.4289 - val_accuracy: 0.8495\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.81 - ETA: 0s - loss: 0.2762 - accuracy: 0.87 - ETA: 0s - loss: 0.2759 - accuracy: 0.87 - ETA: 0s - loss: 0.2792 - accuracy: 0.88 - ETA: 0s - loss: 0.2806 - accuracy: 0.88 - ETA: 0s - loss: 0.2836 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8802 - val_loss: 0.4310 - val_accuracy: 0.8405\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.93 - ETA: 0s - loss: 0.2907 - accuracy: 0.86 - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - ETA: 0s - loss: 0.2933 - accuracy: 0.87 - ETA: 0s - loss: 0.2919 - accuracy: 0.87 - ETA: 0s - loss: 0.2873 - accuracy: 0.87 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8805 - val_loss: 0.4620 - val_accuracy: 0.8475\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.87 - ETA: 0s - loss: 0.2393 - accuracy: 0.90 - ETA: 0s - loss: 0.2480 - accuracy: 0.89 - ETA: 0s - loss: 0.2721 - accuracy: 0.88 - ETA: 0s - loss: 0.2747 - accuracy: 0.88 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8810 - val_loss: 0.4495 - val_accuracy: 0.8425\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.93 - ETA: 0s - loss: 0.2821 - accuracy: 0.88 - ETA: 0s - loss: 0.2863 - accuracy: 0.88 - ETA: 0s - loss: 0.2869 - accuracy: 0.88 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2777 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8855 - val_loss: 0.4403 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.93 - ETA: 0s - loss: 0.2874 - accuracy: 0.87 - ETA: 0s - loss: 0.2711 - accuracy: 0.88 - ETA: 0s - loss: 0.2826 - accuracy: 0.88 - ETA: 0s - loss: 0.2809 - accuracy: 0.88 - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8822 - val_loss: 0.4819 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.90 - ETA: 0s - loss: 0.2874 - accuracy: 0.87 - ETA: 0s - loss: 0.2844 - accuracy: 0.87 - ETA: 0s - loss: 0.2826 - accuracy: 0.88 - ETA: 0s - loss: 0.2814 - accuracy: 0.88 - ETA: 0s - loss: 0.2857 - accuracy: 0.88 - ETA: 0s - loss: 0.2876 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8827 - val_loss: 0.4422 - val_accuracy: 0.8480\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.93 - ETA: 0s - loss: 0.2869 - accuracy: 0.88 - ETA: 0s - loss: 0.2882 - accuracy: 0.87 - ETA: 0s - loss: 0.2849 - accuracy: 0.88 - ETA: 0s - loss: 0.2818 - accuracy: 0.88 - ETA: 0s - loss: 0.2826 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8830 - val_loss: 0.4548 - val_accuracy: 0.8440\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.90 - ETA: 0s - loss: 0.2957 - accuracy: 0.86 - ETA: 0s - loss: 0.2962 - accuracy: 0.87 - ETA: 0s - loss: 0.2867 - accuracy: 0.88 - ETA: 0s - loss: 0.2848 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8827 - val_loss: 0.4344 - val_accuracy: 0.8440\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.87 - ETA: 0s - loss: 0.3054 - accuracy: 0.86 - ETA: 0s - loss: 0.2841 - accuracy: 0.88 - ETA: 0s - loss: 0.2771 - accuracy: 0.88 - ETA: 0s - loss: 0.2820 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8835 - val_loss: 0.4377 - val_accuracy: 0.8430\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.93 - ETA: 0s - loss: 0.2870 - accuracy: 0.88 - ETA: 0s - loss: 0.2810 - accuracy: 0.88 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - ETA: 0s - loss: 0.2822 - accuracy: 0.88 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2837 - accuracy: 0.8818 - val_loss: 0.4542 - val_accuracy: 0.8430\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.84 - ETA: 0s - loss: 0.2732 - accuracy: 0.87 - ETA: 0s - loss: 0.2673 - accuracy: 0.88 - ETA: 0s - loss: 0.2749 - accuracy: 0.88 - ETA: 0s - loss: 0.2763 - accuracy: 0.88 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8853 - val_loss: 0.4572 - val_accuracy: 0.8455\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.87 - ETA: 0s - loss: 0.2713 - accuracy: 0.88 - ETA: 0s - loss: 0.2886 - accuracy: 0.87 - ETA: 0s - loss: 0.2891 - accuracy: 0.87 - ETA: 0s - loss: 0.2837 - accuracy: 0.88 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8825 - val_loss: 0.4679 - val_accuracy: 0.8455\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.96 - ETA: 0s - loss: 0.2771 - accuracy: 0.88 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.87 - ETA: 0s - loss: 0.2914 - accuracy: 0.87 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - ETA: 0s - loss: 0.2865 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8805 - val_loss: 0.4694 - val_accuracy: 0.8390\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.96 - ETA: 0s - loss: 0.2901 - accuracy: 0.86 - ETA: 0s - loss: 0.2863 - accuracy: 0.87 - ETA: 0s - loss: 0.2809 - accuracy: 0.88 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - ETA: 0s - loss: 0.2814 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8835 - val_loss: 0.4627 - val_accuracy: 0.8460\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.90 - ETA: 0s - loss: 0.2701 - accuracy: 0.88 - ETA: 0s - loss: 0.2867 - accuracy: 0.88 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8818 - val_loss: 0.4339 - val_accuracy: 0.8410\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.84 - ETA: 0s - loss: 0.2721 - accuracy: 0.89 - ETA: 0s - loss: 0.2765 - accuracy: 0.88 - ETA: 0s - loss: 0.2872 - accuracy: 0.87 - ETA: 0s - loss: 0.2903 - accuracy: 0.87 - ETA: 0s - loss: 0.2868 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8830 - val_loss: 0.4502 - val_accuracy: 0.8430\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.84 - ETA: 0s - loss: 0.2904 - accuracy: 0.87 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2818 - accuracy: 0.88 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2881 - accuracy: 0.88 - ETA: 0s - loss: 0.2816 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8842 - val_loss: 0.4657 - val_accuracy: 0.8420\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.84 - ETA: 0s - loss: 0.2681 - accuracy: 0.88 - ETA: 0s - loss: 0.2814 - accuracy: 0.87 - ETA: 0s - loss: 0.2801 - accuracy: 0.87 - ETA: 0s - loss: 0.2767 - accuracy: 0.88 - ETA: 0s - loss: 0.2726 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8823 - val_loss: 0.4685 - val_accuracy: 0.8420\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.90 - ETA: 0s - loss: 0.2669 - accuracy: 0.88 - ETA: 0s - loss: 0.2734 - accuracy: 0.88 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2744 - accuracy: 0.88 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8835 - val_loss: 0.4515 - val_accuracy: 0.8440\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.90 - ETA: 0s - loss: 0.2581 - accuracy: 0.89 - ETA: 0s - loss: 0.2712 - accuracy: 0.88 - ETA: 0s - loss: 0.2670 - accuracy: 0.89 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.2788 - accuracy: 0.88 - ETA: 0s - loss: 0.2811 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8850 - val_loss: 0.4768 - val_accuracy: 0.8390\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.87 - ETA: 0s - loss: 0.2850 - accuracy: 0.88 - ETA: 0s - loss: 0.2711 - accuracy: 0.88 - ETA: 0s - loss: 0.2661 - accuracy: 0.89 - ETA: 0s - loss: 0.2711 - accuracy: 0.89 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8845 - val_loss: 0.4574 - val_accuracy: 0.8445\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.81 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2850 - accuracy: 0.88 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - ETA: 0s - loss: 0.2793 - accuracy: 0.88 - ETA: 0s - loss: 0.2770 - accuracy: 0.88 - ETA: 0s - loss: 0.2807 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8820 - val_loss: 0.4566 - val_accuracy: 0.8390\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.84 - ETA: 0s - loss: 0.2867 - accuracy: 0.88 - ETA: 0s - loss: 0.2727 - accuracy: 0.88 - ETA: 0s - loss: 0.2839 - accuracy: 0.88 - ETA: 0s - loss: 0.2818 - accuracy: 0.88 - ETA: 0s - loss: 0.2825 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8857 - val_loss: 0.4658 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.90 - ETA: 0s - loss: 0.2426 - accuracy: 0.90 - ETA: 0s - loss: 0.2554 - accuracy: 0.89 - ETA: 0s - loss: 0.2661 - accuracy: 0.88 - ETA: 0s - loss: 0.2694 - accuracy: 0.88 - ETA: 0s - loss: 0.2730 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8828 - val_loss: 0.4671 - val_accuracy: 0.8435\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.87 - ETA: 0s - loss: 0.2509 - accuracy: 0.88 - ETA: 0s - loss: 0.2619 - accuracy: 0.88 - ETA: 0s - loss: 0.2591 - accuracy: 0.88 - ETA: 0s - loss: 0.2672 - accuracy: 0.88 - ETA: 0s - loss: 0.2742 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8828 - val_loss: 0.4388 - val_accuracy: 0.8490\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.87 - ETA: 0s - loss: 0.2664 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.88 - ETA: 0s - loss: 0.2763 - accuracy: 0.88 - ETA: 0s - loss: 0.2766 - accuracy: 0.88 - ETA: 0s - loss: 0.2764 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8845 - val_loss: 0.5206 - val_accuracy: 0.8435\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.84 - ETA: 0s - loss: 0.2765 - accuracy: 0.88 - ETA: 0s - loss: 0.2750 - accuracy: 0.88 - ETA: 0s - loss: 0.2685 - accuracy: 0.89 - ETA: 0s - loss: 0.2695 - accuracy: 0.89 - ETA: 0s - loss: 0.2757 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8823 - val_loss: 0.4602 - val_accuracy: 0.8470\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - ETA: 0s - loss: 0.2623 - accuracy: 0.88 - ETA: 0s - loss: 0.2692 - accuracy: 0.88 - ETA: 0s - loss: 0.2743 - accuracy: 0.88 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2851 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8828 - val_loss: 0.4776 - val_accuracy: 0.8465\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2723 - accuracy: 0.90 - ETA: 0s - loss: 0.2672 - accuracy: 0.89 - ETA: 0s - loss: 0.2672 - accuracy: 0.88 - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8840 - val_loss: 0.4633 - val_accuracy: 0.8420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1cc22aa6771ff98e3ccae610dfe63031</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8634999990463257</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.18 - ETA: 0s - loss: 0.7031 - accuracy: 0.26 - ETA: 0s - loss: 0.6974 - accuracy: 0.43 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.61 - 1s 3ms/step - loss: 0.6855 - accuracy: 0.6533 - val_loss: 0.6653 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.84 - ETA: 0s - loss: 0.6615 - accuracy: 0.78 - ETA: 0s - loss: 0.6531 - accuracy: 0.79 - ETA: 0s - loss: 0.6457 - accuracy: 0.79 - ETA: 0s - loss: 0.6380 - accuracy: 0.79 - 0s 2ms/step - loss: 0.6336 - accuracy: 0.7948 - val_loss: 0.5881 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.96 - ETA: 0s - loss: 0.5703 - accuracy: 0.82 - ETA: 0s - loss: 0.5702 - accuracy: 0.80 - ETA: 0s - loss: 0.5606 - accuracy: 0.80 - ETA: 0s - loss: 0.5585 - accuracy: 0.79 - ETA: 0s - loss: 0.5504 - accuracy: 0.79 - ETA: 0s - loss: 0.5432 - accuracy: 0.79 - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7948 - val_loss: 0.5012 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.75 - ETA: 0s - loss: 0.4760 - accuracy: 0.81 - ETA: 0s - loss: 0.4915 - accuracy: 0.80 - ETA: 0s - loss: 0.4908 - accuracy: 0.80 - ETA: 0s - loss: 0.4911 - accuracy: 0.79 - ETA: 0s - loss: 0.4905 - accuracy: 0.79 - ETA: 0s - loss: 0.4891 - accuracy: 0.79 - ETA: 0s - loss: 0.4903 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7948 - val_loss: 0.4783 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.68 - ETA: 0s - loss: 0.4956 - accuracy: 0.77 - ETA: 0s - loss: 0.4878 - accuracy: 0.78 - ETA: 0s - loss: 0.4830 - accuracy: 0.79 - ETA: 0s - loss: 0.4766 - accuracy: 0.79 - ETA: 0s - loss: 0.4695 - accuracy: 0.79 - ETA: 0s - loss: 0.4698 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7948 - val_loss: 0.4598 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.71 - ETA: 0s - loss: 0.4584 - accuracy: 0.79 - ETA: 0s - loss: 0.4535 - accuracy: 0.79 - ETA: 0s - loss: 0.4562 - accuracy: 0.78 - ETA: 0s - loss: 0.4577 - accuracy: 0.78 - ETA: 0s - loss: 0.4542 - accuracy: 0.79 - ETA: 0s - loss: 0.4522 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7948 - val_loss: 0.4473 - val_accuracy: 0.7990\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5627 - accuracy: 0.71 - ETA: 0s - loss: 0.4424 - accuracy: 0.79 - ETA: 0s - loss: 0.4361 - accuracy: 0.79 - ETA: 0s - loss: 0.4379 - accuracy: 0.79 - ETA: 0s - loss: 0.4360 - accuracy: 0.79 - ETA: 0s - loss: 0.4308 - accuracy: 0.80 - ETA: 0s - loss: 0.4326 - accuracy: 0.80 - 1s 3ms/step - loss: 0.4346 - accuracy: 0.8040 - val_loss: 0.4381 - val_accuracy: 0.8125\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.87 - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - ETA: 0s - loss: 0.4312 - accuracy: 0.80 - ETA: 0s - loss: 0.4298 - accuracy: 0.81 - ETA: 0s - loss: 0.4274 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8185 - val_loss: 0.4328 - val_accuracy: 0.8190\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.75 - ETA: 0s - loss: 0.4099 - accuracy: 0.82 - ETA: 0s - loss: 0.4194 - accuracy: 0.81 - ETA: 0s - loss: 0.4229 - accuracy: 0.81 - ETA: 0s - loss: 0.4229 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8207 - val_loss: 0.4292 - val_accuracy: 0.8195\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.87 - ETA: 0s - loss: 0.4453 - accuracy: 0.81 - ETA: 0s - loss: 0.4149 - accuracy: 0.82 - ETA: 0s - loss: 0.4121 - accuracy: 0.82 - ETA: 0s - loss: 0.4134 - accuracy: 0.82 - ETA: 0s - loss: 0.4088 - accuracy: 0.82 - ETA: 0s - loss: 0.4134 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8233 - val_loss: 0.4243 - val_accuracy: 0.8170\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.78 - ETA: 0s - loss: 0.4329 - accuracy: 0.80 - ETA: 0s - loss: 0.4120 - accuracy: 0.82 - ETA: 0s - loss: 0.4012 - accuracy: 0.82 - ETA: 0s - loss: 0.4036 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8265 - val_loss: 0.4202 - val_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.93 - ETA: 0s - loss: 0.3801 - accuracy: 0.82 - ETA: 0s - loss: 0.4033 - accuracy: 0.81 - ETA: 0s - loss: 0.4120 - accuracy: 0.81 - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.3952 - accuracy: 0.83 - ETA: 0s - loss: 0.3999 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8283 - val_loss: 0.4150 - val_accuracy: 0.8210\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2788 - accuracy: 0.90 - ETA: 0s - loss: 0.3916 - accuracy: 0.84 - ETA: 0s - loss: 0.3953 - accuracy: 0.83 - ETA: 0s - loss: 0.3894 - accuracy: 0.83 - ETA: 0s - loss: 0.3907 - accuracy: 0.83 - ETA: 0s - loss: 0.3936 - accuracy: 0.83 - ETA: 0s - loss: 0.3918 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8330 - val_loss: 0.4106 - val_accuracy: 0.8265\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.84 - ETA: 0s - loss: 0.4178 - accuracy: 0.82 - ETA: 0s - loss: 0.3922 - accuracy: 0.84 - ETA: 0s - loss: 0.3895 - accuracy: 0.83 - ETA: 0s - loss: 0.3804 - accuracy: 0.84 - ETA: 0s - loss: 0.3763 - accuracy: 0.84 - ETA: 0s - loss: 0.3852 - accuracy: 0.84 - ETA: 0s - loss: 0.3873 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8368 - val_loss: 0.4054 - val_accuracy: 0.8250\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.90 - ETA: 0s - loss: 0.3813 - accuracy: 0.83 - ETA: 0s - loss: 0.3728 - accuracy: 0.84 - ETA: 0s - loss: 0.3913 - accuracy: 0.83 - ETA: 0s - loss: 0.3870 - accuracy: 0.83 - ETA: 0s - loss: 0.3860 - accuracy: 0.83 - ETA: 0s - loss: 0.3863 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8382 - val_loss: 0.4039 - val_accuracy: 0.8320\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.68 - ETA: 0s - loss: 0.4472 - accuracy: 0.77 - ETA: 0s - loss: 0.3816 - accuracy: 0.83 - ETA: 0s - loss: 0.3763 - accuracy: 0.84 - ETA: 0s - loss: 0.3786 - accuracy: 0.84 - ETA: 0s - loss: 0.3797 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8407 - val_loss: 0.3979 - val_accuracy: 0.8345\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.93 - ETA: 0s - loss: 0.3427 - accuracy: 0.86 - ETA: 0s - loss: 0.3643 - accuracy: 0.84 - ETA: 0s - loss: 0.3765 - accuracy: 0.84 - ETA: 0s - loss: 0.3799 - accuracy: 0.84 - ETA: 0s - loss: 0.3753 - accuracy: 0.84 - ETA: 0s - loss: 0.3763 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8438 - val_loss: 0.3950 - val_accuracy: 0.8365\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.84 - ETA: 0s - loss: 0.3613 - accuracy: 0.84 - ETA: 0s - loss: 0.3618 - accuracy: 0.84 - ETA: 0s - loss: 0.3676 - accuracy: 0.84 - ETA: 0s - loss: 0.3748 - accuracy: 0.84 - ETA: 0s - loss: 0.3728 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8440 - val_loss: 0.3927 - val_accuracy: 0.8400\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.84 - ETA: 0s - loss: 0.3700 - accuracy: 0.85 - ETA: 0s - loss: 0.3775 - accuracy: 0.84 - ETA: 0s - loss: 0.3675 - accuracy: 0.84 - ETA: 0s - loss: 0.3745 - accuracy: 0.84 - ETA: 0s - loss: 0.3722 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8453 - val_loss: 0.3900 - val_accuracy: 0.8370\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.87 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3409 - accuracy: 0.86 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3661 - accuracy: 0.84 - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8488 - val_loss: 0.3911 - val_accuracy: 0.8425\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.87 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3490 - accuracy: 0.85 - ETA: 0s - loss: 0.3526 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - ETA: 0s - loss: 0.3634 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8498 - val_loss: 0.3861 - val_accuracy: 0.8405\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.87 - ETA: 0s - loss: 0.3534 - accuracy: 0.84 - ETA: 0s - loss: 0.3508 - accuracy: 0.84 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3565 - accuracy: 0.85 - ETA: 0s - loss: 0.3610 - accuracy: 0.85 - ETA: 0s - loss: 0.3611 - accuracy: 0.84 - ETA: 0s - loss: 0.3594 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8505 - val_loss: 0.3866 - val_accuracy: 0.8395\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3582 - accuracy: 0.84 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - ETA: 0s - loss: 0.3595 - accuracy: 0.85 - ETA: 0s - loss: 0.3593 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8513 - val_loss: 0.3845 - val_accuracy: 0.8415\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.84 - ETA: 0s - loss: 0.3430 - accuracy: 0.84 - ETA: 0s - loss: 0.3523 - accuracy: 0.84 - ETA: 0s - loss: 0.3611 - accuracy: 0.84 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8507 - val_loss: 0.3842 - val_accuracy: 0.8420\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.87 - ETA: 0s - loss: 0.3855 - accuracy: 0.82 - ETA: 0s - loss: 0.3860 - accuracy: 0.83 - ETA: 0s - loss: 0.3648 - accuracy: 0.84 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8537 - val_loss: 0.3833 - val_accuracy: 0.8410\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.93 - ETA: 0s - loss: 0.3549 - accuracy: 0.86 - ETA: 0s - loss: 0.3602 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3588 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3541 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8543 - val_loss: 0.3833 - val_accuracy: 0.8415\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.87 - ETA: 0s - loss: 0.3600 - accuracy: 0.83 - ETA: 0s - loss: 0.3646 - accuracy: 0.83 - ETA: 0s - loss: 0.3626 - accuracy: 0.84 - ETA: 0s - loss: 0.3601 - accuracy: 0.84 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8543 - val_loss: 0.3817 - val_accuracy: 0.8425\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.68 - ETA: 0s - loss: 0.2904 - accuracy: 0.89 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - ETA: 0s - loss: 0.3458 - accuracy: 0.85 - ETA: 0s - loss: 0.3464 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3480 - accuracy: 0.86 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8580 - val_loss: 0.3816 - val_accuracy: 0.8415\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.87 - ETA: 0s - loss: 0.3646 - accuracy: 0.85 - ETA: 0s - loss: 0.3568 - accuracy: 0.85 - ETA: 0s - loss: 0.3490 - accuracy: 0.86 - ETA: 0s - loss: 0.3545 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3555 - accuracy: 0.85 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8563 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 1.00 - ETA: 0s - loss: 0.3353 - accuracy: 0.86 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8578 - val_loss: 0.3819 - val_accuracy: 0.8425\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.81 - ETA: 0s - loss: 0.3842 - accuracy: 0.83 - ETA: 0s - loss: 0.3550 - accuracy: 0.85 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.86 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3438 - accuracy: 0.86 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8592 - val_loss: 0.3811 - val_accuracy: 0.8405\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.93 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3484 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.85 - ETA: 0s - loss: 0.3478 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3505 - accuracy: 0.85 - ETA: 0s - loss: 0.3495 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8600 - val_loss: 0.3811 - val_accuracy: 0.8425\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.84 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3579 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8593 - val_loss: 0.3815 - val_accuracy: 0.8420\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.87 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3408 - accuracy: 0.86 - ETA: 0s - loss: 0.3497 - accuracy: 0.85 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8592 - val_loss: 0.3806 - val_accuracy: 0.8435\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.90 - ETA: 0s - loss: 0.3425 - accuracy: 0.86 - ETA: 0s - loss: 0.3454 - accuracy: 0.86 - ETA: 0s - loss: 0.3403 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8605 - val_loss: 0.3801 - val_accuracy: 0.8430\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.96 - ETA: 0s - loss: 0.3230 - accuracy: 0.87 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3424 - accuracy: 0.86 - ETA: 0s - loss: 0.3489 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.85 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8593 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.90 - ETA: 0s - loss: 0.3321 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3391 - accuracy: 0.85 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - ETA: 0s - loss: 0.3391 - accuracy: 0.86 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - ETA: 0s - loss: 0.3441 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8623 - val_loss: 0.3794 - val_accuracy: 0.8425\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.71 - ETA: 0s - loss: 0.3739 - accuracy: 0.84 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3508 - accuracy: 0.85 - ETA: 0s - loss: 0.3458 - accuracy: 0.86 - ETA: 0s - loss: 0.3442 - accuracy: 0.86 - ETA: 0s - loss: 0.3436 - accuracy: 0.86 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8633 - val_loss: 0.3820 - val_accuracy: 0.8430\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.84 - ETA: 0s - loss: 0.3139 - accuracy: 0.88 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8598 - val_loss: 0.3792 - val_accuracy: 0.8430\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.90 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - ETA: 0s - loss: 0.3390 - accuracy: 0.86 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3392 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8637 - val_loss: 0.3800 - val_accuracy: 0.8450\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.87 - ETA: 0s - loss: 0.3412 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.87 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3376 - accuracy: 0.86 - ETA: 0s - loss: 0.3417 - accuracy: 0.86 - ETA: 0s - loss: 0.3412 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8628 - val_loss: 0.3789 - val_accuracy: 0.8430\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.81 - ETA: 0s - loss: 0.3174 - accuracy: 0.87 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.86 - ETA: 0s - loss: 0.3417 - accuracy: 0.86 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8628 - val_loss: 0.3782 - val_accuracy: 0.8430\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.93 - ETA: 0s - loss: 0.3187 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3197 - accuracy: 0.87 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8635 - val_loss: 0.3781 - val_accuracy: 0.8435\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.90 - ETA: 0s - loss: 0.3060 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3416 - accuracy: 0.85 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8638 - val_loss: 0.3804 - val_accuracy: 0.8460\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.81 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3392 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8650 - val_loss: 0.3784 - val_accuracy: 0.8430\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.78 - ETA: 0s - loss: 0.3281 - accuracy: 0.88 - ETA: 0s - loss: 0.3319 - accuracy: 0.87 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8645 - val_loss: 0.3782 - val_accuracy: 0.8435\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.90 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3446 - accuracy: 0.86 - ETA: 0s - loss: 0.3455 - accuracy: 0.86 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8647 - val_loss: 0.3785 - val_accuracy: 0.8460\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.93 - ETA: 0s - loss: 0.3338 - accuracy: 0.87 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8645 - val_loss: 0.3773 - val_accuracy: 0.8455\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.84 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.86 - ETA: 0s - loss: 0.3447 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8640 - val_loss: 0.3774 - val_accuracy: 0.8470\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.84 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.87 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8643 - val_loss: 0.3769 - val_accuracy: 0.8490\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.87 - ETA: 0s - loss: 0.3662 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3392 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8663 - val_loss: 0.3777 - val_accuracy: 0.8465\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.84 - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8647 - val_loss: 0.3773 - val_accuracy: 0.8475\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.90 - ETA: 0s - loss: 0.3483 - accuracy: 0.86 - ETA: 0s - loss: 0.3474 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8662 - val_loss: 0.3768 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.81 - ETA: 0s - loss: 0.3328 - accuracy: 0.85 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8662 - val_loss: 0.3776 - val_accuracy: 0.8475\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8670 - val_loss: 0.3771 - val_accuracy: 0.8465\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.78 - ETA: 0s - loss: 0.3526 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.87 - ETA: 0s - loss: 0.3270 - accuracy: 0.87 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8660 - val_loss: 0.3760 - val_accuracy: 0.8470\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.75 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8675 - val_loss: 0.3762 - val_accuracy: 0.8445\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.84 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.85 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8668 - val_loss: 0.3759 - val_accuracy: 0.8465\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.87 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3376 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3298 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8665 - val_loss: 0.3768 - val_accuracy: 0.8455\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.93 - ETA: 0s - loss: 0.3111 - accuracy: 0.87 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3181 - accuracy: 0.87 - ETA: 0s - loss: 0.3229 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8680 - val_loss: 0.3754 - val_accuracy: 0.8470\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.81 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.85 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8672 - val_loss: 0.3759 - val_accuracy: 0.8475\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.87 - ETA: 0s - loss: 0.2820 - accuracy: 0.88 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8668 - val_loss: 0.3754 - val_accuracy: 0.8485\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.81 - ETA: 0s - loss: 0.3157 - accuracy: 0.87 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - ETA: 0s - loss: 0.3237 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8670 - val_loss: 0.3764 - val_accuracy: 0.8480\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.78 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3379 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8682 - val_loss: 0.3760 - val_accuracy: 0.8490\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.93 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - ETA: 0s - loss: 0.3171 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3237 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8672 - val_loss: 0.3756 - val_accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.81 - ETA: 0s - loss: 0.3327 - accuracy: 0.85 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - ETA: 0s - loss: 0.3186 - accuracy: 0.86 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8672 - val_loss: 0.3761 - val_accuracy: 0.8470\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.96 - ETA: 0s - loss: 0.3105 - accuracy: 0.88 - ETA: 0s - loss: 0.3246 - accuracy: 0.87 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8672 - val_loss: 0.3756 - val_accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.93 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8685 - val_loss: 0.3754 - val_accuracy: 0.8465\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.87 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8682 - val_loss: 0.3773 - val_accuracy: 0.8460\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.96 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3208 - accuracy: 0.87 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8673 - val_loss: 0.3757 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.87 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3197 - accuracy: 0.87 - ETA: 0s - loss: 0.3223 - accuracy: 0.87 - ETA: 0s - loss: 0.3252 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8677 - val_loss: 0.3754 - val_accuracy: 0.8445\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.84 - ETA: 0s - loss: 0.3279 - accuracy: 0.85 - ETA: 0s - loss: 0.3176 - accuracy: 0.86 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8682 - val_loss: 0.3752 - val_accuracy: 0.8510\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.90 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.87 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8693 - val_loss: 0.3763 - val_accuracy: 0.8470\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.84 - ETA: 0s - loss: 0.3484 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.87 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8692 - val_loss: 0.3772 - val_accuracy: 0.8455\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.84 - ETA: 0s - loss: 0.2952 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3187 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - ETA: 0s - loss: 0.3211 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8692 - val_loss: 0.3783 - val_accuracy: 0.8430\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.78 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.85 - ETA: 0s - loss: 0.3358 - accuracy: 0.85 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8675 - val_loss: 0.3776 - val_accuracy: 0.8455\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.96 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3334 - accuracy: 0.85 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3197 - accuracy: 0.86 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8678 - val_loss: 0.3766 - val_accuracy: 0.8470\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.81 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8685 - val_loss: 0.3768 - val_accuracy: 0.8470\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.75 - ETA: 0s - loss: 0.3317 - accuracy: 0.87 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.85 - ETA: 0s - loss: 0.3216 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8678 - val_loss: 0.3767 - val_accuracy: 0.8485\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.81 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.87 - ETA: 0s - loss: 0.3275 - accuracy: 0.87 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8695 - val_loss: 0.3777 - val_accuracy: 0.8490\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.81 - ETA: 0s - loss: 0.2995 - accuracy: 0.87 - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - ETA: 0s - loss: 0.3054 - accuracy: 0.88 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3171 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8708 - val_loss: 0.3767 - val_accuracy: 0.8475\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.90 - ETA: 0s - loss: 0.3108 - accuracy: 0.86 - ETA: 0s - loss: 0.3121 - accuracy: 0.86 - ETA: 0s - loss: 0.3109 - accuracy: 0.87 - ETA: 0s - loss: 0.3149 - accuracy: 0.87 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8692 - val_loss: 0.3769 - val_accuracy: 0.8450\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.90 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3355 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8705 - val_loss: 0.3791 - val_accuracy: 0.8445\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.90 - ETA: 0s - loss: 0.2846 - accuracy: 0.89 - ETA: 0s - loss: 0.2989 - accuracy: 0.88 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3160 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.3162 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8703 - val_loss: 0.3789 - val_accuracy: 0.8460\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.3336 - accuracy: 0.85 - ETA: 0s - loss: 0.3139 - accuracy: 0.86 - ETA: 0s - loss: 0.3112 - accuracy: 0.87 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8702 - val_loss: 0.3782 - val_accuracy: 0.8490\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.96 - ETA: 0s - loss: 0.3070 - accuracy: 0.87 - ETA: 0s - loss: 0.3059 - accuracy: 0.88 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - ETA: 0s - loss: 0.3103 - accuracy: 0.87 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3186 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8700 - val_loss: 0.3777 - val_accuracy: 0.8485\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.90 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3226 - accuracy: 0.87 - ETA: 0s - loss: 0.3246 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3160 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8703 - val_loss: 0.3776 - val_accuracy: 0.8455\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.93 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3188 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8710 - val_loss: 0.3772 - val_accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.84 - ETA: 0s - loss: 0.3148 - accuracy: 0.86 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3187 - accuracy: 0.8705 - val_loss: 0.3785 - val_accuracy: 0.8480\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.81 - ETA: 0s - loss: 0.3547 - accuracy: 0.84 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - ETA: 0s - loss: 0.3166 - accuracy: 0.87 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8715 - val_loss: 0.3789 - val_accuracy: 0.8475\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.84 - ETA: 0s - loss: 0.2866 - accuracy: 0.89 - ETA: 0s - loss: 0.3034 - accuracy: 0.88 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8700 - val_loss: 0.3772 - val_accuracy: 0.8510\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.90 - ETA: 0s - loss: 0.3291 - accuracy: 0.85 - ETA: 0s - loss: 0.3240 - accuracy: 0.86 - ETA: 0s - loss: 0.3173 - accuracy: 0.86 - ETA: 0s - loss: 0.3155 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8705 - val_loss: 0.3779 - val_accuracy: 0.8475\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.90 - ETA: 0s - loss: 0.3284 - accuracy: 0.85 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.87 - ETA: 0s - loss: 0.3176 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8727 - val_loss: 0.3775 - val_accuracy: 0.8515\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.93 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8728 - val_loss: 0.3780 - val_accuracy: 0.8480\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.87 - ETA: 0s - loss: 0.3456 - accuracy: 0.87 - ETA: 0s - loss: 0.3163 - accuracy: 0.87 - ETA: 0s - loss: 0.3111 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.88 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3171 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8728 - val_loss: 0.3796 - val_accuracy: 0.8455\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.93 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - ETA: 0s - loss: 0.3203 - accuracy: 0.87 - ETA: 0s - loss: 0.3174 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8732 - val_loss: 0.3780 - val_accuracy: 0.8510\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.87 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3131 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.86 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.3157 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8720 - val_loss: 0.3788 - val_accuracy: 0.8490\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.93 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - ETA: 0s - loss: 0.3003 - accuracy: 0.88 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3160 - accuracy: 0.8737 - val_loss: 0.3783 - val_accuracy: 0.8515\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.84 - ETA: 0s - loss: 0.3150 - accuracy: 0.88 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3171 - accuracy: 0.87 - ETA: 0s - loss: 0.3205 - accuracy: 0.86 - ETA: 0s - loss: 0.3204 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3157 - accuracy: 0.8732 - val_loss: 0.3785 - val_accuracy: 0.8505\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.81 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3199 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3175 - accuracy: 0.87 - ETA: 0s - loss: 0.3140 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8727 - val_loss: 0.3794 - val_accuracy: 0.8490\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d5910b6cd03fe2cf1f6c22c1bcc1ec36</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8514999747276306</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.75 - ETA: 0s - loss: 0.5549 - accuracy: 0.77 - ETA: 0s - loss: 0.4963 - accuracy: 0.78 - ETA: 0s - loss: 0.4691 - accuracy: 0.79 - ETA: 0s - loss: 0.4558 - accuracy: 0.79 - 1s 3ms/step - loss: 0.4533 - accuracy: 0.7948 - val_loss: 0.4097 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.87 - ETA: 0s - loss: 0.3980 - accuracy: 0.80 - ETA: 0s - loss: 0.4150 - accuracy: 0.81 - ETA: 0s - loss: 0.4023 - accuracy: 0.82 - ETA: 0s - loss: 0.3985 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8302 - val_loss: 0.3885 - val_accuracy: 0.8390\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.84 - ETA: 0s - loss: 0.3713 - accuracy: 0.86 - ETA: 0s - loss: 0.3786 - accuracy: 0.86 - ETA: 0s - loss: 0.3863 - accuracy: 0.85 - ETA: 0s - loss: 0.3848 - accuracy: 0.85 - ETA: 0s - loss: 0.3857 - accuracy: 0.84 - ETA: 0s - loss: 0.3842 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8453 - val_loss: 0.3785 - val_accuracy: 0.8410\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.87 - ETA: 0s - loss: 0.4003 - accuracy: 0.83 - ETA: 0s - loss: 0.3749 - accuracy: 0.85 - ETA: 0s - loss: 0.3728 - accuracy: 0.84 - ETA: 0s - loss: 0.3738 - accuracy: 0.84 - ETA: 0s - loss: 0.3694 - accuracy: 0.84 - ETA: 0s - loss: 0.3726 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8467 - val_loss: 0.3696 - val_accuracy: 0.8460\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.90 - ETA: 0s - loss: 0.3205 - accuracy: 0.87 - ETA: 0s - loss: 0.3678 - accuracy: 0.84 - ETA: 0s - loss: 0.3766 - accuracy: 0.84 - ETA: 0s - loss: 0.3614 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8500 - val_loss: 0.3545 - val_accuracy: 0.8530\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.84 - ETA: 0s - loss: 0.3464 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8547 - val_loss: 0.3529 - val_accuracy: 0.8540\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.81 - ETA: 0s - loss: 0.3305 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - ETA: 0s - loss: 0.3689 - accuracy: 0.85 - ETA: 0s - loss: 0.3649 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8560 - val_loss: 0.3575 - val_accuracy: 0.8540\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.87 - ETA: 0s - loss: 0.3601 - accuracy: 0.85 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.86 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8583 - val_loss: 0.3656 - val_accuracy: 0.8510\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.75 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8580 - val_loss: 0.3505 - val_accuracy: 0.8580\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.90 - ETA: 0s - loss: 0.3427 - accuracy: 0.86 - ETA: 0s - loss: 0.3415 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3418 - accuracy: 0.86 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8565 - val_loss: 0.3748 - val_accuracy: 0.8565\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3673 - accuracy: 0.86 - ETA: 0s - loss: 0.3534 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8503 - val_loss: 0.3852 - val_accuracy: 0.8440\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.90 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3447 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8615 - val_loss: 0.3535 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.84 - ETA: 0s - loss: 0.3376 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - ETA: 0s - loss: 0.3425 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3407 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8620 - val_loss: 0.3810 - val_accuracy: 0.8435\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.93 - ETA: 0s - loss: 0.3208 - accuracy: 0.87 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3380 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8603 - val_loss: 0.3516 - val_accuracy: 0.8550\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.81 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3376 - accuracy: 0.86 - ETA: 0s - loss: 0.3456 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3355 - accuracy: 0.86 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8625 - val_loss: 0.3586 - val_accuracy: 0.8540\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.81 - ETA: 0s - loss: 0.3307 - accuracy: 0.85 - ETA: 0s - loss: 0.3400 - accuracy: 0.86 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3401 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3422 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8590 - val_loss: 0.3732 - val_accuracy: 0.8495\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.90 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3446 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3386 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8640 - val_loss: 0.3596 - val_accuracy: 0.8535\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.81 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8632 - val_loss: 0.3546 - val_accuracy: 0.8645\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.90 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8617 - val_loss: 0.3577 - val_accuracy: 0.8460\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.93 - ETA: 0s - loss: 0.3245 - accuracy: 0.87 - ETA: 0s - loss: 0.3303 - accuracy: 0.87 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8610 - val_loss: 0.3495 - val_accuracy: 0.8605\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.93 - ETA: 0s - loss: 0.3107 - accuracy: 0.88 - ETA: 0s - loss: 0.3002 - accuracy: 0.88 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.3169 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8627 - val_loss: 0.3491 - val_accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.90 - ETA: 0s - loss: 0.3053 - accuracy: 0.88 - ETA: 0s - loss: 0.3244 - accuracy: 0.87 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8675 - val_loss: 0.3563 - val_accuracy: 0.8635\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.78 - ETA: 0s - loss: 0.3083 - accuracy: 0.86 - ETA: 0s - loss: 0.3193 - accuracy: 0.86 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8662 - val_loss: 0.3509 - val_accuracy: 0.8625\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.84 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8638 - val_loss: 0.3492 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.90 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8663 - val_loss: 0.3687 - val_accuracy: 0.8550\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.96 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8633 - val_loss: 0.3605 - val_accuracy: 0.8565\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.93 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8635 - val_loss: 0.3600 - val_accuracy: 0.8565\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.90 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - ETA: 0s - loss: 0.3175 - accuracy: 0.87 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8642 - val_loss: 0.3498 - val_accuracy: 0.8565\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.84 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8645 - val_loss: 0.3528 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.87 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8650 - val_loss: 0.3522 - val_accuracy: 0.8605\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.84 - ETA: 0s - loss: 0.3260 - accuracy: 0.87 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8648 - val_loss: 0.3605 - val_accuracy: 0.8450\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.84 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8645 - val_loss: 0.3474 - val_accuracy: 0.8615\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.87 - ETA: 0s - loss: 0.3194 - accuracy: 0.86 - ETA: 0s - loss: 0.3162 - accuracy: 0.87 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8650 - val_loss: 0.3521 - val_accuracy: 0.8625\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.90 - ETA: 0s - loss: 0.3504 - accuracy: 0.84 - ETA: 0s - loss: 0.3361 - accuracy: 0.85 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8650 - val_loss: 0.3694 - val_accuracy: 0.8525\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2718 - accuracy: 0.84 - ETA: 0s - loss: 0.3417 - accuracy: 0.84 - ETA: 0s - loss: 0.3312 - accuracy: 0.85 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3250 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8638 - val_loss: 0.3560 - val_accuracy: 0.8600\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.87 - ETA: 0s - loss: 0.3363 - accuracy: 0.85 - ETA: 0s - loss: 0.3301 - accuracy: 0.85 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8673 - val_loss: 0.3623 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.88 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3266 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.87 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8667 - val_loss: 0.3490 - val_accuracy: 0.8585\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.84 - ETA: 0s - loss: 0.3047 - accuracy: 0.88 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3229 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8668 - val_loss: 0.3560 - val_accuracy: 0.8600\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.87 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8657 - val_loss: 0.3571 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.90 - ETA: 0s - loss: 0.3171 - accuracy: 0.86 - ETA: 0s - loss: 0.3150 - accuracy: 0.87 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3211 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8698 - val_loss: 0.3550 - val_accuracy: 0.8610\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.93 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8680 - val_loss: 0.3536 - val_accuracy: 0.8610\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.90 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.88 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8662 - val_loss: 0.3524 - val_accuracy: 0.8595\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.71 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3143 - accuracy: 0.86 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8672 - val_loss: 0.3626 - val_accuracy: 0.8600\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.90 - ETA: 0s - loss: 0.2833 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.85 - ETA: 0s - loss: 0.3377 - accuracy: 0.85 - ETA: 0s - loss: 0.3307 - accuracy: 0.85 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8643 - val_loss: 0.3545 - val_accuracy: 0.8580\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.1964 - accuracy: 0.93 - ETA: 0s - loss: 0.3009 - accuracy: 0.88 - ETA: 0s - loss: 0.3065 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - ETA: 0s - loss: 0.3200 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8675 - val_loss: 0.3561 - val_accuracy: 0.8610\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.84 - ETA: 0s - loss: 0.3380 - accuracy: 0.85 - ETA: 0s - loss: 0.3286 - accuracy: 0.85 - ETA: 0s - loss: 0.3293 - accuracy: 0.85 - ETA: 0s - loss: 0.3285 - accuracy: 0.85 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8640 - val_loss: 0.3528 - val_accuracy: 0.8565\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.84 - ETA: 0s - loss: 0.3170 - accuracy: 0.87 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8675 - val_loss: 0.3586 - val_accuracy: 0.8620\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.75 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8713 - val_loss: 0.3553 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.90 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8688 - val_loss: 0.3570 - val_accuracy: 0.8615\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.78 - ETA: 0s - loss: 0.3310 - accuracy: 0.87 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8657 - val_loss: 0.3634 - val_accuracy: 0.8610\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.87 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8678 - val_loss: 0.3803 - val_accuracy: 0.8555\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.3287 - accuracy: 0.85 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8643 - val_loss: 0.3662 - val_accuracy: 0.8530\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.78 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3187 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8672 - val_loss: 0.3551 - val_accuracy: 0.8570\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.84 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.86 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8673 - val_loss: 0.3577 - val_accuracy: 0.8570\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.84 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8668 - val_loss: 0.3620 - val_accuracy: 0.8565\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.81 - ETA: 0s - loss: 0.3330 - accuracy: 0.85 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.85 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8638 - val_loss: 0.3681 - val_accuracy: 0.8510\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.68 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8648 - val_loss: 0.3539 - val_accuracy: 0.8540\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.78 - ETA: 0s - loss: 0.2899 - accuracy: 0.87 - ETA: 0s - loss: 0.3129 - accuracy: 0.86 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - ETA: 0s - loss: 0.3211 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8683 - val_loss: 0.3548 - val_accuracy: 0.8550\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.90 - ETA: 0s - loss: 0.2911 - accuracy: 0.88 - ETA: 0s - loss: 0.2983 - accuracy: 0.88 - ETA: 0s - loss: 0.3114 - accuracy: 0.86 - ETA: 0s - loss: 0.3146 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8673 - val_loss: 0.3650 - val_accuracy: 0.8490\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.93 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8655 - val_loss: 0.3571 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.75 - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - ETA: 0s - loss: 0.3108 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8703 - val_loss: 0.3589 - val_accuracy: 0.8605\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.90 - ETA: 0s - loss: 0.3224 - accuracy: 0.85 - ETA: 0s - loss: 0.3098 - accuracy: 0.86 - ETA: 0s - loss: 0.3162 - accuracy: 0.86 - ETA: 0s - loss: 0.3168 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8672 - val_loss: 0.3617 - val_accuracy: 0.8615\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.75 - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - ETA: 0s - loss: 0.3124 - accuracy: 0.86 - ETA: 0s - loss: 0.3165 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8655 - val_loss: 0.3600 - val_accuracy: 0.8605\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.90 - ETA: 0s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - ETA: 0s - loss: 0.3115 - accuracy: 0.87 - ETA: 0s - loss: 0.3175 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8695 - val_loss: 0.3629 - val_accuracy: 0.8550\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.90 - ETA: 0s - loss: 0.2976 - accuracy: 0.87 - ETA: 0s - loss: 0.3166 - accuracy: 0.86 - ETA: 0s - loss: 0.3195 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8678 - val_loss: 0.3665 - val_accuracy: 0.8580\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.81 - ETA: 0s - loss: 0.3052 - accuracy: 0.87 - ETA: 0s - loss: 0.3236 - accuracy: 0.86 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8697 - val_loss: 0.3526 - val_accuracy: 0.8590\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.90 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8698 - val_loss: 0.3625 - val_accuracy: 0.8570\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.78 - ETA: 0s - loss: 0.2918 - accuracy: 0.89 - ETA: 0s - loss: 0.3104 - accuracy: 0.88 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8708 - val_loss: 0.3573 - val_accuracy: 0.8600\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.81 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.86 - ETA: 0s - loss: 0.3186 - accuracy: 0.86 - ETA: 0s - loss: 0.3210 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8650 - val_loss: 0.3579 - val_accuracy: 0.8550\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.87 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8653 - val_loss: 0.3518 - val_accuracy: 0.8570\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.84 - ETA: 0s - loss: 0.2962 - accuracy: 0.87 - ETA: 0s - loss: 0.3140 - accuracy: 0.86 - ETA: 0s - loss: 0.3194 - accuracy: 0.86 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8677 - val_loss: 0.3970 - val_accuracy: 0.8580\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.84 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8670 - val_loss: 0.3748 - val_accuracy: 0.8580\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.93 - ETA: 0s - loss: 0.3123 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8655 - val_loss: 0.3613 - val_accuracy: 0.8560\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.90 - ETA: 0s - loss: 0.2946 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - ETA: 0s - loss: 0.3205 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8665 - val_loss: 0.3604 - val_accuracy: 0.8505\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.84 - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - ETA: 0s - loss: 0.2997 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8695 - val_loss: 0.3565 - val_accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.90 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3187 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8700 - val_loss: 0.3581 - val_accuracy: 0.8510\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.84 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8673 - val_loss: 0.3658 - val_accuracy: 0.8575\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.90 - ETA: 0s - loss: 0.3372 - accuracy: 0.85 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8685 - val_loss: 0.3616 - val_accuracy: 0.8585\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.93 - ETA: 0s - loss: 0.3193 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8665 - val_loss: 0.3537 - val_accuracy: 0.8615\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.90 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - ETA: 0s - loss: 0.3403 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8678 - val_loss: 0.3556 - val_accuracy: 0.8610\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8667 - val_loss: 0.3602 - val_accuracy: 0.8540\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 1.00 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3211 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8648 - val_loss: 0.3641 - val_accuracy: 0.8440\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.87 - ETA: 0s - loss: 0.3171 - accuracy: 0.86 - ETA: 0s - loss: 0.3175 - accuracy: 0.86 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - ETA: 0s - loss: 0.3205 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8670 - val_loss: 0.3574 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 1.00 - ETA: 0s - loss: 0.3152 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8690 - val_loss: 0.3551 - val_accuracy: 0.8545\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.90 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8682 - val_loss: 0.3741 - val_accuracy: 0.8460\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.96 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3358 - accuracy: 0.85 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8607 - val_loss: 0.3571 - val_accuracy: 0.8560\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 1.00 - ETA: 0s - loss: 0.3052 - accuracy: 0.88 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.86 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8683 - val_loss: 0.3654 - val_accuracy: 0.8565\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.90 - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3142 - accuracy: 0.86 - ETA: 0s - loss: 0.3169 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8670 - val_loss: 0.3590 - val_accuracy: 0.8540\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.90 - ETA: 0s - loss: 0.3022 - accuracy: 0.86 - ETA: 0s - loss: 0.3149 - accuracy: 0.86 - ETA: 0s - loss: 0.3147 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8708 - val_loss: 0.3616 - val_accuracy: 0.8550\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.81 - ETA: 0s - loss: 0.3169 - accuracy: 0.86 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3164 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8700 - val_loss: 0.3793 - val_accuracy: 0.8465\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.87 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.3109 - accuracy: 0.87 - ETA: 0s - loss: 0.3186 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8717 - val_loss: 0.3656 - val_accuracy: 0.8555\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.84 - ETA: 0s - loss: 0.2973 - accuracy: 0.87 - ETA: 0s - loss: 0.3078 - accuracy: 0.87 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - ETA: 0s - loss: 0.3134 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8700 - val_loss: 0.3563 - val_accuracy: 0.8570\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.93 - ETA: 0s - loss: 0.2995 - accuracy: 0.87 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3103 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8703 - val_loss: 0.3538 - val_accuracy: 0.8580\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.87 - ETA: 0s - loss: 0.2862 - accuracy: 0.88 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3098 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8715 - val_loss: 0.3764 - val_accuracy: 0.8540\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.81 - ETA: 0s - loss: 0.3214 - accuracy: 0.85 - ETA: 0s - loss: 0.3121 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3140 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8670 - val_loss: 0.3636 - val_accuracy: 0.8600\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.93 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3181 - accuracy: 0.87 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - ETA: 0s - loss: 0.3120 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8732 - val_loss: 0.3518 - val_accuracy: 0.8510\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.78 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - ETA: 0s - loss: 0.3275 - accuracy: 0.85 - ETA: 0s - loss: 0.3089 - accuracy: 0.86 - ETA: 0s - loss: 0.3164 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8697 - val_loss: 0.3736 - val_accuracy: 0.8555\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.78 - ETA: 0s - loss: 0.2966 - accuracy: 0.87 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8728 - val_loss: 0.3519 - val_accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.87 - ETA: 0s - loss: 0.2913 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - ETA: 0s - loss: 0.3115 - accuracy: 0.86 - ETA: 0s - loss: 0.3066 - accuracy: 0.87 - ETA: 0s - loss: 0.3100 - accuracy: 0.86 - ETA: 0s - loss: 0.3115 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8712 - val_loss: 0.3775 - val_accuracy: 0.8520\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.84 - ETA: 0s - loss: 0.3190 - accuracy: 0.88 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - ETA: 0s - loss: 0.3204 - accuracy: 0.86 - ETA: 0s - loss: 0.3178 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8698 - val_loss: 0.3724 - val_accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 52cf32d73bb0b25148f810c53099e98d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8644999861717224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.25 - ETA: 0s - loss: 0.6992 - accuracy: 0.51 - ETA: 0s - loss: 0.6829 - accuracy: 0.65 - ETA: 0s - loss: 0.6669 - accuracy: 0.70 - ETA: 0s - loss: 0.6467 - accuracy: 0.72 - 1s 3ms/step - loss: 0.6394 - accuracy: 0.7352 - val_loss: 0.5548 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.78 - ETA: 0s - loss: 0.5479 - accuracy: 0.78 - ETA: 0s - loss: 0.5211 - accuracy: 0.80 - ETA: 0s - loss: 0.5128 - accuracy: 0.80 - ETA: 0s - loss: 0.5165 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7948 - val_loss: 0.4876 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.90 - ETA: 0s - loss: 0.4862 - accuracy: 0.80 - ETA: 0s - loss: 0.4773 - accuracy: 0.80 - ETA: 0s - loss: 0.4738 - accuracy: 0.80 - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7948 - val_loss: 0.4750 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.81 - ETA: 0s - loss: 0.4829 - accuracy: 0.78 - ETA: 0s - loss: 0.4655 - accuracy: 0.79 - ETA: 0s - loss: 0.4700 - accuracy: 0.79 - ETA: 0s - loss: 0.4731 - accuracy: 0.79 - ETA: 0s - loss: 0.4719 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7948 - val_loss: 0.4653 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.81 - ETA: 0s - loss: 0.4465 - accuracy: 0.80 - ETA: 0s - loss: 0.4575 - accuracy: 0.80 - ETA: 0s - loss: 0.4556 - accuracy: 0.80 - ETA: 0s - loss: 0.4601 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7948 - val_loss: 0.4576 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.71 - ETA: 0s - loss: 0.4738 - accuracy: 0.77 - ETA: 0s - loss: 0.4506 - accuracy: 0.79 - ETA: 0s - loss: 0.4475 - accuracy: 0.79 - ETA: 0s - loss: 0.4541 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7948 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.87 - ETA: 0s - loss: 0.4635 - accuracy: 0.77 - ETA: 0s - loss: 0.4447 - accuracy: 0.79 - ETA: 0s - loss: 0.4508 - accuracy: 0.79 - ETA: 0s - loss: 0.4442 - accuracy: 0.80 - ETA: 0s - loss: 0.4452 - accuracy: 0.79 - ETA: 0s - loss: 0.4460 - accuracy: 0.79 - ETA: 0s - loss: 0.4462 - accuracy: 0.79 - 1s 3ms/step - loss: 0.4469 - accuracy: 0.7960 - val_loss: 0.4447 - val_accuracy: 0.8020\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.84 - ETA: 0s - loss: 0.4429 - accuracy: 0.80 - ETA: 0s - loss: 0.4380 - accuracy: 0.80 - ETA: 0s - loss: 0.4452 - accuracy: 0.79 - ETA: 0s - loss: 0.4450 - accuracy: 0.80 - ETA: 0s - loss: 0.4425 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8023 - val_loss: 0.4396 - val_accuracy: 0.8060\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.75 - ETA: 0s - loss: 0.4276 - accuracy: 0.80 - ETA: 0s - loss: 0.4422 - accuracy: 0.79 - ETA: 0s - loss: 0.4404 - accuracy: 0.80 - ETA: 0s - loss: 0.4359 - accuracy: 0.80 - ETA: 0s - loss: 0.4339 - accuracy: 0.80 - ETA: 0s - loss: 0.4360 - accuracy: 0.80 - 1s 3ms/step - loss: 0.4354 - accuracy: 0.8068 - val_loss: 0.4360 - val_accuracy: 0.8075\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.78 - ETA: 0s - loss: 0.4306 - accuracy: 0.80 - ETA: 0s - loss: 0.4298 - accuracy: 0.80 - ETA: 0s - loss: 0.4233 - accuracy: 0.81 - ETA: 0s - loss: 0.4274 - accuracy: 0.81 - ETA: 0s - loss: 0.4314 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8102 - val_loss: 0.4333 - val_accuracy: 0.8105\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.81 - ETA: 0s - loss: 0.4154 - accuracy: 0.82 - ETA: 0s - loss: 0.4138 - accuracy: 0.82 - ETA: 0s - loss: 0.4145 - accuracy: 0.82 - ETA: 0s - loss: 0.4171 - accuracy: 0.82 - ETA: 0s - loss: 0.4276 - accuracy: 0.81 - ETA: 0s - loss: 0.4273 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8132 - val_loss: 0.4313 - val_accuracy: 0.8115\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.78 - ETA: 0s - loss: 0.4401 - accuracy: 0.80 - ETA: 0s - loss: 0.4291 - accuracy: 0.81 - ETA: 0s - loss: 0.4242 - accuracy: 0.81 - ETA: 0s - loss: 0.4265 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8138 - val_loss: 0.4298 - val_accuracy: 0.8150\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.87 - ETA: 0s - loss: 0.4267 - accuracy: 0.81 - ETA: 0s - loss: 0.4171 - accuracy: 0.81 - ETA: 0s - loss: 0.4200 - accuracy: 0.81 - ETA: 0s - loss: 0.4251 - accuracy: 0.81 - ETA: 0s - loss: 0.4251 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8152 - val_loss: 0.4286 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.65 - ETA: 0s - loss: 0.4432 - accuracy: 0.80 - ETA: 0s - loss: 0.4282 - accuracy: 0.81 - ETA: 0s - loss: 0.4209 - accuracy: 0.81 - ETA: 0s - loss: 0.4225 - accuracy: 0.81 - ETA: 0s - loss: 0.4250 - accuracy: 0.81 - ETA: 0s - loss: 0.4255 - accuracy: 0.81 - ETA: 0s - loss: 0.4237 - accuracy: 0.81 - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8162 - val_loss: 0.4273 - val_accuracy: 0.8170\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.93 - ETA: 0s - loss: 0.4416 - accuracy: 0.81 - ETA: 0s - loss: 0.4259 - accuracy: 0.81 - ETA: 0s - loss: 0.4242 - accuracy: 0.81 - ETA: 0s - loss: 0.4249 - accuracy: 0.81 - ETA: 0s - loss: 0.4205 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8173 - val_loss: 0.4268 - val_accuracy: 0.8160\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.84 - ETA: 0s - loss: 0.4397 - accuracy: 0.80 - ETA: 0s - loss: 0.4261 - accuracy: 0.81 - ETA: 0s - loss: 0.4191 - accuracy: 0.81 - ETA: 0s - loss: 0.4119 - accuracy: 0.81 - ETA: 0s - loss: 0.4187 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8188 - val_loss: 0.4252 - val_accuracy: 0.8180\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.84 - ETA: 0s - loss: 0.4384 - accuracy: 0.81 - ETA: 0s - loss: 0.4325 - accuracy: 0.80 - ETA: 0s - loss: 0.4233 - accuracy: 0.81 - ETA: 0s - loss: 0.4157 - accuracy: 0.81 - ETA: 0s - loss: 0.4147 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8202 - val_loss: 0.4238 - val_accuracy: 0.8170\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.81 - ETA: 0s - loss: 0.4026 - accuracy: 0.82 - ETA: 0s - loss: 0.4111 - accuracy: 0.81 - ETA: 0s - loss: 0.4139 - accuracy: 0.81 - ETA: 0s - loss: 0.4157 - accuracy: 0.81 - ETA: 0s - loss: 0.4151 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8197 - val_loss: 0.4228 - val_accuracy: 0.8190\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.84 - ETA: 0s - loss: 0.4310 - accuracy: 0.81 - ETA: 0s - loss: 0.4283 - accuracy: 0.81 - ETA: 0s - loss: 0.4118 - accuracy: 0.82 - ETA: 0s - loss: 0.4124 - accuracy: 0.82 - ETA: 0s - loss: 0.4108 - accuracy: 0.82 - ETA: 0s - loss: 0.4121 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8227 - val_loss: 0.4226 - val_accuracy: 0.8185\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.75 - ETA: 0s - loss: 0.4627 - accuracy: 0.78 - ETA: 0s - loss: 0.4308 - accuracy: 0.80 - ETA: 0s - loss: 0.4225 - accuracy: 0.81 - ETA: 0s - loss: 0.4184 - accuracy: 0.81 - ETA: 0s - loss: 0.4128 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8232 - val_loss: 0.4212 - val_accuracy: 0.8190\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.81 - ETA: 0s - loss: 0.4202 - accuracy: 0.80 - ETA: 0s - loss: 0.4155 - accuracy: 0.81 - ETA: 0s - loss: 0.4129 - accuracy: 0.81 - ETA: 0s - loss: 0.4147 - accuracy: 0.82 - ETA: 0s - loss: 0.4100 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8233 - val_loss: 0.4205 - val_accuracy: 0.8200\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.87 - ETA: 0s - loss: 0.4083 - accuracy: 0.82 - ETA: 0s - loss: 0.4094 - accuracy: 0.82 - ETA: 0s - loss: 0.4148 - accuracy: 0.82 - ETA: 0s - loss: 0.4129 - accuracy: 0.82 - ETA: 0s - loss: 0.4120 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8247 - val_loss: 0.4192 - val_accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.75 - ETA: 0s - loss: 0.4044 - accuracy: 0.83 - ETA: 0s - loss: 0.4100 - accuracy: 0.82 - ETA: 0s - loss: 0.4102 - accuracy: 0.82 - ETA: 0s - loss: 0.4086 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8262 - val_loss: 0.4179 - val_accuracy: 0.8220\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.87 - ETA: 0s - loss: 0.4070 - accuracy: 0.82 - ETA: 0s - loss: 0.3987 - accuracy: 0.83 - ETA: 0s - loss: 0.4066 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8280 - val_loss: 0.4164 - val_accuracy: 0.8235\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.78 - ETA: 0s - loss: 0.3949 - accuracy: 0.82 - ETA: 0s - loss: 0.4046 - accuracy: 0.82 - ETA: 0s - loss: 0.4040 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8272 - val_loss: 0.4151 - val_accuracy: 0.8235\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.68 - ETA: 0s - loss: 0.4145 - accuracy: 0.82 - ETA: 0s - loss: 0.4117 - accuracy: 0.82 - ETA: 0s - loss: 0.4023 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8300 - val_loss: 0.4135 - val_accuracy: 0.8255\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.78 - ETA: 0s - loss: 0.4196 - accuracy: 0.82 - ETA: 0s - loss: 0.4032 - accuracy: 0.82 - ETA: 0s - loss: 0.4065 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8305 - val_loss: 0.4128 - val_accuracy: 0.8280\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.78 - ETA: 0s - loss: 0.3973 - accuracy: 0.83 - ETA: 0s - loss: 0.4026 - accuracy: 0.83 - ETA: 0s - loss: 0.3997 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8330 - val_loss: 0.4109 - val_accuracy: 0.8285\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.84 - ETA: 0s - loss: 0.3995 - accuracy: 0.83 - ETA: 0s - loss: 0.4023 - accuracy: 0.83 - ETA: 0s - loss: 0.3978 - accuracy: 0.83 - ETA: 0s - loss: 0.3950 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8347 - val_loss: 0.4086 - val_accuracy: 0.8275\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.90 - ETA: 0s - loss: 0.3976 - accuracy: 0.83 - ETA: 0s - loss: 0.3851 - accuracy: 0.84 - ETA: 0s - loss: 0.3949 - accuracy: 0.83 - ETA: 0s - loss: 0.3944 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8363 - val_loss: 0.4073 - val_accuracy: 0.8295\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.84 - ETA: 0s - loss: 0.3667 - accuracy: 0.85 - ETA: 0s - loss: 0.3923 - accuracy: 0.83 - ETA: 0s - loss: 0.3898 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8368 - val_loss: 0.4048 - val_accuracy: 0.8345\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.84 - ETA: 0s - loss: 0.3816 - accuracy: 0.84 - ETA: 0s - loss: 0.3853 - accuracy: 0.84 - ETA: 0s - loss: 0.3899 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8390 - val_loss: 0.4028 - val_accuracy: 0.8370\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.90 - ETA: 0s - loss: 0.3724 - accuracy: 0.84 - ETA: 0s - loss: 0.3885 - accuracy: 0.83 - ETA: 0s - loss: 0.3877 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8397 - val_loss: 0.4019 - val_accuracy: 0.8385\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.75 - ETA: 0s - loss: 0.3776 - accuracy: 0.83 - ETA: 0s - loss: 0.3879 - accuracy: 0.84 - ETA: 0s - loss: 0.3871 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8400 - val_loss: 0.3992 - val_accuracy: 0.8385\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.93 - ETA: 0s - loss: 0.3737 - accuracy: 0.84 - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - ETA: 0s - loss: 0.3829 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8408 - val_loss: 0.3967 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.93 - ETA: 0s - loss: 0.3685 - accuracy: 0.85 - ETA: 0s - loss: 0.3720 - accuracy: 0.84 - ETA: 0s - loss: 0.3742 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8418 - val_loss: 0.3945 - val_accuracy: 0.8405\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.87 - ETA: 0s - loss: 0.3738 - accuracy: 0.84 - ETA: 0s - loss: 0.3722 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8435 - val_loss: 0.3939 - val_accuracy: 0.8440\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.87 - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - ETA: 0s - loss: 0.3747 - accuracy: 0.84 - 0s 939us/step - loss: 0.3731 - accuracy: 0.8453 - val_loss: 0.3909 - val_accuracy: 0.8440\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.90 - ETA: 0s - loss: 0.3710 - accuracy: 0.84 - ETA: 0s - loss: 0.3704 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8463 - val_loss: 0.3888 - val_accuracy: 0.8445\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.75 - ETA: 0s - loss: 0.3871 - accuracy: 0.83 - ETA: 0s - loss: 0.3740 - accuracy: 0.84 - 0s 944us/step - loss: 0.3678 - accuracy: 0.8475 - val_loss: 0.3870 - val_accuracy: 0.8445\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.87 - ETA: 0s - loss: 0.3807 - accuracy: 0.83 - ETA: 0s - loss: 0.3640 - accuracy: 0.84 - 0s 931us/step - loss: 0.3659 - accuracy: 0.8483 - val_loss: 0.3854 - val_accuracy: 0.8445\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.87 - ETA: 0s - loss: 0.3666 - accuracy: 0.84 - ETA: 0s - loss: 0.3637 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8490 - val_loss: 0.3834 - val_accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.87 - ETA: 0s - loss: 0.3535 - accuracy: 0.85 - ETA: 0s - loss: 0.3579 - accuracy: 0.85 - 0s 973us/step - loss: 0.3616 - accuracy: 0.8518 - val_loss: 0.3820 - val_accuracy: 0.8480\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.90 - ETA: 0s - loss: 0.3770 - accuracy: 0.84 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8498 - val_loss: 0.3833 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.90 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - 0s 953us/step - loss: 0.3581 - accuracy: 0.8527 - val_loss: 0.3798 - val_accuracy: 0.8490\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.75 - ETA: 0s - loss: 0.3587 - accuracy: 0.85 - ETA: 0s - loss: 0.3597 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8537 - val_loss: 0.3786 - val_accuracy: 0.8510\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.84 - ETA: 0s - loss: 0.3469 - accuracy: 0.86 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8540 - val_loss: 0.3772 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.84 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8555 - val_loss: 0.3756 - val_accuracy: 0.8505\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.84 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3436 - accuracy: 0.86 - 0s 940us/step - loss: 0.3527 - accuracy: 0.8567 - val_loss: 0.3751 - val_accuracy: 0.8495\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1818 - accuracy: 0.93 - ETA: 0s - loss: 0.3540 - accuracy: 0.86 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8550 - val_loss: 0.3741 - val_accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.87 - ETA: 0s - loss: 0.3595 - accuracy: 0.85 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8575 - val_loss: 0.3757 - val_accuracy: 0.8540\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.75 - ETA: 0s - loss: 0.3735 - accuracy: 0.83 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8587 - val_loss: 0.3725 - val_accuracy: 0.8540\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.87 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3454 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8572 - val_loss: 0.3718 - val_accuracy: 0.8545\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.87 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8568 - val_loss: 0.3722 - val_accuracy: 0.8530\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.87 - ETA: 0s - loss: 0.3431 - accuracy: 0.86 - ETA: 0s - loss: 0.3447 - accuracy: 0.86 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8580 - val_loss: 0.3705 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.96 - ETA: 0s - loss: 0.3693 - accuracy: 0.84 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - 0s 925us/step - loss: 0.3461 - accuracy: 0.8572 - val_loss: 0.3707 - val_accuracy: 0.8540\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.87 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3506 - accuracy: 0.85 - 0s 915us/step - loss: 0.3455 - accuracy: 0.8573 - val_loss: 0.3705 - val_accuracy: 0.8545\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.90 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.86 - 0s 930us/step - loss: 0.3446 - accuracy: 0.8608 - val_loss: 0.3695 - val_accuracy: 0.8535\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.87 - ETA: 0s - loss: 0.3512 - accuracy: 0.85 - ETA: 0s - loss: 0.3478 - accuracy: 0.85 - 0s 926us/step - loss: 0.3441 - accuracy: 0.8583 - val_loss: 0.3682 - val_accuracy: 0.8545\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.84 - ETA: 0s - loss: 0.3424 - accuracy: 0.85 - ETA: 0s - loss: 0.3409 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8585 - val_loss: 0.3688 - val_accuracy: 0.8565\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.84 - ETA: 0s - loss: 0.3489 - accuracy: 0.85 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - 0s 916us/step - loss: 0.3428 - accuracy: 0.8588 - val_loss: 0.3672 - val_accuracy: 0.8550\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.90 - ETA: 0s - loss: 0.3466 - accuracy: 0.85 - ETA: 0s - loss: 0.3384 - accuracy: 0.85 - 0s 952us/step - loss: 0.3414 - accuracy: 0.8587 - val_loss: 0.3676 - val_accuracy: 0.8560\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.93 - ETA: 0s - loss: 0.3171 - accuracy: 0.86 - ETA: 0s - loss: 0.3432 - accuracy: 0.85 - 0s 945us/step - loss: 0.3422 - accuracy: 0.8575 - val_loss: 0.3667 - val_accuracy: 0.8545\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.87 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - 0s 956us/step - loss: 0.3407 - accuracy: 0.8597 - val_loss: 0.3665 - val_accuracy: 0.8555\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.81 - ETA: 0s - loss: 0.3552 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - 0s 950us/step - loss: 0.3402 - accuracy: 0.8583 - val_loss: 0.3668 - val_accuracy: 0.8565\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.87 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - 0s 920us/step - loss: 0.3396 - accuracy: 0.8597 - val_loss: 0.3658 - val_accuracy: 0.8565\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.96 - ETA: 0s - loss: 0.3209 - accuracy: 0.87 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - 0s 982us/step - loss: 0.3391 - accuracy: 0.8587 - val_loss: 0.3651 - val_accuracy: 0.8555\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.84 - ETA: 0s - loss: 0.3391 - accuracy: 0.85 - ETA: 0s - loss: 0.3441 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8578 - val_loss: 0.3659 - val_accuracy: 0.8580\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.75 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3378 - accuracy: 0.85 - 0s 983us/step - loss: 0.3378 - accuracy: 0.8592 - val_loss: 0.3648 - val_accuracy: 0.8540\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - 0s 899us/step - loss: 0.3372 - accuracy: 0.8583 - val_loss: 0.3644 - val_accuracy: 0.8565\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.84 - ETA: 0s - loss: 0.3392 - accuracy: 0.85 - ETA: 0s - loss: 0.3377 - accuracy: 0.85 - 0s 993us/step - loss: 0.3368 - accuracy: 0.8583 - val_loss: 0.3639 - val_accuracy: 0.8545\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.84 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - 0s 932us/step - loss: 0.3365 - accuracy: 0.8593 - val_loss: 0.3638 - val_accuracy: 0.8575\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.87 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3400 - accuracy: 0.85 - 0s 993us/step - loss: 0.3359 - accuracy: 0.8592 - val_loss: 0.3640 - val_accuracy: 0.8540\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.75 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3355 - accuracy: 0.85 - 0s 946us/step - loss: 0.3354 - accuracy: 0.8598 - val_loss: 0.3635 - val_accuracy: 0.8540\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.78 - ETA: 0s - loss: 0.3311 - accuracy: 0.85 - ETA: 0s - loss: 0.3367 - accuracy: 0.85 - 0s 977us/step - loss: 0.3343 - accuracy: 0.8603 - val_loss: 0.3635 - val_accuracy: 0.8570\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.78 - ETA: 0s - loss: 0.3361 - accuracy: 0.85 - ETA: 0s - loss: 0.3346 - accuracy: 0.85 - 0s 970us/step - loss: 0.3350 - accuracy: 0.8595 - val_loss: 0.3630 - val_accuracy: 0.8555\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.90 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.85 - 0s 907us/step - loss: 0.3340 - accuracy: 0.8592 - val_loss: 0.3626 - val_accuracy: 0.8555\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.71 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - 0s 921us/step - loss: 0.3336 - accuracy: 0.8612 - val_loss: 0.3629 - val_accuracy: 0.8550\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.81 - ETA: 0s - loss: 0.3356 - accuracy: 0.85 - ETA: 0s - loss: 0.3378 - accuracy: 0.85 - 0s 936us/step - loss: 0.3330 - accuracy: 0.8600 - val_loss: 0.3631 - val_accuracy: 0.8565\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4431 - accuracy: 0.84 - ETA: 0s - loss: 0.3273 - accuracy: 0.85 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - 0s 964us/step - loss: 0.3321 - accuracy: 0.8623 - val_loss: 0.3623 - val_accuracy: 0.8545\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.81 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - 0s 924us/step - loss: 0.3323 - accuracy: 0.8622 - val_loss: 0.3616 - val_accuracy: 0.8545\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.78 - ETA: 0s - loss: 0.3178 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 923us/step - loss: 0.3316 - accuracy: 0.8602 - val_loss: 0.3621 - val_accuracy: 0.8520\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.87 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - 0s 919us/step - loss: 0.3313 - accuracy: 0.8620 - val_loss: 0.3620 - val_accuracy: 0.8525\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.78 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - ETA: 0s - loss: 0.3334 - accuracy: 0.85 - 0s 939us/step - loss: 0.3307 - accuracy: 0.8638 - val_loss: 0.3633 - val_accuracy: 0.8555\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.81 - ETA: 0s - loss: 0.3439 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - 0s 935us/step - loss: 0.3307 - accuracy: 0.8645 - val_loss: 0.3621 - val_accuracy: 0.8540\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.78 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - 0s 943us/step - loss: 0.3308 - accuracy: 0.8640 - val_loss: 0.3627 - val_accuracy: 0.8545\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.87 - ETA: 0s - loss: 0.3085 - accuracy: 0.87 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - 0s 927us/step - loss: 0.3296 - accuracy: 0.8632 - val_loss: 0.3612 - val_accuracy: 0.8530\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.87 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3368 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8653 - val_loss: 0.3626 - val_accuracy: 0.8545\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - 0s 900us/step - loss: 0.3289 - accuracy: 0.8633 - val_loss: 0.3625 - val_accuracy: 0.8560\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.78 - ETA: 0s - loss: 0.3268 - accuracy: 0.87 - ETA: 0s - loss: 0.3237 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8628 - val_loss: 0.3622 - val_accuracy: 0.8565\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.84 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8660 - val_loss: 0.3623 - val_accuracy: 0.8540\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.90 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8650 - val_loss: 0.3617 - val_accuracy: 0.8525\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.84 - ETA: 0s - loss: 0.3499 - accuracy: 0.85 - ETA: 0s - loss: 0.3342 - accuracy: 0.85 - 0s 953us/step - loss: 0.3273 - accuracy: 0.8655 - val_loss: 0.3627 - val_accuracy: 0.8550\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.87 - ETA: 0s - loss: 0.3389 - accuracy: 0.85 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8647 - val_loss: 0.3621 - val_accuracy: 0.8530\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.84 - ETA: 0s - loss: 0.3195 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 996us/step - loss: 0.3265 - accuracy: 0.8655 - val_loss: 0.3612 - val_accuracy: 0.8525\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.81 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3243 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8647 - val_loss: 0.3619 - val_accuracy: 0.8515\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.87 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - 0s 965us/step - loss: 0.3257 - accuracy: 0.8670 - val_loss: 0.3620 - val_accuracy: 0.8535\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.90 - ETA: 0s - loss: 0.3089 - accuracy: 0.88 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8657 - val_loss: 0.3616 - val_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.90 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.86 - 0s 927us/step - loss: 0.3252 - accuracy: 0.8658 - val_loss: 0.3609 - val_accuracy: 0.8520\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.81 - ETA: 0s - loss: 0.3308 - accuracy: 0.85 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8660 - val_loss: 0.3615 - val_accuracy: 0.8530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 4fce77b7631ee7cc822f45777b43c6ac</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8579999804496765</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.12 - ETA: 0s - loss: 0.6253 - accuracy: 0.76 - ETA: 0s - loss: 0.5648 - accuracy: 0.77 - ETA: 0s - loss: 0.5323 - accuracy: 0.78 - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7832 - val_loss: 0.4644 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.81 - ETA: 0s - loss: 0.4512 - accuracy: 0.80 - ETA: 0s - loss: 0.4511 - accuracy: 0.79 - ETA: 0s - loss: 0.4510 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7982 - val_loss: 0.4440 - val_accuracy: 0.8090\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.84 - ETA: 0s - loss: 0.4317 - accuracy: 0.80 - ETA: 0s - loss: 0.4363 - accuracy: 0.80 - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8078 - val_loss: 0.4303 - val_accuracy: 0.8190\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.90 - ETA: 0s - loss: 0.4100 - accuracy: 0.81 - ETA: 0s - loss: 0.4120 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8165 - val_loss: 0.4237 - val_accuracy: 0.8190\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.78 - ETA: 0s - loss: 0.4277 - accuracy: 0.81 - ETA: 0s - loss: 0.4227 - accuracy: 0.81 - ETA: 0s - loss: 0.4160 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8228 - val_loss: 0.4202 - val_accuracy: 0.8285\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.78 - ETA: 0s - loss: 0.4210 - accuracy: 0.81 - ETA: 0s - loss: 0.4046 - accuracy: 0.82 - ETA: 0s - loss: 0.4018 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8263 - val_loss: 0.4119 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.78 - ETA: 0s - loss: 0.3860 - accuracy: 0.83 - ETA: 0s - loss: 0.3890 - accuracy: 0.83 - ETA: 0s - loss: 0.3893 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8340 - val_loss: 0.3969 - val_accuracy: 0.8335\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.84 - ETA: 0s - loss: 0.3597 - accuracy: 0.85 - ETA: 0s - loss: 0.3665 - accuracy: 0.84 - ETA: 0s - loss: 0.3764 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8400 - val_loss: 0.3894 - val_accuracy: 0.8355\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.87 - ETA: 0s - loss: 0.3653 - accuracy: 0.84 - ETA: 0s - loss: 0.3754 - accuracy: 0.83 - ETA: 0s - loss: 0.3685 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8418 - val_loss: 0.3790 - val_accuracy: 0.8375\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.78 - ETA: 0s - loss: 0.3701 - accuracy: 0.84 - ETA: 0s - loss: 0.3665 - accuracy: 0.84 - ETA: 0s - loss: 0.3632 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8428 - val_loss: 0.3758 - val_accuracy: 0.8405\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.90 - ETA: 0s - loss: 0.3766 - accuracy: 0.84 - ETA: 0s - loss: 0.3578 - accuracy: 0.84 - ETA: 0s - loss: 0.3600 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8468 - val_loss: 0.3765 - val_accuracy: 0.8430\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.81 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.84 - ETA: 0s - loss: 0.3559 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8468 - val_loss: 0.3695 - val_accuracy: 0.8415\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.90 - ETA: 0s - loss: 0.3358 - accuracy: 0.85 - ETA: 0s - loss: 0.3537 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8500 - val_loss: 0.3656 - val_accuracy: 0.8475\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.81 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8493 - val_loss: 0.3688 - val_accuracy: 0.8450\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.84 - ETA: 0s - loss: 0.3506 - accuracy: 0.84 - ETA: 0s - loss: 0.3551 - accuracy: 0.84 - 0s 981us/step - loss: 0.3518 - accuracy: 0.8512 - val_loss: 0.3703 - val_accuracy: 0.8415\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.87 - ETA: 0s - loss: 0.3620 - accuracy: 0.85 - ETA: 0s - loss: 0.3588 - accuracy: 0.84 - ETA: 0s - loss: 0.3476 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8533 - val_loss: 0.3642 - val_accuracy: 0.8435\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.93 - ETA: 0s - loss: 0.3298 - accuracy: 0.85 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3512 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8540 - val_loss: 0.3685 - val_accuracy: 0.8470\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.75 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - ETA: 0s - loss: 0.3503 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8540 - val_loss: 0.3640 - val_accuracy: 0.8515\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.90 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3472 - accuracy: 0.85 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8522 - val_loss: 0.3669 - val_accuracy: 0.8500\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.84 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - ETA: 0s - loss: 0.3505 - accuracy: 0.85 - ETA: 0s - loss: 0.3448 - accuracy: 0.85 - ETA: 0s - loss: 0.3443 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8555 - val_loss: 0.3597 - val_accuracy: 0.8615\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.81 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8550 - val_loss: 0.3627 - val_accuracy: 0.8575\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.87 - ETA: 0s - loss: 0.3388 - accuracy: 0.85 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8573 - val_loss: 0.3604 - val_accuracy: 0.8560\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.87 - ETA: 0s - loss: 0.3499 - accuracy: 0.86 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - ETA: 0s - loss: 0.3384 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8557 - val_loss: 0.3605 - val_accuracy: 0.8535\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.90 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8555 - val_loss: 0.3608 - val_accuracy: 0.8495\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.84 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3472 - accuracy: 0.85 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8570 - val_loss: 0.3594 - val_accuracy: 0.8570\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.90 - ETA: 0s - loss: 0.3327 - accuracy: 0.87 - ETA: 0s - loss: 0.3277 - accuracy: 0.87 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8578 - val_loss: 0.3583 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.78 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8583 - val_loss: 0.3603 - val_accuracy: 0.8490\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.87 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8597 - val_loss: 0.3580 - val_accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 1.00 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3433 - accuracy: 0.86 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8588 - val_loss: 0.3598 - val_accuracy: 0.8525\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.87 - ETA: 0s - loss: 0.3276 - accuracy: 0.87 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3384 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8593 - val_loss: 0.3608 - val_accuracy: 0.8540\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.81 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8620 - val_loss: 0.3667 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.84 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8622 - val_loss: 0.3566 - val_accuracy: 0.8580\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.87 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8612 - val_loss: 0.3575 - val_accuracy: 0.8570\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.75 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8628 - val_loss: 0.3642 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.87 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - ETA: 0s - loss: 0.3346 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8605 - val_loss: 0.3559 - val_accuracy: 0.8560\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.87 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8633 - val_loss: 0.3579 - val_accuracy: 0.8580\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.81 - ETA: 0s - loss: 0.3337 - accuracy: 0.85 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8612 - val_loss: 0.3583 - val_accuracy: 0.8575\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.78 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3314 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8630 - val_loss: 0.3573 - val_accuracy: 0.8620\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.81 - ETA: 0s - loss: 0.3172 - accuracy: 0.86 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3365 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8602 - val_loss: 0.3593 - val_accuracy: 0.8595\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.90 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8660 - val_loss: 0.3548 - val_accuracy: 0.8565\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.84 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3334 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8630 - val_loss: 0.3593 - val_accuracy: 0.8530\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.75 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - 0s 972us/step - loss: 0.3317 - accuracy: 0.8640 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.93 - ETA: 0s - loss: 0.3329 - accuracy: 0.85 - ETA: 0s - loss: 0.3385 - accuracy: 0.85 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8642 - val_loss: 0.3578 - val_accuracy: 0.8620\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.90 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - 0s 946us/step - loss: 0.3316 - accuracy: 0.8637 - val_loss: 0.3583 - val_accuracy: 0.8575\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.90 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8638 - val_loss: 0.3622 - val_accuracy: 0.8545\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.87 - ETA: 0s - loss: 0.3077 - accuracy: 0.87 - ETA: 0s - loss: 0.3173 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8653 - val_loss: 0.3560 - val_accuracy: 0.8575\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.93 - ETA: 0s - loss: 0.3067 - accuracy: 0.87 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8655 - val_loss: 0.3578 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.75 - ETA: 0s - loss: 0.3432 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8663 - val_loss: 0.3548 - val_accuracy: 0.8615\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.84 - ETA: 0s - loss: 0.3375 - accuracy: 0.85 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8630 - val_loss: 0.3562 - val_accuracy: 0.8550\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.90 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - ETA: 0s - loss: 0.3373 - accuracy: 0.85 - ETA: 0s - loss: 0.3330 - accuracy: 0.85 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8625 - val_loss: 0.3564 - val_accuracy: 0.8575\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.81 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3391 - accuracy: 0.85 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8660 - val_loss: 0.3535 - val_accuracy: 0.8615\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8660 - val_loss: 0.3567 - val_accuracy: 0.8545\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.93 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - ETA: 0s - loss: 0.3229 - accuracy: 0.87 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8668 - val_loss: 0.3537 - val_accuracy: 0.8575\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.87 - ETA: 0s - loss: 0.3421 - accuracy: 0.85 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8660 - val_loss: 0.3642 - val_accuracy: 0.8590\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.90 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8668 - val_loss: 0.3540 - val_accuracy: 0.8545\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.75 - ETA: 0s - loss: 0.3471 - accuracy: 0.84 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8663 - val_loss: 0.3605 - val_accuracy: 0.8560\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.75 - ETA: 0s - loss: 0.3109 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8662 - val_loss: 0.3645 - val_accuracy: 0.8590\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.78 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3191 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8648 - val_loss: 0.3606 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.87 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8632 - val_loss: 0.3565 - val_accuracy: 0.8620\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.90 - ETA: 0s - loss: 0.3473 - accuracy: 0.84 - ETA: 0s - loss: 0.3175 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8655 - val_loss: 0.3697 - val_accuracy: 0.8485\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.81 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8678 - val_loss: 0.3558 - val_accuracy: 0.8570\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.90 - ETA: 0s - loss: 0.3508 - accuracy: 0.84 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8663 - val_loss: 0.3577 - val_accuracy: 0.8560\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.90 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8658 - val_loss: 0.3622 - val_accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.90 - ETA: 0s - loss: 0.3200 - accuracy: 0.87 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8672 - val_loss: 0.3634 - val_accuracy: 0.8550\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.78 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8663 - val_loss: 0.3595 - val_accuracy: 0.8590\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.93 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3247 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8673 - val_loss: 0.3591 - val_accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3082 - accuracy: 0.81 - ETA: 0s - loss: 0.2940 - accuracy: 0.88 - ETA: 0s - loss: 0.3141 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8680 - val_loss: 0.3595 - val_accuracy: 0.8595\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - ETA: 0s - loss: 0.3152 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8690 - val_loss: 0.3622 - val_accuracy: 0.8580\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.78 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3200 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8673 - val_loss: 0.3620 - val_accuracy: 0.8615\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.84 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8678 - val_loss: 0.3632 - val_accuracy: 0.8540\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.84 - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8697 - val_loss: 0.3590 - val_accuracy: 0.8570\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.93 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - 0s 978us/step - loss: 0.3215 - accuracy: 0.8677 - val_loss: 0.3620 - val_accuracy: 0.8590\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.90 - ETA: 0s - loss: 0.3281 - accuracy: 0.87 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - ETA: 0s - loss: 0.3193 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8690 - val_loss: 0.3589 - val_accuracy: 0.8585\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.81 - ETA: 0s - loss: 0.3330 - accuracy: 0.85 - ETA: 0s - loss: 0.3311 - accuracy: 0.85 - 0s 968us/step - loss: 0.3192 - accuracy: 0.8670 - val_loss: 0.3726 - val_accuracy: 0.8495\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.87 - ETA: 0s - loss: 0.3115 - accuracy: 0.87 - ETA: 0s - loss: 0.3158 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8702 - val_loss: 0.3635 - val_accuracy: 0.8550\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.87 - ETA: 0s - loss: 0.3017 - accuracy: 0.88 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8688 - val_loss: 0.3635 - val_accuracy: 0.8575\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.87 - ETA: 0s - loss: 0.3100 - accuracy: 0.87 - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - ETA: 0s - loss: 0.3172 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8713 - val_loss: 0.3713 - val_accuracy: 0.8555\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.81 - ETA: 0s - loss: 0.3301 - accuracy: 0.85 - ETA: 0s - loss: 0.3141 - accuracy: 0.86 - ETA: 0s - loss: 0.3192 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8667 - val_loss: 0.3629 - val_accuracy: 0.8520\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.78 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8687 - val_loss: 0.3663 - val_accuracy: 0.8540\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.87 - ETA: 0s - loss: 0.3229 - accuracy: 0.86 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - ETA: 0s - loss: 0.3197 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8693 - val_loss: 0.3620 - val_accuracy: 0.8605\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.81 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - ETA: 0s - loss: 0.3175 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8700 - val_loss: 0.3665 - val_accuracy: 0.8600\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.84 - ETA: 0s - loss: 0.3312 - accuracy: 0.85 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8692 - val_loss: 0.3768 - val_accuracy: 0.8525\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.87 - ETA: 0s - loss: 0.3122 - accuracy: 0.87 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8683 - val_loss: 0.3615 - val_accuracy: 0.8515\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.84 - ETA: 0s - loss: 0.2952 - accuracy: 0.88 - ETA: 0s - loss: 0.3091 - accuracy: 0.87 - ETA: 0s - loss: 0.3150 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8712 - val_loss: 0.3834 - val_accuracy: 0.8535\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.75 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3131 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8698 - val_loss: 0.3692 - val_accuracy: 0.8555\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.81 - ETA: 0s - loss: 0.3135 - accuracy: 0.87 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8713 - val_loss: 0.3655 - val_accuracy: 0.8545\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.84 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8693 - val_loss: 0.3666 - val_accuracy: 0.8475\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.96 - ETA: 0s - loss: 0.3352 - accuracy: 0.85 - ETA: 0s - loss: 0.3183 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8698 - val_loss: 0.3693 - val_accuracy: 0.8510\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.87 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - ETA: 0s - loss: 0.3089 - accuracy: 0.87 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8713 - val_loss: 0.3670 - val_accuracy: 0.8605\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.87 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8695 - val_loss: 0.3732 - val_accuracy: 0.8610\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.2893 - accuracy: 0.87 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - 0s 943us/step - loss: 0.3133 - accuracy: 0.8712 - val_loss: 0.3748 - val_accuracy: 0.8555\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.93 - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - 0s 998us/step - loss: 0.3152 - accuracy: 0.8728 - val_loss: 0.3659 - val_accuracy: 0.8600\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.93 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - 0s 978us/step - loss: 0.3136 - accuracy: 0.8732 - val_loss: 0.3735 - val_accuracy: 0.8570\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - ETA: 0s - loss: 0.3018 - accuracy: 0.87 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8690 - val_loss: 0.3655 - val_accuracy: 0.8580\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.87 - ETA: 0s - loss: 0.2946 - accuracy: 0.87 - ETA: 0s - loss: 0.3126 - accuracy: 0.86 - ETA: 0s - loss: 0.3094 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8720 - val_loss: 0.3707 - val_accuracy: 0.8570\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.90 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - ETA: 0s - loss: 0.3174 - accuracy: 0.87 - ETA: 0s - loss: 0.3181 - accuracy: 0.87 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8728 - val_loss: 0.3694 - val_accuracy: 0.8560\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.78 - ETA: 0s - loss: 0.3364 - accuracy: 0.85 - ETA: 0s - loss: 0.3157 - accuracy: 0.86 - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8720 - val_loss: 0.3728 - val_accuracy: 0.8575\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.96 - ETA: 0s - loss: 0.2868 - accuracy: 0.89 - ETA: 0s - loss: 0.2948 - accuracy: 0.88 - ETA: 0s - loss: 0.2966 - accuracy: 0.88 - ETA: 0s - loss: 0.3066 - accuracy: 0.87 - ETA: 0s - loss: 0.3111 - accuracy: 0.87 - ETA: 0s - loss: 0.3149 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8700 - val_loss: 0.3619 - val_accuracy: 0.8570\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.90 - ETA: 0s - loss: 0.2873 - accuracy: 0.87 - ETA: 0s - loss: 0.2980 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3025 - accuracy: 0.87 - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8698 - val_loss: 0.3696 - val_accuracy: 0.8595\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.84 - ETA: 0s - loss: 0.3325 - accuracy: 0.85 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8728 - val_loss: 0.3649 - val_accuracy: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 22dc031d812dc49c4948b1637bf2df01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8619999885559082</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.53 - ETA: 0s - loss: 0.5367 - accuracy: 0.79 - ETA: 0s - loss: 0.4927 - accuracy: 0.79 - ETA: 0s - loss: 0.4731 - accuracy: 0.79 - ETA: 0s - loss: 0.4631 - accuracy: 0.79 - 1s 3ms/step - loss: 0.4587 - accuracy: 0.7942 - val_loss: 0.4126 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.78 - ETA: 0s - loss: 0.4143 - accuracy: 0.78 - ETA: 0s - loss: 0.3998 - accuracy: 0.79 - ETA: 0s - loss: 0.4069 - accuracy: 0.79 - ETA: 0s - loss: 0.3996 - accuracy: 0.80 - ETA: 0s - loss: 0.4018 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8082 - val_loss: 0.3821 - val_accuracy: 0.8425\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.87 - ETA: 0s - loss: 0.3720 - accuracy: 0.84 - ETA: 0s - loss: 0.3766 - accuracy: 0.84 - ETA: 0s - loss: 0.3676 - accuracy: 0.84 - ETA: 0s - loss: 0.3568 - accuracy: 0.85 - ETA: 0s - loss: 0.3645 - accuracy: 0.85 - ETA: 0s - loss: 0.3692 - accuracy: 0.85 - ETA: 0s - loss: 0.3725 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3733 - accuracy: 0.8473 - val_loss: 0.3743 - val_accuracy: 0.8460\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.81 - ETA: 0s - loss: 0.4095 - accuracy: 0.82 - ETA: 0s - loss: 0.3800 - accuracy: 0.83 - ETA: 0s - loss: 0.3717 - accuracy: 0.84 - ETA: 0s - loss: 0.3702 - accuracy: 0.84 - ETA: 0s - loss: 0.3683 - accuracy: 0.84 - ETA: 0s - loss: 0.3620 - accuracy: 0.85 - ETA: 0s - loss: 0.3550 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3620 - accuracy: 0.8532 - val_loss: 0.4468 - val_accuracy: 0.8545\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.96 - ETA: 0s - loss: 0.3626 - accuracy: 0.87 - ETA: 0s - loss: 0.3405 - accuracy: 0.87 - ETA: 0s - loss: 0.3517 - accuracy: 0.86 - ETA: 0s - loss: 0.3437 - accuracy: 0.86 - ETA: 0s - loss: 0.3440 - accuracy: 0.86 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8543 - val_loss: 0.3667 - val_accuracy: 0.8510\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.84 - ETA: 0s - loss: 0.3609 - accuracy: 0.84 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3457 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8598 - val_loss: 0.3553 - val_accuracy: 0.8540\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.96 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3229 - accuracy: 0.86 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - ETA: 0s - loss: 0.3489 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8607 - val_loss: 0.3650 - val_accuracy: 0.8490\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.90 - ETA: 0s - loss: 0.3477 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8628 - val_loss: 0.3738 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.75 - ETA: 0s - loss: 0.3484 - accuracy: 0.86 - ETA: 0s - loss: 0.3586 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8592 - val_loss: 0.3528 - val_accuracy: 0.8485\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.87 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3423 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8633 - val_loss: 0.3543 - val_accuracy: 0.8575\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.96 - ETA: 0s - loss: 0.3567 - accuracy: 0.85 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - ETA: 0s - loss: 0.3205 - accuracy: 0.87 - ETA: 0s - loss: 0.3337 - accuracy: 0.87 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8620 - val_loss: 0.3568 - val_accuracy: 0.8565\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.87 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.85 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3368 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8623 - val_loss: 0.3495 - val_accuracy: 0.8600\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3340 - accuracy: 0.85 - ETA: 0s - loss: 0.3229 - accuracy: 0.87 - ETA: 0s - loss: 0.3268 - accuracy: 0.87 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8690 - val_loss: 0.3469 - val_accuracy: 0.8565\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.96 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8645 - val_loss: 0.3598 - val_accuracy: 0.8530\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8672 - val_loss: 0.3484 - val_accuracy: 0.8520\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.90 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8702 - val_loss: 0.3509 - val_accuracy: 0.8595\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.87 - ETA: 0s - loss: 0.3069 - accuracy: 0.88 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8650 - val_loss: 0.3547 - val_accuracy: 0.8555\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.90 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8652 - val_loss: 0.3586 - val_accuracy: 0.8610\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.90 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8682 - val_loss: 0.3601 - val_accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - ETA: 0s - loss: 0.3016 - accuracy: 0.87 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8707 - val_loss: 0.3651 - val_accuracy: 0.8530\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.81 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.87 - ETA: 0s - loss: 0.3232 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8702 - val_loss: 0.3625 - val_accuracy: 0.8570\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.3341 - accuracy: 0.85 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3210 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8658 - val_loss: 0.3597 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.87 - ETA: 0s - loss: 0.3396 - accuracy: 0.85 - ETA: 0s - loss: 0.3333 - accuracy: 0.85 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8642 - val_loss: 0.3902 - val_accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.90 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8680 - val_loss: 0.3557 - val_accuracy: 0.8560\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.90 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8668 - val_loss: 0.3622 - val_accuracy: 0.8510\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.93 - ETA: 0s - loss: 0.3187 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8650 - val_loss: 0.3541 - val_accuracy: 0.8545\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.96 - ETA: 0s - loss: 0.3126 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8723 - val_loss: 0.4066 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.87 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8643 - val_loss: 0.3488 - val_accuracy: 0.8655\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.90 - ETA: 0s - loss: 0.3135 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3228 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8710 - val_loss: 0.3542 - val_accuracy: 0.8600\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.87 - ETA: 0s - loss: 0.3052 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3098 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8755 - val_loss: 0.3565 - val_accuracy: 0.8580\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.90 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - ETA: 0s - loss: 0.3059 - accuracy: 0.87 - ETA: 0s - loss: 0.3166 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8728 - val_loss: 0.3570 - val_accuracy: 0.8545\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.90 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8710 - val_loss: 0.3669 - val_accuracy: 0.8475\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.90 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - ETA: 0s - loss: 0.3101 - accuracy: 0.87 - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8737 - val_loss: 0.3566 - val_accuracy: 0.8550\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.2892 - accuracy: 0.88 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3097 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8747 - val_loss: 0.3786 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.84 - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - ETA: 0s - loss: 0.3055 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8765 - val_loss: 0.3521 - val_accuracy: 0.8620\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.87 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8767 - val_loss: 0.4121 - val_accuracy: 0.8490\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.87 - ETA: 0s - loss: 0.2913 - accuracy: 0.88 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8690 - val_loss: 0.3742 - val_accuracy: 0.8420\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.81 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.85 - ETA: 0s - loss: 0.3235 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8647 - val_loss: 0.3782 - val_accuracy: 0.8565\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.84 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3185 - accuracy: 0.87 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8740 - val_loss: 0.3735 - val_accuracy: 0.8595\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.84 - ETA: 0s - loss: 0.2941 - accuracy: 0.87 - ETA: 0s - loss: 0.3000 - accuracy: 0.87 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8750 - val_loss: 0.3567 - val_accuracy: 0.8540\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.87 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - ETA: 0s - loss: 0.3114 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8755 - val_loss: 0.3664 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.93 - ETA: 0s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3051 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3053 - accuracy: 0.8765 - val_loss: 0.3723 - val_accuracy: 0.8590\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.84 - ETA: 0s - loss: 0.2938 - accuracy: 0.88 - ETA: 0s - loss: 0.2993 - accuracy: 0.88 - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8772 - val_loss: 0.3523 - val_accuracy: 0.8585\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.90 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8767 - val_loss: 0.3650 - val_accuracy: 0.8585\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.78 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8777 - val_loss: 0.3880 - val_accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.96 - ETA: 0s - loss: 0.2934 - accuracy: 0.87 - ETA: 0s - loss: 0.3066 - accuracy: 0.87 - ETA: 0s - loss: 0.3025 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3023 - accuracy: 0.8750 - val_loss: 0.3677 - val_accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.93 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8737 - val_loss: 0.3529 - val_accuracy: 0.8585\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.81 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - ETA: 0s - loss: 0.3122 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8705 - val_loss: 0.3559 - val_accuracy: 0.8560\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.81 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - ETA: 0s - loss: 0.2991 - accuracy: 0.87 - ETA: 0s - loss: 0.2967 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8768 - val_loss: 0.3572 - val_accuracy: 0.8565\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.81 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - ETA: 0s - loss: 0.2988 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8770 - val_loss: 0.3531 - val_accuracy: 0.8595\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.84 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.3005 - accuracy: 0.87 - ETA: 0s - loss: 0.2949 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8755 - val_loss: 0.3609 - val_accuracy: 0.8545\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.90 - ETA: 0s - loss: 0.2968 - accuracy: 0.88 - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8730 - val_loss: 0.3532 - val_accuracy: 0.8560\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.90 - ETA: 0s - loss: 0.2963 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.88 - ETA: 0s - loss: 0.2978 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8795 - val_loss: 0.4052 - val_accuracy: 0.8555\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - ETA: 0s - loss: 0.2886 - accuracy: 0.88 - ETA: 0s - loss: 0.2882 - accuracy: 0.88 - ETA: 0s - loss: 0.2919 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8787 - val_loss: 0.3758 - val_accuracy: 0.8570\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.84 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8790 - val_loss: 0.3907 - val_accuracy: 0.8555\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.84 - ETA: 0s - loss: 0.3068 - accuracy: 0.88 - ETA: 0s - loss: 0.3059 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8745 - val_loss: 0.3706 - val_accuracy: 0.8470\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.87 - ETA: 0s - loss: 0.2892 - accuracy: 0.86 - ETA: 0s - loss: 0.2979 - accuracy: 0.87 - ETA: 0s - loss: 0.2996 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3046 - accuracy: 0.8770 - val_loss: 0.3711 - val_accuracy: 0.8545\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.90 - ETA: 0s - loss: 0.5096 - accuracy: 0.86 - ETA: 0s - loss: 0.4322 - accuracy: 0.86 - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8593 - val_loss: 0.3897 - val_accuracy: 0.8400\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.93 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3402 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8613 - val_loss: 0.3888 - val_accuracy: 0.8410\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.81 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3195 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8672 - val_loss: 0.4124 - val_accuracy: 0.8490\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.81 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3061 - accuracy: 0.88 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3150 - accuracy: 0.86 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8710 - val_loss: 0.3919 - val_accuracy: 0.8505\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.90 - ETA: 0s - loss: 0.2905 - accuracy: 0.88 - ETA: 0s - loss: 0.2886 - accuracy: 0.88 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.2993 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3014 - accuracy: 0.8758 - val_loss: 0.3744 - val_accuracy: 0.8500\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.90 - ETA: 0s - loss: 0.2695 - accuracy: 0.89 - ETA: 0s - loss: 0.2856 - accuracy: 0.88 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - ETA: 0s - loss: 0.3063 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8730 - val_loss: 0.3842 - val_accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.90 - ETA: 0s - loss: 0.3317 - accuracy: 0.87 - ETA: 0s - loss: 0.3126 - accuracy: 0.88 - ETA: 0s - loss: 0.3031 - accuracy: 0.88 - ETA: 0s - loss: 0.3048 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8765 - val_loss: 0.3750 - val_accuracy: 0.8520\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.90 - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - ETA: 0s - loss: 0.2879 - accuracy: 0.88 - ETA: 0s - loss: 0.2892 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8798 - val_loss: 0.4083 - val_accuracy: 0.8555\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.93 - ETA: 0s - loss: 0.2725 - accuracy: 0.89 - ETA: 0s - loss: 0.2824 - accuracy: 0.88 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8813 - val_loss: 0.4099 - val_accuracy: 0.8480\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.93 - ETA: 0s - loss: 0.2706 - accuracy: 0.88 - ETA: 0s - loss: 0.2756 - accuracy: 0.88 - ETA: 0s - loss: 0.2781 - accuracy: 0.88 - ETA: 0s - loss: 0.2852 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8855 - val_loss: 0.3798 - val_accuracy: 0.8570\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.90 - ETA: 0s - loss: 0.2762 - accuracy: 0.89 - ETA: 0s - loss: 0.2699 - accuracy: 0.89 - ETA: 0s - loss: 0.2777 - accuracy: 0.88 - ETA: 0s - loss: 0.2806 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8828 - val_loss: 0.4123 - val_accuracy: 0.8565\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - ETA: 0s - loss: 0.2969 - accuracy: 0.88 - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - ETA: 0s - loss: 0.2835 - accuracy: 0.88 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8838 - val_loss: 0.4203 - val_accuracy: 0.8565\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 1.00 - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - ETA: 0s - loss: 0.2801 - accuracy: 0.88 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8848 - val_loss: 0.3979 - val_accuracy: 0.8555\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.81 - ETA: 0s - loss: 0.2859 - accuracy: 0.88 - ETA: 0s - loss: 0.2734 - accuracy: 0.88 - ETA: 0s - loss: 0.2715 - accuracy: 0.89 - ETA: 0s - loss: 0.2797 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8858 - val_loss: 0.4027 - val_accuracy: 0.8510\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.87 - ETA: 0s - loss: 0.2741 - accuracy: 0.88 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.3255 - accuracy: 0.88 - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8763 - val_loss: 0.3955 - val_accuracy: 0.8445\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.93 - ETA: 0s - loss: 0.3304 - accuracy: 0.85 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8715 - val_loss: 0.3900 - val_accuracy: 0.8530\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.81 - ETA: 0s - loss: 0.2956 - accuracy: 0.88 - ETA: 0s - loss: 0.2876 - accuracy: 0.88 - ETA: 0s - loss: 0.2980 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8790 - val_loss: 0.3764 - val_accuracy: 0.8570\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8808 - val_loss: 0.3924 - val_accuracy: 0.8525\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.84 - ETA: 0s - loss: 0.2604 - accuracy: 0.88 - ETA: 0s - loss: 0.2768 - accuracy: 0.88 - ETA: 0s - loss: 0.2833 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8807 - val_loss: 0.3732 - val_accuracy: 0.8565\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.81 - ETA: 0s - loss: 0.2727 - accuracy: 0.89 - ETA: 0s - loss: 0.2709 - accuracy: 0.89 - ETA: 0s - loss: 0.2793 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8850 - val_loss: 0.3773 - val_accuracy: 0.8575\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.93 - ETA: 0s - loss: 0.2657 - accuracy: 0.88 - ETA: 0s - loss: 0.2740 - accuracy: 0.88 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2813 - accuracy: 0.8810 - val_loss: 0.3840 - val_accuracy: 0.8555\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.84 - ETA: 0s - loss: 0.2661 - accuracy: 0.88 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.2717 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2783 - accuracy: 0.8855 - val_loss: 0.3906 - val_accuracy: 0.8575\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.81 - ETA: 0s - loss: 0.2825 - accuracy: 0.87 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - ETA: 0s - loss: 0.2756 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8802 - val_loss: 0.3719 - val_accuracy: 0.8465\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.93 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3208 - accuracy: 0.87 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - ETA: 0s - loss: 0.2968 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8755 - val_loss: 0.3853 - val_accuracy: 0.8550\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.90 - ETA: 0s - loss: 0.2842 - accuracy: 0.88 - ETA: 0s - loss: 0.2675 - accuracy: 0.88 - ETA: 0s - loss: 0.2815 - accuracy: 0.87 - ETA: 0s - loss: 0.2804 - accuracy: 0.88 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - 1s 3ms/step - loss: 0.2807 - accuracy: 0.8802 - val_loss: 0.3843 - val_accuracy: 0.8550\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.93 - ETA: 0s - loss: 0.2690 - accuracy: 0.89 - ETA: 0s - loss: 0.2602 - accuracy: 0.89 - ETA: 0s - loss: 0.2658 - accuracy: 0.88 - ETA: 0s - loss: 0.2625 - accuracy: 0.89 - ETA: 0s - loss: 0.2638 - accuracy: 0.88 - ETA: 0s - loss: 0.2681 - accuracy: 0.88 - ETA: 0s - loss: 0.2746 - accuracy: 0.88 - 1s 3ms/step - loss: 0.2786 - accuracy: 0.8837 - val_loss: 0.3969 - val_accuracy: 0.8510\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.84 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - ETA: 0s - loss: 0.3367 - accuracy: 0.85 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3117 - accuracy: 0.86 - ETA: 0s - loss: 0.3081 - accuracy: 0.86 - ETA: 0s - loss: 0.2988 - accuracy: 0.87 - ETA: 0s - loss: 0.2948 - accuracy: 0.87 - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8770 - val_loss: 0.3922 - val_accuracy: 0.8545\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.78 - ETA: 0s - loss: 0.2784 - accuracy: 0.88 - ETA: 0s - loss: 0.2716 - accuracy: 0.88 - ETA: 0s - loss: 0.2864 - accuracy: 0.87 - ETA: 0s - loss: 0.2809 - accuracy: 0.87 - ETA: 0s - loss: 0.2781 - accuracy: 0.88 - ETA: 0s - loss: 0.2802 - accuracy: 0.87 - ETA: 0s - loss: 0.2842 - accuracy: 0.87 - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8807 - val_loss: 0.4345 - val_accuracy: 0.8555\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.84 - ETA: 0s - loss: 0.2604 - accuracy: 0.89 - ETA: 0s - loss: 0.2723 - accuracy: 0.88 - ETA: 0s - loss: 0.2580 - accuracy: 0.89 - ETA: 0s - loss: 0.2659 - accuracy: 0.88 - ETA: 0s - loss: 0.2719 - accuracy: 0.88 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - ETA: 0s - loss: 0.2820 - accuracy: 0.88 - 1s 3ms/step - loss: 0.2838 - accuracy: 0.8810 - val_loss: 0.3892 - val_accuracy: 0.8575\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.87 - ETA: 0s - loss: 0.2624 - accuracy: 0.89 - ETA: 0s - loss: 0.2677 - accuracy: 0.88 - ETA: 0s - loss: 0.2761 - accuracy: 0.88 - ETA: 0s - loss: 0.2824 - accuracy: 0.88 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8818 - val_loss: 0.3750 - val_accuracy: 0.8560\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.96 - ETA: 0s - loss: 0.2952 - accuracy: 0.87 - ETA: 0s - loss: 0.2959 - accuracy: 0.87 - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - ETA: 0s - loss: 0.2855 - accuracy: 0.87 - ETA: 0s - loss: 0.2865 - accuracy: 0.87 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8795 - val_loss: 0.3853 - val_accuracy: 0.8545\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.93 - ETA: 0s - loss: 0.2673 - accuracy: 0.88 - ETA: 0s - loss: 0.2586 - accuracy: 0.89 - ETA: 0s - loss: 0.2650 - accuracy: 0.88 - ETA: 0s - loss: 0.2805 - accuracy: 0.88 - ETA: 0s - loss: 0.2810 - accuracy: 0.88 - ETA: 0s - loss: 0.2841 - accuracy: 0.88 - ETA: 0s - loss: 0.2906 - accuracy: 0.87 - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8795 - val_loss: 0.3968 - val_accuracy: 0.8570\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.90 - ETA: 0s - loss: 0.2809 - accuracy: 0.87 - ETA: 0s - loss: 0.2840 - accuracy: 0.87 - ETA: 0s - loss: 0.2825 - accuracy: 0.87 - ETA: 0s - loss: 0.2856 - accuracy: 0.87 - ETA: 0s - loss: 0.2860 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8777 - val_loss: 0.3826 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.81 - ETA: 0s - loss: 0.2715 - accuracy: 0.88 - ETA: 0s - loss: 0.2686 - accuracy: 0.88 - ETA: 0s - loss: 0.2759 - accuracy: 0.87 - ETA: 0s - loss: 0.2720 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8827 - val_loss: 0.3789 - val_accuracy: 0.8570\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.87 - ETA: 0s - loss: 0.2857 - accuracy: 0.87 - ETA: 0s - loss: 0.2884 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - ETA: 0s - loss: 0.2773 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8838 - val_loss: 0.3962 - val_accuracy: 0.8560\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.87 - ETA: 0s - loss: 0.2415 - accuracy: 0.90 - ETA: 0s - loss: 0.2521 - accuracy: 0.89 - ETA: 0s - loss: 0.2622 - accuracy: 0.89 - ETA: 0s - loss: 0.2626 - accuracy: 0.89 - ETA: 0s - loss: 0.2705 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8895 - val_loss: 0.3736 - val_accuracy: 0.8510\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.84 - ETA: 0s - loss: 0.2834 - accuracy: 0.87 - ETA: 0s - loss: 0.2742 - accuracy: 0.87 - ETA: 0s - loss: 0.2674 - accuracy: 0.88 - ETA: 0s - loss: 0.2688 - accuracy: 0.88 - ETA: 0s - loss: 0.2688 - accuracy: 0.88 - ETA: 0s - loss: 0.2735 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8842 - val_loss: 0.4451 - val_accuracy: 0.8550\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.87 - ETA: 0s - loss: 0.2666 - accuracy: 0.88 - ETA: 0s - loss: 0.2621 - accuracy: 0.88 - ETA: 0s - loss: 0.2739 - accuracy: 0.88 - ETA: 0s - loss: 0.2798 - accuracy: 0.88 - ETA: 0s - loss: 0.2847 - accuracy: 0.87 - ETA: 0s - loss: 0.3472 - accuracy: 0.88 - ETA: 0s - loss: 0.3382 - accuracy: 0.88 - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8842 - val_loss: 0.4140 - val_accuracy: 0.8460\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.87 - ETA: 0s - loss: 0.2999 - accuracy: 0.88 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.2991 - accuracy: 0.87 - ETA: 0s - loss: 0.3035 - accuracy: 0.87 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8797 - val_loss: 0.4023 - val_accuracy: 0.8475\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - ETA: 0s - loss: 0.2884 - accuracy: 0.88 - ETA: 0s - loss: 0.2833 - accuracy: 0.88 - ETA: 0s - loss: 0.2905 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - ETA: 0s - loss: 0.2911 - accuracy: 0.88 - ETA: 0s - loss: 0.2902 - accuracy: 0.88 - ETA: 0s - loss: 0.2893 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8825 - val_loss: 0.3905 - val_accuracy: 0.8495\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.96 - ETA: 0s - loss: 0.2922 - accuracy: 0.87 - ETA: 0s - loss: 0.2758 - accuracy: 0.88 - ETA: 0s - loss: 0.2881 - accuracy: 0.87 - ETA: 0s - loss: 0.2880 - accuracy: 0.87 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - ETA: 0s - loss: 0.2781 - accuracy: 0.88 - ETA: 0s - loss: 0.2828 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8840 - val_loss: 0.4289 - val_accuracy: 0.8460\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.90 - ETA: 0s - loss: 0.2400 - accuracy: 0.90 - ETA: 0s - loss: 0.2562 - accuracy: 0.89 - ETA: 0s - loss: 0.2688 - accuracy: 0.88 - ETA: 0s - loss: 0.2668 - accuracy: 0.89 - ETA: 0s - loss: 0.2766 - accuracy: 0.88 - ETA: 0s - loss: 0.2781 - accuracy: 0.88 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - 1s 3ms/step - loss: 0.2803 - accuracy: 0.8833 - val_loss: 0.4171 - val_accuracy: 0.8460\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.84 - ETA: 0s - loss: 0.3000 - accuracy: 0.86 - ETA: 0s - loss: 0.2840 - accuracy: 0.87 - ETA: 0s - loss: 0.2894 - accuracy: 0.87 - ETA: 0s - loss: 0.2776 - accuracy: 0.88 - ETA: 0s - loss: 0.2747 - accuracy: 0.88 - ETA: 0s - loss: 0.2767 - accuracy: 0.88 - ETA: 0s - loss: 0.2779 - accuracy: 0.88 - 1s 3ms/step - loss: 0.2769 - accuracy: 0.8832 - val_loss: 0.4358 - val_accuracy: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 690055055f6b26574c0679b98b26b231</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8654999732971191</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7251 - accuracy: 0.18 - ETA: 0s - loss: 0.7124 - accuracy: 0.20 - ETA: 0s - loss: 0.7058 - accuracy: 0.27 - ETA: 0s - loss: 0.6998 - accuracy: 0.42 - ETA: 0s - loss: 0.6951 - accuracy: 0.51 - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5178 - val_loss: 0.6768 - val_accuracy: 0.7895\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.84 - ETA: 0s - loss: 0.6757 - accuracy: 0.77 - ETA: 0s - loss: 0.6718 - accuracy: 0.78 - ETA: 0s - loss: 0.6668 - accuracy: 0.78 - ETA: 0s - loss: 0.6605 - accuracy: 0.78 - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7933 - val_loss: 0.6187 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.75 - ETA: 0s - loss: 0.6158 - accuracy: 0.78 - ETA: 0s - loss: 0.6085 - accuracy: 0.78 - ETA: 0s - loss: 0.5962 - accuracy: 0.78 - ETA: 0s - loss: 0.5841 - accuracy: 0.79 - ETA: 0s - loss: 0.5747 - accuracy: 0.79 - ETA: 0s - loss: 0.5651 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7948 - val_loss: 0.5093 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5538 - accuracy: 0.78 - ETA: 0s - loss: 0.5252 - accuracy: 0.78 - ETA: 0s - loss: 0.5124 - accuracy: 0.79 - ETA: 0s - loss: 0.5026 - accuracy: 0.79 - ETA: 0s - loss: 0.4968 - accuracy: 0.79 - ETA: 0s - loss: 0.4938 - accuracy: 0.80 - ETA: 0s - loss: 0.4955 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7948 - val_loss: 0.4802 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.71 - ETA: 0s - loss: 0.4782 - accuracy: 0.79 - ETA: 0s - loss: 0.4738 - accuracy: 0.80 - ETA: 0s - loss: 0.4739 - accuracy: 0.79 - ETA: 0s - loss: 0.4784 - accuracy: 0.79 - ETA: 0s - loss: 0.4759 - accuracy: 0.79 - ETA: 0s - loss: 0.4735 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7948 - val_loss: 0.4649 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.84 - ETA: 0s - loss: 0.4716 - accuracy: 0.78 - ETA: 0s - loss: 0.4526 - accuracy: 0.80 - ETA: 0s - loss: 0.4543 - accuracy: 0.79 - ETA: 0s - loss: 0.4521 - accuracy: 0.79 - ETA: 0s - loss: 0.4537 - accuracy: 0.79 - ETA: 0s - loss: 0.4560 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7948 - val_loss: 0.4526 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.84 - ETA: 0s - loss: 0.4396 - accuracy: 0.80 - ETA: 0s - loss: 0.4436 - accuracy: 0.80 - ETA: 0s - loss: 0.4484 - accuracy: 0.80 - ETA: 0s - loss: 0.4437 - accuracy: 0.80 - ETA: 0s - loss: 0.4414 - accuracy: 0.80 - ETA: 0s - loss: 0.4431 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7947 - val_loss: 0.4430 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.75 - ETA: 0s - loss: 0.4366 - accuracy: 0.79 - ETA: 0s - loss: 0.4161 - accuracy: 0.80 - ETA: 0s - loss: 0.4269 - accuracy: 0.80 - ETA: 0s - loss: 0.4308 - accuracy: 0.80 - ETA: 0s - loss: 0.4364 - accuracy: 0.79 - ETA: 0s - loss: 0.4347 - accuracy: 0.80 - 1s 3ms/step - loss: 0.4328 - accuracy: 0.8028 - val_loss: 0.4378 - val_accuracy: 0.8115\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3991 - accuracy: 0.81 - ETA: 0s - loss: 0.4240 - accuracy: 0.81 - ETA: 0s - loss: 0.4248 - accuracy: 0.81 - ETA: 0s - loss: 0.4293 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8123 - val_loss: 0.4344 - val_accuracy: 0.8155\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.78 - ETA: 0s - loss: 0.3951 - accuracy: 0.83 - ETA: 0s - loss: 0.4051 - accuracy: 0.82 - ETA: 0s - loss: 0.4086 - accuracy: 0.82 - ETA: 0s - loss: 0.4221 - accuracy: 0.81 - ETA: 0s - loss: 0.4237 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8160 - val_loss: 0.4318 - val_accuracy: 0.8120\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.90 - ETA: 0s - loss: 0.4492 - accuracy: 0.81 - ETA: 0s - loss: 0.4311 - accuracy: 0.81 - ETA: 0s - loss: 0.4298 - accuracy: 0.81 - ETA: 0s - loss: 0.4280 - accuracy: 0.81 - ETA: 0s - loss: 0.4224 - accuracy: 0.81 - ETA: 0s - loss: 0.4181 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8195 - val_loss: 0.4305 - val_accuracy: 0.8190\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.90 - ETA: 0s - loss: 0.4460 - accuracy: 0.80 - ETA: 0s - loss: 0.4451 - accuracy: 0.80 - ETA: 0s - loss: 0.4308 - accuracy: 0.81 - ETA: 0s - loss: 0.4195 - accuracy: 0.81 - ETA: 0s - loss: 0.4153 - accuracy: 0.82 - ETA: 0s - loss: 0.4164 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8198 - val_loss: 0.4268 - val_accuracy: 0.8140\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4123 - accuracy: 0.87 - ETA: 0s - loss: 0.4002 - accuracy: 0.84 - ETA: 0s - loss: 0.3995 - accuracy: 0.83 - ETA: 0s - loss: 0.3976 - accuracy: 0.83 - ETA: 0s - loss: 0.4116 - accuracy: 0.82 - ETA: 0s - loss: 0.4074 - accuracy: 0.82 - ETA: 0s - loss: 0.4077 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8237 - val_loss: 0.4239 - val_accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.84 - ETA: 0s - loss: 0.4110 - accuracy: 0.81 - ETA: 0s - loss: 0.4058 - accuracy: 0.82 - ETA: 0s - loss: 0.4151 - accuracy: 0.82 - ETA: 0s - loss: 0.4182 - accuracy: 0.82 - ETA: 0s - loss: 0.4152 - accuracy: 0.82 - ETA: 0s - loss: 0.4111 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8253 - val_loss: 0.4212 - val_accuracy: 0.8170\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.84 - ETA: 0s - loss: 0.3752 - accuracy: 0.83 - ETA: 0s - loss: 0.3943 - accuracy: 0.83 - ETA: 0s - loss: 0.3959 - accuracy: 0.83 - ETA: 0s - loss: 0.4058 - accuracy: 0.83 - ETA: 0s - loss: 0.4019 - accuracy: 0.83 - ETA: 0s - loss: 0.4027 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8282 - val_loss: 0.4180 - val_accuracy: 0.8170\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.90 - ETA: 0s - loss: 0.3985 - accuracy: 0.84 - ETA: 0s - loss: 0.3942 - accuracy: 0.84 - ETA: 0s - loss: 0.4042 - accuracy: 0.83 - ETA: 0s - loss: 0.4018 - accuracy: 0.83 - ETA: 0s - loss: 0.4020 - accuracy: 0.83 - ETA: 0s - loss: 0.4029 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8323 - val_loss: 0.4143 - val_accuracy: 0.8170\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.93 - ETA: 0s - loss: 0.4001 - accuracy: 0.82 - ETA: 0s - loss: 0.3778 - accuracy: 0.84 - ETA: 0s - loss: 0.3873 - accuracy: 0.84 - ETA: 0s - loss: 0.3958 - accuracy: 0.83 - ETA: 0s - loss: 0.4030 - accuracy: 0.83 - ETA: 0s - loss: 0.3966 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8353 - val_loss: 0.4108 - val_accuracy: 0.8215\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.75 - ETA: 0s - loss: 0.4000 - accuracy: 0.82 - ETA: 0s - loss: 0.4028 - accuracy: 0.83 - ETA: 0s - loss: 0.3998 - accuracy: 0.83 - ETA: 0s - loss: 0.3967 - accuracy: 0.83 - ETA: 0s - loss: 0.3940 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8383 - val_loss: 0.4066 - val_accuracy: 0.8235\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.90 - ETA: 0s - loss: 0.4035 - accuracy: 0.83 - ETA: 0s - loss: 0.4116 - accuracy: 0.82 - ETA: 0s - loss: 0.4066 - accuracy: 0.83 - ETA: 0s - loss: 0.3965 - accuracy: 0.83 - ETA: 0s - loss: 0.3946 - accuracy: 0.83 - ETA: 0s - loss: 0.3927 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3893 - accuracy: 0.8405 - val_loss: 0.4029 - val_accuracy: 0.8280\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.81 - ETA: 0s - loss: 0.3753 - accuracy: 0.85 - ETA: 0s - loss: 0.3826 - accuracy: 0.84 - ETA: 0s - loss: 0.3938 - accuracy: 0.83 - ETA: 0s - loss: 0.3886 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8412 - val_loss: 0.3987 - val_accuracy: 0.8295\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.87 - ETA: 0s - loss: 0.3799 - accuracy: 0.84 - ETA: 0s - loss: 0.3994 - accuracy: 0.83 - ETA: 0s - loss: 0.3877 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8405 - val_loss: 0.3950 - val_accuracy: 0.8355\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.87 - ETA: 0s - loss: 0.4006 - accuracy: 0.83 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - ETA: 0s - loss: 0.3850 - accuracy: 0.84 - ETA: 0s - loss: 0.3777 - accuracy: 0.84 - ETA: 0s - loss: 0.3777 - accuracy: 0.84 - ETA: 0s - loss: 0.3761 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8438 - val_loss: 0.3911 - val_accuracy: 0.8360\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.90 - ETA: 0s - loss: 0.3761 - accuracy: 0.84 - ETA: 0s - loss: 0.3957 - accuracy: 0.83 - ETA: 0s - loss: 0.3876 - accuracy: 0.83 - ETA: 0s - loss: 0.3788 - accuracy: 0.84 - ETA: 0s - loss: 0.3779 - accuracy: 0.84 - ETA: 0s - loss: 0.3785 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8440 - val_loss: 0.3876 - val_accuracy: 0.8380\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.87 - ETA: 0s - loss: 0.3465 - accuracy: 0.86 - ETA: 0s - loss: 0.3702 - accuracy: 0.85 - ETA: 0s - loss: 0.3665 - accuracy: 0.84 - ETA: 0s - loss: 0.3733 - accuracy: 0.84 - ETA: 0s - loss: 0.3722 - accuracy: 0.84 - ETA: 0s - loss: 0.3707 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8458 - val_loss: 0.3845 - val_accuracy: 0.8360\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.65 - ETA: 0s - loss: 0.3864 - accuracy: 0.83 - ETA: 0s - loss: 0.3896 - accuracy: 0.83 - ETA: 0s - loss: 0.3921 - accuracy: 0.83 - ETA: 0s - loss: 0.3819 - accuracy: 0.84 - ETA: 0s - loss: 0.3729 - accuracy: 0.84 - ETA: 0s - loss: 0.3688 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8482 - val_loss: 0.3825 - val_accuracy: 0.8385\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.90 - ETA: 0s - loss: 0.3633 - accuracy: 0.85 - ETA: 0s - loss: 0.3686 - accuracy: 0.84 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3621 - accuracy: 0.84 - ETA: 0s - loss: 0.3707 - accuracy: 0.84 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8495 - val_loss: 0.3802 - val_accuracy: 0.8415\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4538 - accuracy: 0.81 - ETA: 0s - loss: 0.3745 - accuracy: 0.83 - ETA: 0s - loss: 0.3741 - accuracy: 0.84 - ETA: 0s - loss: 0.3679 - accuracy: 0.84 - ETA: 0s - loss: 0.3632 - accuracy: 0.85 - ETA: 0s - loss: 0.3632 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8515 - val_loss: 0.3784 - val_accuracy: 0.8405\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.84 - ETA: 0s - loss: 0.3720 - accuracy: 0.84 - ETA: 0s - loss: 0.3595 - accuracy: 0.85 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - ETA: 0s - loss: 0.3582 - accuracy: 0.85 - ETA: 0s - loss: 0.3593 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8520 - val_loss: 0.3772 - val_accuracy: 0.8440\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.90 - ETA: 0s - loss: 0.3380 - accuracy: 0.87 - ETA: 0s - loss: 0.3438 - accuracy: 0.86 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3619 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8535 - val_loss: 0.3756 - val_accuracy: 0.8445\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.81 - ETA: 0s - loss: 0.3502 - accuracy: 0.84 - ETA: 0s - loss: 0.3604 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3584 - accuracy: 0.85 - ETA: 0s - loss: 0.3610 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8537 - val_loss: 0.3750 - val_accuracy: 0.8440\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.90 - ETA: 0s - loss: 0.3749 - accuracy: 0.84 - ETA: 0s - loss: 0.3706 - accuracy: 0.85 - ETA: 0s - loss: 0.3621 - accuracy: 0.85 - ETA: 0s - loss: 0.3577 - accuracy: 0.85 - ETA: 0s - loss: 0.3585 - accuracy: 0.85 - ETA: 0s - loss: 0.3578 - accuracy: 0.85 - ETA: 0s - loss: 0.3579 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3567 - accuracy: 0.8547 - val_loss: 0.3739 - val_accuracy: 0.8450\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.84 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3420 - accuracy: 0.86 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8555 - val_loss: 0.3731 - val_accuracy: 0.8460\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.71 - ETA: 0s - loss: 0.3202 - accuracy: 0.87 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8552 - val_loss: 0.3727 - val_accuracy: 0.8470\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.93 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8553 - val_loss: 0.3725 - val_accuracy: 0.8480\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.81 - ETA: 0s - loss: 0.3884 - accuracy: 0.82 - ETA: 0s - loss: 0.3695 - accuracy: 0.84 - ETA: 0s - loss: 0.3658 - accuracy: 0.84 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8550 - val_loss: 0.3724 - val_accuracy: 0.8480\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.84 - ETA: 0s - loss: 0.3705 - accuracy: 0.84 - ETA: 0s - loss: 0.3632 - accuracy: 0.84 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8565 - val_loss: 0.3718 - val_accuracy: 0.8485\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.87 - ETA: 0s - loss: 0.3442 - accuracy: 0.84 - ETA: 0s - loss: 0.3406 - accuracy: 0.85 - ETA: 0s - loss: 0.3432 - accuracy: 0.85 - ETA: 0s - loss: 0.3498 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8563 - val_loss: 0.3714 - val_accuracy: 0.8480\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.90 - ETA: 0s - loss: 0.3467 - accuracy: 0.86 - ETA: 0s - loss: 0.3466 - accuracy: 0.86 - ETA: 0s - loss: 0.3508 - accuracy: 0.85 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8565 - val_loss: 0.3710 - val_accuracy: 0.8505\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.84 - ETA: 0s - loss: 0.3438 - accuracy: 0.86 - ETA: 0s - loss: 0.3470 - accuracy: 0.86 - ETA: 0s - loss: 0.3467 - accuracy: 0.86 - ETA: 0s - loss: 0.3466 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8572 - val_loss: 0.3705 - val_accuracy: 0.8495\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.93 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - ETA: 0s - loss: 0.3387 - accuracy: 0.85 - ETA: 0s - loss: 0.3552 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3508 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8582 - val_loss: 0.3706 - val_accuracy: 0.8495\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.84 - ETA: 0s - loss: 0.3443 - accuracy: 0.86 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8570 - val_loss: 0.3699 - val_accuracy: 0.8510\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.90 - ETA: 0s - loss: 0.3761 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.86 - ETA: 0s - loss: 0.3492 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3513 - accuracy: 0.85 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8575 - val_loss: 0.3701 - val_accuracy: 0.8495\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.78 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.3582 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.86 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - ETA: 0s - loss: 0.3449 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8588 - val_loss: 0.3698 - val_accuracy: 0.8480\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.87 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3618 - accuracy: 0.84 - ETA: 0s - loss: 0.3494 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8593 - val_loss: 0.3701 - val_accuracy: 0.8475\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4678 - accuracy: 0.78 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3512 - accuracy: 0.85 - ETA: 0s - loss: 0.3550 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8593 - val_loss: 0.3697 - val_accuracy: 0.8505\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.84 - ETA: 0s - loss: 0.3008 - accuracy: 0.87 - ETA: 0s - loss: 0.3402 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.86 - ETA: 0s - loss: 0.3378 - accuracy: 0.86 - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8603 - val_loss: 0.3690 - val_accuracy: 0.8490\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.75 - ETA: 0s - loss: 0.3641 - accuracy: 0.85 - ETA: 0s - loss: 0.3638 - accuracy: 0.85 - ETA: 0s - loss: 0.3603 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8588 - val_loss: 0.3694 - val_accuracy: 0.8490\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.84 - ETA: 0s - loss: 0.3585 - accuracy: 0.86 - ETA: 0s - loss: 0.3556 - accuracy: 0.86 - ETA: 0s - loss: 0.3497 - accuracy: 0.86 - ETA: 0s - loss: 0.3390 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8603 - val_loss: 0.3687 - val_accuracy: 0.8495\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.87 - ETA: 0s - loss: 0.3222 - accuracy: 0.87 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - ETA: 0s - loss: 0.3432 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8613 - val_loss: 0.3690 - val_accuracy: 0.8480\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.84 - ETA: 0s - loss: 0.3721 - accuracy: 0.84 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.86 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3423 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8605 - val_loss: 0.3695 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.87 - ETA: 0s - loss: 0.3443 - accuracy: 0.86 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8605 - val_loss: 0.3691 - val_accuracy: 0.8460\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.84 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8617 - val_loss: 0.3695 - val_accuracy: 0.8460\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.90 - ETA: 0s - loss: 0.3388 - accuracy: 0.85 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - ETA: 0s - loss: 0.3368 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8602 - val_loss: 0.3689 - val_accuracy: 0.8455\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.90 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3274 - accuracy: 0.87 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8622 - val_loss: 0.3691 - val_accuracy: 0.8445\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.90 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3244 - accuracy: 0.87 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - ETA: 0s - loss: 0.3418 - accuracy: 0.86 - ETA: 0s - loss: 0.3420 - accuracy: 0.86 - ETA: 0s - loss: 0.3418 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8610 - val_loss: 0.3681 - val_accuracy: 0.8470\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.87 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3152 - accuracy: 0.87 - ETA: 0s - loss: 0.3384 - accuracy: 0.86 - ETA: 0s - loss: 0.3392 - accuracy: 0.86 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3441 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8613 - val_loss: 0.3684 - val_accuracy: 0.8475\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.84 - ETA: 0s - loss: 0.3187 - accuracy: 0.88 - ETA: 0s - loss: 0.3524 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - ETA: 0s - loss: 0.3433 - accuracy: 0.86 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8635 - val_loss: 0.3690 - val_accuracy: 0.8455\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.81 - ETA: 0s - loss: 0.3876 - accuracy: 0.83 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - ETA: 0s - loss: 0.3570 - accuracy: 0.85 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3402 - accuracy: 0.86 - ETA: 0s - loss: 0.3408 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8628 - val_loss: 0.3691 - val_accuracy: 0.8465\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.84 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8625 - val_loss: 0.3680 - val_accuracy: 0.8450\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.87 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - ETA: 0s - loss: 0.3448 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3392 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8628 - val_loss: 0.3680 - val_accuracy: 0.8450\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.93 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3390 - accuracy: 0.86 - ETA: 0s - loss: 0.3381 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8625 - val_loss: 0.3685 - val_accuracy: 0.8475\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.87 - ETA: 0s - loss: 0.3491 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.87 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8642 - val_loss: 0.3676 - val_accuracy: 0.8475\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.96 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8638 - val_loss: 0.3683 - val_accuracy: 0.8475\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.84 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3381 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8648 - val_loss: 0.3676 - val_accuracy: 0.8445\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.81 - ETA: 0s - loss: 0.3555 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - ETA: 0s - loss: 0.3355 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8643 - val_loss: 0.3677 - val_accuracy: 0.8455\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.93 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3378 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8652 - val_loss: 0.3680 - val_accuracy: 0.8470\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.87 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - ETA: 0s - loss: 0.3459 - accuracy: 0.85 - ETA: 0s - loss: 0.3416 - accuracy: 0.85 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8640 - val_loss: 0.3681 - val_accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.84 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8643 - val_loss: 0.3685 - val_accuracy: 0.8455\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4697 - accuracy: 0.84 - ETA: 0s - loss: 0.3449 - accuracy: 0.86 - ETA: 0s - loss: 0.3480 - accuracy: 0.86 - ETA: 0s - loss: 0.3499 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8655 - val_loss: 0.3673 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.88 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8663 - val_loss: 0.3676 - val_accuracy: 0.8470\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.84 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8643 - val_loss: 0.3673 - val_accuracy: 0.8455\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.87 - ETA: 0s - loss: 0.3251 - accuracy: 0.87 - ETA: 0s - loss: 0.3526 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3266 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8652 - val_loss: 0.3679 - val_accuracy: 0.8465\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.84 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8650 - val_loss: 0.3676 - val_accuracy: 0.8485\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.84 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.87 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8645 - val_loss: 0.3671 - val_accuracy: 0.8475\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.87 - ETA: 0s - loss: 0.3421 - accuracy: 0.86 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - ETA: 0s - loss: 0.3368 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8658 - val_loss: 0.3675 - val_accuracy: 0.8475\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.87 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8655 - val_loss: 0.3676 - val_accuracy: 0.8485\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.81 - ETA: 0s - loss: 0.3376 - accuracy: 0.85 - ETA: 0s - loss: 0.3351 - accuracy: 0.85 - ETA: 0s - loss: 0.3335 - accuracy: 0.85 - ETA: 0s - loss: 0.3368 - accuracy: 0.85 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8648 - val_loss: 0.3665 - val_accuracy: 0.8465\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.81 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3479 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8672 - val_loss: 0.3674 - val_accuracy: 0.8475\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3331 - accuracy: 0.87 - ETA: 0s - loss: 0.3201 - accuracy: 0.87 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8665 - val_loss: 0.3665 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.78 - ETA: 0s - loss: 0.3436 - accuracy: 0.86 - ETA: 0s - loss: 0.3406 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8668 - val_loss: 0.3670 - val_accuracy: 0.8485\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.84 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3152 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8665 - val_loss: 0.3665 - val_accuracy: 0.8480\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.87 - ETA: 0s - loss: 0.3187 - accuracy: 0.88 - ETA: 0s - loss: 0.3297 - accuracy: 0.87 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - ETA: 0s - loss: 0.3334 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8662 - val_loss: 0.3670 - val_accuracy: 0.8480\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.93 - ETA: 0s - loss: 0.3247 - accuracy: 0.87 - ETA: 0s - loss: 0.3202 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.87 - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8662 - val_loss: 0.3669 - val_accuracy: 0.8490\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6484 - accuracy: 0.78 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3422 - accuracy: 0.85 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8670 - val_loss: 0.3675 - val_accuracy: 0.8470\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.84 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.87 - ETA: 0s - loss: 0.3297 - accuracy: 0.87 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8675 - val_loss: 0.3670 - val_accuracy: 0.8485\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.90 - ETA: 0s - loss: 0.2923 - accuracy: 0.88 - ETA: 0s - loss: 0.2970 - accuracy: 0.88 - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - ETA: 0s - loss: 0.3172 - accuracy: 0.87 - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8672 - val_loss: 0.3661 - val_accuracy: 0.8505\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.75 - ETA: 0s - loss: 0.3067 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - ETA: 0s - loss: 0.3210 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8672 - val_loss: 0.3666 - val_accuracy: 0.8495\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.71 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3406 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8682 - val_loss: 0.3679 - val_accuracy: 0.8505\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.87 - ETA: 0s - loss: 0.2905 - accuracy: 0.88 - ETA: 0s - loss: 0.3005 - accuracy: 0.88 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8672 - val_loss: 0.3664 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.81 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3203 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.87 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8675 - val_loss: 0.3671 - val_accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.84 - ETA: 0s - loss: 0.3311 - accuracy: 0.85 - ETA: 0s - loss: 0.3250 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8688 - val_loss: 0.3675 - val_accuracy: 0.8500\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.96 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3269 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8695 - val_loss: 0.3671 - val_accuracy: 0.8505\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.81 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.87 - ETA: 0s - loss: 0.3232 - accuracy: 0.87 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8687 - val_loss: 0.3665 - val_accuracy: 0.8510\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - ETA: 0s - loss: 0.3391 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8682 - val_loss: 0.3680 - val_accuracy: 0.8505\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.93 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - ETA: 0s - loss: 0.3037 - accuracy: 0.88 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3251 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8680 - val_loss: 0.3683 - val_accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.81 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3174 - accuracy: 0.87 - ETA: 0s - loss: 0.3223 - accuracy: 0.87 - ETA: 0s - loss: 0.3208 - accuracy: 0.87 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8692 - val_loss: 0.3678 - val_accuracy: 0.8500\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.93 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3176 - accuracy: 0.87 - ETA: 0s - loss: 0.3240 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3263 - accuracy: 0.8687 - val_loss: 0.3672 - val_accuracy: 0.8530\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.81 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8678 - val_loss: 0.3679 - val_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.87 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.87 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8695 - val_loss: 0.3688 - val_accuracy: 0.8510\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.87 - ETA: 0s - loss: 0.3378 - accuracy: 0.85 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8678 - val_loss: 0.3679 - val_accuracy: 0.8535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c9c264c9cecdfd65b4474d71a73a2856</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8535000085830688</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.8611 - accuracy: 0.34 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.5805 - accuracy: 0.71 - ETA: 0s - loss: 0.5390 - accuracy: 0.74 - ETA: 0s - loss: 0.5197 - accuracy: 0.75 - 1s 3ms/step - loss: 0.5146 - accuracy: 0.7600 - val_loss: 0.4544 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.78 - ETA: 0s - loss: 0.4378 - accuracy: 0.80 - ETA: 0s - loss: 0.4522 - accuracy: 0.78 - ETA: 0s - loss: 0.4423 - accuracy: 0.79 - ETA: 0s - loss: 0.4412 - accuracy: 0.79 - ETA: 0s - loss: 0.4372 - accuracy: 0.80 - ETA: 0s - loss: 0.4307 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8093 - val_loss: 0.4214 - val_accuracy: 0.8165\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.90 - ETA: 0s - loss: 0.4169 - accuracy: 0.82 - ETA: 0s - loss: 0.4037 - accuracy: 0.82 - ETA: 0s - loss: 0.3917 - accuracy: 0.83 - ETA: 0s - loss: 0.3906 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8322 - val_loss: 0.3880 - val_accuracy: 0.8360\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.81 - ETA: 0s - loss: 0.3760 - accuracy: 0.84 - ETA: 0s - loss: 0.3685 - accuracy: 0.84 - ETA: 0s - loss: 0.3632 - accuracy: 0.85 - ETA: 0s - loss: 0.3638 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8512 - val_loss: 0.3669 - val_accuracy: 0.8445\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.93 - ETA: 0s - loss: 0.3420 - accuracy: 0.85 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3484 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8573 - val_loss: 0.3621 - val_accuracy: 0.8455\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.84 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8572 - val_loss: 0.3597 - val_accuracy: 0.8475\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.96 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3372 - accuracy: 0.85 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8590 - val_loss: 0.3615 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.84 - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - ETA: 0s - loss: 0.3256 - accuracy: 0.87 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8635 - val_loss: 0.3572 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.84 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3200 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8625 - val_loss: 0.3555 - val_accuracy: 0.8510\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.81 - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.86 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8615 - val_loss: 0.3552 - val_accuracy: 0.8510\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.75 - ETA: 0s - loss: 0.3070 - accuracy: 0.87 - ETA: 0s - loss: 0.3298 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8638 - val_loss: 0.3554 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.84 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - ETA: 0s - loss: 0.3174 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8628 - val_loss: 0.3583 - val_accuracy: 0.8515\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3185 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8635 - val_loss: 0.3556 - val_accuracy: 0.8515\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.84 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8653 - val_loss: 0.3587 - val_accuracy: 0.8495\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.81 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3240 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8648 - val_loss: 0.3533 - val_accuracy: 0.8580\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.90 - ETA: 0s - loss: 0.3304 - accuracy: 0.85 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8645 - val_loss: 0.3544 - val_accuracy: 0.8525\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.78 - ETA: 0s - loss: 0.3190 - accuracy: 0.85 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8675 - val_loss: 0.3548 - val_accuracy: 0.8510\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.90 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8665 - val_loss: 0.3551 - val_accuracy: 0.8570\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.84 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8663 - val_loss: 0.3571 - val_accuracy: 0.8545\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.81 - ETA: 0s - loss: 0.2786 - accuracy: 0.87 - ETA: 0s - loss: 0.3000 - accuracy: 0.87 - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8690 - val_loss: 0.3532 - val_accuracy: 0.8590\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.84 - ETA: 0s - loss: 0.2963 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8685 - val_loss: 0.3541 - val_accuracy: 0.8585\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.81 - ETA: 0s - loss: 0.3054 - accuracy: 0.87 - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3169 - accuracy: 0.87 - ETA: 0s - loss: 0.3151 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8688 - val_loss: 0.3512 - val_accuracy: 0.8595\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.90 - ETA: 0s - loss: 0.2974 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - ETA: 0s - loss: 0.3160 - accuracy: 0.86 - ETA: 0s - loss: 0.3175 - accuracy: 0.86 - ETA: 0s - loss: 0.3153 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8677 - val_loss: 0.3543 - val_accuracy: 0.8575\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - ETA: 0s - loss: 0.3026 - accuracy: 0.88 - ETA: 0s - loss: 0.3103 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - ETA: 0s - loss: 0.3141 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8708 - val_loss: 0.3581 - val_accuracy: 0.8555\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.93 - ETA: 0s - loss: 0.2965 - accuracy: 0.87 - ETA: 0s - loss: 0.3204 - accuracy: 0.86 - ETA: 0s - loss: 0.3049 - accuracy: 0.87 - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - ETA: 0s - loss: 0.3055 - accuracy: 0.87 - ETA: 0s - loss: 0.3127 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8690 - val_loss: 0.3533 - val_accuracy: 0.8570\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.87 - ETA: 0s - loss: 0.3138 - accuracy: 0.86 - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8735 - val_loss: 0.3550 - val_accuracy: 0.8535\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.93 - ETA: 0s - loss: 0.3351 - accuracy: 0.85 - ETA: 0s - loss: 0.3183 - accuracy: 0.86 - ETA: 0s - loss: 0.3183 - accuracy: 0.86 - ETA: 0s - loss: 0.3170 - accuracy: 0.86 - ETA: 0s - loss: 0.3121 - accuracy: 0.86 - ETA: 0s - loss: 0.3108 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8707 - val_loss: 0.3609 - val_accuracy: 0.8545\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.90 - ETA: 0s - loss: 0.2828 - accuracy: 0.88 - ETA: 0s - loss: 0.2939 - accuracy: 0.87 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8722 - val_loss: 0.3594 - val_accuracy: 0.8570\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.84 - ETA: 0s - loss: 0.3229 - accuracy: 0.85 - ETA: 0s - loss: 0.3170 - accuracy: 0.86 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3069 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8725 - val_loss: 0.3541 - val_accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.90 - ETA: 0s - loss: 0.3147 - accuracy: 0.86 - ETA: 0s - loss: 0.2938 - accuracy: 0.88 - ETA: 0s - loss: 0.3002 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3035 - accuracy: 0.87 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8732 - val_loss: 0.3634 - val_accuracy: 0.8535\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.96 - ETA: 0s - loss: 0.2908 - accuracy: 0.87 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.86 - ETA: 0s - loss: 0.3167 - accuracy: 0.86 - ETA: 0s - loss: 0.3163 - accuracy: 0.86 - ETA: 0s - loss: 0.3068 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8725 - val_loss: 0.3602 - val_accuracy: 0.8605\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.81 - ETA: 0s - loss: 0.2942 - accuracy: 0.87 - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - ETA: 0s - loss: 0.3054 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8752 - val_loss: 0.3566 - val_accuracy: 0.8605\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.90 - ETA: 0s - loss: 0.3310 - accuracy: 0.85 - ETA: 0s - loss: 0.3156 - accuracy: 0.86 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8738 - val_loss: 0.3580 - val_accuracy: 0.8560\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.81 - ETA: 0s - loss: 0.2872 - accuracy: 0.87 - ETA: 0s - loss: 0.2906 - accuracy: 0.87 - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - ETA: 0s - loss: 0.2986 - accuracy: 0.87 - ETA: 0s - loss: 0.3005 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8760 - val_loss: 0.3559 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.93 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2920 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.2996 - accuracy: 0.87 - ETA: 0s - loss: 0.3007 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8743 - val_loss: 0.3580 - val_accuracy: 0.8635\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.90 - ETA: 0s - loss: 0.2964 - accuracy: 0.87 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2949 - accuracy: 0.87 - ETA: 0s - loss: 0.2979 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8747 - val_loss: 0.3605 - val_accuracy: 0.8575\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.84 - ETA: 0s - loss: 0.2757 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.88 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - ETA: 0s - loss: 0.3007 - accuracy: 0.87 - ETA: 0s - loss: 0.3018 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8745 - val_loss: 0.3583 - val_accuracy: 0.8600\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.96 - ETA: 0s - loss: 0.3097 - accuracy: 0.86 - ETA: 0s - loss: 0.2885 - accuracy: 0.87 - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - ETA: 0s - loss: 0.2956 - accuracy: 0.87 - ETA: 0s - loss: 0.2944 - accuracy: 0.87 - ETA: 0s - loss: 0.2988 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8757 - val_loss: 0.3600 - val_accuracy: 0.8555\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 1.00 - ETA: 0s - loss: 0.3099 - accuracy: 0.86 - ETA: 0s - loss: 0.2923 - accuracy: 0.87 - ETA: 0s - loss: 0.2944 - accuracy: 0.87 - ETA: 0s - loss: 0.2989 - accuracy: 0.87 - ETA: 0s - loss: 0.2971 - accuracy: 0.87 - ETA: 0s - loss: 0.3018 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8763 - val_loss: 0.3719 - val_accuracy: 0.8555\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.84 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2891 - accuracy: 0.87 - ETA: 0s - loss: 0.2962 - accuracy: 0.87 - ETA: 0s - loss: 0.2958 - accuracy: 0.87 - ETA: 0s - loss: 0.2975 - accuracy: 0.87 - ETA: 0s - loss: 0.2986 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8763 - val_loss: 0.3590 - val_accuracy: 0.8595\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.81 - ETA: 0s - loss: 0.3075 - accuracy: 0.86 - ETA: 0s - loss: 0.2900 - accuracy: 0.87 - ETA: 0s - loss: 0.2931 - accuracy: 0.87 - ETA: 0s - loss: 0.2937 - accuracy: 0.88 - ETA: 0s - loss: 0.2935 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8782 - val_loss: 0.3613 - val_accuracy: 0.8600\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.93 - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - ETA: 0s - loss: 0.3070 - accuracy: 0.86 - ETA: 0s - loss: 0.2958 - accuracy: 0.87 - ETA: 0s - loss: 0.2923 - accuracy: 0.87 - ETA: 0s - loss: 0.2944 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8770 - val_loss: 0.3639 - val_accuracy: 0.8610\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.84 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.2942 - accuracy: 0.87 - ETA: 0s - loss: 0.2971 - accuracy: 0.87 - ETA: 0s - loss: 0.2921 - accuracy: 0.87 - ETA: 0s - loss: 0.2931 - accuracy: 0.87 - ETA: 0s - loss: 0.2951 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8752 - val_loss: 0.3642 - val_accuracy: 0.8560\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.96 - ETA: 0s - loss: 0.2579 - accuracy: 0.89 - ETA: 0s - loss: 0.2901 - accuracy: 0.88 - ETA: 0s - loss: 0.2952 - accuracy: 0.87 - ETA: 0s - loss: 0.3016 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.2941 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8772 - val_loss: 0.3664 - val_accuracy: 0.8575\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.90 - ETA: 0s - loss: 0.2619 - accuracy: 0.88 - ETA: 0s - loss: 0.2808 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.87 - ETA: 0s - loss: 0.2959 - accuracy: 0.87 - ETA: 0s - loss: 0.2942 - accuracy: 0.87 - ETA: 0s - loss: 0.2929 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8780 - val_loss: 0.3646 - val_accuracy: 0.8605\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.87 - ETA: 0s - loss: 0.2970 - accuracy: 0.88 - ETA: 0s - loss: 0.2728 - accuracy: 0.89 - ETA: 0s - loss: 0.2719 - accuracy: 0.88 - ETA: 0s - loss: 0.2815 - accuracy: 0.88 - ETA: 0s - loss: 0.2836 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8770 - val_loss: 0.3657 - val_accuracy: 0.8495\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 1.00 - ETA: 0s - loss: 0.2883 - accuracy: 0.89 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - ETA: 0s - loss: 0.2940 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8795 - val_loss: 0.3666 - val_accuracy: 0.8595\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 1.00 - ETA: 0s - loss: 0.2685 - accuracy: 0.88 - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - ETA: 0s - loss: 0.2868 - accuracy: 0.87 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - ETA: 0s - loss: 0.2913 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8778 - val_loss: 0.3679 - val_accuracy: 0.8570\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.81 - ETA: 0s - loss: 0.2974 - accuracy: 0.88 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - ETA: 0s - loss: 0.2930 - accuracy: 0.87 - ETA: 0s - loss: 0.2954 - accuracy: 0.87 - ETA: 0s - loss: 0.2913 - accuracy: 0.87 - ETA: 0s - loss: 0.2898 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8795 - val_loss: 0.3708 - val_accuracy: 0.8570\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4431 - accuracy: 0.87 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - ETA: 0s - loss: 0.2902 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.88 - ETA: 0s - loss: 0.2955 - accuracy: 0.87 - ETA: 0s - loss: 0.2921 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8795 - val_loss: 0.3697 - val_accuracy: 0.8490\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.2937 - accuracy: 0.87 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2964 - accuracy: 0.87 - ETA: 0s - loss: 0.2943 - accuracy: 0.88 - ETA: 0s - loss: 0.2913 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8798 - val_loss: 0.3652 - val_accuracy: 0.8565\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.81 - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - ETA: 0s - loss: 0.2995 - accuracy: 0.87 - ETA: 0s - loss: 0.2887 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8813 - val_loss: 0.3749 - val_accuracy: 0.8580\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.84 - ETA: 0s - loss: 0.3007 - accuracy: 0.87 - ETA: 0s - loss: 0.2886 - accuracy: 0.88 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - ETA: 0s - loss: 0.2935 - accuracy: 0.87 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - ETA: 0s - loss: 0.2892 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8812 - val_loss: 0.3740 - val_accuracy: 0.8590\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.93 - ETA: 0s - loss: 0.2647 - accuracy: 0.88 - ETA: 0s - loss: 0.2841 - accuracy: 0.87 - ETA: 0s - loss: 0.2920 - accuracy: 0.87 - ETA: 0s - loss: 0.2891 - accuracy: 0.87 - ETA: 0s - loss: 0.2860 - accuracy: 0.87 - ETA: 0s - loss: 0.2883 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8580\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.93 - ETA: 0s - loss: 0.2602 - accuracy: 0.89 - ETA: 0s - loss: 0.2844 - accuracy: 0.88 - ETA: 0s - loss: 0.2896 - accuracy: 0.88 - ETA: 0s - loss: 0.2948 - accuracy: 0.87 - ETA: 0s - loss: 0.2876 - accuracy: 0.88 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8812 - val_loss: 0.3703 - val_accuracy: 0.8545\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.81 - ETA: 0s - loss: 0.2671 - accuracy: 0.89 - ETA: 0s - loss: 0.2834 - accuracy: 0.88 - ETA: 0s - loss: 0.2821 - accuracy: 0.88 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8793 - val_loss: 0.3718 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.90 - ETA: 0s - loss: 0.2959 - accuracy: 0.88 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - ETA: 0s - loss: 0.2801 - accuracy: 0.88 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - ETA: 0s - loss: 0.2824 - accuracy: 0.88 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8813 - val_loss: 0.3698 - val_accuracy: 0.8580\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.84 - ETA: 0s - loss: 0.2854 - accuracy: 0.87 - ETA: 0s - loss: 0.2855 - accuracy: 0.87 - ETA: 0s - loss: 0.2843 - accuracy: 0.88 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2871 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8820 - val_loss: 0.3731 - val_accuracy: 0.8585\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.93 - ETA: 0s - loss: 0.2935 - accuracy: 0.86 - ETA: 0s - loss: 0.2931 - accuracy: 0.87 - ETA: 0s - loss: 0.2926 - accuracy: 0.87 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - ETA: 0s - loss: 0.2844 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8843 - val_loss: 0.3728 - val_accuracy: 0.8435\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.78 - ETA: 0s - loss: 0.3121 - accuracy: 0.86 - ETA: 0s - loss: 0.2989 - accuracy: 0.87 - ETA: 0s - loss: 0.2859 - accuracy: 0.87 - ETA: 0s - loss: 0.2806 - accuracy: 0.88 - ETA: 0s - loss: 0.2822 - accuracy: 0.88 - ETA: 0s - loss: 0.2820 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8802 - val_loss: 0.3777 - val_accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.2944 - accuracy: 0.86 - ETA: 0s - loss: 0.2844 - accuracy: 0.87 - ETA: 0s - loss: 0.2851 - accuracy: 0.87 - ETA: 0s - loss: 0.2889 - accuracy: 0.87 - ETA: 0s - loss: 0.2837 - accuracy: 0.87 - ETA: 0s - loss: 0.2847 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8817 - val_loss: 0.3727 - val_accuracy: 0.8595\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.96 - ETA: 0s - loss: 0.2565 - accuracy: 0.89 - ETA: 0s - loss: 0.2738 - accuracy: 0.88 - ETA: 0s - loss: 0.2753 - accuracy: 0.88 - ETA: 0s - loss: 0.2794 - accuracy: 0.87 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2813 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8822 - val_loss: 0.3685 - val_accuracy: 0.8510\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.81 - ETA: 0s - loss: 0.2822 - accuracy: 0.87 - ETA: 0s - loss: 0.2739 - accuracy: 0.88 - ETA: 0s - loss: 0.2803 - accuracy: 0.87 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2835 - accuracy: 0.88 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8843 - val_loss: 0.3703 - val_accuracy: 0.8520\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7029 - accuracy: 0.75 - ETA: 0s - loss: 0.3003 - accuracy: 0.88 - ETA: 0s - loss: 0.2807 - accuracy: 0.88 - ETA: 0s - loss: 0.2767 - accuracy: 0.88 - ETA: 0s - loss: 0.2798 - accuracy: 0.88 - ETA: 0s - loss: 0.2814 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8847 - val_loss: 0.3690 - val_accuracy: 0.8535\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 1.00 - ETA: 0s - loss: 0.2523 - accuracy: 0.89 - ETA: 0s - loss: 0.2599 - accuracy: 0.89 - ETA: 0s - loss: 0.2632 - accuracy: 0.89 - ETA: 0s - loss: 0.2725 - accuracy: 0.88 - ETA: 0s - loss: 0.2731 - accuracy: 0.88 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8840 - val_loss: 0.3700 - val_accuracy: 0.8475\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.90 - ETA: 0s - loss: 0.2862 - accuracy: 0.88 - ETA: 0s - loss: 0.2730 - accuracy: 0.89 - ETA: 0s - loss: 0.2660 - accuracy: 0.89 - ETA: 0s - loss: 0.2736 - accuracy: 0.88 - ETA: 0s - loss: 0.2767 - accuracy: 0.88 - ETA: 0s - loss: 0.2791 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8848 - val_loss: 0.3773 - val_accuracy: 0.8465\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.96 - ETA: 0s - loss: 0.2561 - accuracy: 0.90 - ETA: 0s - loss: 0.2561 - accuracy: 0.89 - ETA: 0s - loss: 0.2575 - accuracy: 0.89 - ETA: 0s - loss: 0.2708 - accuracy: 0.88 - ETA: 0s - loss: 0.2720 - accuracy: 0.88 - ETA: 0s - loss: 0.2788 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8845 - val_loss: 0.3827 - val_accuracy: 0.8530\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.81 - ETA: 0s - loss: 0.2686 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.88 - ETA: 0s - loss: 0.2802 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2822 - accuracy: 0.88 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8855 - val_loss: 0.3890 - val_accuracy: 0.8545\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.93 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - ETA: 0s - loss: 0.2774 - accuracy: 0.88 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - ETA: 0s - loss: 0.2747 - accuracy: 0.88 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8828 - val_loss: 0.3724 - val_accuracy: 0.8510\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.90 - ETA: 0s - loss: 0.2904 - accuracy: 0.87 - ETA: 0s - loss: 0.2817 - accuracy: 0.87 - ETA: 0s - loss: 0.2707 - accuracy: 0.88 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - ETA: 0s - loss: 0.2766 - accuracy: 0.88 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8827 - val_loss: 0.3756 - val_accuracy: 0.8475\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.78 - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - ETA: 0s - loss: 0.2876 - accuracy: 0.87 - ETA: 0s - loss: 0.2806 - accuracy: 0.88 - ETA: 0s - loss: 0.2746 - accuracy: 0.88 - ETA: 0s - loss: 0.2697 - accuracy: 0.88 - ETA: 0s - loss: 0.2779 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8822 - val_loss: 0.3748 - val_accuracy: 0.8520\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.87 - ETA: 0s - loss: 0.2859 - accuracy: 0.87 - ETA: 0s - loss: 0.2696 - accuracy: 0.89 - ETA: 0s - loss: 0.2758 - accuracy: 0.88 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - ETA: 0s - loss: 0.2761 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8862 - val_loss: 0.3724 - val_accuracy: 0.8495\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.78 - ETA: 0s - loss: 0.2745 - accuracy: 0.88 - ETA: 0s - loss: 0.2837 - accuracy: 0.87 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - ETA: 0s - loss: 0.2769 - accuracy: 0.88 - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8843 - val_loss: 0.3780 - val_accuracy: 0.8420\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.84 - ETA: 0s - loss: 0.2886 - accuracy: 0.87 - ETA: 0s - loss: 0.2798 - accuracy: 0.87 - ETA: 0s - loss: 0.2741 - accuracy: 0.88 - ETA: 0s - loss: 0.2715 - accuracy: 0.88 - ETA: 0s - loss: 0.2750 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8848 - val_loss: 0.3747 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.87 - ETA: 0s - loss: 0.2743 - accuracy: 0.88 - ETA: 0s - loss: 0.2731 - accuracy: 0.88 - ETA: 0s - loss: 0.2612 - accuracy: 0.89 - ETA: 0s - loss: 0.2670 - accuracy: 0.89 - ETA: 0s - loss: 0.2675 - accuracy: 0.89 - ETA: 0s - loss: 0.2743 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8877 - val_loss: 0.3835 - val_accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.84 - ETA: 0s - loss: 0.2304 - accuracy: 0.90 - ETA: 0s - loss: 0.2575 - accuracy: 0.89 - ETA: 0s - loss: 0.2602 - accuracy: 0.89 - ETA: 0s - loss: 0.2653 - accuracy: 0.88 - ETA: 0s - loss: 0.2690 - accuracy: 0.88 - ETA: 0s - loss: 0.2706 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8843 - val_loss: 0.3844 - val_accuracy: 0.8410\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.78 - ETA: 0s - loss: 0.2518 - accuracy: 0.89 - ETA: 0s - loss: 0.2601 - accuracy: 0.88 - ETA: 0s - loss: 0.2687 - accuracy: 0.88 - ETA: 0s - loss: 0.2743 - accuracy: 0.88 - ETA: 0s - loss: 0.2695 - accuracy: 0.88 - ETA: 0s - loss: 0.2724 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8860 - val_loss: 0.3781 - val_accuracy: 0.8515\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.84 - ETA: 0s - loss: 0.2463 - accuracy: 0.90 - ETA: 0s - loss: 0.2675 - accuracy: 0.88 - ETA: 0s - loss: 0.2656 - accuracy: 0.88 - ETA: 0s - loss: 0.2687 - accuracy: 0.88 - ETA: 0s - loss: 0.2676 - accuracy: 0.88 - ETA: 0s - loss: 0.2702 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8862 - val_loss: 0.3819 - val_accuracy: 0.8505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.84 - ETA: 0s - loss: 0.2863 - accuracy: 0.88 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2747 - accuracy: 0.88 - ETA: 0s - loss: 0.2699 - accuracy: 0.88 - ETA: 0s - loss: 0.2711 - accuracy: 0.88 - ETA: 0s - loss: 0.2738 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8855 - val_loss: 0.3772 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.81 - ETA: 0s - loss: 0.2429 - accuracy: 0.89 - ETA: 0s - loss: 0.2523 - accuracy: 0.89 - ETA: 0s - loss: 0.2610 - accuracy: 0.89 - ETA: 0s - loss: 0.2752 - accuracy: 0.88 - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - ETA: 0s - loss: 0.2731 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8888 - val_loss: 0.3749 - val_accuracy: 0.8515\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3195 - accuracy: 0.84 - ETA: 0s - loss: 0.2562 - accuracy: 0.89 - ETA: 0s - loss: 0.2649 - accuracy: 0.89 - ETA: 0s - loss: 0.2721 - accuracy: 0.88 - ETA: 0s - loss: 0.2684 - accuracy: 0.88 - ETA: 0s - loss: 0.2736 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8860 - val_loss: 0.3757 - val_accuracy: 0.8525\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.81 - ETA: 0s - loss: 0.2768 - accuracy: 0.88 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - ETA: 0s - loss: 0.2721 - accuracy: 0.88 - ETA: 0s - loss: 0.2716 - accuracy: 0.88 - ETA: 0s - loss: 0.2701 - accuracy: 0.88 - ETA: 0s - loss: 0.2720 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8883 - val_loss: 0.3753 - val_accuracy: 0.8505\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 1.00 - ETA: 0s - loss: 0.2565 - accuracy: 0.89 - ETA: 0s - loss: 0.2697 - accuracy: 0.88 - ETA: 0s - loss: 0.2675 - accuracy: 0.88 - ETA: 0s - loss: 0.2664 - accuracy: 0.88 - ETA: 0s - loss: 0.2738 - accuracy: 0.88 - ETA: 0s - loss: 0.2690 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8890 - val_loss: 0.3814 - val_accuracy: 0.8535\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.87 - ETA: 0s - loss: 0.2629 - accuracy: 0.88 - ETA: 0s - loss: 0.2572 - accuracy: 0.88 - ETA: 0s - loss: 0.2627 - accuracy: 0.88 - ETA: 0s - loss: 0.2615 - accuracy: 0.88 - ETA: 0s - loss: 0.2699 - accuracy: 0.88 - ETA: 0s - loss: 0.2684 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8873 - val_loss: 0.3835 - val_accuracy: 0.8495\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.93 - ETA: 0s - loss: 0.2650 - accuracy: 0.88 - ETA: 0s - loss: 0.2599 - accuracy: 0.88 - ETA: 0s - loss: 0.2586 - accuracy: 0.89 - ETA: 0s - loss: 0.2632 - accuracy: 0.89 - ETA: 0s - loss: 0.2627 - accuracy: 0.89 - ETA: 0s - loss: 0.2698 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8875 - val_loss: 0.3916 - val_accuracy: 0.8530\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.87 - ETA: 0s - loss: 0.2841 - accuracy: 0.86 - ETA: 0s - loss: 0.2666 - accuracy: 0.88 - ETA: 0s - loss: 0.2654 - accuracy: 0.88 - ETA: 0s - loss: 0.2713 - accuracy: 0.88 - ETA: 0s - loss: 0.2696 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2714 - accuracy: 0.8835 - val_loss: 0.3795 - val_accuracy: 0.8560\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.90 - ETA: 0s - loss: 0.2399 - accuracy: 0.90 - ETA: 0s - loss: 0.2569 - accuracy: 0.89 - ETA: 0s - loss: 0.2628 - accuracy: 0.89 - ETA: 0s - loss: 0.2626 - accuracy: 0.89 - ETA: 0s - loss: 0.2762 - accuracy: 0.88 - ETA: 0s - loss: 0.2690 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8867 - val_loss: 0.3809 - val_accuracy: 0.8495\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.84 - ETA: 0s - loss: 0.2868 - accuracy: 0.87 - ETA: 0s - loss: 0.2742 - accuracy: 0.87 - ETA: 0s - loss: 0.2722 - accuracy: 0.88 - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - ETA: 0s - loss: 0.2676 - accuracy: 0.88 - ETA: 0s - loss: 0.2695 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2693 - accuracy: 0.8865 - val_loss: 0.3810 - val_accuracy: 0.8550\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.90 - ETA: 0s - loss: 0.2634 - accuracy: 0.89 - ETA: 0s - loss: 0.2656 - accuracy: 0.89 - ETA: 0s - loss: 0.2619 - accuracy: 0.89 - ETA: 0s - loss: 0.2688 - accuracy: 0.88 - ETA: 0s - loss: 0.2663 - accuracy: 0.88 - ETA: 0s - loss: 0.2701 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8857 - val_loss: 0.3813 - val_accuracy: 0.8450\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.84 - ETA: 0s - loss: 0.2475 - accuracy: 0.89 - ETA: 0s - loss: 0.2547 - accuracy: 0.89 - ETA: 0s - loss: 0.2584 - accuracy: 0.89 - ETA: 0s - loss: 0.2650 - accuracy: 0.88 - ETA: 0s - loss: 0.2684 - accuracy: 0.88 - ETA: 0s - loss: 0.2687 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8885 - val_loss: 0.3838 - val_accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.81 - ETA: 0s - loss: 0.2590 - accuracy: 0.89 - ETA: 0s - loss: 0.2582 - accuracy: 0.89 - ETA: 0s - loss: 0.2578 - accuracy: 0.89 - ETA: 0s - loss: 0.2591 - accuracy: 0.89 - ETA: 0s - loss: 0.2656 - accuracy: 0.88 - ETA: 0s - loss: 0.2647 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8870 - val_loss: 0.3833 - val_accuracy: 0.8530\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.2571 - accuracy: 0.88 - ETA: 0s - loss: 0.2627 - accuracy: 0.89 - ETA: 0s - loss: 0.2650 - accuracy: 0.89 - ETA: 0s - loss: 0.2691 - accuracy: 0.88 - ETA: 0s - loss: 0.2662 - accuracy: 0.88 - ETA: 0s - loss: 0.2629 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8902 - val_loss: 0.3829 - val_accuracy: 0.8480\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.90 - ETA: 0s - loss: 0.2374 - accuracy: 0.89 - ETA: 0s - loss: 0.2440 - accuracy: 0.89 - ETA: 0s - loss: 0.2547 - accuracy: 0.89 - ETA: 0s - loss: 0.2647 - accuracy: 0.88 - ETA: 0s - loss: 0.2670 - accuracy: 0.88 - ETA: 0s - loss: 0.2651 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8905 - val_loss: 0.3916 - val_accuracy: 0.8495\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.93 - ETA: 0s - loss: 0.2487 - accuracy: 0.90 - ETA: 0s - loss: 0.2530 - accuracy: 0.90 - ETA: 0s - loss: 0.2578 - accuracy: 0.89 - ETA: 0s - loss: 0.2580 - accuracy: 0.89 - ETA: 0s - loss: 0.2580 - accuracy: 0.89 - ETA: 0s - loss: 0.2649 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8920 - val_loss: 0.3832 - val_accuracy: 0.8520\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.87 - ETA: 0s - loss: 0.2494 - accuracy: 0.89 - ETA: 0s - loss: 0.2523 - accuracy: 0.89 - ETA: 0s - loss: 0.2548 - accuracy: 0.89 - ETA: 0s - loss: 0.2620 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8875 - val_loss: 0.3865 - val_accuracy: 0.8470\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.90 - ETA: 0s - loss: 0.2653 - accuracy: 0.88 - ETA: 0s - loss: 0.2544 - accuracy: 0.89 - ETA: 0s - loss: 0.2619 - accuracy: 0.88 - ETA: 0s - loss: 0.2627 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8885 - val_loss: 0.3850 - val_accuracy: 0.8500\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.93 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.2526 - accuracy: 0.88 - ETA: 0s - loss: 0.2508 - accuracy: 0.89 - ETA: 0s - loss: 0.2587 - accuracy: 0.89 - ETA: 0s - loss: 0.2628 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8887 - val_loss: 0.3827 - val_accuracy: 0.8485\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.90 - ETA: 0s - loss: 0.2654 - accuracy: 0.88 - ETA: 0s - loss: 0.2603 - accuracy: 0.88 - ETA: 0s - loss: 0.2665 - accuracy: 0.88 - ETA: 0s - loss: 0.2638 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8900 - val_loss: 0.3874 - val_accuracy: 0.8520\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.87 - ETA: 0s - loss: 0.2438 - accuracy: 0.89 - ETA: 0s - loss: 0.2490 - accuracy: 0.89 - ETA: 0s - loss: 0.2523 - accuracy: 0.89 - ETA: 0s - loss: 0.2620 - accuracy: 0.89 - ETA: 0s - loss: 0.2639 - accuracy: 0.89 - ETA: 0s - loss: 0.2629 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8918 - val_loss: 0.3867 - val_accuracy: 0.8515\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.93 - ETA: 0s - loss: 0.3061 - accuracy: 0.86 - ETA: 0s - loss: 0.2622 - accuracy: 0.88 - ETA: 0s - loss: 0.2680 - accuracy: 0.88 - ETA: 0s - loss: 0.2681 - accuracy: 0.88 - ETA: 0s - loss: 0.2661 - accuracy: 0.88 - ETA: 0s - loss: 0.2613 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8888 - val_loss: 0.3920 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 06cc3c082e6391b4369c6f0f00766d5e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8634999990463257</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.65 - ETA: 0s - loss: 0.6747 - accuracy: 0.74 - ETA: 0s - loss: 0.6520 - accuracy: 0.79 - ETA: 0s - loss: 0.6266 - accuracy: 0.79 - ETA: 0s - loss: 0.6070 - accuracy: 0.79 - 1s 3ms/step - loss: 0.5962 - accuracy: 0.7907 - val_loss: 0.5095 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.84 - ETA: 0s - loss: 0.5098 - accuracy: 0.79 - ETA: 0s - loss: 0.4991 - accuracy: 0.79 - ETA: 0s - loss: 0.4962 - accuracy: 0.79 - ETA: 0s - loss: 0.4900 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7948 - val_loss: 0.4710 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.65 - ETA: 0s - loss: 0.4544 - accuracy: 0.80 - ETA: 0s - loss: 0.4615 - accuracy: 0.79 - ETA: 0s - loss: 0.4586 - accuracy: 0.80 - ETA: 0s - loss: 0.4677 - accuracy: 0.79 - ETA: 0s - loss: 0.4711 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7948 - val_loss: 0.4558 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.81 - ETA: 0s - loss: 0.4686 - accuracy: 0.78 - ETA: 0s - loss: 0.4639 - accuracy: 0.78 - ETA: 0s - loss: 0.4697 - accuracy: 0.78 - ETA: 0s - loss: 0.4639 - accuracy: 0.79 - ETA: 0s - loss: 0.4558 - accuracy: 0.79 - ETA: 0s - loss: 0.4532 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7950 - val_loss: 0.4436 - val_accuracy: 0.8005\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.81 - ETA: 0s - loss: 0.4052 - accuracy: 0.81 - ETA: 0s - loss: 0.4102 - accuracy: 0.81 - ETA: 0s - loss: 0.4277 - accuracy: 0.81 - ETA: 0s - loss: 0.4254 - accuracy: 0.81 - ETA: 0s - loss: 0.4365 - accuracy: 0.80 - ETA: 0s - loss: 0.4383 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8050 - val_loss: 0.4358 - val_accuracy: 0.8110\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.81 - ETA: 0s - loss: 0.4245 - accuracy: 0.81 - ETA: 0s - loss: 0.4401 - accuracy: 0.80 - ETA: 0s - loss: 0.4423 - accuracy: 0.80 - ETA: 0s - loss: 0.4376 - accuracy: 0.81 - ETA: 0s - loss: 0.4357 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8145 - val_loss: 0.4310 - val_accuracy: 0.8130\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.78 - ETA: 0s - loss: 0.4172 - accuracy: 0.82 - ETA: 0s - loss: 0.4274 - accuracy: 0.82 - ETA: 0s - loss: 0.4302 - accuracy: 0.81 - ETA: 0s - loss: 0.4274 - accuracy: 0.81 - ETA: 0s - loss: 0.4235 - accuracy: 0.82 - ETA: 0s - loss: 0.4246 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8170 - val_loss: 0.4279 - val_accuracy: 0.8115\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.75 - ETA: 0s - loss: 0.4122 - accuracy: 0.82 - ETA: 0s - loss: 0.4057 - accuracy: 0.83 - ETA: 0s - loss: 0.4259 - accuracy: 0.81 - ETA: 0s - loss: 0.4271 - accuracy: 0.81 - ETA: 0s - loss: 0.4255 - accuracy: 0.81 - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - ETA: 0s - loss: 0.4218 - accuracy: 0.81 - 1s 3ms/step - loss: 0.4218 - accuracy: 0.8187 - val_loss: 0.4251 - val_accuracy: 0.8135\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.78 - ETA: 0s - loss: 0.3919 - accuracy: 0.83 - ETA: 0s - loss: 0.4035 - accuracy: 0.82 - ETA: 0s - loss: 0.4189 - accuracy: 0.82 - ETA: 0s - loss: 0.4154 - accuracy: 0.82 - ETA: 0s - loss: 0.4179 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8198 - val_loss: 0.4219 - val_accuracy: 0.8150\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.68 - ETA: 0s - loss: 0.4019 - accuracy: 0.83 - ETA: 0s - loss: 0.3989 - accuracy: 0.83 - ETA: 0s - loss: 0.3978 - accuracy: 0.82 - ETA: 0s - loss: 0.4074 - accuracy: 0.82 - ETA: 0s - loss: 0.4102 - accuracy: 0.82 - ETA: 0s - loss: 0.4125 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8222 - val_loss: 0.4196 - val_accuracy: 0.8175\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.84 - ETA: 0s - loss: 0.3975 - accuracy: 0.82 - ETA: 0s - loss: 0.4083 - accuracy: 0.82 - ETA: 0s - loss: 0.4055 - accuracy: 0.82 - ETA: 0s - loss: 0.4095 - accuracy: 0.82 - ETA: 0s - loss: 0.4160 - accuracy: 0.82 - ETA: 0s - loss: 0.4108 - accuracy: 0.82 - 1s 3ms/step - loss: 0.4074 - accuracy: 0.8250 - val_loss: 0.4178 - val_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.78 - ETA: 0s - loss: 0.4222 - accuracy: 0.81 - ETA: 0s - loss: 0.4072 - accuracy: 0.82 - ETA: 0s - loss: 0.4085 - accuracy: 0.82 - ETA: 0s - loss: 0.4077 - accuracy: 0.82 - ETA: 0s - loss: 0.4051 - accuracy: 0.82 - ETA: 0s - loss: 0.4029 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8257 - val_loss: 0.4135 - val_accuracy: 0.8190\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.81 - ETA: 0s - loss: 0.4104 - accuracy: 0.82 - ETA: 0s - loss: 0.4061 - accuracy: 0.82 - ETA: 0s - loss: 0.4077 - accuracy: 0.82 - ETA: 0s - loss: 0.3993 - accuracy: 0.83 - ETA: 0s - loss: 0.4022 - accuracy: 0.82 - ETA: 0s - loss: 0.3980 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8300 - val_loss: 0.4103 - val_accuracy: 0.8210\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.93 - ETA: 0s - loss: 0.3776 - accuracy: 0.84 - ETA: 0s - loss: 0.3889 - accuracy: 0.83 - ETA: 0s - loss: 0.3868 - accuracy: 0.83 - ETA: 0s - loss: 0.3919 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8338 - val_loss: 0.4066 - val_accuracy: 0.8215\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.87 - ETA: 0s - loss: 0.3870 - accuracy: 0.83 - ETA: 0s - loss: 0.3848 - accuracy: 0.84 - ETA: 0s - loss: 0.3902 - accuracy: 0.83 - ETA: 0s - loss: 0.3874 - accuracy: 0.83 - ETA: 0s - loss: 0.3894 - accuracy: 0.83 - ETA: 0s - loss: 0.3876 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8363 - val_loss: 0.4029 - val_accuracy: 0.8225\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.87 - ETA: 0s - loss: 0.3834 - accuracy: 0.83 - ETA: 0s - loss: 0.3890 - accuracy: 0.83 - ETA: 0s - loss: 0.3926 - accuracy: 0.83 - ETA: 0s - loss: 0.3812 - accuracy: 0.83 - ETA: 0s - loss: 0.3801 - accuracy: 0.84 - ETA: 0s - loss: 0.3837 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8392 - val_loss: 0.3992 - val_accuracy: 0.8270\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.81 - ETA: 0s - loss: 0.3671 - accuracy: 0.86 - ETA: 0s - loss: 0.3830 - accuracy: 0.84 - ETA: 0s - loss: 0.3789 - accuracy: 0.84 - ETA: 0s - loss: 0.3788 - accuracy: 0.83 - ETA: 0s - loss: 0.3780 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8385 - val_loss: 0.3959 - val_accuracy: 0.8250\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.78 - ETA: 0s - loss: 0.3574 - accuracy: 0.85 - ETA: 0s - loss: 0.3687 - accuracy: 0.84 - ETA: 0s - loss: 0.3770 - accuracy: 0.84 - ETA: 0s - loss: 0.3730 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8445 - val_loss: 0.3925 - val_accuracy: 0.8305\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.84 - ETA: 0s - loss: 0.3702 - accuracy: 0.84 - ETA: 0s - loss: 0.3576 - accuracy: 0.84 - ETA: 0s - loss: 0.3642 - accuracy: 0.84 - ETA: 0s - loss: 0.3637 - accuracy: 0.84 - ETA: 0s - loss: 0.3662 - accuracy: 0.84 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8452 - val_loss: 0.3893 - val_accuracy: 0.8375\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.90 - ETA: 0s - loss: 0.3860 - accuracy: 0.83 - ETA: 0s - loss: 0.3681 - accuracy: 0.84 - ETA: 0s - loss: 0.3807 - accuracy: 0.84 - ETA: 0s - loss: 0.3733 - accuracy: 0.84 - ETA: 0s - loss: 0.3693 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8485 - val_loss: 0.3866 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.96 - ETA: 0s - loss: 0.3506 - accuracy: 0.85 - ETA: 0s - loss: 0.3552 - accuracy: 0.85 - ETA: 0s - loss: 0.3631 - accuracy: 0.85 - ETA: 0s - loss: 0.3651 - accuracy: 0.84 - ETA: 0s - loss: 0.3640 - accuracy: 0.85 - ETA: 0s - loss: 0.3618 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8502 - val_loss: 0.3839 - val_accuracy: 0.8370\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.71 - ETA: 0s - loss: 0.3775 - accuracy: 0.84 - ETA: 0s - loss: 0.3674 - accuracy: 0.84 - ETA: 0s - loss: 0.3549 - accuracy: 0.84 - ETA: 0s - loss: 0.3534 - accuracy: 0.84 - ETA: 0s - loss: 0.3522 - accuracy: 0.84 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8498 - val_loss: 0.3816 - val_accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.84 - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - ETA: 0s - loss: 0.3565 - accuracy: 0.85 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3469 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8527 - val_loss: 0.3792 - val_accuracy: 0.8420\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.81 - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3445 - accuracy: 0.85 - ETA: 0s - loss: 0.3506 - accuracy: 0.85 - ETA: 0s - loss: 0.3535 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8537 - val_loss: 0.3768 - val_accuracy: 0.8415\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.75 - ETA: 0s - loss: 0.3638 - accuracy: 0.83 - ETA: 0s - loss: 0.3590 - accuracy: 0.84 - ETA: 0s - loss: 0.3508 - accuracy: 0.84 - ETA: 0s - loss: 0.3459 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3490 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3496 - accuracy: 0.8543 - val_loss: 0.3758 - val_accuracy: 0.8450\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.90 - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - ETA: 0s - loss: 0.3637 - accuracy: 0.84 - ETA: 0s - loss: 0.3562 - accuracy: 0.84 - ETA: 0s - loss: 0.3513 - accuracy: 0.85 - ETA: 0s - loss: 0.3495 - accuracy: 0.85 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8550 - val_loss: 0.3741 - val_accuracy: 0.8460\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.96 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8543 - val_loss: 0.3746 - val_accuracy: 0.8440\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.81 - ETA: 0s - loss: 0.3400 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.85 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3445 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3454 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8553 - val_loss: 0.3717 - val_accuracy: 0.8470\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.93 - ETA: 0s - loss: 0.3455 - accuracy: 0.84 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3445 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8560 - val_loss: 0.3702 - val_accuracy: 0.8480\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.90 - ETA: 0s - loss: 0.3236 - accuracy: 0.87 - ETA: 0s - loss: 0.3466 - accuracy: 0.85 - ETA: 0s - loss: 0.3458 - accuracy: 0.85 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8563 - val_loss: 0.3699 - val_accuracy: 0.8500\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.90 - ETA: 0s - loss: 0.3307 - accuracy: 0.85 - ETA: 0s - loss: 0.3391 - accuracy: 0.85 - ETA: 0s - loss: 0.3389 - accuracy: 0.85 - ETA: 0s - loss: 0.3439 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.85 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8585 - val_loss: 0.3694 - val_accuracy: 0.8475\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.90 - ETA: 0s - loss: 0.3245 - accuracy: 0.86 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8587 - val_loss: 0.3679 - val_accuracy: 0.8495\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.93 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8602 - val_loss: 0.3664 - val_accuracy: 0.8510\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.90 - ETA: 0s - loss: 0.3216 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3237 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8613 - val_loss: 0.3655 - val_accuracy: 0.8510\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.78 - ETA: 0s - loss: 0.3674 - accuracy: 0.85 - ETA: 0s - loss: 0.3410 - accuracy: 0.85 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3405 - accuracy: 0.85 - ETA: 0s - loss: 0.3410 - accuracy: 0.85 - ETA: 0s - loss: 0.3374 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8610 - val_loss: 0.3651 - val_accuracy: 0.8510\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - ETA: 0s - loss: 0.3149 - accuracy: 0.87 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8608 - val_loss: 0.3644 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.87 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3323 - accuracy: 0.8627 - val_loss: 0.3639 - val_accuracy: 0.8520\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.93 - ETA: 0s - loss: 0.2830 - accuracy: 0.88 - ETA: 0s - loss: 0.3074 - accuracy: 0.87 - ETA: 0s - loss: 0.3085 - accuracy: 0.87 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8612 - val_loss: 0.3630 - val_accuracy: 0.8515\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.78 - ETA: 0s - loss: 0.3310 - accuracy: 0.85 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8617 - val_loss: 0.3633 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.84 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8628 - val_loss: 0.3621 - val_accuracy: 0.8525\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.90 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3385 - accuracy: 0.85 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8627 - val_loss: 0.3616 - val_accuracy: 0.8545\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.93 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8630 - val_loss: 0.3621 - val_accuracy: 0.8535\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.84 - ETA: 0s - loss: 0.3468 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3176 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8640 - val_loss: 0.3629 - val_accuracy: 0.8520\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.81 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8645 - val_loss: 0.3613 - val_accuracy: 0.8545\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.87 - ETA: 0s - loss: 0.3321 - accuracy: 0.85 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8657 - val_loss: 0.3602 - val_accuracy: 0.8515\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.86 - ETA: 0s - loss: 0.3049 - accuracy: 0.87 - ETA: 0s - loss: 0.3107 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8655 - val_loss: 0.3612 - val_accuracy: 0.8535\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.96 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8655 - val_loss: 0.3613 - val_accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.87 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3158 - accuracy: 0.87 - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - ETA: 0s - loss: 0.3200 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8680 - val_loss: 0.3595 - val_accuracy: 0.8540\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.90 - ETA: 0s - loss: 0.3028 - accuracy: 0.88 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8650 - val_loss: 0.3602 - val_accuracy: 0.8545\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.93 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8672 - val_loss: 0.3602 - val_accuracy: 0.8545\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.81 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3250 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8653 - val_loss: 0.3606 - val_accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.78 - ETA: 0s - loss: 0.2784 - accuracy: 0.88 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8673 - val_loss: 0.3588 - val_accuracy: 0.8545\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.93 - ETA: 0s - loss: 0.3138 - accuracy: 0.86 - ETA: 0s - loss: 0.3156 - accuracy: 0.86 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3194 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8665 - val_loss: 0.3588 - val_accuracy: 0.8545\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.3240 - accuracy: 0.86 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3191 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8673 - val_loss: 0.3591 - val_accuracy: 0.8520\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.84 - ETA: 0s - loss: 0.2961 - accuracy: 0.88 - ETA: 0s - loss: 0.3084 - accuracy: 0.86 - ETA: 0s - loss: 0.3178 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3195 - accuracy: 0.8687 - val_loss: 0.3577 - val_accuracy: 0.8555\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.90 - ETA: 0s - loss: 0.3216 - accuracy: 0.87 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8687 - val_loss: 0.3592 - val_accuracy: 0.8555\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.81 - ETA: 0s - loss: 0.2830 - accuracy: 0.88 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - ETA: 0s - loss: 0.3120 - accuracy: 0.86 - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - ETA: 0s - loss: 0.3163 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8670 - val_loss: 0.3579 - val_accuracy: 0.8555\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.84 - ETA: 0s - loss: 0.3045 - accuracy: 0.88 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3157 - accuracy: 0.86 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8688 - val_loss: 0.3574 - val_accuracy: 0.8555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.81 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3200 - accuracy: 0.86 - ETA: 0s - loss: 0.3173 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8680 - val_loss: 0.3580 - val_accuracy: 0.8530\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.81 - ETA: 0s - loss: 0.3130 - accuracy: 0.86 - ETA: 0s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8702 - val_loss: 0.3571 - val_accuracy: 0.8580\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.84 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - ETA: 0s - loss: 0.3200 - accuracy: 0.86 - ETA: 0s - loss: 0.3170 - accuracy: 0.86 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.3128 - accuracy: 0.86 - ETA: 0s - loss: 0.3106 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8678 - val_loss: 0.3584 - val_accuracy: 0.8570\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.84 - ETA: 0s - loss: 0.3108 - accuracy: 0.88 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - ETA: 0s - loss: 0.3069 - accuracy: 0.87 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8703 - val_loss: 0.3569 - val_accuracy: 0.8550\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.84 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3187 - accuracy: 0.86 - ETA: 0s - loss: 0.3160 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8695 - val_loss: 0.3600 - val_accuracy: 0.8530\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - ETA: 0s - loss: 0.3195 - accuracy: 0.86 - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3061 - accuracy: 0.86 - ETA: 0s - loss: 0.3105 - accuracy: 0.86 - ETA: 0s - loss: 0.3142 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8690 - val_loss: 0.3569 - val_accuracy: 0.8555\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.90 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - ETA: 0s - loss: 0.3174 - accuracy: 0.86 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8700 - val_loss: 0.3574 - val_accuracy: 0.8560\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.93 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - ETA: 0s - loss: 0.3106 - accuracy: 0.86 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3068 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.86 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8718 - val_loss: 0.3575 - val_accuracy: 0.8545\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3151 - accuracy: 0.86 - ETA: 0s - loss: 0.3148 - accuracy: 0.86 - ETA: 0s - loss: 0.3157 - accuracy: 0.86 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3136 - accuracy: 0.8708 - val_loss: 0.3561 - val_accuracy: 0.8585\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.84 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3131 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8712 - val_loss: 0.3563 - val_accuracy: 0.8575\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.84 - ETA: 0s - loss: 0.3078 - accuracy: 0.87 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - ETA: 0s - loss: 0.3078 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8730 - val_loss: 0.3572 - val_accuracy: 0.8555\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.81 - ETA: 0s - loss: 0.3142 - accuracy: 0.88 - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3067 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8703 - val_loss: 0.3562 - val_accuracy: 0.8570\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.93 - ETA: 0s - loss: 0.3096 - accuracy: 0.86 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8708 - val_loss: 0.3568 - val_accuracy: 0.8590\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.90 - ETA: 0s - loss: 0.2972 - accuracy: 0.88 - ETA: 0s - loss: 0.2958 - accuracy: 0.88 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.3100 - accuracy: 0.87 - ETA: 0s - loss: 0.3054 - accuracy: 0.87 - ETA: 0s - loss: 0.3094 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8717 - val_loss: 0.3561 - val_accuracy: 0.8580\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.81 - ETA: 0s - loss: 0.2967 - accuracy: 0.88 - ETA: 0s - loss: 0.3069 - accuracy: 0.87 - ETA: 0s - loss: 0.3014 - accuracy: 0.88 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - ETA: 0s - loss: 0.3108 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8723 - val_loss: 0.3564 - val_accuracy: 0.8550\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.93 - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - ETA: 0s - loss: 0.2891 - accuracy: 0.88 - ETA: 0s - loss: 0.2949 - accuracy: 0.88 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - ETA: 0s - loss: 0.3053 - accuracy: 0.87 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8715 - val_loss: 0.3560 - val_accuracy: 0.8570\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.78 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8723 - val_loss: 0.3570 - val_accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.84 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8725 - val_loss: 0.3564 - val_accuracy: 0.8570\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.84 - ETA: 0s - loss: 0.3108 - accuracy: 0.86 - ETA: 0s - loss: 0.3074 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3117 - accuracy: 0.86 - ETA: 0s - loss: 0.3074 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8720 - val_loss: 0.3573 - val_accuracy: 0.8580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.90 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3097 - accuracy: 0.87 - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - ETA: 0s - loss: 0.3097 - accuracy: 0.87 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8742 - val_loss: 0.3579 - val_accuracy: 0.8555\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - ETA: 0s - loss: 0.3175 - accuracy: 0.87 - ETA: 0s - loss: 0.3161 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.86 - ETA: 0s - loss: 0.3114 - accuracy: 0.87 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3083 - accuracy: 0.8722 - val_loss: 0.3569 - val_accuracy: 0.8595\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.93 - ETA: 0s - loss: 0.2886 - accuracy: 0.87 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2940 - accuracy: 0.88 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.3077 - accuracy: 0.87 - ETA: 0s - loss: 0.3068 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8733 - val_loss: 0.3584 - val_accuracy: 0.8550\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.84 - ETA: 0s - loss: 0.3207 - accuracy: 0.85 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - ETA: 0s - loss: 0.3153 - accuracy: 0.86 - ETA: 0s - loss: 0.3070 - accuracy: 0.87 - ETA: 0s - loss: 0.3108 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8732 - val_loss: 0.3578 - val_accuracy: 0.8545\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.87 - ETA: 0s - loss: 0.3069 - accuracy: 0.88 - ETA: 0s - loss: 0.3169 - accuracy: 0.87 - ETA: 0s - loss: 0.3172 - accuracy: 0.86 - ETA: 0s - loss: 0.3109 - accuracy: 0.87 - ETA: 0s - loss: 0.3034 - accuracy: 0.87 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8728 - val_loss: 0.3595 - val_accuracy: 0.8555\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.93 - ETA: 0s - loss: 0.3129 - accuracy: 0.86 - ETA: 0s - loss: 0.3068 - accuracy: 0.87 - ETA: 0s - loss: 0.3049 - accuracy: 0.87 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3006 - accuracy: 0.87 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8750 - val_loss: 0.3599 - val_accuracy: 0.8560\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.96 - ETA: 0s - loss: 0.3162 - accuracy: 0.86 - ETA: 0s - loss: 0.3004 - accuracy: 0.88 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8735 - val_loss: 0.3572 - val_accuracy: 0.8590\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.87 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - ETA: 0s - loss: 0.3015 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8740 - val_loss: 0.3570 - val_accuracy: 0.8570\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 1.00 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.2997 - accuracy: 0.87 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - ETA: 0s - loss: 0.3057 - accuracy: 0.87 - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8735 - val_loss: 0.3569 - val_accuracy: 0.8580\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.90 - ETA: 0s - loss: 0.2980 - accuracy: 0.87 - ETA: 0s - loss: 0.2882 - accuracy: 0.88 - ETA: 0s - loss: 0.2953 - accuracy: 0.87 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8738 - val_loss: 0.3567 - val_accuracy: 0.8585\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.84 - ETA: 0s - loss: 0.2828 - accuracy: 0.89 - ETA: 0s - loss: 0.3054 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8742 - val_loss: 0.3580 - val_accuracy: 0.8590\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.90 - ETA: 0s - loss: 0.2955 - accuracy: 0.88 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8745 - val_loss: 0.3572 - val_accuracy: 0.8585\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.75 - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - ETA: 0s - loss: 0.2864 - accuracy: 0.88 - ETA: 0s - loss: 0.2865 - accuracy: 0.88 - ETA: 0s - loss: 0.2984 - accuracy: 0.87 - ETA: 0s - loss: 0.2965 - accuracy: 0.87 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8748 - val_loss: 0.3594 - val_accuracy: 0.8560\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.87 - ETA: 0s - loss: 0.2900 - accuracy: 0.87 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - ETA: 0s - loss: 0.2975 - accuracy: 0.87 - ETA: 0s - loss: 0.2997 - accuracy: 0.87 - ETA: 0s - loss: 0.3008 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8742 - val_loss: 0.3593 - val_accuracy: 0.8575\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.87 - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - ETA: 0s - loss: 0.3001 - accuracy: 0.87 - ETA: 0s - loss: 0.2989 - accuracy: 0.87 - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8765 - val_loss: 0.3577 - val_accuracy: 0.8585\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.93 - ETA: 0s - loss: 0.3200 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - ETA: 0s - loss: 0.3034 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8762 - val_loss: 0.3603 - val_accuracy: 0.8565\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.81 - ETA: 0s - loss: 0.3079 - accuracy: 0.88 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.2974 - accuracy: 0.87 - ETA: 0s - loss: 0.3000 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8760 - val_loss: 0.3576 - val_accuracy: 0.8570\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.90 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3015 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8753 - val_loss: 0.3579 - val_accuracy: 0.8575\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.93 - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3065 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3033 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8753 - val_loss: 0.3582 - val_accuracy: 0.8565\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.90 - ETA: 0s - loss: 0.3025 - accuracy: 0.87 - ETA: 0s - loss: 0.3185 - accuracy: 0.86 - ETA: 0s - loss: 0.3119 - accuracy: 0.87 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - ETA: 0s - loss: 0.3112 - accuracy: 0.87 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8757 - val_loss: 0.3622 - val_accuracy: 0.8560\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.84 - ETA: 0s - loss: 0.2966 - accuracy: 0.87 - ETA: 0s - loss: 0.2966 - accuracy: 0.87 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - ETA: 0s - loss: 0.2933 - accuracy: 0.87 - ETA: 0s - loss: 0.2979 - accuracy: 0.87 - ETA: 0s - loss: 0.2973 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8752 - val_loss: 0.3595 - val_accuracy: 0.8575\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.78 - ETA: 0s - loss: 0.3084 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.85 - ETA: 0s - loss: 0.3178 - accuracy: 0.86 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - ETA: 0s - loss: 0.3063 - accuracy: 0.87 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8745 - val_loss: 0.3603 - val_accuracy: 0.8550\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.90 - ETA: 0s - loss: 0.2961 - accuracy: 0.88 - ETA: 0s - loss: 0.2897 - accuracy: 0.88 - ETA: 0s - loss: 0.2896 - accuracy: 0.87 - ETA: 0s - loss: 0.2951 - accuracy: 0.87 - ETA: 0s - loss: 0.3009 - accuracy: 0.87 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8765 - val_loss: 0.3585 - val_accuracy: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a4176dbd38f51a51d2bca2bc6686bab5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859499990940094</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.40 - ETA: 0s - loss: 0.6910 - accuracy: 0.62 - ETA: 0s - loss: 0.6873 - accuracy: 0.72 - ETA: 0s - loss: 0.6813 - accuracy: 0.75 - ETA: 0s - loss: 0.6743 - accuracy: 0.77 - 1s 3ms/step - loss: 0.6678 - accuracy: 0.7718 - val_loss: 0.6240 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.6433 - accuracy: 0.75 - ETA: 0s - loss: 0.6191 - accuracy: 0.79 - ETA: 0s - loss: 0.6004 - accuracy: 0.79 - ETA: 0s - loss: 0.5790 - accuracy: 0.79 - ETA: 0s - loss: 0.5640 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7948 - val_loss: 0.5056 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.78 - ETA: 0s - loss: 0.5239 - accuracy: 0.77 - ETA: 0s - loss: 0.5095 - accuracy: 0.78 - ETA: 0s - loss: 0.5008 - accuracy: 0.79 - ETA: 0s - loss: 0.4920 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7948 - val_loss: 0.4833 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.87 - ETA: 0s - loss: 0.4614 - accuracy: 0.81 - ETA: 0s - loss: 0.4809 - accuracy: 0.79 - ETA: 0s - loss: 0.4788 - accuracy: 0.79 - ETA: 0s - loss: 0.4780 - accuracy: 0.79 - ETA: 0s - loss: 0.4817 - accuracy: 0.79 - ETA: 0s - loss: 0.4777 - accuracy: 0.79 - ETA: 0s - loss: 0.4740 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7948 - val_loss: 0.4691 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.84 - ETA: 0s - loss: 0.4753 - accuracy: 0.79 - ETA: 0s - loss: 0.4464 - accuracy: 0.81 - ETA: 0s - loss: 0.4470 - accuracy: 0.80 - ETA: 0s - loss: 0.4511 - accuracy: 0.80 - ETA: 0s - loss: 0.4583 - accuracy: 0.79 - ETA: 0s - loss: 0.4585 - accuracy: 0.79 - ETA: 0s - loss: 0.4599 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7948 - val_loss: 0.4570 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.84 - ETA: 0s - loss: 0.4390 - accuracy: 0.79 - ETA: 0s - loss: 0.4395 - accuracy: 0.79 - ETA: 0s - loss: 0.4409 - accuracy: 0.79 - ETA: 0s - loss: 0.4482 - accuracy: 0.79 - ETA: 0s - loss: 0.4496 - accuracy: 0.79 - ETA: 0s - loss: 0.4502 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7948 - val_loss: 0.4475 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5456 - accuracy: 0.71 - ETA: 0s - loss: 0.4325 - accuracy: 0.79 - ETA: 0s - loss: 0.4481 - accuracy: 0.78 - ETA: 0s - loss: 0.4383 - accuracy: 0.79 - ETA: 0s - loss: 0.4360 - accuracy: 0.79 - ETA: 0s - loss: 0.4365 - accuracy: 0.79 - ETA: 0s - loss: 0.4342 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7948 - val_loss: 0.4398 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5535 - accuracy: 0.68 - ETA: 0s - loss: 0.4335 - accuracy: 0.78 - ETA: 0s - loss: 0.4335 - accuracy: 0.79 - ETA: 0s - loss: 0.4300 - accuracy: 0.78 - ETA: 0s - loss: 0.4282 - accuracy: 0.79 - ETA: 0s - loss: 0.4233 - accuracy: 0.79 - ETA: 0s - loss: 0.4249 - accuracy: 0.79 - 1s 3ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4345 - val_accuracy: 0.8030\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.87 - ETA: 0s - loss: 0.4161 - accuracy: 0.80 - ETA: 0s - loss: 0.4198 - accuracy: 0.80 - ETA: 0s - loss: 0.4298 - accuracy: 0.79 - ETA: 0s - loss: 0.4285 - accuracy: 0.80 - ETA: 0s - loss: 0.4275 - accuracy: 0.80 - ETA: 0s - loss: 0.4235 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8083 - val_loss: 0.4301 - val_accuracy: 0.8150\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.90 - ETA: 0s - loss: 0.4000 - accuracy: 0.82 - ETA: 0s - loss: 0.3901 - accuracy: 0.83 - ETA: 0s - loss: 0.4037 - accuracy: 0.82 - ETA: 0s - loss: 0.4177 - accuracy: 0.82 - ETA: 0s - loss: 0.4177 - accuracy: 0.82 - ETA: 0s - loss: 0.4164 - accuracy: 0.82 - 1s 3ms/step - loss: 0.4174 - accuracy: 0.8238 - val_loss: 0.4251 - val_accuracy: 0.8190\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.87 - ETA: 0s - loss: 0.4069 - accuracy: 0.81 - ETA: 0s - loss: 0.4152 - accuracy: 0.81 - ETA: 0s - loss: 0.4097 - accuracy: 0.82 - ETA: 0s - loss: 0.4121 - accuracy: 0.82 - ETA: 0s - loss: 0.4147 - accuracy: 0.82 - ETA: 0s - loss: 0.4137 - accuracy: 0.82 - 1s 3ms/step - loss: 0.4112 - accuracy: 0.8272 - val_loss: 0.4205 - val_accuracy: 0.8230\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.84 - ETA: 0s - loss: 0.4219 - accuracy: 0.82 - ETA: 0s - loss: 0.4121 - accuracy: 0.82 - ETA: 0s - loss: 0.4080 - accuracy: 0.82 - ETA: 0s - loss: 0.4104 - accuracy: 0.82 - ETA: 0s - loss: 0.4088 - accuracy: 0.82 - ETA: 0s - loss: 0.4063 - accuracy: 0.83 - 1s 3ms/step - loss: 0.4048 - accuracy: 0.8312 - val_loss: 0.4154 - val_accuracy: 0.8260\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.78 - ETA: 0s - loss: 0.3728 - accuracy: 0.85 - ETA: 0s - loss: 0.4097 - accuracy: 0.83 - ETA: 0s - loss: 0.3954 - accuracy: 0.84 - ETA: 0s - loss: 0.4000 - accuracy: 0.83 - ETA: 0s - loss: 0.3998 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8368 - val_loss: 0.4113 - val_accuracy: 0.8260\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.75 - ETA: 0s - loss: 0.3982 - accuracy: 0.83 - ETA: 0s - loss: 0.3956 - accuracy: 0.83 - ETA: 0s - loss: 0.3961 - accuracy: 0.83 - ETA: 0s - loss: 0.3910 - accuracy: 0.83 - ETA: 0s - loss: 0.3984 - accuracy: 0.83 - ETA: 0s - loss: 0.3954 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3925 - accuracy: 0.8400 - val_loss: 0.4073 - val_accuracy: 0.8300\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.75 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - ETA: 0s - loss: 0.3986 - accuracy: 0.83 - ETA: 0s - loss: 0.3970 - accuracy: 0.83 - ETA: 0s - loss: 0.3863 - accuracy: 0.84 - ETA: 0s - loss: 0.3786 - accuracy: 0.84 - ETA: 0s - loss: 0.3871 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8422 - val_loss: 0.4035 - val_accuracy: 0.8285\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.93 - ETA: 0s - loss: 0.3577 - accuracy: 0.86 - ETA: 0s - loss: 0.3733 - accuracy: 0.85 - ETA: 0s - loss: 0.3714 - accuracy: 0.84 - ETA: 0s - loss: 0.3702 - accuracy: 0.84 - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - ETA: 0s - loss: 0.3837 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3822 - accuracy: 0.8447 - val_loss: 0.3988 - val_accuracy: 0.8320\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.81 - ETA: 0s - loss: 0.3988 - accuracy: 0.85 - ETA: 0s - loss: 0.3989 - accuracy: 0.84 - ETA: 0s - loss: 0.3868 - accuracy: 0.84 - ETA: 0s - loss: 0.3775 - accuracy: 0.85 - ETA: 0s - loss: 0.3761 - accuracy: 0.85 - ETA: 0s - loss: 0.3770 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8478 - val_loss: 0.3959 - val_accuracy: 0.8355\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.84 - ETA: 0s - loss: 0.3717 - accuracy: 0.84 - ETA: 0s - loss: 0.3660 - accuracy: 0.85 - ETA: 0s - loss: 0.3687 - accuracy: 0.85 - ETA: 0s - loss: 0.3701 - accuracy: 0.85 - ETA: 0s - loss: 0.3765 - accuracy: 0.84 - ETA: 0s - loss: 0.3734 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8508 - val_loss: 0.3927 - val_accuracy: 0.8355\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.87 - ETA: 0s - loss: 0.3685 - accuracy: 0.85 - ETA: 0s - loss: 0.3768 - accuracy: 0.85 - ETA: 0s - loss: 0.3744 - accuracy: 0.85 - ETA: 0s - loss: 0.3731 - accuracy: 0.85 - ETA: 0s - loss: 0.3673 - accuracy: 0.85 - ETA: 0s - loss: 0.3669 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8522 - val_loss: 0.3898 - val_accuracy: 0.8370\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.90 - ETA: 0s - loss: 0.3473 - accuracy: 0.85 - ETA: 0s - loss: 0.3484 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3587 - accuracy: 0.85 - ETA: 0s - loss: 0.3650 - accuracy: 0.85 - ETA: 0s - loss: 0.3635 - accuracy: 0.85 - ETA: 0s - loss: 0.3652 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8552 - val_loss: 0.3849 - val_accuracy: 0.8430\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.78 - ETA: 0s - loss: 0.3395 - accuracy: 0.87 - ETA: 0s - loss: 0.3564 - accuracy: 0.86 - ETA: 0s - loss: 0.3570 - accuracy: 0.86 - ETA: 0s - loss: 0.3592 - accuracy: 0.85 - ETA: 0s - loss: 0.3641 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8555 - val_loss: 0.3846 - val_accuracy: 0.8450\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.75 - ETA: 0s - loss: 0.3443 - accuracy: 0.86 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3636 - accuracy: 0.85 - ETA: 0s - loss: 0.3638 - accuracy: 0.85 - ETA: 0s - loss: 0.3632 - accuracy: 0.85 - ETA: 0s - loss: 0.3599 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8555 - val_loss: 0.3797 - val_accuracy: 0.8475\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.81 - ETA: 0s - loss: 0.3683 - accuracy: 0.84 - ETA: 0s - loss: 0.3475 - accuracy: 0.86 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3545 - accuracy: 0.86 - ETA: 0s - loss: 0.3522 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8588 - val_loss: 0.3768 - val_accuracy: 0.8470\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.78 - ETA: 0s - loss: 0.3479 - accuracy: 0.87 - ETA: 0s - loss: 0.3535 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8605 - val_loss: 0.3753 - val_accuracy: 0.8490\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.81 - ETA: 0s - loss: 0.3503 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3537 - accuracy: 0.85 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.86 - ETA: 0s - loss: 0.3492 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8605 - val_loss: 0.3729 - val_accuracy: 0.8495\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.93 - ETA: 0s - loss: 0.3301 - accuracy: 0.87 - ETA: 0s - loss: 0.3534 - accuracy: 0.86 - ETA: 0s - loss: 0.3493 - accuracy: 0.86 - ETA: 0s - loss: 0.3479 - accuracy: 0.86 - ETA: 0s - loss: 0.3472 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8622 - val_loss: 0.3703 - val_accuracy: 0.8510\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.81 - ETA: 0s - loss: 0.3639 - accuracy: 0.85 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - ETA: 0s - loss: 0.3443 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8635 - val_loss: 0.3681 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.96 - ETA: 0s - loss: 0.3294 - accuracy: 0.87 - ETA: 0s - loss: 0.3477 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - ETA: 0s - loss: 0.3431 - accuracy: 0.86 - ETA: 0s - loss: 0.3433 - accuracy: 0.86 - ETA: 0s - loss: 0.3412 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8652 - val_loss: 0.3681 - val_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.93 - ETA: 0s - loss: 0.3352 - accuracy: 0.87 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3456 - accuracy: 0.86 - ETA: 0s - loss: 0.3465 - accuracy: 0.86 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8662 - val_loss: 0.3673 - val_accuracy: 0.8505\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.78 - ETA: 0s - loss: 0.3528 - accuracy: 0.86 - ETA: 0s - loss: 0.3513 - accuracy: 0.86 - ETA: 0s - loss: 0.3550 - accuracy: 0.85 - ETA: 0s - loss: 0.3464 - accuracy: 0.86 - ETA: 0s - loss: 0.3394 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8677 - val_loss: 0.3672 - val_accuracy: 0.8510\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3343 - accuracy: 0.87 - ETA: 0s - loss: 0.3385 - accuracy: 0.87 - ETA: 0s - loss: 0.3386 - accuracy: 0.87 - ETA: 0s - loss: 0.3392 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8690 - val_loss: 0.3638 - val_accuracy: 0.8510\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.84 - ETA: 0s - loss: 0.3396 - accuracy: 0.87 - ETA: 0s - loss: 0.3420 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.87 - ETA: 0s - loss: 0.3374 - accuracy: 0.87 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8685 - val_loss: 0.3671 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.87 - ETA: 0s - loss: 0.3731 - accuracy: 0.86 - ETA: 0s - loss: 0.3474 - accuracy: 0.87 - ETA: 0s - loss: 0.3406 - accuracy: 0.87 - ETA: 0s - loss: 0.3300 - accuracy: 0.87 - ETA: 0s - loss: 0.3353 - accuracy: 0.87 - ETA: 0s - loss: 0.3342 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8717 - val_loss: 0.3632 - val_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.81 - ETA: 0s - loss: 0.3747 - accuracy: 0.84 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3543 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8715 - val_loss: 0.3627 - val_accuracy: 0.8525\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.93 - ETA: 0s - loss: 0.3190 - accuracy: 0.88 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8703 - val_loss: 0.3615 - val_accuracy: 0.8515\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.84 - ETA: 0s - loss: 0.3044 - accuracy: 0.88 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3254 - accuracy: 0.87 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8710 - val_loss: 0.3608 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.87 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.87 - ETA: 0s - loss: 0.3294 - accuracy: 0.87 - ETA: 0s - loss: 0.3309 - accuracy: 0.87 - ETA: 0s - loss: 0.3294 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8713 - val_loss: 0.3610 - val_accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.87 - ETA: 0s - loss: 0.3152 - accuracy: 0.88 - ETA: 0s - loss: 0.3418 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.87 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3271 - accuracy: 0.87 - ETA: 0s - loss: 0.3270 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8705 - val_loss: 0.3605 - val_accuracy: 0.8530\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.87 - ETA: 0s - loss: 0.3282 - accuracy: 0.87 - ETA: 0s - loss: 0.3311 - accuracy: 0.87 - ETA: 0s - loss: 0.3162 - accuracy: 0.88 - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - ETA: 0s - loss: 0.3294 - accuracy: 0.87 - ETA: 0s - loss: 0.3307 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8715 - val_loss: 0.3604 - val_accuracy: 0.8505\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.96 - ETA: 0s - loss: 0.3192 - accuracy: 0.89 - ETA: 0s - loss: 0.3432 - accuracy: 0.87 - ETA: 0s - loss: 0.3513 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.87 - ETA: 0s - loss: 0.3366 - accuracy: 0.87 - ETA: 0s - loss: 0.3343 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8732 - val_loss: 0.3612 - val_accuracy: 0.8520\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.96 - ETA: 0s - loss: 0.2807 - accuracy: 0.90 - ETA: 0s - loss: 0.3142 - accuracy: 0.88 - ETA: 0s - loss: 0.3106 - accuracy: 0.88 - ETA: 0s - loss: 0.3262 - accuracy: 0.87 - ETA: 0s - loss: 0.3267 - accuracy: 0.87 - ETA: 0s - loss: 0.3312 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8733 - val_loss: 0.3606 - val_accuracy: 0.8540\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.96 - ETA: 0s - loss: 0.3092 - accuracy: 0.88 - ETA: 0s - loss: 0.3197 - accuracy: 0.87 - ETA: 0s - loss: 0.3303 - accuracy: 0.87 - ETA: 0s - loss: 0.3268 - accuracy: 0.87 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8733 - val_loss: 0.3614 - val_accuracy: 0.8520\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.78 - ETA: 0s - loss: 0.3387 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.88 - ETA: 0s - loss: 0.3255 - accuracy: 0.87 - ETA: 0s - loss: 0.3265 - accuracy: 0.87 - ETA: 0s - loss: 0.3232 - accuracy: 0.87 - ETA: 0s - loss: 0.3229 - accuracy: 0.87 - ETA: 0s - loss: 0.3268 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3268 - accuracy: 0.8743 - val_loss: 0.3592 - val_accuracy: 0.8550\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.90 - ETA: 0s - loss: 0.3102 - accuracy: 0.88 - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - ETA: 0s - loss: 0.3163 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - ETA: 0s - loss: 0.3260 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8737 - val_loss: 0.3593 - val_accuracy: 0.8540\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3556 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.88 - ETA: 0s - loss: 0.3361 - accuracy: 0.87 - ETA: 0s - loss: 0.3301 - accuracy: 0.87 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - ETA: 0s - loss: 0.3273 - accuracy: 0.87 - ETA: 0s - loss: 0.3262 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3254 - accuracy: 0.8747 - val_loss: 0.3587 - val_accuracy: 0.8565\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.96 - ETA: 0s - loss: 0.2841 - accuracy: 0.89 - ETA: 0s - loss: 0.3095 - accuracy: 0.88 - ETA: 0s - loss: 0.3234 - accuracy: 0.87 - ETA: 0s - loss: 0.3220 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.87 - ETA: 0s - loss: 0.3188 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8747 - val_loss: 0.3586 - val_accuracy: 0.8550\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2570 - accuracy: 0.93 - ETA: 0s - loss: 0.3086 - accuracy: 0.88 - ETA: 0s - loss: 0.3149 - accuracy: 0.88 - ETA: 0s - loss: 0.3216 - accuracy: 0.87 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3257 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.87 - ETA: 0s - loss: 0.3238 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8760 - val_loss: 0.3586 - val_accuracy: 0.8555\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.93 - ETA: 0s - loss: 0.3048 - accuracy: 0.89 - ETA: 0s - loss: 0.3107 - accuracy: 0.89 - ETA: 0s - loss: 0.3185 - accuracy: 0.88 - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.87 - ETA: 0s - loss: 0.3226 - accuracy: 0.87 - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8757 - val_loss: 0.3596 - val_accuracy: 0.8535\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.87 - ETA: 0s - loss: 0.3529 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3188 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.87 - ETA: 0s - loss: 0.3204 - accuracy: 0.87 - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8747 - val_loss: 0.3581 - val_accuracy: 0.8560\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.87 - ETA: 0s - loss: 0.3270 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.87 - ETA: 0s - loss: 0.3245 - accuracy: 0.87 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3171 - accuracy: 0.87 - ETA: 0s - loss: 0.3209 - accuracy: 0.87 - ETA: 0s - loss: 0.3211 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8757 - val_loss: 0.3585 - val_accuracy: 0.8565\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.84 - ETA: 0s - loss: 0.3068 - accuracy: 0.88 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - ETA: 0s - loss: 0.3052 - accuracy: 0.88 - ETA: 0s - loss: 0.3164 - accuracy: 0.87 - ETA: 0s - loss: 0.3125 - accuracy: 0.88 - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8770 - val_loss: 0.3578 - val_accuracy: 0.8560\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.93 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3216 - accuracy: 0.86 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8768 - val_loss: 0.3593 - val_accuracy: 0.8555\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.87 - ETA: 0s - loss: 0.2791 - accuracy: 0.88 - ETA: 0s - loss: 0.2953 - accuracy: 0.88 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.3170 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8772 - val_loss: 0.3580 - val_accuracy: 0.8535\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.84 - ETA: 0s - loss: 0.3179 - accuracy: 0.88 - ETA: 0s - loss: 0.3272 - accuracy: 0.87 - ETA: 0s - loss: 0.3246 - accuracy: 0.87 - ETA: 0s - loss: 0.3253 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8773 - val_loss: 0.3589 - val_accuracy: 0.8540\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.90 - ETA: 0s - loss: 0.3197 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - ETA: 0s - loss: 0.3125 - accuracy: 0.88 - ETA: 0s - loss: 0.3100 - accuracy: 0.88 - ETA: 0s - loss: 0.3130 - accuracy: 0.88 - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8772 - val_loss: 0.3593 - val_accuracy: 0.8535\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.96 - ETA: 0s - loss: 0.3152 - accuracy: 0.88 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3296 - accuracy: 0.87 - ETA: 0s - loss: 0.3323 - accuracy: 0.87 - ETA: 0s - loss: 0.3261 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3173 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8795 - val_loss: 0.3606 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.93 - ETA: 0s - loss: 0.2991 - accuracy: 0.89 - ETA: 0s - loss: 0.3139 - accuracy: 0.88 - ETA: 0s - loss: 0.3086 - accuracy: 0.88 - ETA: 0s - loss: 0.3062 - accuracy: 0.88 - ETA: 0s - loss: 0.3099 - accuracy: 0.88 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8763 - val_loss: 0.3581 - val_accuracy: 0.8565\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.84 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3436 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.87 - ETA: 0s - loss: 0.3156 - accuracy: 0.88 - ETA: 0s - loss: 0.3203 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3166 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8792 - val_loss: 0.3598 - val_accuracy: 0.8535\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.90 - ETA: 0s - loss: 0.3212 - accuracy: 0.88 - ETA: 0s - loss: 0.3078 - accuracy: 0.88 - ETA: 0s - loss: 0.3114 - accuracy: 0.88 - ETA: 0s - loss: 0.3123 - accuracy: 0.88 - ETA: 0s - loss: 0.3138 - accuracy: 0.88 - ETA: 0s - loss: 0.3137 - accuracy: 0.88 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8785 - val_loss: 0.3585 - val_accuracy: 0.8555\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.84 - ETA: 0s - loss: 0.3175 - accuracy: 0.88 - ETA: 0s - loss: 0.3328 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.87 - ETA: 0s - loss: 0.3272 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8795 - val_loss: 0.3601 - val_accuracy: 0.8555\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.96 - ETA: 0s - loss: 0.3170 - accuracy: 0.88 - ETA: 0s - loss: 0.3088 - accuracy: 0.88 - ETA: 0s - loss: 0.3016 - accuracy: 0.89 - ETA: 0s - loss: 0.3077 - accuracy: 0.88 - ETA: 0s - loss: 0.3130 - accuracy: 0.88 - ETA: 0s - loss: 0.3105 - accuracy: 0.88 - ETA: 0s - loss: 0.3147 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8803 - val_loss: 0.3591 - val_accuracy: 0.8550\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.90 - ETA: 0s - loss: 0.3033 - accuracy: 0.88 - ETA: 0s - loss: 0.3090 - accuracy: 0.88 - ETA: 0s - loss: 0.3079 - accuracy: 0.88 - ETA: 0s - loss: 0.3069 - accuracy: 0.88 - ETA: 0s - loss: 0.3062 - accuracy: 0.88 - ETA: 0s - loss: 0.3069 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8800 - val_loss: 0.3586 - val_accuracy: 0.8535\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.75 - ETA: 0s - loss: 0.3437 - accuracy: 0.87 - ETA: 0s - loss: 0.3281 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.88 - ETA: 0s - loss: 0.3167 - accuracy: 0.88 - ETA: 0s - loss: 0.3151 - accuracy: 0.88 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8797 - val_loss: 0.3595 - val_accuracy: 0.8540\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.93 - ETA: 0s - loss: 0.3574 - accuracy: 0.86 - ETA: 0s - loss: 0.3123 - accuracy: 0.88 - ETA: 0s - loss: 0.3066 - accuracy: 0.88 - ETA: 0s - loss: 0.3007 - accuracy: 0.88 - ETA: 0s - loss: 0.3077 - accuracy: 0.88 - ETA: 0s - loss: 0.3083 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8808 - val_loss: 0.3590 - val_accuracy: 0.8555\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.93 - ETA: 0s - loss: 0.3007 - accuracy: 0.89 - ETA: 0s - loss: 0.3058 - accuracy: 0.89 - ETA: 0s - loss: 0.3102 - accuracy: 0.88 - ETA: 0s - loss: 0.3099 - accuracy: 0.88 - ETA: 0s - loss: 0.3130 - accuracy: 0.88 - ETA: 0s - loss: 0.3136 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8818 - val_loss: 0.3589 - val_accuracy: 0.8530\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.84 - ETA: 0s - loss: 0.2908 - accuracy: 0.88 - ETA: 0s - loss: 0.2878 - accuracy: 0.88 - ETA: 0s - loss: 0.3051 - accuracy: 0.88 - ETA: 0s - loss: 0.3061 - accuracy: 0.88 - ETA: 0s - loss: 0.3105 - accuracy: 0.88 - ETA: 0s - loss: 0.3114 - accuracy: 0.88 - ETA: 0s - loss: 0.3114 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8805 - val_loss: 0.3598 - val_accuracy: 0.8560\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.90 - ETA: 0s - loss: 0.3320 - accuracy: 0.87 - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.3172 - accuracy: 0.87 - ETA: 0s - loss: 0.3202 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3114 - accuracy: 0.8810 - val_loss: 0.3603 - val_accuracy: 0.8575\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.78 - ETA: 0s - loss: 0.3063 - accuracy: 0.88 - ETA: 0s - loss: 0.3064 - accuracy: 0.88 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - ETA: 0s - loss: 0.3112 - accuracy: 0.88 - ETA: 0s - loss: 0.3069 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8810 - val_loss: 0.3596 - val_accuracy: 0.8550\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.78 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.3063 - accuracy: 0.88 - ETA: 0s - loss: 0.3097 - accuracy: 0.88 - ETA: 0s - loss: 0.3025 - accuracy: 0.88 - ETA: 0s - loss: 0.3046 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8815 - val_loss: 0.3587 - val_accuracy: 0.8570\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.90 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.3117 - accuracy: 0.88 - ETA: 0s - loss: 0.3117 - accuracy: 0.88 - ETA: 0s - loss: 0.3092 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8832 - val_loss: 0.3599 - val_accuracy: 0.8545\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.96 - ETA: 0s - loss: 0.2949 - accuracy: 0.89 - ETA: 0s - loss: 0.2977 - accuracy: 0.88 - ETA: 0s - loss: 0.2998 - accuracy: 0.88 - ETA: 0s - loss: 0.2972 - accuracy: 0.89 - ETA: 0s - loss: 0.2980 - accuracy: 0.89 - ETA: 0s - loss: 0.3068 - accuracy: 0.88 - ETA: 0s - loss: 0.3080 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8822 - val_loss: 0.3612 - val_accuracy: 0.8555\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.90 - ETA: 0s - loss: 0.2803 - accuracy: 0.89 - ETA: 0s - loss: 0.2866 - accuracy: 0.89 - ETA: 0s - loss: 0.2929 - accuracy: 0.89 - ETA: 0s - loss: 0.3014 - accuracy: 0.88 - ETA: 0s - loss: 0.3034 - accuracy: 0.88 - ETA: 0s - loss: 0.3032 - accuracy: 0.88 - ETA: 0s - loss: 0.3080 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8828 - val_loss: 0.3596 - val_accuracy: 0.8545\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.87 - ETA: 0s - loss: 0.3080 - accuracy: 0.88 - ETA: 0s - loss: 0.3055 - accuracy: 0.88 - ETA: 0s - loss: 0.2999 - accuracy: 0.88 - ETA: 0s - loss: 0.3093 - accuracy: 0.88 - ETA: 0s - loss: 0.3024 - accuracy: 0.88 - ETA: 0s - loss: 0.3008 - accuracy: 0.88 - ETA: 0s - loss: 0.3086 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8847 - val_loss: 0.3599 - val_accuracy: 0.8545\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.90 - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - ETA: 0s - loss: 0.2962 - accuracy: 0.88 - ETA: 0s - loss: 0.3043 - accuracy: 0.88 - ETA: 0s - loss: 0.3055 - accuracy: 0.88 - ETA: 0s - loss: 0.3061 - accuracy: 0.88 - ETA: 0s - loss: 0.3067 - accuracy: 0.88 - ETA: 0s - loss: 0.3068 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3068 - accuracy: 0.8842 - val_loss: 0.3595 - val_accuracy: 0.8565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.81 - ETA: 0s - loss: 0.2571 - accuracy: 0.90 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - ETA: 0s - loss: 0.3030 - accuracy: 0.88 - ETA: 0s - loss: 0.3030 - accuracy: 0.88 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - ETA: 0s - loss: 0.3071 - accuracy: 0.88 - ETA: 0s - loss: 0.3060 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8848 - val_loss: 0.3596 - val_accuracy: 0.8555\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.87 - ETA: 0s - loss: 0.3257 - accuracy: 0.87 - ETA: 0s - loss: 0.2992 - accuracy: 0.88 - ETA: 0s - loss: 0.3079 - accuracy: 0.88 - ETA: 0s - loss: 0.3157 - accuracy: 0.88 - ETA: 0s - loss: 0.3136 - accuracy: 0.88 - ETA: 0s - loss: 0.3110 - accuracy: 0.88 - ETA: 0s - loss: 0.3056 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8848 - val_loss: 0.3636 - val_accuracy: 0.8560\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.90 - ETA: 0s - loss: 0.3097 - accuracy: 0.88 - ETA: 0s - loss: 0.3062 - accuracy: 0.88 - ETA: 0s - loss: 0.3098 - accuracy: 0.88 - ETA: 0s - loss: 0.3141 - accuracy: 0.88 - ETA: 0s - loss: 0.3098 - accuracy: 0.88 - ETA: 0s - loss: 0.3041 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8837 - val_loss: 0.3613 - val_accuracy: 0.8535\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2445 - accuracy: 0.87 - ETA: 0s - loss: 0.2792 - accuracy: 0.89 - ETA: 0s - loss: 0.3049 - accuracy: 0.88 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - ETA: 0s - loss: 0.2985 - accuracy: 0.89 - ETA: 0s - loss: 0.3054 - accuracy: 0.88 - ETA: 0s - loss: 0.3051 - accuracy: 0.88 - ETA: 0s - loss: 0.3046 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8855 - val_loss: 0.3617 - val_accuracy: 0.8560\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.81 - ETA: 0s - loss: 0.2844 - accuracy: 0.89 - ETA: 0s - loss: 0.2813 - accuracy: 0.89 - ETA: 0s - loss: 0.2957 - accuracy: 0.89 - ETA: 0s - loss: 0.3066 - accuracy: 0.88 - ETA: 0s - loss: 0.3068 - accuracy: 0.88 - ETA: 0s - loss: 0.3060 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8858 - val_loss: 0.3609 - val_accuracy: 0.8540\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.93 - ETA: 0s - loss: 0.3298 - accuracy: 0.87 - ETA: 0s - loss: 0.3226 - accuracy: 0.87 - ETA: 0s - loss: 0.3034 - accuracy: 0.88 - ETA: 0s - loss: 0.3132 - accuracy: 0.88 - ETA: 0s - loss: 0.3090 - accuracy: 0.88 - ETA: 0s - loss: 0.3072 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8855 - val_loss: 0.3632 - val_accuracy: 0.8560\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.90 - ETA: 0s - loss: 0.2948 - accuracy: 0.88 - ETA: 0s - loss: 0.2956 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.89 - ETA: 0s - loss: 0.2963 - accuracy: 0.89 - ETA: 0s - loss: 0.2981 - accuracy: 0.88 - ETA: 0s - loss: 0.3010 - accuracy: 0.88 - ETA: 0s - loss: 0.3032 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8850 - val_loss: 0.3624 - val_accuracy: 0.8545\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.81 - ETA: 0s - loss: 0.2944 - accuracy: 0.89 - ETA: 0s - loss: 0.2858 - accuracy: 0.89 - ETA: 0s - loss: 0.2926 - accuracy: 0.88 - ETA: 0s - loss: 0.2951 - accuracy: 0.88 - ETA: 0s - loss: 0.2947 - accuracy: 0.88 - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - ETA: 0s - loss: 0.3011 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8862 - val_loss: 0.3620 - val_accuracy: 0.8545\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.93 - ETA: 0s - loss: 0.2923 - accuracy: 0.89 - ETA: 0s - loss: 0.2994 - accuracy: 0.88 - ETA: 0s - loss: 0.2895 - accuracy: 0.88 - ETA: 0s - loss: 0.2946 - accuracy: 0.88 - ETA: 0s - loss: 0.2956 - accuracy: 0.88 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8862 - val_loss: 0.3618 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.81 - ETA: 0s - loss: 0.3180 - accuracy: 0.88 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3122 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.88 - ETA: 0s - loss: 0.3061 - accuracy: 0.88 - ETA: 0s - loss: 0.3016 - accuracy: 0.88 - ETA: 0s - loss: 0.3012 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8868 - val_loss: 0.3630 - val_accuracy: 0.8560\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.90 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3190 - accuracy: 0.87 - ETA: 0s - loss: 0.3025 - accuracy: 0.88 - ETA: 0s - loss: 0.3043 - accuracy: 0.88 - ETA: 0s - loss: 0.3048 - accuracy: 0.88 - ETA: 0s - loss: 0.3039 - accuracy: 0.88 - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8862 - val_loss: 0.3653 - val_accuracy: 0.8560\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.88 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.2990 - accuracy: 0.88 - ETA: 0s - loss: 0.2988 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8873 - val_loss: 0.3695 - val_accuracy: 0.8535\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.81 - ETA: 0s - loss: 0.3222 - accuracy: 0.87 - ETA: 0s - loss: 0.2992 - accuracy: 0.88 - ETA: 0s - loss: 0.3100 - accuracy: 0.88 - ETA: 0s - loss: 0.3056 - accuracy: 0.88 - ETA: 0s - loss: 0.2997 - accuracy: 0.88 - ETA: 0s - loss: 0.3014 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8863 - val_loss: 0.3636 - val_accuracy: 0.8570\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.93 - ETA: 0s - loss: 0.2562 - accuracy: 0.91 - ETA: 0s - loss: 0.2886 - accuracy: 0.89 - ETA: 0s - loss: 0.2935 - accuracy: 0.88 - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - ETA: 0s - loss: 0.2937 - accuracy: 0.88 - ETA: 0s - loss: 0.2984 - accuracy: 0.88 - ETA: 0s - loss: 0.2994 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8877 - val_loss: 0.3654 - val_accuracy: 0.8565\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.90 - ETA: 0s - loss: 0.2747 - accuracy: 0.90 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - ETA: 0s - loss: 0.2950 - accuracy: 0.88 - ETA: 0s - loss: 0.2963 - accuracy: 0.88 - ETA: 0s - loss: 0.3011 - accuracy: 0.88 - ETA: 0s - loss: 0.2993 - accuracy: 0.88 - ETA: 0s - loss: 0.2986 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8873 - val_loss: 0.3640 - val_accuracy: 0.8545\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.93 - ETA: 0s - loss: 0.2910 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.89 - ETA: 0s - loss: 0.2804 - accuracy: 0.89 - ETA: 0s - loss: 0.2863 - accuracy: 0.89 - ETA: 0s - loss: 0.2889 - accuracy: 0.89 - ETA: 0s - loss: 0.2951 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8882 - val_loss: 0.3636 - val_accuracy: 0.8525\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.90 - ETA: 0s - loss: 0.3136 - accuracy: 0.85 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.2966 - accuracy: 0.88 - ETA: 0s - loss: 0.2929 - accuracy: 0.88 - ETA: 0s - loss: 0.2894 - accuracy: 0.89 - ETA: 0s - loss: 0.2957 - accuracy: 0.88 - ETA: 0s - loss: 0.2973 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8875 - val_loss: 0.3662 - val_accuracy: 0.8570\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.87 - ETA: 0s - loss: 0.2640 - accuracy: 0.90 - ETA: 0s - loss: 0.2798 - accuracy: 0.89 - ETA: 0s - loss: 0.2892 - accuracy: 0.89 - ETA: 0s - loss: 0.2952 - accuracy: 0.88 - ETA: 0s - loss: 0.2952 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8887 - val_loss: 0.3656 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.90 - ETA: 0s - loss: 0.2989 - accuracy: 0.89 - ETA: 0s - loss: 0.2991 - accuracy: 0.89 - ETA: 0s - loss: 0.2989 - accuracy: 0.89 - ETA: 0s - loss: 0.2949 - accuracy: 0.89 - ETA: 0s - loss: 0.2946 - accuracy: 0.89 - ETA: 0s - loss: 0.2950 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8887 - val_loss: 0.3669 - val_accuracy: 0.8540\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.93 - ETA: 0s - loss: 0.2894 - accuracy: 0.89 - ETA: 0s - loss: 0.2932 - accuracy: 0.89 - ETA: 0s - loss: 0.3011 - accuracy: 0.89 - ETA: 0s - loss: 0.3016 - accuracy: 0.88 - ETA: 0s - loss: 0.2995 - accuracy: 0.88 - ETA: 0s - loss: 0.2973 - accuracy: 0.88 - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - 1s 3ms/step - loss: 0.2958 - accuracy: 0.8898 - val_loss: 0.3657 - val_accuracy: 0.8560\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.81 - ETA: 0s - loss: 0.3175 - accuracy: 0.88 - ETA: 0s - loss: 0.3110 - accuracy: 0.88 - ETA: 0s - loss: 0.2999 - accuracy: 0.89 - ETA: 0s - loss: 0.2982 - accuracy: 0.88 - ETA: 0s - loss: 0.2995 - accuracy: 0.88 - ETA: 0s - loss: 0.2974 - accuracy: 0.89 - ETA: 0s - loss: 0.2949 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8898 - val_loss: 0.3661 - val_accuracy: 0.8530\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.87 - ETA: 0s - loss: 0.2728 - accuracy: 0.89 - ETA: 0s - loss: 0.2789 - accuracy: 0.89 - ETA: 0s - loss: 0.2899 - accuracy: 0.89 - ETA: 0s - loss: 0.2885 - accuracy: 0.89 - ETA: 0s - loss: 0.2878 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8908 - val_loss: 0.3655 - val_accuracy: 0.8555\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.93 - ETA: 0s - loss: 0.3063 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.88 - ETA: 0s - loss: 0.2984 - accuracy: 0.88 - ETA: 0s - loss: 0.3002 - accuracy: 0.88 - ETA: 0s - loss: 0.2953 - accuracy: 0.88 - ETA: 0s - loss: 0.2934 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8898 - val_loss: 0.3675 - val_accuracy: 0.8530\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.93 - ETA: 0s - loss: 0.3039 - accuracy: 0.88 - ETA: 0s - loss: 0.2931 - accuracy: 0.89 - ETA: 0s - loss: 0.2973 - accuracy: 0.88 - ETA: 0s - loss: 0.2913 - accuracy: 0.89 - ETA: 0s - loss: 0.2937 - accuracy: 0.88 - ETA: 0s - loss: 0.2961 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8903 - val_loss: 0.3660 - val_accuracy: 0.8550\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.90 - ETA: 0s - loss: 0.2911 - accuracy: 0.89 - ETA: 0s - loss: 0.2950 - accuracy: 0.89 - ETA: 0s - loss: 0.2928 - accuracy: 0.89 - ETA: 0s - loss: 0.2906 - accuracy: 0.89 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - ETA: 0s - loss: 0.2919 - accuracy: 0.89 - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8905 - val_loss: 0.3680 - val_accuracy: 0.8540\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.93 - ETA: 0s - loss: 0.2903 - accuracy: 0.89 - ETA: 0s - loss: 0.2731 - accuracy: 0.90 - ETA: 0s - loss: 0.2914 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.89 - ETA: 0s - loss: 0.2966 - accuracy: 0.88 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8903 - val_loss: 0.3705 - val_accuracy: 0.8535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: f58c0ba474ca7d7f7499a8aaef386a8f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8575000166893005</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.9584 - accuracy: 0.09 - ETA: 0s - loss: 0.8277 - accuracy: 0.21 - ETA: 0s - loss: 0.7985 - accuracy: 0.24 - ETA: 0s - loss: 0.7799 - accuracy: 0.28 - 0s 2ms/step - loss: 0.7725 - accuracy: 0.3117 - val_loss: 0.7103 - val_accuracy: 0.5320\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.65 - ETA: 0s - loss: 0.6943 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.61 - ETA: 0s - loss: 0.6719 - accuracy: 0.65 - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6625 - val_loss: 0.6233 - val_accuracy: 0.7440\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.75 - ETA: 0s - loss: 0.6168 - accuracy: 0.73 - ETA: 0s - loss: 0.6100 - accuracy: 0.74 - ETA: 0s - loss: 0.6000 - accuracy: 0.75 - 0s 1ms/step - loss: 0.5933 - accuracy: 0.7633 - val_loss: 0.5618 - val_accuracy: 0.7895\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.75 - ETA: 0s - loss: 0.5631 - accuracy: 0.78 - ETA: 0s - loss: 0.5610 - accuracy: 0.78 - ETA: 0s - loss: 0.5501 - accuracy: 0.79 - ETA: 0s - loss: 0.5474 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7902 - val_loss: 0.5263 - val_accuracy: 0.7985\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.65 - ETA: 0s - loss: 0.5365 - accuracy: 0.78 - ETA: 0s - loss: 0.5266 - accuracy: 0.79 - ETA: 0s - loss: 0.5203 - accuracy: 0.79 - ETA: 0s - loss: 0.5214 - accuracy: 0.79 - ETA: 0s - loss: 0.5219 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7950 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.59 - ETA: 0s - loss: 0.5426 - accuracy: 0.76 - ETA: 0s - loss: 0.5280 - accuracy: 0.77 - ETA: 0s - loss: 0.5100 - accuracy: 0.79 - ETA: 0s - loss: 0.5069 - accuracy: 0.79 - ETA: 0s - loss: 0.5082 - accuracy: 0.79 - ETA: 0s - loss: 0.5078 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7950 - val_loss: 0.4953 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.75 - ETA: 0s - loss: 0.4933 - accuracy: 0.79 - ETA: 0s - loss: 0.4951 - accuracy: 0.79 - ETA: 0s - loss: 0.5028 - accuracy: 0.78 - ETA: 0s - loss: 0.4932 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7950 - val_loss: 0.4870 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.78 - ETA: 0s - loss: 0.5051 - accuracy: 0.77 - ETA: 0s - loss: 0.4875 - accuracy: 0.79 - ETA: 0s - loss: 0.4858 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7948 - val_loss: 0.4805 - val_accuracy: 0.7985\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.84 - ETA: 0s - loss: 0.4887 - accuracy: 0.78 - ETA: 0s - loss: 0.4828 - accuracy: 0.79 - ETA: 0s - loss: 0.4754 - accuracy: 0.79 - ETA: 0s - loss: 0.4731 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7953 - val_loss: 0.4750 - val_accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.78 - ETA: 0s - loss: 0.4712 - accuracy: 0.79 - ETA: 0s - loss: 0.4713 - accuracy: 0.79 - ETA: 0s - loss: 0.4651 - accuracy: 0.80 - ETA: 0s - loss: 0.4679 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7958 - val_loss: 0.4702 - val_accuracy: 0.8010\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.81 - ETA: 0s - loss: 0.4863 - accuracy: 0.79 - ETA: 0s - loss: 0.4728 - accuracy: 0.79 - ETA: 0s - loss: 0.4747 - accuracy: 0.78 - ETA: 0s - loss: 0.4642 - accuracy: 0.79 - ETA: 0s - loss: 0.4656 - accuracy: 0.79 - ETA: 0s - loss: 0.4639 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7965 - val_loss: 0.4659 - val_accuracy: 0.7980\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.81 - ETA: 0s - loss: 0.4682 - accuracy: 0.79 - ETA: 0s - loss: 0.4568 - accuracy: 0.79 - ETA: 0s - loss: 0.4667 - accuracy: 0.79 - ETA: 0s - loss: 0.4647 - accuracy: 0.79 - ETA: 0s - loss: 0.4636 - accuracy: 0.79 - ETA: 0s - loss: 0.4583 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7973 - val_loss: 0.4621 - val_accuracy: 0.7980\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.90 - ETA: 0s - loss: 0.4739 - accuracy: 0.79 - ETA: 0s - loss: 0.4598 - accuracy: 0.79 - ETA: 0s - loss: 0.4664 - accuracy: 0.78 - ETA: 0s - loss: 0.4620 - accuracy: 0.79 - ETA: 0s - loss: 0.4556 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7972 - val_loss: 0.4587 - val_accuracy: 0.7990\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.81 - ETA: 0s - loss: 0.4572 - accuracy: 0.79 - ETA: 0s - loss: 0.4559 - accuracy: 0.80 - ETA: 0s - loss: 0.4546 - accuracy: 0.79 - ETA: 0s - loss: 0.4504 - accuracy: 0.79 - ETA: 0s - loss: 0.4474 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7977 - val_loss: 0.4555 - val_accuracy: 0.7990\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.81 - ETA: 0s - loss: 0.4286 - accuracy: 0.81 - ETA: 0s - loss: 0.4418 - accuracy: 0.80 - ETA: 0s - loss: 0.4403 - accuracy: 0.80 - ETA: 0s - loss: 0.4459 - accuracy: 0.80 - ETA: 0s - loss: 0.4411 - accuracy: 0.80 - ETA: 0s - loss: 0.4444 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7990 - val_loss: 0.4525 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.87 - ETA: 0s - loss: 0.4176 - accuracy: 0.82 - ETA: 0s - loss: 0.4435 - accuracy: 0.80 - ETA: 0s - loss: 0.4436 - accuracy: 0.80 - ETA: 0s - loss: 0.4535 - accuracy: 0.79 - ETA: 0s - loss: 0.4454 - accuracy: 0.80 - ETA: 0s - loss: 0.4428 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8003 - val_loss: 0.4496 - val_accuracy: 0.8015\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.75 - ETA: 0s - loss: 0.4279 - accuracy: 0.80 - ETA: 0s - loss: 0.4334 - accuracy: 0.80 - ETA: 0s - loss: 0.4270 - accuracy: 0.80 - ETA: 0s - loss: 0.4345 - accuracy: 0.79 - ETA: 0s - loss: 0.4330 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8007 - val_loss: 0.4471 - val_accuracy: 0.8030\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.75 - ETA: 0s - loss: 0.4461 - accuracy: 0.79 - ETA: 0s - loss: 0.4334 - accuracy: 0.80 - ETA: 0s - loss: 0.4371 - accuracy: 0.79 - ETA: 0s - loss: 0.4347 - accuracy: 0.79 - ETA: 0s - loss: 0.4359 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8005 - val_loss: 0.4448 - val_accuracy: 0.8035\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.75 - ETA: 0s - loss: 0.4192 - accuracy: 0.81 - ETA: 0s - loss: 0.4193 - accuracy: 0.80 - ETA: 0s - loss: 0.4273 - accuracy: 0.80 - ETA: 0s - loss: 0.4310 - accuracy: 0.80 - ETA: 0s - loss: 0.4283 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8027 - val_loss: 0.4428 - val_accuracy: 0.8045\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.90 - ETA: 0s - loss: 0.4134 - accuracy: 0.82 - ETA: 0s - loss: 0.4356 - accuracy: 0.81 - ETA: 0s - loss: 0.4364 - accuracy: 0.80 - ETA: 0s - loss: 0.4341 - accuracy: 0.80 - ETA: 0s - loss: 0.4245 - accuracy: 0.80 - ETA: 0s - loss: 0.4263 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8043 - val_loss: 0.4410 - val_accuracy: 0.8075\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.84 - ETA: 0s - loss: 0.4046 - accuracy: 0.82 - ETA: 0s - loss: 0.4185 - accuracy: 0.81 - ETA: 0s - loss: 0.4250 - accuracy: 0.80 - ETA: 0s - loss: 0.4275 - accuracy: 0.80 - ETA: 0s - loss: 0.4261 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8063 - val_loss: 0.4392 - val_accuracy: 0.8085\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.84 - ETA: 0s - loss: 0.4268 - accuracy: 0.80 - ETA: 0s - loss: 0.4258 - accuracy: 0.80 - ETA: 0s - loss: 0.4222 - accuracy: 0.80 - ETA: 0s - loss: 0.4247 - accuracy: 0.80 - ETA: 0s - loss: 0.4222 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8078 - val_loss: 0.4376 - val_accuracy: 0.8105\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.87 - ETA: 0s - loss: 0.4416 - accuracy: 0.79 - ETA: 0s - loss: 0.4256 - accuracy: 0.80 - ETA: 0s - loss: 0.4259 - accuracy: 0.80 - ETA: 0s - loss: 0.4240 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8083 - val_loss: 0.4362 - val_accuracy: 0.8100\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.78 - ETA: 0s - loss: 0.4509 - accuracy: 0.79 - ETA: 0s - loss: 0.4330 - accuracy: 0.80 - ETA: 0s - loss: 0.4176 - accuracy: 0.80 - ETA: 0s - loss: 0.4171 - accuracy: 0.81 - ETA: 0s - loss: 0.4200 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8095 - val_loss: 0.4350 - val_accuracy: 0.8095\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.81 - ETA: 0s - loss: 0.4265 - accuracy: 0.81 - ETA: 0s - loss: 0.4273 - accuracy: 0.80 - ETA: 0s - loss: 0.4198 - accuracy: 0.81 - ETA: 0s - loss: 0.4200 - accuracy: 0.80 - ETA: 0s - loss: 0.4183 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8103 - val_loss: 0.4338 - val_accuracy: 0.8080\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4031 - accuracy: 0.81 - ETA: 0s - loss: 0.4264 - accuracy: 0.80 - ETA: 0s - loss: 0.4168 - accuracy: 0.80 - ETA: 0s - loss: 0.4192 - accuracy: 0.80 - ETA: 0s - loss: 0.4162 - accuracy: 0.80 - ETA: 0s - loss: 0.4165 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8108 - val_loss: 0.4326 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.81 - ETA: 0s - loss: 0.4317 - accuracy: 0.79 - ETA: 0s - loss: 0.4235 - accuracy: 0.80 - ETA: 0s - loss: 0.4257 - accuracy: 0.80 - ETA: 0s - loss: 0.4250 - accuracy: 0.80 - ETA: 0s - loss: 0.4154 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8147 - val_loss: 0.4317 - val_accuracy: 0.8060\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.84 - ETA: 0s - loss: 0.4078 - accuracy: 0.82 - ETA: 0s - loss: 0.4091 - accuracy: 0.81 - ETA: 0s - loss: 0.4131 - accuracy: 0.81 - ETA: 0s - loss: 0.4084 - accuracy: 0.81 - ETA: 0s - loss: 0.4108 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8150 - val_loss: 0.4304 - val_accuracy: 0.8075\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.75 - ETA: 0s - loss: 0.4278 - accuracy: 0.80 - ETA: 0s - loss: 0.4149 - accuracy: 0.81 - ETA: 0s - loss: 0.4168 - accuracy: 0.81 - ETA: 0s - loss: 0.4078 - accuracy: 0.81 - ETA: 0s - loss: 0.4078 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8178 - val_loss: 0.4291 - val_accuracy: 0.8075\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.81 - ETA: 0s - loss: 0.4079 - accuracy: 0.81 - ETA: 0s - loss: 0.4102 - accuracy: 0.81 - ETA: 0s - loss: 0.4079 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8182 - val_loss: 0.4281 - val_accuracy: 0.8095\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.90 - ETA: 0s - loss: 0.3990 - accuracy: 0.82 - ETA: 0s - loss: 0.3988 - accuracy: 0.82 - ETA: 0s - loss: 0.4066 - accuracy: 0.81 - ETA: 0s - loss: 0.4048 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8192 - val_loss: 0.4269 - val_accuracy: 0.8100\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.81 - ETA: 0s - loss: 0.3954 - accuracy: 0.82 - ETA: 0s - loss: 0.3990 - accuracy: 0.81 - ETA: 0s - loss: 0.4072 - accuracy: 0.81 - ETA: 0s - loss: 0.4055 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8187 - val_loss: 0.4258 - val_accuracy: 0.8105\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.87 - ETA: 0s - loss: 0.3961 - accuracy: 0.82 - ETA: 0s - loss: 0.3904 - accuracy: 0.82 - ETA: 0s - loss: 0.3966 - accuracy: 0.82 - ETA: 0s - loss: 0.4009 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8203 - val_loss: 0.4245 - val_accuracy: 0.8105\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.93 - ETA: 0s - loss: 0.4129 - accuracy: 0.81 - ETA: 0s - loss: 0.4101 - accuracy: 0.82 - ETA: 0s - loss: 0.4013 - accuracy: 0.82 - ETA: 0s - loss: 0.4074 - accuracy: 0.82 - ETA: 0s - loss: 0.4015 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8225 - val_loss: 0.4233 - val_accuracy: 0.8115\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.87 - ETA: 0s - loss: 0.3924 - accuracy: 0.82 - ETA: 0s - loss: 0.3967 - accuracy: 0.82 - ETA: 0s - loss: 0.3974 - accuracy: 0.82 - ETA: 0s - loss: 0.4006 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8225 - val_loss: 0.4221 - val_accuracy: 0.8115\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.87 - ETA: 0s - loss: 0.3936 - accuracy: 0.83 - ETA: 0s - loss: 0.3966 - accuracy: 0.82 - ETA: 0s - loss: 0.3969 - accuracy: 0.82 - ETA: 0s - loss: 0.3970 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8233 - val_loss: 0.4210 - val_accuracy: 0.8110\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.87 - ETA: 0s - loss: 0.3852 - accuracy: 0.83 - ETA: 0s - loss: 0.3953 - accuracy: 0.82 - ETA: 0s - loss: 0.3938 - accuracy: 0.82 - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8243 - val_loss: 0.4196 - val_accuracy: 0.8110\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.87 - ETA: 0s - loss: 0.4121 - accuracy: 0.81 - ETA: 0s - loss: 0.4013 - accuracy: 0.81 - ETA: 0s - loss: 0.3915 - accuracy: 0.82 - ETA: 0s - loss: 0.3904 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8255 - val_loss: 0.4183 - val_accuracy: 0.8100\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.81 - ETA: 0s - loss: 0.4155 - accuracy: 0.82 - ETA: 0s - loss: 0.4042 - accuracy: 0.82 - ETA: 0s - loss: 0.3915 - accuracy: 0.82 - ETA: 0s - loss: 0.3877 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8280 - val_loss: 0.4172 - val_accuracy: 0.8105\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.87 - ETA: 0s - loss: 0.3743 - accuracy: 0.84 - ETA: 0s - loss: 0.3841 - accuracy: 0.83 - ETA: 0s - loss: 0.3990 - accuracy: 0.82 - ETA: 0s - loss: 0.3868 - accuracy: 0.83 - ETA: 0s - loss: 0.3927 - accuracy: 0.82 - ETA: 0s - loss: 0.3915 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8293 - val_loss: 0.4156 - val_accuracy: 0.8110\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.87 - ETA: 0s - loss: 0.3872 - accuracy: 0.83 - ETA: 0s - loss: 0.3872 - accuracy: 0.83 - ETA: 0s - loss: 0.3923 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8310 - val_loss: 0.4143 - val_accuracy: 0.8120\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.84 - ETA: 0s - loss: 0.3729 - accuracy: 0.84 - ETA: 0s - loss: 0.3770 - accuracy: 0.83 - ETA: 0s - loss: 0.3832 - accuracy: 0.83 - ETA: 0s - loss: 0.3839 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8307 - val_loss: 0.4127 - val_accuracy: 0.8130\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.81 - ETA: 0s - loss: 0.4107 - accuracy: 0.82 - ETA: 0s - loss: 0.3940 - accuracy: 0.83 - ETA: 0s - loss: 0.3832 - accuracy: 0.83 - ETA: 0s - loss: 0.3897 - accuracy: 0.83 - ETA: 0s - loss: 0.3880 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8332 - val_loss: 0.4114 - val_accuracy: 0.8150\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.84 - ETA: 0s - loss: 0.3889 - accuracy: 0.82 - ETA: 0s - loss: 0.3845 - accuracy: 0.83 - ETA: 0s - loss: 0.3825 - accuracy: 0.83 - ETA: 0s - loss: 0.3845 - accuracy: 0.83 - ETA: 0s - loss: 0.3859 - accuracy: 0.83 - ETA: 0s - loss: 0.3858 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8338 - val_loss: 0.4099 - val_accuracy: 0.8140\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3962 - accuracy: 0.84 - ETA: 0s - loss: 0.3627 - accuracy: 0.85 - ETA: 0s - loss: 0.3812 - accuracy: 0.83 - ETA: 0s - loss: 0.3798 - accuracy: 0.83 - ETA: 0s - loss: 0.3824 - accuracy: 0.83 - ETA: 0s - loss: 0.3837 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8362 - val_loss: 0.4086 - val_accuracy: 0.8160\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.87 - ETA: 0s - loss: 0.3690 - accuracy: 0.84 - ETA: 0s - loss: 0.3725 - accuracy: 0.84 - ETA: 0s - loss: 0.3752 - accuracy: 0.84 - ETA: 0s - loss: 0.3796 - accuracy: 0.83 - ETA: 0s - loss: 0.3745 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8375 - val_loss: 0.4068 - val_accuracy: 0.8170\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.93 - ETA: 0s - loss: 0.3835 - accuracy: 0.83 - ETA: 0s - loss: 0.3748 - accuracy: 0.84 - ETA: 0s - loss: 0.3757 - accuracy: 0.84 - ETA: 0s - loss: 0.3845 - accuracy: 0.83 - ETA: 0s - loss: 0.3811 - accuracy: 0.83 - ETA: 0s - loss: 0.3799 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8382 - val_loss: 0.4052 - val_accuracy: 0.8175\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.81 - ETA: 0s - loss: 0.3661 - accuracy: 0.85 - ETA: 0s - loss: 0.3778 - accuracy: 0.83 - ETA: 0s - loss: 0.3802 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8398 - val_loss: 0.4038 - val_accuracy: 0.8170\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.84 - ETA: 0s - loss: 0.3779 - accuracy: 0.83 - ETA: 0s - loss: 0.3844 - accuracy: 0.83 - ETA: 0s - loss: 0.3801 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8405 - val_loss: 0.4025 - val_accuracy: 0.8200\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.93 - ETA: 0s - loss: 0.3773 - accuracy: 0.83 - ETA: 0s - loss: 0.3636 - accuracy: 0.84 - ETA: 0s - loss: 0.3724 - accuracy: 0.84 - ETA: 0s - loss: 0.3752 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8398 - val_loss: 0.4005 - val_accuracy: 0.8210\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.87 - ETA: 0s - loss: 0.3402 - accuracy: 0.85 - ETA: 0s - loss: 0.3677 - accuracy: 0.84 - ETA: 0s - loss: 0.3672 - accuracy: 0.84 - ETA: 0s - loss: 0.3715 - accuracy: 0.84 - ETA: 0s - loss: 0.3694 - accuracy: 0.84 - ETA: 0s - loss: 0.3722 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3730 - accuracy: 0.8420 - val_loss: 0.3989 - val_accuracy: 0.8230\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.90 - ETA: 0s - loss: 0.3603 - accuracy: 0.84 - ETA: 0s - loss: 0.3751 - accuracy: 0.83 - ETA: 0s - loss: 0.3782 - accuracy: 0.83 - ETA: 0s - loss: 0.3748 - accuracy: 0.84 - ETA: 0s - loss: 0.3707 - accuracy: 0.84 - ETA: 0s - loss: 0.3723 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8430 - val_loss: 0.3975 - val_accuracy: 0.8240\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.93 - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - ETA: 0s - loss: 0.3758 - accuracy: 0.84 - ETA: 0s - loss: 0.3754 - accuracy: 0.84 - ETA: 0s - loss: 0.3730 - accuracy: 0.84 - ETA: 0s - loss: 0.3716 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8438 - val_loss: 0.3961 - val_accuracy: 0.8260\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.78 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3682 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8443 - val_loss: 0.3944 - val_accuracy: 0.8275\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.81 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3656 - accuracy: 0.84 - ETA: 0s - loss: 0.3636 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8448 - val_loss: 0.3928 - val_accuracy: 0.8285\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.84 - ETA: 0s - loss: 0.3712 - accuracy: 0.84 - ETA: 0s - loss: 0.3671 - accuracy: 0.84 - ETA: 0s - loss: 0.3650 - accuracy: 0.84 - ETA: 0s - loss: 0.3686 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8467 - val_loss: 0.3918 - val_accuracy: 0.8300\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.93 - ETA: 0s - loss: 0.3446 - accuracy: 0.86 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.84 - ETA: 0s - loss: 0.3565 - accuracy: 0.85 - ETA: 0s - loss: 0.3625 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8467 - val_loss: 0.3901 - val_accuracy: 0.8305\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.75 - ETA: 0s - loss: 0.3957 - accuracy: 0.83 - ETA: 0s - loss: 0.3831 - accuracy: 0.84 - ETA: 0s - loss: 0.3639 - accuracy: 0.85 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3643 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8488 - val_loss: 0.3890 - val_accuracy: 0.8325\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.84 - ETA: 0s - loss: 0.3655 - accuracy: 0.85 - ETA: 0s - loss: 0.3632 - accuracy: 0.84 - ETA: 0s - loss: 0.3591 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8478 - val_loss: 0.3878 - val_accuracy: 0.8320\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.90 - ETA: 0s - loss: 0.3636 - accuracy: 0.84 - ETA: 0s - loss: 0.3637 - accuracy: 0.84 - ETA: 0s - loss: 0.3613 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8487 - val_loss: 0.3865 - val_accuracy: 0.8335\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.78 - ETA: 0s - loss: 0.3522 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8497 - val_loss: 0.3852 - val_accuracy: 0.8325\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.81 - ETA: 0s - loss: 0.3845 - accuracy: 0.82 - ETA: 0s - loss: 0.3725 - accuracy: 0.83 - ETA: 0s - loss: 0.3624 - accuracy: 0.84 - ETA: 0s - loss: 0.3562 - accuracy: 0.84 - ETA: 0s - loss: 0.3578 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8492 - val_loss: 0.3845 - val_accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.93 - ETA: 0s - loss: 0.3583 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3584 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8500 - val_loss: 0.3831 - val_accuracy: 0.8355\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.84 - ETA: 0s - loss: 0.3657 - accuracy: 0.84 - ETA: 0s - loss: 0.3604 - accuracy: 0.85 - ETA: 0s - loss: 0.3576 - accuracy: 0.84 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8497 - val_loss: 0.3823 - val_accuracy: 0.8360\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.71 - ETA: 0s - loss: 0.3458 - accuracy: 0.85 - ETA: 0s - loss: 0.3515 - accuracy: 0.84 - ETA: 0s - loss: 0.3503 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8507 - val_loss: 0.3813 - val_accuracy: 0.8360\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.78 - ETA: 0s - loss: 0.3492 - accuracy: 0.85 - ETA: 0s - loss: 0.3579 - accuracy: 0.84 - ETA: 0s - loss: 0.3557 - accuracy: 0.84 - ETA: 0s - loss: 0.3547 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8517 - val_loss: 0.3803 - val_accuracy: 0.8375\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.81 - ETA: 0s - loss: 0.3557 - accuracy: 0.84 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8522 - val_loss: 0.3798 - val_accuracy: 0.8385\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.84 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8520 - val_loss: 0.3787 - val_accuracy: 0.8405\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.87 - ETA: 0s - loss: 0.3554 - accuracy: 0.83 - ETA: 0s - loss: 0.3559 - accuracy: 0.84 - ETA: 0s - loss: 0.3535 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8530 - val_loss: 0.3783 - val_accuracy: 0.8410\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.78 - ETA: 0s - loss: 0.3382 - accuracy: 0.85 - ETA: 0s - loss: 0.3533 - accuracy: 0.84 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8523 - val_loss: 0.3775 - val_accuracy: 0.8410\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - ETA: 0s - loss: 0.3569 - accuracy: 0.84 - ETA: 0s - loss: 0.3498 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8527 - val_loss: 0.3771 - val_accuracy: 0.8415\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.87 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - ETA: 0s - loss: 0.3508 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8537 - val_loss: 0.3762 - val_accuracy: 0.8415\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.87 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8533 - val_loss: 0.3758 - val_accuracy: 0.8410\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.90 - ETA: 0s - loss: 0.3243 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8538 - val_loss: 0.3750 - val_accuracy: 0.8430\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.84 - ETA: 0s - loss: 0.3548 - accuracy: 0.84 - ETA: 0s - loss: 0.3636 - accuracy: 0.84 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3510 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8550 - val_loss: 0.3750 - val_accuracy: 0.8420\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.93 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3445 - accuracy: 0.85 - ETA: 0s - loss: 0.3420 - accuracy: 0.85 - ETA: 0s - loss: 0.3457 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8543 - val_loss: 0.3742 - val_accuracy: 0.8425\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.90 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - ETA: 0s - loss: 0.3362 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.85 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3443 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8552 - val_loss: 0.3735 - val_accuracy: 0.8420\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.84 - ETA: 0s - loss: 0.3565 - accuracy: 0.84 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3466 - accuracy: 0.85 - ETA: 0s - loss: 0.3498 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8552 - val_loss: 0.3735 - val_accuracy: 0.8435\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.84 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3372 - accuracy: 0.85 - ETA: 0s - loss: 0.3352 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.85 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8558 - val_loss: 0.3729 - val_accuracy: 0.8425\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.84 - ETA: 0s - loss: 0.3467 - accuracy: 0.84 - ETA: 0s - loss: 0.3364 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8550 - val_loss: 0.3726 - val_accuracy: 0.8435\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.90 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3375 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3416 - accuracy: 0.85 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8553 - val_loss: 0.3722 - val_accuracy: 0.8455\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.84 - ETA: 0s - loss: 0.3698 - accuracy: 0.83 - ETA: 0s - loss: 0.3558 - accuracy: 0.84 - ETA: 0s - loss: 0.3499 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8543 - val_loss: 0.3719 - val_accuracy: 0.8450\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.93 - ETA: 0s - loss: 0.3702 - accuracy: 0.83 - ETA: 0s - loss: 0.3505 - accuracy: 0.84 - ETA: 0s - loss: 0.3458 - accuracy: 0.84 - ETA: 0s - loss: 0.3502 - accuracy: 0.84 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8555 - val_loss: 0.3723 - val_accuracy: 0.8445\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.84 - ETA: 0s - loss: 0.3427 - accuracy: 0.84 - ETA: 0s - loss: 0.3588 - accuracy: 0.84 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3418 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8563 - val_loss: 0.3716 - val_accuracy: 0.8455\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.71 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3403 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8558 - val_loss: 0.3714 - val_accuracy: 0.8450\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.84 - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - ETA: 0s - loss: 0.3374 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3446 - accuracy: 0.85 - ETA: 0s - loss: 0.3442 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8565 - val_loss: 0.3711 - val_accuracy: 0.8450\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.90 - ETA: 0s - loss: 0.3485 - accuracy: 0.84 - ETA: 0s - loss: 0.3402 - accuracy: 0.85 - ETA: 0s - loss: 0.3461 - accuracy: 0.85 - ETA: 0s - loss: 0.3368 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8558 - val_loss: 0.3710 - val_accuracy: 0.8465\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.93 - ETA: 0s - loss: 0.3176 - accuracy: 0.85 - ETA: 0s - loss: 0.3264 - accuracy: 0.85 - ETA: 0s - loss: 0.3354 - accuracy: 0.85 - ETA: 0s - loss: 0.3375 - accuracy: 0.85 - ETA: 0s - loss: 0.3370 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8572 - val_loss: 0.3707 - val_accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.84 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3557 - accuracy: 0.84 - ETA: 0s - loss: 0.3471 - accuracy: 0.84 - ETA: 0s - loss: 0.3482 - accuracy: 0.84 - ETA: 0s - loss: 0.3439 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8558 - val_loss: 0.3705 - val_accuracy: 0.8475\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.87 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - ETA: 0s - loss: 0.3336 - accuracy: 0.85 - ETA: 0s - loss: 0.3420 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.85 - ETA: 0s - loss: 0.3380 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8573 - val_loss: 0.3706 - val_accuracy: 0.8470\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.87 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8593 - val_loss: 0.3703 - val_accuracy: 0.8485\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.90 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3403 - accuracy: 0.85 - ETA: 0s - loss: 0.3384 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.85 - ETA: 0s - loss: 0.3378 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8570 - val_loss: 0.3700 - val_accuracy: 0.8480\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.75 - ETA: 0s - loss: 0.3433 - accuracy: 0.86 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3446 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3392 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8580 - val_loss: 0.3701 - val_accuracy: 0.8475\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.84 - ETA: 0s - loss: 0.3578 - accuracy: 0.84 - ETA: 0s - loss: 0.3472 - accuracy: 0.84 - ETA: 0s - loss: 0.3387 - accuracy: 0.85 - ETA: 0s - loss: 0.3370 - accuracy: 0.85 - ETA: 0s - loss: 0.3389 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8583 - val_loss: 0.3695 - val_accuracy: 0.8490\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.84 - ETA: 0s - loss: 0.3588 - accuracy: 0.84 - ETA: 0s - loss: 0.3389 - accuracy: 0.85 - ETA: 0s - loss: 0.3358 - accuracy: 0.85 - ETA: 0s - loss: 0.3400 - accuracy: 0.85 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8597 - val_loss: 0.3694 - val_accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.2908 - accuracy: 0.90 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8587 - val_loss: 0.3691 - val_accuracy: 0.8505\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.81 - ETA: 0s - loss: 0.3446 - accuracy: 0.85 - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - ETA: 0s - loss: 0.3380 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8598 - val_loss: 0.3692 - val_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.78 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8593 - val_loss: 0.3686 - val_accuracy: 0.8505\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.81 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8600 - val_loss: 0.3684 - val_accuracy: 0.8515\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.90 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8600 - val_loss: 0.3683 - val_accuracy: 0.8505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a1e7923290557a0fc91a6bb0a173c950</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8514999747276306</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6861 - accuracy: 0.87 - ETA: 0s - loss: 0.6784 - accuracy: 0.79 - ETA: 0s - loss: 0.6651 - accuracy: 0.79 - ETA: 0s - loss: 0.6506 - accuracy: 0.79 - 1s 3ms/step - loss: 0.6327 - accuracy: 0.7948 - val_loss: 0.5559 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.93 - ETA: 0s - loss: 0.5450 - accuracy: 0.79 - ETA: 0s - loss: 0.5452 - accuracy: 0.78 - ETA: 0s - loss: 0.5311 - accuracy: 0.79 - ETA: 0s - loss: 0.5215 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7948 - val_loss: 0.5045 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.84 - ETA: 0s - loss: 0.4834 - accuracy: 0.81 - ETA: 0s - loss: 0.5024 - accuracy: 0.79 - ETA: 0s - loss: 0.5011 - accuracy: 0.79 - ETA: 0s - loss: 0.4994 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7948 - val_loss: 0.4937 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.75 - ETA: 0s - loss: 0.5117 - accuracy: 0.77 - ETA: 0s - loss: 0.4985 - accuracy: 0.78 - ETA: 0s - loss: 0.4916 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7948 - val_loss: 0.4853 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.84 - ETA: 0s - loss: 0.5022 - accuracy: 0.78 - ETA: 0s - loss: 0.4748 - accuracy: 0.79 - ETA: 0s - loss: 0.4754 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7948 - val_loss: 0.4768 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.81 - ETA: 0s - loss: 0.4804 - accuracy: 0.78 - ETA: 0s - loss: 0.4700 - accuracy: 0.79 - ETA: 0s - loss: 0.4677 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7948 - val_loss: 0.4687 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.71 - ETA: 0s - loss: 0.4488 - accuracy: 0.80 - ETA: 0s - loss: 0.4488 - accuracy: 0.80 - ETA: 0s - loss: 0.4540 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7948 - val_loss: 0.4595 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.62 - ETA: 0s - loss: 0.4497 - accuracy: 0.79 - ETA: 0s - loss: 0.4461 - accuracy: 0.79 - ETA: 0s - loss: 0.4488 - accuracy: 0.79 - ETA: 0s - loss: 0.4475 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7983 - val_loss: 0.4538 - val_accuracy: 0.8035\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.78 - ETA: 0s - loss: 0.4232 - accuracy: 0.81 - ETA: 0s - loss: 0.4283 - accuracy: 0.81 - ETA: 0s - loss: 0.4295 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8107 - val_loss: 0.4512 - val_accuracy: 0.8075\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.62 - ETA: 0s - loss: 0.4575 - accuracy: 0.80 - ETA: 0s - loss: 0.4527 - accuracy: 0.80 - ETA: 0s - loss: 0.4417 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8138 - val_loss: 0.4474 - val_accuracy: 0.8095\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.75 - ETA: 0s - loss: 0.4368 - accuracy: 0.81 - ETA: 0s - loss: 0.4343 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8135 - val_loss: 0.4447 - val_accuracy: 0.8080\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2570 - accuracy: 0.90 - ETA: 0s - loss: 0.4349 - accuracy: 0.81 - ETA: 0s - loss: 0.4360 - accuracy: 0.80 - ETA: 0s - loss: 0.4278 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8153 - val_loss: 0.4425 - val_accuracy: 0.8095\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.87 - ETA: 0s - loss: 0.4101 - accuracy: 0.83 - ETA: 0s - loss: 0.4127 - accuracy: 0.82 - ETA: 0s - loss: 0.4226 - accuracy: 0.82 - ETA: 0s - loss: 0.4271 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8198 - val_loss: 0.4399 - val_accuracy: 0.8105\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.84 - ETA: 0s - loss: 0.4120 - accuracy: 0.82 - ETA: 0s - loss: 0.4168 - accuracy: 0.82 - ETA: 0s - loss: 0.4225 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8220 - val_loss: 0.4377 - val_accuracy: 0.8110\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.78 - ETA: 0s - loss: 0.4331 - accuracy: 0.82 - ETA: 0s - loss: 0.4222 - accuracy: 0.82 - ETA: 0s - loss: 0.4213 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8230 - val_loss: 0.4368 - val_accuracy: 0.8115\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4719 - accuracy: 0.75 - ETA: 0s - loss: 0.4156 - accuracy: 0.83 - ETA: 0s - loss: 0.4100 - accuracy: 0.83 - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8248 - val_loss: 0.4340 - val_accuracy: 0.8130\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.84 - ETA: 0s - loss: 0.4268 - accuracy: 0.82 - ETA: 0s - loss: 0.4219 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8255 - val_loss: 0.4321 - val_accuracy: 0.8130\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.84 - ETA: 0s - loss: 0.4100 - accuracy: 0.82 - ETA: 0s - loss: 0.4110 - accuracy: 0.83 - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8302 - val_loss: 0.4297 - val_accuracy: 0.8170\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4772 - accuracy: 0.75 - ETA: 0s - loss: 0.4090 - accuracy: 0.83 - ETA: 0s - loss: 0.4033 - accuracy: 0.83 - ETA: 0s - loss: 0.4043 - accuracy: 0.83 - ETA: 0s - loss: 0.4107 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8302 - val_loss: 0.4275 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.84 - ETA: 0s - loss: 0.4012 - accuracy: 0.82 - ETA: 0s - loss: 0.4024 - accuracy: 0.83 - ETA: 0s - loss: 0.4047 - accuracy: 0.83 - ETA: 0s - loss: 0.4076 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8320 - val_loss: 0.4266 - val_accuracy: 0.8165\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.90 - ETA: 0s - loss: 0.4194 - accuracy: 0.82 - ETA: 0s - loss: 0.4065 - accuracy: 0.83 - ETA: 0s - loss: 0.4059 - accuracy: 0.83 - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8317 - val_loss: 0.4248 - val_accuracy: 0.8200\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.81 - ETA: 0s - loss: 0.3944 - accuracy: 0.84 - ETA: 0s - loss: 0.3980 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8358 - val_loss: 0.4224 - val_accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.84 - ETA: 0s - loss: 0.4000 - accuracy: 0.85 - ETA: 0s - loss: 0.4023 - accuracy: 0.83 - ETA: 0s - loss: 0.3947 - accuracy: 0.84 - ETA: 0s - loss: 0.3995 - accuracy: 0.83 - ETA: 0s - loss: 0.3987 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8368 - val_loss: 0.4210 - val_accuracy: 0.8230\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.84 - ETA: 0s - loss: 0.3984 - accuracy: 0.83 - ETA: 0s - loss: 0.3984 - accuracy: 0.83 - ETA: 0s - loss: 0.3963 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8367 - val_loss: 0.4189 - val_accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.81 - ETA: 0s - loss: 0.4252 - accuracy: 0.82 - ETA: 0s - loss: 0.4022 - accuracy: 0.83 - ETA: 0s - loss: 0.3981 - accuracy: 0.83 - ETA: 0s - loss: 0.3953 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8385 - val_loss: 0.4179 - val_accuracy: 0.8235\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.78 - ETA: 0s - loss: 0.4162 - accuracy: 0.82 - ETA: 0s - loss: 0.3931 - accuracy: 0.83 - ETA: 0s - loss: 0.3901 - accuracy: 0.84 - ETA: 0s - loss: 0.3893 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8403 - val_loss: 0.4156 - val_accuracy: 0.8190\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.84 - ETA: 0s - loss: 0.3874 - accuracy: 0.83 - ETA: 0s - loss: 0.4100 - accuracy: 0.82 - ETA: 0s - loss: 0.3975 - accuracy: 0.83 - ETA: 0s - loss: 0.3996 - accuracy: 0.83 - ETA: 0s - loss: 0.3969 - accuracy: 0.83 - ETA: 0s - loss: 0.3969 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3902 - accuracy: 0.8415 - val_loss: 0.4161 - val_accuracy: 0.8265\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.68 - ETA: 0s - loss: 0.3971 - accuracy: 0.84 - ETA: 0s - loss: 0.3954 - accuracy: 0.84 - ETA: 0s - loss: 0.3878 - accuracy: 0.84 - ETA: 0s - loss: 0.3857 - accuracy: 0.84 - ETA: 0s - loss: 0.3892 - accuracy: 0.84 - ETA: 0s - loss: 0.3874 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8427 - val_loss: 0.4117 - val_accuracy: 0.8230\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.96 - ETA: 0s - loss: 0.3676 - accuracy: 0.84 - ETA: 0s - loss: 0.3651 - accuracy: 0.85 - ETA: 0s - loss: 0.3759 - accuracy: 0.84 - ETA: 0s - loss: 0.3811 - accuracy: 0.84 - ETA: 0s - loss: 0.3820 - accuracy: 0.84 - ETA: 0s - loss: 0.3841 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8428 - val_loss: 0.4098 - val_accuracy: 0.8250\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.90 - ETA: 0s - loss: 0.3668 - accuracy: 0.85 - ETA: 0s - loss: 0.3774 - accuracy: 0.84 - ETA: 0s - loss: 0.3761 - accuracy: 0.84 - ETA: 0s - loss: 0.3753 - accuracy: 0.84 - ETA: 0s - loss: 0.3764 - accuracy: 0.84 - ETA: 0s - loss: 0.3811 - accuracy: 0.84 - ETA: 0s - loss: 0.3853 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3837 - accuracy: 0.8450 - val_loss: 0.4076 - val_accuracy: 0.8260\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.87 - ETA: 0s - loss: 0.3412 - accuracy: 0.87 - ETA: 0s - loss: 0.3668 - accuracy: 0.85 - ETA: 0s - loss: 0.3718 - accuracy: 0.85 - ETA: 0s - loss: 0.3741 - accuracy: 0.85 - ETA: 0s - loss: 0.3792 - accuracy: 0.84 - ETA: 0s - loss: 0.3822 - accuracy: 0.84 - ETA: 0s - loss: 0.3825 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8470 - val_loss: 0.4072 - val_accuracy: 0.8275\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.96 - ETA: 0s - loss: 0.3735 - accuracy: 0.84 - ETA: 0s - loss: 0.3761 - accuracy: 0.84 - ETA: 0s - loss: 0.3802 - accuracy: 0.84 - ETA: 0s - loss: 0.3834 - accuracy: 0.84 - ETA: 0s - loss: 0.3793 - accuracy: 0.84 - ETA: 0s - loss: 0.3815 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8452 - val_loss: 0.4042 - val_accuracy: 0.8280\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.81 - ETA: 0s - loss: 0.3547 - accuracy: 0.85 - ETA: 0s - loss: 0.3635 - accuracy: 0.85 - ETA: 0s - loss: 0.3693 - accuracy: 0.85 - ETA: 0s - loss: 0.3820 - accuracy: 0.84 - ETA: 0s - loss: 0.3822 - accuracy: 0.84 - ETA: 0s - loss: 0.3780 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8467 - val_loss: 0.4034 - val_accuracy: 0.8285\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.84 - ETA: 0s - loss: 0.3991 - accuracy: 0.83 - ETA: 0s - loss: 0.3794 - accuracy: 0.84 - ETA: 0s - loss: 0.3790 - accuracy: 0.84 - ETA: 0s - loss: 0.3746 - accuracy: 0.84 - ETA: 0s - loss: 0.3749 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8478 - val_loss: 0.4005 - val_accuracy: 0.8290\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.78 - ETA: 0s - loss: 0.3558 - accuracy: 0.84 - ETA: 0s - loss: 0.3745 - accuracy: 0.84 - ETA: 0s - loss: 0.3707 - accuracy: 0.85 - ETA: 0s - loss: 0.3701 - accuracy: 0.85 - ETA: 0s - loss: 0.3698 - accuracy: 0.85 - ETA: 0s - loss: 0.3730 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8488 - val_loss: 0.4004 - val_accuracy: 0.8300\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.96 - ETA: 0s - loss: 0.3549 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3575 - accuracy: 0.85 - ETA: 0s - loss: 0.3715 - accuracy: 0.85 - ETA: 0s - loss: 0.3689 - accuracy: 0.85 - ETA: 0s - loss: 0.3703 - accuracy: 0.85 - ETA: 0s - loss: 0.3716 - accuracy: 0.84 - 1s 3ms/step - loss: 0.3703 - accuracy: 0.8507 - val_loss: 0.3975 - val_accuracy: 0.8285\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.90 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3453 - accuracy: 0.86 - ETA: 0s - loss: 0.3463 - accuracy: 0.86 - ETA: 0s - loss: 0.3545 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - ETA: 0s - loss: 0.3625 - accuracy: 0.85 - ETA: 0s - loss: 0.3684 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8500 - val_loss: 0.3948 - val_accuracy: 0.8310\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.84 - ETA: 0s - loss: 0.3615 - accuracy: 0.84 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3623 - accuracy: 0.85 - ETA: 0s - loss: 0.3613 - accuracy: 0.85 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3650 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8533 - val_loss: 0.3949 - val_accuracy: 0.8335\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.81 - ETA: 0s - loss: 0.3906 - accuracy: 0.82 - ETA: 0s - loss: 0.3793 - accuracy: 0.84 - ETA: 0s - loss: 0.3787 - accuracy: 0.84 - ETA: 0s - loss: 0.3736 - accuracy: 0.84 - ETA: 0s - loss: 0.3692 - accuracy: 0.85 - ETA: 0s - loss: 0.3650 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8527 - val_loss: 0.3929 - val_accuracy: 0.8315\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3604 - accuracy: 0.85 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - ETA: 0s - loss: 0.3494 - accuracy: 0.86 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8552 - val_loss: 0.3902 - val_accuracy: 0.8330\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.87 - ETA: 0s - loss: 0.3483 - accuracy: 0.86 - ETA: 0s - loss: 0.3565 - accuracy: 0.86 - ETA: 0s - loss: 0.3714 - accuracy: 0.85 - ETA: 0s - loss: 0.3637 - accuracy: 0.85 - ETA: 0s - loss: 0.3626 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8570 - val_loss: 0.3887 - val_accuracy: 0.8335\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.84 - ETA: 0s - loss: 0.3487 - accuracy: 0.86 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3640 - accuracy: 0.85 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3612 - accuracy: 0.85 - ETA: 0s - loss: 0.3593 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8567 - val_loss: 0.3879 - val_accuracy: 0.8350\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.90 - ETA: 0s - loss: 0.3775 - accuracy: 0.85 - ETA: 0s - loss: 0.3513 - accuracy: 0.86 - ETA: 0s - loss: 0.3561 - accuracy: 0.85 - ETA: 0s - loss: 0.3553 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3589 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8567 - val_loss: 0.3860 - val_accuracy: 0.8360\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.78 - ETA: 0s - loss: 0.3444 - accuracy: 0.86 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3644 - accuracy: 0.85 - ETA: 0s - loss: 0.3593 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3555 - accuracy: 0.8585 - val_loss: 0.3851 - val_accuracy: 0.8370\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.90 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - ETA: 0s - loss: 0.3605 - accuracy: 0.85 - ETA: 0s - loss: 0.3512 - accuracy: 0.86 - ETA: 0s - loss: 0.3543 - accuracy: 0.86 - ETA: 0s - loss: 0.3508 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8600 - val_loss: 0.3837 - val_accuracy: 0.8370\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.84 - ETA: 0s - loss: 0.3563 - accuracy: 0.86 - ETA: 0s - loss: 0.3595 - accuracy: 0.85 - ETA: 0s - loss: 0.3555 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8593 - val_loss: 0.3826 - val_accuracy: 0.8370\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.75 - ETA: 0s - loss: 0.3512 - accuracy: 0.86 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8590 - val_loss: 0.3817 - val_accuracy: 0.8395\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.87 - ETA: 0s - loss: 0.3786 - accuracy: 0.85 - ETA: 0s - loss: 0.3576 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3492 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8602 - val_loss: 0.3821 - val_accuracy: 0.8435\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.90 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3250 - accuracy: 0.87 - ETA: 0s - loss: 0.3267 - accuracy: 0.87 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3408 - accuracy: 0.86 - ETA: 0s - loss: 0.3473 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8608 - val_loss: 0.3791 - val_accuracy: 0.8420\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.84 - ETA: 0s - loss: 0.3512 - accuracy: 0.85 - ETA: 0s - loss: 0.3413 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8603 - val_loss: 0.3806 - val_accuracy: 0.8465\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.87 - ETA: 0s - loss: 0.3429 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3455 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - ETA: 0s - loss: 0.3435 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8607 - val_loss: 0.3778 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.84 - ETA: 0s - loss: 0.3510 - accuracy: 0.85 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - ETA: 0s - loss: 0.3476 - accuracy: 0.85 - ETA: 0s - loss: 0.3464 - accuracy: 0.86 - ETA: 0s - loss: 0.3457 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8630 - val_loss: 0.3797 - val_accuracy: 0.8460\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.68 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3171 - accuracy: 0.87 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8628 - val_loss: 0.3785 - val_accuracy: 0.8500\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.90 - ETA: 0s - loss: 0.3223 - accuracy: 0.87 - ETA: 0s - loss: 0.3257 - accuracy: 0.87 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8610 - val_loss: 0.3760 - val_accuracy: 0.8460\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.93 - ETA: 0s - loss: 0.3049 - accuracy: 0.89 - ETA: 0s - loss: 0.3252 - accuracy: 0.87 - ETA: 0s - loss: 0.3430 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8633 - val_loss: 0.3758 - val_accuracy: 0.8480\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.96 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3422 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3381 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8653 - val_loss: 0.3756 - val_accuracy: 0.8450\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.84 - ETA: 0s - loss: 0.3532 - accuracy: 0.86 - ETA: 0s - loss: 0.3442 - accuracy: 0.85 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3421 - accuracy: 0.86 - ETA: 0s - loss: 0.3425 - accuracy: 0.86 - ETA: 0s - loss: 0.3406 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8633 - val_loss: 0.3755 - val_accuracy: 0.8490\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.87 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8638 - val_loss: 0.3753 - val_accuracy: 0.8510\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.84 - ETA: 0s - loss: 0.3610 - accuracy: 0.85 - ETA: 0s - loss: 0.3442 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8640 - val_loss: 0.3755 - val_accuracy: 0.8425\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.84 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8645 - val_loss: 0.3766 - val_accuracy: 0.8495\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.93 - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - ETA: 0s - loss: 0.3241 - accuracy: 0.87 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8642 - val_loss: 0.3752 - val_accuracy: 0.8455\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.81 - ETA: 0s - loss: 0.3559 - accuracy: 0.84 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3430 - accuracy: 0.86 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3334 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8635 - val_loss: 0.3732 - val_accuracy: 0.8465\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.90 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3298 - accuracy: 0.86 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8647 - val_loss: 0.3754 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.78 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3304 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8658 - val_loss: 0.3729 - val_accuracy: 0.8470\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.81 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3422 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.87 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8667 - val_loss: 0.3729 - val_accuracy: 0.8500\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.93 - ETA: 0s - loss: 0.3495 - accuracy: 0.86 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - ETA: 0s - loss: 0.3245 - accuracy: 0.87 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3394 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8663 - val_loss: 0.3733 - val_accuracy: 0.8480\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.81 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3422 - accuracy: 0.86 - ETA: 0s - loss: 0.3448 - accuracy: 0.85 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8658 - val_loss: 0.3733 - val_accuracy: 0.8475\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.90 - ETA: 0s - loss: 0.3174 - accuracy: 0.87 - ETA: 0s - loss: 0.3171 - accuracy: 0.87 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3250 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8672 - val_loss: 0.3723 - val_accuracy: 0.8480\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.78 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3289 - accuracy: 0.8668 - val_loss: 0.3719 - val_accuracy: 0.8495\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.84 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3275 - accuracy: 0.85 - ETA: 0s - loss: 0.3339 - accuracy: 0.85 - ETA: 0s - loss: 0.3263 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3284 - accuracy: 0.8658 - val_loss: 0.3720 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.81 - ETA: 0s - loss: 0.3664 - accuracy: 0.85 - ETA: 0s - loss: 0.3445 - accuracy: 0.86 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8682 - val_loss: 0.3756 - val_accuracy: 0.8500\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.93 - ETA: 0s - loss: 0.3173 - accuracy: 0.88 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3238 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8690 - val_loss: 0.3740 - val_accuracy: 0.8485\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.87 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8670 - val_loss: 0.3732 - val_accuracy: 0.8490\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.84 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8687 - val_loss: 0.3746 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.87 - ETA: 0s - loss: 0.3394 - accuracy: 0.86 - ETA: 0s - loss: 0.3423 - accuracy: 0.85 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8678 - val_loss: 0.3713 - val_accuracy: 0.8475\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.90 - ETA: 0s - loss: 0.2975 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - ETA: 0s - loss: 0.3190 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8678 - val_loss: 0.3716 - val_accuracy: 0.8470\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.96 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - ETA: 0s - loss: 0.3203 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8670 - val_loss: 0.3699 - val_accuracy: 0.8475\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.84 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3254 - accuracy: 0.8690 - val_loss: 0.3717 - val_accuracy: 0.8495\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.90 - ETA: 0s - loss: 0.3003 - accuracy: 0.89 - ETA: 0s - loss: 0.3078 - accuracy: 0.88 - ETA: 0s - loss: 0.3262 - accuracy: 0.87 - ETA: 0s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8703 - val_loss: 0.3735 - val_accuracy: 0.8475\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.90 - ETA: 0s - loss: 0.3131 - accuracy: 0.85 - ETA: 0s - loss: 0.3155 - accuracy: 0.86 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8685 - val_loss: 0.3704 - val_accuracy: 0.8480\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.87 - ETA: 0s - loss: 0.2973 - accuracy: 0.88 - ETA: 0s - loss: 0.3089 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3192 - accuracy: 0.86 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8678 - val_loss: 0.3705 - val_accuracy: 0.8495\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.90 - ETA: 0s - loss: 0.3528 - accuracy: 0.84 - ETA: 0s - loss: 0.3330 - accuracy: 0.85 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3207 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8695 - val_loss: 0.3770 - val_accuracy: 0.8480\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.84 - ETA: 0s - loss: 0.3561 - accuracy: 0.85 - ETA: 0s - loss: 0.3436 - accuracy: 0.86 - ETA: 0s - loss: 0.3158 - accuracy: 0.87 - ETA: 0s - loss: 0.3287 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.87 - ETA: 0s - loss: 0.3245 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.87 - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8713 - val_loss: 0.3703 - val_accuracy: 0.8485\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.87 - ETA: 0s - loss: 0.3089 - accuracy: 0.87 - ETA: 0s - loss: 0.3107 - accuracy: 0.87 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8693 - val_loss: 0.3704 - val_accuracy: 0.8505\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.75 - ETA: 0s - loss: 0.3480 - accuracy: 0.86 - ETA: 0s - loss: 0.3378 - accuracy: 0.86 - ETA: 0s - loss: 0.3306 - accuracy: 0.86 - ETA: 0s - loss: 0.3266 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3236 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8702 - val_loss: 0.3702 - val_accuracy: 0.8490\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.90 - ETA: 0s - loss: 0.3052 - accuracy: 0.87 - ETA: 0s - loss: 0.3069 - accuracy: 0.86 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3218 - accuracy: 0.8687 - val_loss: 0.3709 - val_accuracy: 0.8490\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.78 - ETA: 0s - loss: 0.3142 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.3262 - accuracy: 0.87 - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8705 - val_loss: 0.3699 - val_accuracy: 0.8510\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.90 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8692 - val_loss: 0.3697 - val_accuracy: 0.8495\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.88 - ETA: 0s - loss: 0.3122 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3100 - accuracy: 0.87 - ETA: 0s - loss: 0.3198 - accuracy: 0.87 - ETA: 0s - loss: 0.3204 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8693 - val_loss: 0.3693 - val_accuracy: 0.8505\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.84 - ETA: 0s - loss: 0.3078 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.87 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8695 - val_loss: 0.3724 - val_accuracy: 0.8485\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.90 - ETA: 0s - loss: 0.3135 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3186 - accuracy: 0.86 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8707 - val_loss: 0.3696 - val_accuracy: 0.8490\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.84 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8695 - val_loss: 0.3690 - val_accuracy: 0.8495\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.78 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - ETA: 0s - loss: 0.3222 - accuracy: 0.87 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8688 - val_loss: 0.3697 - val_accuracy: 0.8485\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.84 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8715 - val_loss: 0.3688 - val_accuracy: 0.8480\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.78 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3045 - accuracy: 0.87 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8683 - val_loss: 0.3702 - val_accuracy: 0.8510\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.78 - ETA: 0s - loss: 0.3372 - accuracy: 0.85 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8703 - val_loss: 0.3707 - val_accuracy: 0.8500\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.84 - ETA: 0s - loss: 0.2986 - accuracy: 0.88 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3162 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8723 - val_loss: 0.3700 - val_accuracy: 0.8510\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.87 - ETA: 0s - loss: 0.2987 - accuracy: 0.87 - ETA: 0s - loss: 0.3160 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8703 - val_loss: 0.3701 - val_accuracy: 0.8475\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.84 - ETA: 0s - loss: 0.3439 - accuracy: 0.85 - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8712 - val_loss: 0.3690 - val_accuracy: 0.8490\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.90 - ETA: 0s - loss: 0.3257 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.87 - ETA: 0s - loss: 0.3208 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8708 - val_loss: 0.3693 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d125400bfcae8227d88ac78d6acc7590</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8510000109672546</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.53 - ETA: 0s - loss: 0.6476 - accuracy: 0.73 - ETA: 0s - loss: 0.6345 - accuracy: 0.75 - ETA: 0s - loss: 0.6150 - accuracy: 0.77 - 1s 3ms/step - loss: 0.6037 - accuracy: 0.7808 - val_loss: 0.5647 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.78 - ETA: 0s - loss: 0.5552 - accuracy: 0.79 - ETA: 0s - loss: 0.5580 - accuracy: 0.78 - ETA: 0s - loss: 0.5501 - accuracy: 0.79 - ETA: 0s - loss: 0.5426 - accuracy: 0.79 - ETA: 0s - loss: 0.5395 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7948 - val_loss: 0.5212 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.84 - ETA: 0s - loss: 0.5252 - accuracy: 0.79 - ETA: 0s - loss: 0.5141 - accuracy: 0.79 - ETA: 0s - loss: 0.5107 - accuracy: 0.79 - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7948 - val_loss: 0.5001 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.68 - ETA: 0s - loss: 0.5204 - accuracy: 0.77 - ETA: 0s - loss: 0.4944 - accuracy: 0.78 - ETA: 0s - loss: 0.4869 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7948 - val_loss: 0.4866 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6117 - accuracy: 0.75 - ETA: 0s - loss: 0.4756 - accuracy: 0.79 - ETA: 0s - loss: 0.4628 - accuracy: 0.80 - ETA: 0s - loss: 0.4734 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7957 - val_loss: 0.4760 - val_accuracy: 0.8005\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.87 - ETA: 0s - loss: 0.4712 - accuracy: 0.79 - ETA: 0s - loss: 0.4630 - accuracy: 0.80 - ETA: 0s - loss: 0.4660 - accuracy: 0.79 - ETA: 0s - loss: 0.4699 - accuracy: 0.79 - ETA: 0s - loss: 0.4663 - accuracy: 0.79 - ETA: 0s - loss: 0.4620 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7993 - val_loss: 0.4682 - val_accuracy: 0.8020\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.75 - ETA: 0s - loss: 0.4603 - accuracy: 0.80 - ETA: 0s - loss: 0.4498 - accuracy: 0.81 - ETA: 0s - loss: 0.4523 - accuracy: 0.80 - ETA: 0s - loss: 0.4526 - accuracy: 0.80 - ETA: 0s - loss: 0.4572 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8032 - val_loss: 0.4623 - val_accuracy: 0.8020\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.81 - ETA: 0s - loss: 0.4401 - accuracy: 0.81 - ETA: 0s - loss: 0.4495 - accuracy: 0.80 - ETA: 0s - loss: 0.4585 - accuracy: 0.79 - ETA: 0s - loss: 0.4483 - accuracy: 0.80 - ETA: 0s - loss: 0.4481 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8048 - val_loss: 0.4582 - val_accuracy: 0.8025\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.75 - ETA: 0s - loss: 0.4474 - accuracy: 0.79 - ETA: 0s - loss: 0.4444 - accuracy: 0.80 - ETA: 0s - loss: 0.4457 - accuracy: 0.80 - ETA: 0s - loss: 0.4443 - accuracy: 0.80 - ETA: 0s - loss: 0.4422 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8072 - val_loss: 0.4549 - val_accuracy: 0.8030\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.87 - ETA: 0s - loss: 0.4234 - accuracy: 0.81 - ETA: 0s - loss: 0.4300 - accuracy: 0.81 - ETA: 0s - loss: 0.4315 - accuracy: 0.81 - ETA: 0s - loss: 0.4364 - accuracy: 0.81 - ETA: 0s - loss: 0.4333 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8105 - val_loss: 0.4519 - val_accuracy: 0.8060\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.78 - ETA: 0s - loss: 0.4225 - accuracy: 0.81 - ETA: 0s - loss: 0.4300 - accuracy: 0.81 - ETA: 0s - loss: 0.4289 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8117 - val_loss: 0.4495 - val_accuracy: 0.8050\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.4546 - accuracy: 0.80 - ETA: 0s - loss: 0.4323 - accuracy: 0.80 - ETA: 0s - loss: 0.4340 - accuracy: 0.80 - ETA: 0s - loss: 0.4331 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8113 - val_loss: 0.4472 - val_accuracy: 0.8055\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.87 - ETA: 0s - loss: 0.4200 - accuracy: 0.81 - ETA: 0s - loss: 0.4329 - accuracy: 0.80 - ETA: 0s - loss: 0.4253 - accuracy: 0.81 - ETA: 0s - loss: 0.4241 - accuracy: 0.81 - ETA: 0s - loss: 0.4306 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8125 - val_loss: 0.4452 - val_accuracy: 0.8070\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.4257 - accuracy: 0.80 - ETA: 0s - loss: 0.4222 - accuracy: 0.80 - ETA: 0s - loss: 0.4250 - accuracy: 0.81 - ETA: 0s - loss: 0.4252 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8148 - val_loss: 0.4433 - val_accuracy: 0.8055\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.84 - ETA: 0s - loss: 0.4047 - accuracy: 0.82 - ETA: 0s - loss: 0.4246 - accuracy: 0.81 - ETA: 0s - loss: 0.4211 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8173 - val_loss: 0.4415 - val_accuracy: 0.8070\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.75 - ETA: 0s - loss: 0.4091 - accuracy: 0.82 - ETA: 0s - loss: 0.4091 - accuracy: 0.82 - ETA: 0s - loss: 0.4163 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8188 - val_loss: 0.4395 - val_accuracy: 0.8085\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.93 - ETA: 0s - loss: 0.4215 - accuracy: 0.81 - ETA: 0s - loss: 0.4135 - accuracy: 0.82 - ETA: 0s - loss: 0.4168 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8208 - val_loss: 0.4377 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.81 - ETA: 0s - loss: 0.4063 - accuracy: 0.83 - ETA: 0s - loss: 0.3949 - accuracy: 0.83 - ETA: 0s - loss: 0.4052 - accuracy: 0.82 - ETA: 0s - loss: 0.4059 - accuracy: 0.82 - ETA: 0s - loss: 0.4099 - accuracy: 0.82 - ETA: 0s - loss: 0.4150 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8232 - val_loss: 0.4360 - val_accuracy: 0.8105\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.84 - ETA: 0s - loss: 0.4036 - accuracy: 0.82 - ETA: 0s - loss: 0.4095 - accuracy: 0.82 - ETA: 0s - loss: 0.4108 - accuracy: 0.82 - ETA: 0s - loss: 0.4106 - accuracy: 0.82 - ETA: 0s - loss: 0.4133 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8233 - val_loss: 0.4342 - val_accuracy: 0.8115\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.81 - ETA: 0s - loss: 0.4249 - accuracy: 0.81 - ETA: 0s - loss: 0.4107 - accuracy: 0.82 - ETA: 0s - loss: 0.4167 - accuracy: 0.81 - ETA: 0s - loss: 0.4124 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8253 - val_loss: 0.4326 - val_accuracy: 0.8120\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.84 - ETA: 0s - loss: 0.3687 - accuracy: 0.85 - ETA: 0s - loss: 0.3964 - accuracy: 0.84 - ETA: 0s - loss: 0.4053 - accuracy: 0.83 - ETA: 0s - loss: 0.4087 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8262 - val_loss: 0.4310 - val_accuracy: 0.8150\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.87 - ETA: 0s - loss: 0.3878 - accuracy: 0.83 - ETA: 0s - loss: 0.3975 - accuracy: 0.83 - ETA: 0s - loss: 0.4070 - accuracy: 0.82 - ETA: 0s - loss: 0.4092 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8265 - val_loss: 0.4295 - val_accuracy: 0.8150\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.78 - ETA: 0s - loss: 0.3962 - accuracy: 0.82 - ETA: 0s - loss: 0.3984 - accuracy: 0.83 - ETA: 0s - loss: 0.4049 - accuracy: 0.82 - ETA: 0s - loss: 0.4055 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8275 - val_loss: 0.4280 - val_accuracy: 0.8155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.75 - ETA: 0s - loss: 0.3968 - accuracy: 0.83 - ETA: 0s - loss: 0.4045 - accuracy: 0.83 - ETA: 0s - loss: 0.4082 - accuracy: 0.82 - ETA: 0s - loss: 0.4048 - accuracy: 0.82 - ETA: 0s - loss: 0.4043 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8298 - val_loss: 0.4265 - val_accuracy: 0.8165\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.81 - ETA: 0s - loss: 0.4004 - accuracy: 0.83 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - ETA: 0s - loss: 0.3955 - accuracy: 0.83 - ETA: 0s - loss: 0.4042 - accuracy: 0.82 - ETA: 0s - loss: 0.4022 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8288 - val_loss: 0.4251 - val_accuracy: 0.8175\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.87 - ETA: 0s - loss: 0.3831 - accuracy: 0.83 - ETA: 0s - loss: 0.4025 - accuracy: 0.82 - ETA: 0s - loss: 0.4014 - accuracy: 0.82 - ETA: 0s - loss: 0.3975 - accuracy: 0.83 - ETA: 0s - loss: 0.3954 - accuracy: 0.83 - ETA: 0s - loss: 0.3992 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8313 - val_loss: 0.4240 - val_accuracy: 0.8175\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.87 - ETA: 0s - loss: 0.4153 - accuracy: 0.82 - ETA: 0s - loss: 0.3967 - accuracy: 0.83 - ETA: 0s - loss: 0.3917 - accuracy: 0.83 - ETA: 0s - loss: 0.3972 - accuracy: 0.83 - ETA: 0s - loss: 0.3957 - accuracy: 0.83 - ETA: 0s - loss: 0.3987 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8328 - val_loss: 0.4224 - val_accuracy: 0.8165\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.84 - ETA: 0s - loss: 0.4139 - accuracy: 0.82 - ETA: 0s - loss: 0.4003 - accuracy: 0.82 - ETA: 0s - loss: 0.3940 - accuracy: 0.83 - ETA: 0s - loss: 0.3996 - accuracy: 0.83 - ETA: 0s - loss: 0.3998 - accuracy: 0.83 - ETA: 0s - loss: 0.3965 - accuracy: 0.83 - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8330 - val_loss: 0.4213 - val_accuracy: 0.8200\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.78 - ETA: 0s - loss: 0.3988 - accuracy: 0.83 - ETA: 0s - loss: 0.3950 - accuracy: 0.83 - ETA: 0s - loss: 0.3888 - accuracy: 0.84 - ETA: 0s - loss: 0.3854 - accuracy: 0.84 - ETA: 0s - loss: 0.3946 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8345 - val_loss: 0.4200 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.84 - ETA: 0s - loss: 0.3937 - accuracy: 0.83 - ETA: 0s - loss: 0.4029 - accuracy: 0.83 - ETA: 0s - loss: 0.4027 - accuracy: 0.83 - ETA: 0s - loss: 0.3975 - accuracy: 0.83 - ETA: 0s - loss: 0.3914 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8362 - val_loss: 0.4189 - val_accuracy: 0.8205\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.93 - ETA: 0s - loss: 0.4006 - accuracy: 0.83 - ETA: 0s - loss: 0.3966 - accuracy: 0.83 - ETA: 0s - loss: 0.3908 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8375 - val_loss: 0.4176 - val_accuracy: 0.8205\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.96 - ETA: 0s - loss: 0.3944 - accuracy: 0.83 - ETA: 0s - loss: 0.3850 - accuracy: 0.84 - ETA: 0s - loss: 0.3899 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8368 - val_loss: 0.4164 - val_accuracy: 0.8200\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.87 - ETA: 0s - loss: 0.3996 - accuracy: 0.83 - ETA: 0s - loss: 0.3936 - accuracy: 0.83 - ETA: 0s - loss: 0.3920 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8380 - val_loss: 0.4153 - val_accuracy: 0.8230\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.87 - ETA: 0s - loss: 0.3913 - accuracy: 0.83 - ETA: 0s - loss: 0.3881 - accuracy: 0.83 - ETA: 0s - loss: 0.3848 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8397 - val_loss: 0.4139 - val_accuracy: 0.8225\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.81 - ETA: 0s - loss: 0.3928 - accuracy: 0.84 - ETA: 0s - loss: 0.3931 - accuracy: 0.84 - ETA: 0s - loss: 0.3939 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8410 - val_loss: 0.4128 - val_accuracy: 0.8250\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.71 - ETA: 0s - loss: 0.3770 - accuracy: 0.84 - ETA: 0s - loss: 0.3991 - accuracy: 0.83 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8430 - val_loss: 0.4116 - val_accuracy: 0.8270\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 1.00 - ETA: 0s - loss: 0.3716 - accuracy: 0.85 - ETA: 0s - loss: 0.3901 - accuracy: 0.84 - ETA: 0s - loss: 0.3872 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8445 - val_loss: 0.4104 - val_accuracy: 0.8270\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.78 - ETA: 0s - loss: 0.3855 - accuracy: 0.83 - ETA: 0s - loss: 0.3939 - accuracy: 0.83 - ETA: 0s - loss: 0.3949 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8440 - val_loss: 0.4090 - val_accuracy: 0.8295\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.84 - ETA: 0s - loss: 0.3772 - accuracy: 0.84 - ETA: 0s - loss: 0.3798 - accuracy: 0.84 - ETA: 0s - loss: 0.3821 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8450 - val_loss: 0.4077 - val_accuracy: 0.8300\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.87 - ETA: 0s - loss: 0.3543 - accuracy: 0.86 - ETA: 0s - loss: 0.3772 - accuracy: 0.84 - ETA: 0s - loss: 0.3747 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8462 - val_loss: 0.4061 - val_accuracy: 0.8275\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.81 - ETA: 0s - loss: 0.3843 - accuracy: 0.84 - ETA: 0s - loss: 0.3812 - accuracy: 0.84 - ETA: 0s - loss: 0.3748 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8453 - val_loss: 0.4051 - val_accuracy: 0.8295\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.93 - ETA: 0s - loss: 0.3686 - accuracy: 0.84 - ETA: 0s - loss: 0.3861 - accuracy: 0.83 - ETA: 0s - loss: 0.3794 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8457 - val_loss: 0.4038 - val_accuracy: 0.8320\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.81 - ETA: 0s - loss: 0.3696 - accuracy: 0.85 - ETA: 0s - loss: 0.3582 - accuracy: 0.86 - ETA: 0s - loss: 0.3689 - accuracy: 0.85 - ETA: 0s - loss: 0.3765 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8485 - val_loss: 0.4023 - val_accuracy: 0.8310\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.96 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - ETA: 0s - loss: 0.3768 - accuracy: 0.84 - ETA: 0s - loss: 0.3759 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8462 - val_loss: 0.4011 - val_accuracy: 0.8335\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.90 - ETA: 0s - loss: 0.3710 - accuracy: 0.84 - ETA: 0s - loss: 0.3795 - accuracy: 0.84 - ETA: 0s - loss: 0.3754 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8467 - val_loss: 0.3998 - val_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.90 - ETA: 0s - loss: 0.3715 - accuracy: 0.84 - ETA: 0s - loss: 0.3699 - accuracy: 0.84 - ETA: 0s - loss: 0.3670 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8477 - val_loss: 0.3984 - val_accuracy: 0.8365\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.87 - ETA: 0s - loss: 0.3721 - accuracy: 0.84 - ETA: 0s - loss: 0.3736 - accuracy: 0.84 - ETA: 0s - loss: 0.3652 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8490 - val_loss: 0.3973 - val_accuracy: 0.8365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.87 - ETA: 0s - loss: 0.3766 - accuracy: 0.83 - ETA: 0s - loss: 0.3746 - accuracy: 0.84 - ETA: 0s - loss: 0.3693 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8480 - val_loss: 0.3959 - val_accuracy: 0.8365\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.87 - ETA: 0s - loss: 0.3771 - accuracy: 0.84 - ETA: 0s - loss: 0.3690 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8498 - val_loss: 0.3947 - val_accuracy: 0.8360\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.84 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - ETA: 0s - loss: 0.3659 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8515 - val_loss: 0.3931 - val_accuracy: 0.8360\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.87 - ETA: 0s - loss: 0.3665 - accuracy: 0.84 - ETA: 0s - loss: 0.3607 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8520 - val_loss: 0.3919 - val_accuracy: 0.8380\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.90 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - ETA: 0s - loss: 0.3584 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8535 - val_loss: 0.3907 - val_accuracy: 0.8385\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.81 - ETA: 0s - loss: 0.3383 - accuracy: 0.86 - ETA: 0s - loss: 0.3565 - accuracy: 0.85 - ETA: 0s - loss: 0.3584 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8550 - val_loss: 0.3890 - val_accuracy: 0.8380\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.87 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3582 - accuracy: 0.85 - ETA: 0s - loss: 0.3588 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8543 - val_loss: 0.3878 - val_accuracy: 0.8385\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.90 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3559 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8543 - val_loss: 0.3866 - val_accuracy: 0.8405\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.93 - ETA: 0s - loss: 0.3607 - accuracy: 0.84 - ETA: 0s - loss: 0.3552 - accuracy: 0.85 - 0s 942us/step - loss: 0.3545 - accuracy: 0.8553 - val_loss: 0.3856 - val_accuracy: 0.8395\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.78 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - 0s 990us/step - loss: 0.3533 - accuracy: 0.8555 - val_loss: 0.3843 - val_accuracy: 0.8425\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.96 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - 0s 894us/step - loss: 0.3521 - accuracy: 0.8570 - val_loss: 0.3832 - val_accuracy: 0.8420\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.75 - ETA: 0s - loss: 0.3459 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8567 - val_loss: 0.3821 - val_accuracy: 0.8430\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.90 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - 0s 936us/step - loss: 0.3497 - accuracy: 0.8573 - val_loss: 0.3811 - val_accuracy: 0.8420\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.90 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - 0s 979us/step - loss: 0.3487 - accuracy: 0.8578 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.90 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - 0s 979us/step - loss: 0.3478 - accuracy: 0.8583 - val_loss: 0.3795 - val_accuracy: 0.8445\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.93 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3460 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8587 - val_loss: 0.3787 - val_accuracy: 0.8455\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.93 - ETA: 0s - loss: 0.3466 - accuracy: 0.85 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8575 - val_loss: 0.3778 - val_accuracy: 0.8460\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.87 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - 0s 967us/step - loss: 0.3449 - accuracy: 0.8590 - val_loss: 0.3770 - val_accuracy: 0.8465\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.81 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - ETA: 0s - loss: 0.3440 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8592 - val_loss: 0.3762 - val_accuracy: 0.8470\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.93 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8597 - val_loss: 0.3755 - val_accuracy: 0.8465\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.75 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8598 - val_loss: 0.3750 - val_accuracy: 0.8470\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.81 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - ETA: 0s - loss: 0.3442 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8608 - val_loss: 0.3746 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.87 - ETA: 0s - loss: 0.3506 - accuracy: 0.85 - ETA: 0s - loss: 0.3408 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8598 - val_loss: 0.3739 - val_accuracy: 0.8490\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.84 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - 0s 857us/step - loss: 0.3405 - accuracy: 0.8602 - val_loss: 0.3736 - val_accuracy: 0.8490\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.68 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - ETA: 0s - loss: 0.3420 - accuracy: 0.85 - 0s 854us/step - loss: 0.3399 - accuracy: 0.8598 - val_loss: 0.3726 - val_accuracy: 0.8490\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.81 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - 0s 894us/step - loss: 0.3392 - accuracy: 0.8595 - val_loss: 0.3723 - val_accuracy: 0.8475\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.78 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - 0s 936us/step - loss: 0.3388 - accuracy: 0.8597 - val_loss: 0.3717 - val_accuracy: 0.8480\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.90 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - 0s 857us/step - loss: 0.3380 - accuracy: 0.8598 - val_loss: 0.3711 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.78 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3393 - accuracy: 0.85 - 0s 857us/step - loss: 0.3374 - accuracy: 0.8607 - val_loss: 0.3708 - val_accuracy: 0.8480\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.81 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8593 - val_loss: 0.3703 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.78 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3353 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8607 - val_loss: 0.3701 - val_accuracy: 0.8485\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.87 - ETA: 0s - loss: 0.3315 - accuracy: 0.85 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - 0s 894us/step - loss: 0.3359 - accuracy: 0.8600 - val_loss: 0.3698 - val_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.90 - ETA: 0s - loss: 0.3565 - accuracy: 0.85 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8612 - val_loss: 0.3698 - val_accuracy: 0.8505\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - 0s 936us/step - loss: 0.3349 - accuracy: 0.8607 - val_loss: 0.3691 - val_accuracy: 0.8465\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.81 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - 0s 894us/step - loss: 0.3343 - accuracy: 0.8617 - val_loss: 0.3695 - val_accuracy: 0.8495\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.84 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - 0s 894us/step - loss: 0.3340 - accuracy: 0.8605 - val_loss: 0.3685 - val_accuracy: 0.8465\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4064 - accuracy: 0.84 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - 0s 936us/step - loss: 0.3335 - accuracy: 0.8618 - val_loss: 0.3684 - val_accuracy: 0.8475\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.90 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 857us/step - loss: 0.3332 - accuracy: 0.8618 - val_loss: 0.3684 - val_accuracy: 0.8480\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.81 - ETA: 0s - loss: 0.3213 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - 0s 894us/step - loss: 0.3327 - accuracy: 0.8617 - val_loss: 0.3680 - val_accuracy: 0.8465\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.81 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3377 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8607 - val_loss: 0.3679 - val_accuracy: 0.8485\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.84 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8618 - val_loss: 0.3678 - val_accuracy: 0.8465\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.87 - ETA: 0s - loss: 0.3126 - accuracy: 0.87 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8612 - val_loss: 0.3675 - val_accuracy: 0.8460\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - ETA: 0s - loss: 0.3187 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - 0s 857us/step - loss: 0.3312 - accuracy: 0.8613 - val_loss: 0.3671 - val_accuracy: 0.8465\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.84 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - 0s 919us/step - loss: 0.3309 - accuracy: 0.8627 - val_loss: 0.3670 - val_accuracy: 0.8460\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.87 - ETA: 0s - loss: 0.3459 - accuracy: 0.85 - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - 0s 809us/step - loss: 0.3304 - accuracy: 0.8622 - val_loss: 0.3671 - val_accuracy: 0.8475\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.90 - ETA: 0s - loss: 0.3175 - accuracy: 0.86 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - 0s 766us/step - loss: 0.3300 - accuracy: 0.8622 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.81 - ETA: 0s - loss: 0.3231 - accuracy: 0.86 - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 809us/step - loss: 0.3298 - accuracy: 0.8618 - val_loss: 0.3666 - val_accuracy: 0.8455\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - 0s 809us/step - loss: 0.3296 - accuracy: 0.8620 - val_loss: 0.3666 - val_accuracy: 0.8475\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.87 - ETA: 0s - loss: 0.3287 - accuracy: 0.85 - ETA: 0s - loss: 0.3317 - accuracy: 0.86 - 0s 851us/step - loss: 0.3289 - accuracy: 0.8628 - val_loss: 0.3666 - val_accuracy: 0.8480\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.87 - ETA: 0s - loss: 0.3148 - accuracy: 0.86 - ETA: 0s - loss: 0.3314 - accuracy: 0.86 - 0s 885us/step - loss: 0.3289 - accuracy: 0.8638 - val_loss: 0.3665 - val_accuracy: 0.8470\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.90 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - 0s 894us/step - loss: 0.3283 - accuracy: 0.8638 - val_loss: 0.3664 - val_accuracy: 0.8450\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.90 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 979us/step - loss: 0.3281 - accuracy: 0.8637 - val_loss: 0.3664 - val_accuracy: 0.8485\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.90 - ETA: 0s - loss: 0.3362 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8645 - val_loss: 0.3662 - val_accuracy: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3a4f178c75f9e885b1f3017483e9bea7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8504999876022339</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.81 - ETA: 0s - loss: 0.5430 - accuracy: 0.77 - ETA: 0s - loss: 0.5110 - accuracy: 0.78 - ETA: 0s - loss: 0.4822 - accuracy: 0.79 - ETA: 0s - loss: 0.4687 - accuracy: 0.79 - 1s 3ms/step - loss: 0.4692 - accuracy: 0.7948 - val_loss: 0.4349 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.81 - ETA: 0s - loss: 0.4175 - accuracy: 0.80 - ETA: 0s - loss: 0.4298 - accuracy: 0.79 - ETA: 0s - loss: 0.4303 - accuracy: 0.79 - ETA: 0s - loss: 0.4325 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7997 - val_loss: 0.4132 - val_accuracy: 0.8230\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.87 - ETA: 0s - loss: 0.4220 - accuracy: 0.81 - ETA: 0s - loss: 0.4116 - accuracy: 0.82 - ETA: 0s - loss: 0.4066 - accuracy: 0.82 - ETA: 0s - loss: 0.4063 - accuracy: 0.82 - ETA: 0s - loss: 0.4145 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8158 - val_loss: 0.4045 - val_accuracy: 0.8225\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.90 - ETA: 0s - loss: 0.3871 - accuracy: 0.82 - ETA: 0s - loss: 0.3942 - accuracy: 0.81 - ETA: 0s - loss: 0.4001 - accuracy: 0.81 - ETA: 0s - loss: 0.3960 - accuracy: 0.82 - ETA: 0s - loss: 0.3934 - accuracy: 0.83 - ETA: 0s - loss: 0.3944 - accuracy: 0.83 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3930 - accuracy: 0.8353 - val_loss: 0.4150 - val_accuracy: 0.8395\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.87 - ETA: 0s - loss: 0.3651 - accuracy: 0.85 - ETA: 0s - loss: 0.3776 - accuracy: 0.84 - ETA: 0s - loss: 0.3873 - accuracy: 0.84 - ETA: 0s - loss: 0.3819 - accuracy: 0.84 - ETA: 0s - loss: 0.3870 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8412 - val_loss: 0.4100 - val_accuracy: 0.8405\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.93 - ETA: 0s - loss: 0.3630 - accuracy: 0.86 - ETA: 0s - loss: 0.3718 - accuracy: 0.84 - ETA: 0s - loss: 0.3743 - accuracy: 0.84 - ETA: 0s - loss: 0.3752 - accuracy: 0.84 - ETA: 0s - loss: 0.3775 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8448 - val_loss: 0.3825 - val_accuracy: 0.8415\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.81 - ETA: 0s - loss: 0.3494 - accuracy: 0.87 - ETA: 0s - loss: 0.3892 - accuracy: 0.85 - ETA: 0s - loss: 0.3854 - accuracy: 0.85 - ETA: 0s - loss: 0.3872 - accuracy: 0.84 - ETA: 0s - loss: 0.3801 - accuracy: 0.85 - ETA: 0s - loss: 0.3764 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8500 - val_loss: 0.3731 - val_accuracy: 0.8525\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.93 - ETA: 0s - loss: 0.3602 - accuracy: 0.85 - ETA: 0s - loss: 0.3574 - accuracy: 0.85 - ETA: 0s - loss: 0.3683 - accuracy: 0.85 - ETA: 0s - loss: 0.3695 - accuracy: 0.85 - ETA: 0s - loss: 0.3707 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8500 - val_loss: 0.3738 - val_accuracy: 0.8480\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.84 - ETA: 0s - loss: 0.3825 - accuracy: 0.83 - ETA: 0s - loss: 0.3896 - accuracy: 0.83 - ETA: 0s - loss: 0.3838 - accuracy: 0.83 - ETA: 0s - loss: 0.3726 - accuracy: 0.84 - ETA: 0s - loss: 0.3700 - accuracy: 0.84 - ETA: 0s - loss: 0.3697 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8497 - val_loss: 0.3762 - val_accuracy: 0.8540\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.87 - ETA: 0s - loss: 0.3876 - accuracy: 0.82 - ETA: 0s - loss: 0.3854 - accuracy: 0.83 - ETA: 0s - loss: 0.3704 - accuracy: 0.84 - ETA: 0s - loss: 0.3681 - accuracy: 0.85 - ETA: 0s - loss: 0.3640 - accuracy: 0.85 - ETA: 0s - loss: 0.3636 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8508 - val_loss: 0.3708 - val_accuracy: 0.8430\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.93 - ETA: 0s - loss: 0.3667 - accuracy: 0.85 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - ETA: 0s - loss: 0.3577 - accuracy: 0.85 - ETA: 0s - loss: 0.3613 - accuracy: 0.85 - ETA: 0s - loss: 0.3622 - accuracy: 0.85 - ETA: 0s - loss: 0.3615 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8543 - val_loss: 0.3641 - val_accuracy: 0.8535\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.84 - ETA: 0s - loss: 0.3577 - accuracy: 0.85 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - ETA: 0s - loss: 0.3499 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.86 - ETA: 0s - loss: 0.3465 - accuracy: 0.86 - ETA: 0s - loss: 0.3474 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8580 - val_loss: 0.3618 - val_accuracy: 0.8530\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.84 - ETA: 0s - loss: 0.3692 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.86 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3471 - accuracy: 0.86 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8560 - val_loss: 0.3656 - val_accuracy: 0.8570\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.78 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3505 - accuracy: 0.85 - ETA: 0s - loss: 0.3604 - accuracy: 0.84 - ETA: 0s - loss: 0.3551 - accuracy: 0.84 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8528 - val_loss: 0.3765 - val_accuracy: 0.8540\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.87 - ETA: 0s - loss: 0.3638 - accuracy: 0.86 - ETA: 0s - loss: 0.3644 - accuracy: 0.86 - ETA: 0s - loss: 0.3505 - accuracy: 0.86 - ETA: 0s - loss: 0.3470 - accuracy: 0.86 - ETA: 0s - loss: 0.3498 - accuracy: 0.86 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8572 - val_loss: 0.3655 - val_accuracy: 0.8495\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.81 - ETA: 0s - loss: 0.3573 - accuracy: 0.84 - ETA: 0s - loss: 0.3566 - accuracy: 0.85 - ETA: 0s - loss: 0.3454 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8535 - val_loss: 0.3561 - val_accuracy: 0.8555\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.93 - ETA: 0s - loss: 0.3404 - accuracy: 0.85 - ETA: 0s - loss: 0.3445 - accuracy: 0.85 - ETA: 0s - loss: 0.3405 - accuracy: 0.85 - ETA: 0s - loss: 0.3426 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3422 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8585 - val_loss: 0.3602 - val_accuracy: 0.8545\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.93 - ETA: 0s - loss: 0.3263 - accuracy: 0.87 - ETA: 0s - loss: 0.3496 - accuracy: 0.86 - ETA: 0s - loss: 0.3475 - accuracy: 0.86 - ETA: 0s - loss: 0.3489 - accuracy: 0.86 - ETA: 0s - loss: 0.3479 - accuracy: 0.86 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8610 - val_loss: 0.3562 - val_accuracy: 0.8540\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.78 - ETA: 0s - loss: 0.3373 - accuracy: 0.85 - ETA: 0s - loss: 0.3616 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3522 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8590 - val_loss: 0.3545 - val_accuracy: 0.8515\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.87 - ETA: 0s - loss: 0.3432 - accuracy: 0.85 - ETA: 0s - loss: 0.3384 - accuracy: 0.85 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8628 - val_loss: 0.3667 - val_accuracy: 0.8475\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.87 - ETA: 0s - loss: 0.3386 - accuracy: 0.86 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - ETA: 0s - loss: 0.3472 - accuracy: 0.85 - ETA: 0s - loss: 0.3443 - accuracy: 0.85 - ETA: 0s - loss: 0.3439 - accuracy: 0.86 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8637 - val_loss: 0.3551 - val_accuracy: 0.8520\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.90 - ETA: 0s - loss: 0.3238 - accuracy: 0.87 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3398 - accuracy: 0.86 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3434 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8602 - val_loss: 0.3610 - val_accuracy: 0.8580\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.93 - ETA: 0s - loss: 0.3173 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.85 - ETA: 0s - loss: 0.3431 - accuracy: 0.85 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8623 - val_loss: 0.3613 - val_accuracy: 0.8530\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.87 - ETA: 0s - loss: 0.3687 - accuracy: 0.84 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3457 - accuracy: 0.85 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - ETA: 0s - loss: 0.3469 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8583 - val_loss: 0.3828 - val_accuracy: 0.8405\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 1.00 - ETA: 0s - loss: 0.3317 - accuracy: 0.87 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3480 - accuracy: 0.86 - ETA: 0s - loss: 0.3486 - accuracy: 0.86 - ETA: 0s - loss: 0.3496 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8592 - val_loss: 0.3733 - val_accuracy: 0.8515\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.87 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3406 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3333 - accuracy: 0.86 - ETA: 0s - loss: 0.3408 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8613 - val_loss: 0.3661 - val_accuracy: 0.8510\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.81 - ETA: 0s - loss: 0.3602 - accuracy: 0.84 - ETA: 0s - loss: 0.3512 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3420 - accuracy: 0.86 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3430 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8605 - val_loss: 0.3606 - val_accuracy: 0.8530\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.78 - ETA: 0s - loss: 0.3475 - accuracy: 0.86 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3391 - accuracy: 0.86 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3384 - accuracy: 0.86 - ETA: 0s - loss: 0.3384 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8627 - val_loss: 0.3612 - val_accuracy: 0.8475\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.3953 - accuracy: 0.84 - ETA: 0s - loss: 0.3402 - accuracy: 0.85 - ETA: 0s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3473 - accuracy: 0.85 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - ETA: 0s - loss: 0.3473 - accuracy: 0.85 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8595 - val_loss: 0.3594 - val_accuracy: 0.8530\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.90 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - ETA: 0s - loss: 0.3422 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3386 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8657 - val_loss: 0.3701 - val_accuracy: 0.8530\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.81 - ETA: 0s - loss: 0.3252 - accuracy: 0.87 - ETA: 0s - loss: 0.3490 - accuracy: 0.86 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3612 - accuracy: 0.85 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3374 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8643 - val_loss: 0.3637 - val_accuracy: 0.8570\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.75 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.85 - ETA: 0s - loss: 0.3402 - accuracy: 0.85 - ETA: 0s - loss: 0.3396 - accuracy: 0.85 - ETA: 0s - loss: 0.3416 - accuracy: 0.85 - ETA: 0s - loss: 0.3423 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8620 - val_loss: 0.3600 - val_accuracy: 0.8585\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.96 - ETA: 0s - loss: 0.3360 - accuracy: 0.87 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3422 - accuracy: 0.86 - ETA: 0s - loss: 0.3439 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - ETA: 0s - loss: 0.3407 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8620 - val_loss: 0.3651 - val_accuracy: 0.8550\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3030 - accuracy: 0.88 - ETA: 0s - loss: 0.2917 - accuracy: 0.88 - ETA: 0s - loss: 0.3058 - accuracy: 0.88 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8635 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.93 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - ETA: 0s - loss: 0.3250 - accuracy: 0.87 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - ETA: 0s - loss: 0.3409 - accuracy: 0.86 - ETA: 0s - loss: 0.3454 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8623 - val_loss: 0.3829 - val_accuracy: 0.8460\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.81 - ETA: 0s - loss: 0.3746 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - ETA: 0s - loss: 0.3491 - accuracy: 0.86 - ETA: 0s - loss: 0.3535 - accuracy: 0.85 - ETA: 0s - loss: 0.3513 - accuracy: 0.85 - ETA: 0s - loss: 0.3461 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8595 - val_loss: 0.3845 - val_accuracy: 0.8510\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.90 - ETA: 0s - loss: 0.3472 - accuracy: 0.85 - ETA: 0s - loss: 0.3351 - accuracy: 0.86 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - ETA: 0s - loss: 0.3427 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8625 - val_loss: 0.3588 - val_accuracy: 0.8565\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.93 - ETA: 0s - loss: 0.3577 - accuracy: 0.85 - ETA: 0s - loss: 0.3547 - accuracy: 0.85 - ETA: 0s - loss: 0.3443 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8628 - val_loss: 0.3617 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.84 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8645 - val_loss: 0.3577 - val_accuracy: 0.8555\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.75 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8655 - val_loss: 0.3586 - val_accuracy: 0.8560\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.78 - ETA: 0s - loss: 0.3723 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - ETA: 0s - loss: 0.3390 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8628 - val_loss: 0.3608 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.90 - ETA: 0s - loss: 0.3526 - accuracy: 0.86 - ETA: 0s - loss: 0.3568 - accuracy: 0.85 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - ETA: 0s - loss: 0.3397 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8648 - val_loss: 0.3581 - val_accuracy: 0.8480\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.87 - ETA: 0s - loss: 0.3312 - accuracy: 0.87 - ETA: 0s - loss: 0.3250 - accuracy: 0.87 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3278 - accuracy: 0.87 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8678 - val_loss: 0.3568 - val_accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.84 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8625 - val_loss: 0.3553 - val_accuracy: 0.8565\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.93 - ETA: 0s - loss: 0.3067 - accuracy: 0.88 - ETA: 0s - loss: 0.3165 - accuracy: 0.87 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8638 - val_loss: 0.3626 - val_accuracy: 0.8560\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.87 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3452 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8632 - val_loss: 0.3560 - val_accuracy: 0.8535\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.90 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8663 - val_loss: 0.3537 - val_accuracy: 0.8590\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.90 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3355 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8622 - val_loss: 0.3552 - val_accuracy: 0.8560\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.87 - ETA: 0s - loss: 0.3357 - accuracy: 0.85 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3342 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3340 - accuracy: 0.8677 - val_loss: 0.3544 - val_accuracy: 0.8600\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.78 - ETA: 0s - loss: 0.3216 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3473 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8672 - val_loss: 0.3531 - val_accuracy: 0.8595\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.87 - ETA: 0s - loss: 0.3421 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3346 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8628 - val_loss: 0.3732 - val_accuracy: 0.8485\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.87 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3331 - accuracy: 0.85 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3386 - accuracy: 0.85 - ETA: 0s - loss: 0.3423 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8577 - val_loss: 0.3580 - val_accuracy: 0.8535\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.87 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3353 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8625 - val_loss: 0.3657 - val_accuracy: 0.8485\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.96 - ETA: 0s - loss: 0.3373 - accuracy: 0.87 - ETA: 0s - loss: 0.3513 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3391 - accuracy: 0.86 - ETA: 0s - loss: 0.3407 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8638 - val_loss: 0.3637 - val_accuracy: 0.8545\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.96 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.87 - ETA: 0s - loss: 0.3384 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - ETA: 0s - loss: 0.3404 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8630 - val_loss: 0.3514 - val_accuracy: 0.8600\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.96 - ETA: 0s - loss: 0.3359 - accuracy: 0.85 - ETA: 0s - loss: 0.3309 - accuracy: 0.85 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8627 - val_loss: 0.3602 - val_accuracy: 0.8520\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.93 - ETA: 0s - loss: 0.3506 - accuracy: 0.85 - ETA: 0s - loss: 0.3517 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - ETA: 0s - loss: 0.3398 - accuracy: 0.85 - ETA: 0s - loss: 0.3380 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8583 - val_loss: 0.3568 - val_accuracy: 0.8560\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.81 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3433 - accuracy: 0.86 - ETA: 0s - loss: 0.3456 - accuracy: 0.86 - ETA: 0s - loss: 0.3456 - accuracy: 0.86 - ETA: 0s - loss: 0.3461 - accuracy: 0.86 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8632 - val_loss: 0.3657 - val_accuracy: 0.8490\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.81 - ETA: 0s - loss: 0.3523 - accuracy: 0.84 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.87 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8632 - val_loss: 0.3607 - val_accuracy: 0.8560\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.71 - ETA: 0s - loss: 0.3179 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3190 - accuracy: 0.87 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - ETA: 0s - loss: 0.3309 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8672 - val_loss: 0.3704 - val_accuracy: 0.8490\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.87 - ETA: 0s - loss: 0.3359 - accuracy: 0.87 - ETA: 0s - loss: 0.3514 - accuracy: 0.86 - ETA: 0s - loss: 0.3452 - accuracy: 0.86 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3378 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8677 - val_loss: 0.3635 - val_accuracy: 0.8510\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.96 - ETA: 0s - loss: 0.3493 - accuracy: 0.86 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3419 - accuracy: 0.86 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - ETA: 0s - loss: 0.3362 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8648 - val_loss: 0.3612 - val_accuracy: 0.8540\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.87 - ETA: 0s - loss: 0.3588 - accuracy: 0.85 - ETA: 0s - loss: 0.3315 - accuracy: 0.87 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8660 - val_loss: 0.3660 - val_accuracy: 0.8470\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4910 - accuracy: 0.78 - ETA: 0s - loss: 0.3586 - accuracy: 0.85 - ETA: 0s - loss: 0.3326 - accuracy: 0.87 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8688 - val_loss: 0.3577 - val_accuracy: 0.8520\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.78 - ETA: 0s - loss: 0.3343 - accuracy: 0.85 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3310 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8665 - val_loss: 0.3612 - val_accuracy: 0.8450\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.68 - ETA: 0s - loss: 0.3571 - accuracy: 0.85 - ETA: 0s - loss: 0.3339 - accuracy: 0.87 - ETA: 0s - loss: 0.3285 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8712 - val_loss: 0.3604 - val_accuracy: 0.8470\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.75 - ETA: 0s - loss: 0.3146 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8665 - val_loss: 0.3582 - val_accuracy: 0.8540\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.96 - ETA: 0s - loss: 0.3432 - accuracy: 0.86 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3278 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8668 - val_loss: 0.3669 - val_accuracy: 0.8525\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.84 - ETA: 0s - loss: 0.3283 - accuracy: 0.86 - ETA: 0s - loss: 0.3091 - accuracy: 0.87 - ETA: 0s - loss: 0.3203 - accuracy: 0.87 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8642 - val_loss: 0.3617 - val_accuracy: 0.8565\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.71 - ETA: 0s - loss: 0.3066 - accuracy: 0.88 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3332 - accuracy: 0.86 - ETA: 0s - loss: 0.3252 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.87 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8685 - val_loss: 0.3613 - val_accuracy: 0.8570\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.87 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3169 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.86 - ETA: 0s - loss: 0.3119 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.86 - ETA: 0s - loss: 0.3267 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8650 - val_loss: 0.3736 - val_accuracy: 0.8515\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.87 - ETA: 0s - loss: 0.3656 - accuracy: 0.83 - ETA: 0s - loss: 0.3400 - accuracy: 0.85 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3347 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.86 - ETA: 0s - loss: 0.3303 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8637 - val_loss: 0.3697 - val_accuracy: 0.8500\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.87 - ETA: 0s - loss: 0.3140 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.86 - ETA: 0s - loss: 0.3275 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8670 - val_loss: 0.3552 - val_accuracy: 0.8560\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.96 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - ETA: 0s - loss: 0.3070 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3252 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8693 - val_loss: 0.3590 - val_accuracy: 0.8500\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.84 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3343 - accuracy: 0.86 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8678 - val_loss: 0.3586 - val_accuracy: 0.8530\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.81 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3238 - accuracy: 0.87 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8663 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 1.00 - ETA: 0s - loss: 0.3012 - accuracy: 0.88 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3238 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8685 - val_loss: 0.3617 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.93 - ETA: 0s - loss: 0.3161 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3205 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - ETA: 0s - loss: 0.3277 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8645 - val_loss: 0.3613 - val_accuracy: 0.8530\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.84 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - ETA: 0s - loss: 0.3184 - accuracy: 0.86 - ETA: 0s - loss: 0.3273 - accuracy: 0.86 - ETA: 0s - loss: 0.3269 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8663 - val_loss: 0.3699 - val_accuracy: 0.8560\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.96 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - ETA: 0s - loss: 0.3373 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8668 - val_loss: 0.3589 - val_accuracy: 0.8505\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.84 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - ETA: 0s - loss: 0.3655 - accuracy: 0.84 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3513 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8620 - val_loss: 0.3844 - val_accuracy: 0.8495\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.87 - ETA: 0s - loss: 0.3109 - accuracy: 0.87 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - ETA: 0s - loss: 0.3334 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8648 - val_loss: 0.3576 - val_accuracy: 0.8520\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.90 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - ETA: 0s - loss: 0.3356 - accuracy: 0.86 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8658 - val_loss: 0.3620 - val_accuracy: 0.8540\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.71 - ETA: 0s - loss: 0.3449 - accuracy: 0.85 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8663 - val_loss: 0.3646 - val_accuracy: 0.8520\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.96 - ETA: 0s - loss: 0.3619 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - ETA: 0s - loss: 0.3352 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8635 - val_loss: 0.3660 - val_accuracy: 0.8545\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.81 - ETA: 0s - loss: 0.3107 - accuracy: 0.88 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.3157 - accuracy: 0.87 - ETA: 0s - loss: 0.3283 - accuracy: 0.87 - ETA: 0s - loss: 0.3229 - accuracy: 0.87 - ETA: 0s - loss: 0.3236 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8682 - val_loss: 0.3657 - val_accuracy: 0.8550\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.78 - ETA: 0s - loss: 0.3273 - accuracy: 0.87 - ETA: 0s - loss: 0.3503 - accuracy: 0.85 - ETA: 0s - loss: 0.3394 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - ETA: 0s - loss: 0.3376 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8668 - val_loss: 0.3630 - val_accuracy: 0.8510\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.93 - ETA: 0s - loss: 0.3097 - accuracy: 0.88 - ETA: 0s - loss: 0.3264 - accuracy: 0.87 - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3266 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8673 - val_loss: 0.3646 - val_accuracy: 0.8570\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.90 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.88 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8630 - val_loss: 0.3611 - val_accuracy: 0.8515\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.90 - ETA: 0s - loss: 0.3628 - accuracy: 0.85 - ETA: 0s - loss: 0.3492 - accuracy: 0.85 - ETA: 0s - loss: 0.3549 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3506 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8568 - val_loss: 0.3665 - val_accuracy: 0.8525\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.90 - ETA: 0s - loss: 0.3473 - accuracy: 0.86 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3293 - accuracy: 0.87 - ETA: 0s - loss: 0.3355 - accuracy: 0.86 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8653 - val_loss: 0.3604 - val_accuracy: 0.8530\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.84 - ETA: 0s - loss: 0.3491 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8700 - val_loss: 0.3605 - val_accuracy: 0.8545\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.90 - ETA: 0s - loss: 0.2975 - accuracy: 0.89 - ETA: 0s - loss: 0.2984 - accuracy: 0.89 - ETA: 0s - loss: 0.3116 - accuracy: 0.88 - ETA: 0s - loss: 0.3263 - accuracy: 0.87 - ETA: 0s - loss: 0.3265 - accuracy: 0.87 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8662 - val_loss: 0.3717 - val_accuracy: 0.8555\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.90 - ETA: 0s - loss: 0.3592 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.86 - ETA: 0s - loss: 0.3409 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8698 - val_loss: 0.3575 - val_accuracy: 0.8585\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.90 - ETA: 0s - loss: 0.3136 - accuracy: 0.88 - ETA: 0s - loss: 0.3357 - accuracy: 0.87 - ETA: 0s - loss: 0.3260 - accuracy: 0.87 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8683 - val_loss: 0.3682 - val_accuracy: 0.8545\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.90 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - ETA: 0s - loss: 0.3537 - accuracy: 0.85 - ETA: 0s - loss: 0.3575 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8567 - val_loss: 0.3778 - val_accuracy: 0.8510\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4758 - accuracy: 0.81 - ETA: 0s - loss: 0.3485 - accuracy: 0.84 - ETA: 0s - loss: 0.3411 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3369 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8620 - val_loss: 0.3650 - val_accuracy: 0.8535\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.84 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8660 - val_loss: 0.3600 - val_accuracy: 0.8565\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.84 - ETA: 0s - loss: 0.3383 - accuracy: 0.86 - ETA: 0s - loss: 0.3386 - accuracy: 0.85 - ETA: 0s - loss: 0.3390 - accuracy: 0.86 - ETA: 0s - loss: 0.3307 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8682 - val_loss: 0.3625 - val_accuracy: 0.8545\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 1s - loss: 0.2386 - accuracy: 0.84 - ETA: 0s - loss: 0.3286 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.87 - ETA: 0s - loss: 0.3264 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8725 - val_loss: 0.3682 - val_accuracy: 0.8545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9a9b88ef9dc0a70657ae59a98c00516f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8600000143051147</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.12 - ETA: 0s - loss: 0.6321 - accuracy: 0.75 - ETA: 0s - loss: 0.5686 - accuracy: 0.77 - ETA: 0s - loss: 0.5338 - accuracy: 0.78 - ETA: 0s - loss: 0.5183 - accuracy: 0.78 - 1s 3ms/step - loss: 0.5117 - accuracy: 0.7842 - val_loss: 0.4419 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.84 - ETA: 0s - loss: 0.4384 - accuracy: 0.78 - ETA: 0s - loss: 0.4256 - accuracy: 0.79 - ETA: 0s - loss: 0.4258 - accuracy: 0.80 - ETA: 0s - loss: 0.4273 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8040 - val_loss: 0.4254 - val_accuracy: 0.8100\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.81 - ETA: 0s - loss: 0.4193 - accuracy: 0.81 - ETA: 0s - loss: 0.4100 - accuracy: 0.82 - ETA: 0s - loss: 0.4096 - accuracy: 0.82 - ETA: 0s - loss: 0.4086 - accuracy: 0.82 - ETA: 0s - loss: 0.4067 - accuracy: 0.82 - ETA: 0s - loss: 0.4065 - accuracy: 0.82 - 1s 3ms/step - loss: 0.4024 - accuracy: 0.8297 - val_loss: 0.4049 - val_accuracy: 0.8290\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.90 - ETA: 0s - loss: 0.3714 - accuracy: 0.84 - ETA: 0s - loss: 0.3703 - accuracy: 0.84 - ETA: 0s - loss: 0.3744 - accuracy: 0.84 - ETA: 0s - loss: 0.3776 - accuracy: 0.84 - ETA: 0s - loss: 0.3715 - accuracy: 0.84 - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8478 - val_loss: 0.3752 - val_accuracy: 0.8460\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.84 - ETA: 0s - loss: 0.3197 - accuracy: 0.87 - ETA: 0s - loss: 0.3434 - accuracy: 0.85 - ETA: 0s - loss: 0.3458 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8592 - val_loss: 0.3658 - val_accuracy: 0.8500\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.87 - ETA: 0s - loss: 0.3038 - accuracy: 0.88 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8588 - val_loss: 0.3704 - val_accuracy: 0.8480\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.87 - ETA: 0s - loss: 0.3223 - accuracy: 0.87 - ETA: 0s - loss: 0.3364 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8622 - val_loss: 0.3606 - val_accuracy: 0.8505\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.78 - ETA: 0s - loss: 0.3411 - accuracy: 0.86 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3321 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8615 - val_loss: 0.3713 - val_accuracy: 0.8465\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.87 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - ETA: 0s - loss: 0.3317 - accuracy: 0.85 - ETA: 0s - loss: 0.3329 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8630 - val_loss: 0.3623 - val_accuracy: 0.8450\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.90 - ETA: 0s - loss: 0.3219 - accuracy: 0.85 - ETA: 0s - loss: 0.3247 - accuracy: 0.86 - ETA: 0s - loss: 0.3272 - accuracy: 0.85 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8617 - val_loss: 0.3619 - val_accuracy: 0.8535\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.87 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3193 - accuracy: 0.86 - ETA: 0s - loss: 0.3270 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8653 - val_loss: 0.3567 - val_accuracy: 0.8555\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.84 - ETA: 0s - loss: 0.3297 - accuracy: 0.85 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3176 - accuracy: 0.86 - ETA: 0s - loss: 0.3204 - accuracy: 0.86 - ETA: 0s - loss: 0.3229 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8638 - val_loss: 0.3746 - val_accuracy: 0.8440\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.81 - ETA: 0s - loss: 0.3241 - accuracy: 0.86 - ETA: 0s - loss: 0.3333 - accuracy: 0.85 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - ETA: 0s - loss: 0.3162 - accuracy: 0.86 - ETA: 0s - loss: 0.3210 - accuracy: 0.86 - ETA: 0s - loss: 0.3211 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8642 - val_loss: 0.3533 - val_accuracy: 0.8515\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.84 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3172 - accuracy: 0.87 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3163 - accuracy: 0.86 - ETA: 0s - loss: 0.3146 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8683 - val_loss: 0.3630 - val_accuracy: 0.8510\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.87 - ETA: 0s - loss: 0.3291 - accuracy: 0.86 - ETA: 0s - loss: 0.3186 - accuracy: 0.86 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8650 - val_loss: 0.3568 - val_accuracy: 0.8520\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.2982 - accuracy: 0.88 - ETA: 0s - loss: 0.3015 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3130 - accuracy: 0.86 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8695 - val_loss: 0.3681 - val_accuracy: 0.8525\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.84 - ETA: 0s - loss: 0.2903 - accuracy: 0.88 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3174 - accuracy: 0.86 - ETA: 0s - loss: 0.3085 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8707 - val_loss: 0.3556 - val_accuracy: 0.8505\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.84 - ETA: 0s - loss: 0.3194 - accuracy: 0.86 - ETA: 0s - loss: 0.3164 - accuracy: 0.86 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3184 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8713 - val_loss: 0.3553 - val_accuracy: 0.8540\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.93 - ETA: 0s - loss: 0.3212 - accuracy: 0.87 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8713 - val_loss: 0.3592 - val_accuracy: 0.8590\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.93 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - ETA: 0s - loss: 0.2968 - accuracy: 0.87 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3077 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8728 - val_loss: 0.3577 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.84 - ETA: 0s - loss: 0.3060 - accuracy: 0.85 - ETA: 0s - loss: 0.3070 - accuracy: 0.86 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8722 - val_loss: 0.3689 - val_accuracy: 0.8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.93 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - ETA: 0s - loss: 0.3049 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8758 - val_loss: 0.3575 - val_accuracy: 0.8570\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.78 - ETA: 0s - loss: 0.3026 - accuracy: 0.88 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3045 - accuracy: 0.87 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8765 - val_loss: 0.3616 - val_accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.90 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8763 - val_loss: 0.3602 - val_accuracy: 0.8540\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.87 - ETA: 0s - loss: 0.2968 - accuracy: 0.88 - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - ETA: 0s - loss: 0.3122 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8750 - val_loss: 0.3709 - val_accuracy: 0.8510\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.96 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - ETA: 0s - loss: 0.3074 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.87 - ETA: 0s - loss: 0.3006 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.3615 - val_accuracy: 0.8520\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.87 - ETA: 0s - loss: 0.2922 - accuracy: 0.87 - ETA: 0s - loss: 0.3096 - accuracy: 0.86 - ETA: 0s - loss: 0.3105 - accuracy: 0.86 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8757 - val_loss: 0.3742 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4425 - accuracy: 0.81 - ETA: 0s - loss: 0.3071 - accuracy: 0.88 - ETA: 0s - loss: 0.2995 - accuracy: 0.88 - ETA: 0s - loss: 0.2911 - accuracy: 0.88 - ETA: 0s - loss: 0.2967 - accuracy: 0.88 - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8803 - val_loss: 0.3736 - val_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.78 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - ETA: 0s - loss: 0.3101 - accuracy: 0.87 - ETA: 0s - loss: 0.2960 - accuracy: 0.87 - ETA: 0s - loss: 0.2984 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8790 - val_loss: 0.3806 - val_accuracy: 0.8540\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.84 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - ETA: 0s - loss: 0.2891 - accuracy: 0.88 - ETA: 0s - loss: 0.2969 - accuracy: 0.87 - ETA: 0s - loss: 0.2964 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8765 - val_loss: 0.3775 - val_accuracy: 0.8495\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.90 - ETA: 0s - loss: 0.2867 - accuracy: 0.88 - ETA: 0s - loss: 0.2934 - accuracy: 0.88 - ETA: 0s - loss: 0.2914 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8790 - val_loss: 0.3781 - val_accuracy: 0.8455\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.93 - ETA: 0s - loss: 0.2878 - accuracy: 0.88 - ETA: 0s - loss: 0.2935 - accuracy: 0.87 - ETA: 0s - loss: 0.2964 - accuracy: 0.87 - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8765 - val_loss: 0.3764 - val_accuracy: 0.8465\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.84 - ETA: 0s - loss: 0.2825 - accuracy: 0.88 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - ETA: 0s - loss: 0.2853 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8812 - val_loss: 0.3771 - val_accuracy: 0.8495\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.93 - ETA: 0s - loss: 0.2839 - accuracy: 0.88 - ETA: 0s - loss: 0.2857 - accuracy: 0.88 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8820 - val_loss: 0.3818 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.90 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8822 - val_loss: 0.3898 - val_accuracy: 0.8450\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.93 - ETA: 0s - loss: 0.3005 - accuracy: 0.87 - ETA: 0s - loss: 0.2987 - accuracy: 0.87 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2882 - accuracy: 0.8832 - val_loss: 0.3896 - val_accuracy: 0.8480\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.90 - ETA: 0s - loss: 0.2881 - accuracy: 0.88 - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8822 - val_loss: 0.3810 - val_accuracy: 0.8475\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.84 - ETA: 0s - loss: 0.2886 - accuracy: 0.87 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2854 - accuracy: 0.8825 - val_loss: 0.3964 - val_accuracy: 0.8420\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.93 - ETA: 0s - loss: 0.2464 - accuracy: 0.90 - ETA: 0s - loss: 0.2822 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2847 - accuracy: 0.8835 - val_loss: 0.3961 - val_accuracy: 0.8460\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.87 - ETA: 0s - loss: 0.2931 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2839 - accuracy: 0.8843 - val_loss: 0.4074 - val_accuracy: 0.8470\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.90 - ETA: 0s - loss: 0.2830 - accuracy: 0.89 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8867 - val_loss: 0.3926 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.93 - ETA: 0s - loss: 0.2779 - accuracy: 0.89 - ETA: 0s - loss: 0.2745 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8875 - val_loss: 0.4051 - val_accuracy: 0.8460\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.93 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2821 - accuracy: 0.8840 - val_loss: 0.4031 - val_accuracy: 0.8420\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.81 - ETA: 0s - loss: 0.2597 - accuracy: 0.89 - ETA: 0s - loss: 0.2832 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2800 - accuracy: 0.8872 - val_loss: 0.3939 - val_accuracy: 0.8460\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.87 - ETA: 0s - loss: 0.2653 - accuracy: 0.89 - ETA: 0s - loss: 0.2732 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8898 - val_loss: 0.4082 - val_accuracy: 0.8470\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.90 - ETA: 0s - loss: 0.2733 - accuracy: 0.88 - ETA: 0s - loss: 0.2645 - accuracy: 0.89 - ETA: 0s - loss: 0.2746 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8888 - val_loss: 0.4162 - val_accuracy: 0.8470\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.96 - ETA: 0s - loss: 0.2666 - accuracy: 0.89 - ETA: 0s - loss: 0.2756 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8890 - val_loss: 0.4023 - val_accuracy: 0.8500\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.87 - ETA: 0s - loss: 0.2608 - accuracy: 0.89 - ETA: 0s - loss: 0.2697 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8893 - val_loss: 0.4064 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.87 - ETA: 0s - loss: 0.2707 - accuracy: 0.89 - ETA: 0s - loss: 0.2719 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2726 - accuracy: 0.8895 - val_loss: 0.4190 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.93 - ETA: 0s - loss: 0.2697 - accuracy: 0.89 - ETA: 0s - loss: 0.2704 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2704 - accuracy: 0.8905 - val_loss: 0.4027 - val_accuracy: 0.8460\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.84 - ETA: 0s - loss: 0.2653 - accuracy: 0.88 - ETA: 0s - loss: 0.2722 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2708 - accuracy: 0.8900 - val_loss: 0.3957 - val_accuracy: 0.8520\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.87 - ETA: 0s - loss: 0.2572 - accuracy: 0.89 - ETA: 0s - loss: 0.2666 - accuracy: 0.89 - ETA: 0s - loss: 0.2691 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8918 - val_loss: 0.4159 - val_accuracy: 0.8470\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.90 - ETA: 0s - loss: 0.2555 - accuracy: 0.89 - ETA: 0s - loss: 0.2626 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8938 - val_loss: 0.4145 - val_accuracy: 0.8455\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.96 - ETA: 0s - loss: 0.2615 - accuracy: 0.90 - ETA: 0s - loss: 0.2599 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2669 - accuracy: 0.8957 - val_loss: 0.4254 - val_accuracy: 0.8480\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 1.00 - ETA: 0s - loss: 0.2588 - accuracy: 0.89 - ETA: 0s - loss: 0.2644 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.4232 - val_accuracy: 0.8510\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.93 - ETA: 0s - loss: 0.2446 - accuracy: 0.89 - ETA: 0s - loss: 0.2575 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2622 - accuracy: 0.8960 - val_loss: 0.4134 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.84 - ETA: 0s - loss: 0.2554 - accuracy: 0.89 - ETA: 0s - loss: 0.2627 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8920 - val_loss: 0.4467 - val_accuracy: 0.8465\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.93 - ETA: 0s - loss: 0.2656 - accuracy: 0.89 - ETA: 0s - loss: 0.2601 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8948 - val_loss: 0.4415 - val_accuracy: 0.8435\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.90 - ETA: 0s - loss: 0.2634 - accuracy: 0.89 - ETA: 0s - loss: 0.2591 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2615 - accuracy: 0.8963 - val_loss: 0.4324 - val_accuracy: 0.8460\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.81 - ETA: 0s - loss: 0.2469 - accuracy: 0.89 - ETA: 0s - loss: 0.2444 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8965 - val_loss: 0.4366 - val_accuracy: 0.8470\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.87 - ETA: 0s - loss: 0.2521 - accuracy: 0.89 - ETA: 0s - loss: 0.2491 - accuracy: 0.89 - 0s 985us/step - loss: 0.2534 - accuracy: 0.8975 - val_loss: 0.4661 - val_accuracy: 0.8340\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.87 - ETA: 0s - loss: 0.2638 - accuracy: 0.89 - ETA: 0s - loss: 0.2620 - accuracy: 0.89 - ETA: 0s - loss: 0.2582 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8972 - val_loss: 0.4523 - val_accuracy: 0.8440\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.90 - ETA: 0s - loss: 0.2573 - accuracy: 0.90 - ETA: 0s - loss: 0.2571 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2594 - accuracy: 0.8952 - val_loss: 0.4561 - val_accuracy: 0.8410\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.87 - ETA: 0s - loss: 0.2447 - accuracy: 0.90 - ETA: 0s - loss: 0.2508 - accuracy: 0.89 - ETA: 0s - loss: 0.2509 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2522 - accuracy: 0.8968 - val_loss: 0.4689 - val_accuracy: 0.8495\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.96 - ETA: 0s - loss: 0.2365 - accuracy: 0.90 - ETA: 0s - loss: 0.2511 - accuracy: 0.90 - 0s 978us/step - loss: 0.2540 - accuracy: 0.8978 - val_loss: 0.4683 - val_accuracy: 0.8380\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.87 - ETA: 0s - loss: 0.2488 - accuracy: 0.90 - ETA: 0s - loss: 0.2514 - accuracy: 0.89 - 0s 985us/step - loss: 0.2513 - accuracy: 0.8975 - val_loss: 0.4792 - val_accuracy: 0.8420\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.90 - ETA: 0s - loss: 0.2468 - accuracy: 0.90 - ETA: 0s - loss: 0.2451 - accuracy: 0.90 - ETA: 0s - loss: 0.2533 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2532 - accuracy: 0.8980 - val_loss: 0.4257 - val_accuracy: 0.8435\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.87 - ETA: 0s - loss: 0.2552 - accuracy: 0.89 - ETA: 0s - loss: 0.2543 - accuracy: 0.89 - 0s 1ms/step - loss: 0.2537 - accuracy: 0.8955 - val_loss: 0.4888 - val_accuracy: 0.8350\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.87 - ETA: 0s - loss: 0.2393 - accuracy: 0.90 - ETA: 0s - loss: 0.2402 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2449 - accuracy: 0.9043 - val_loss: 0.4941 - val_accuracy: 0.8320\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.96 - ETA: 0s - loss: 0.2403 - accuracy: 0.90 - ETA: 0s - loss: 0.2503 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2464 - accuracy: 0.9043 - val_loss: 0.4669 - val_accuracy: 0.8465\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.96 - ETA: 0s - loss: 0.2341 - accuracy: 0.90 - ETA: 0s - loss: 0.2452 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9022 - val_loss: 0.4794 - val_accuracy: 0.8455\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.93 - ETA: 0s - loss: 0.2367 - accuracy: 0.90 - ETA: 0s - loss: 0.2422 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2488 - accuracy: 0.9013 - val_loss: 0.4788 - val_accuracy: 0.8385\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.87 - ETA: 0s - loss: 0.2562 - accuracy: 0.90 - ETA: 0s - loss: 0.2441 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2472 - accuracy: 0.9028 - val_loss: 0.4985 - val_accuracy: 0.8430\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.87 - ETA: 0s - loss: 0.2427 - accuracy: 0.90 - ETA: 0s - loss: 0.2417 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9012 - val_loss: 0.5000 - val_accuracy: 0.8415\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2512 - accuracy: 0.90 - ETA: 0s - loss: 0.2223 - accuracy: 0.91 - ETA: 0s - loss: 0.2386 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8997 - val_loss: 0.4757 - val_accuracy: 0.8385\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 1.00 - ETA: 0s - loss: 0.2357 - accuracy: 0.91 - ETA: 0s - loss: 0.2417 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2449 - accuracy: 0.9025 - val_loss: 0.4740 - val_accuracy: 0.8375\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 1.00 - ETA: 0s - loss: 0.2467 - accuracy: 0.89 - ETA: 0s - loss: 0.2420 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9018 - val_loss: 0.4859 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.81 - ETA: 0s - loss: 0.2403 - accuracy: 0.89 - ETA: 0s - loss: 0.2356 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9058 - val_loss: 0.5016 - val_accuracy: 0.8390\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.84 - ETA: 0s - loss: 0.2272 - accuracy: 0.91 - ETA: 0s - loss: 0.2305 - accuracy: 0.90 - ETA: 0s - loss: 0.2337 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9040 - val_loss: 0.4974 - val_accuracy: 0.8335\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.84 - ETA: 0s - loss: 0.2372 - accuracy: 0.90 - ETA: 0s - loss: 0.2368 - accuracy: 0.90 - ETA: 0s - loss: 0.2344 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9068 - val_loss: 0.5072 - val_accuracy: 0.8435\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.90 - ETA: 0s - loss: 0.2192 - accuracy: 0.91 - ETA: 0s - loss: 0.2215 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9060 - val_loss: 0.5408 - val_accuracy: 0.8335\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.87 - ETA: 0s - loss: 0.2277 - accuracy: 0.91 - ETA: 0s - loss: 0.2303 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9058 - val_loss: 0.5117 - val_accuracy: 0.8425\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.93 - ETA: 0s - loss: 0.2266 - accuracy: 0.90 - ETA: 0s - loss: 0.2386 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9042 - val_loss: 0.4990 - val_accuracy: 0.8375\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.90 - ETA: 0s - loss: 0.2237 - accuracy: 0.91 - ETA: 0s - loss: 0.2213 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9083 - val_loss: 0.4715 - val_accuracy: 0.8350\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.87 - ETA: 0s - loss: 0.2487 - accuracy: 0.90 - ETA: 0s - loss: 0.2359 - accuracy: 0.90 - ETA: 0s - loss: 0.2417 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2421 - accuracy: 0.9030 - val_loss: 0.5104 - val_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.87 - ETA: 0s - loss: 0.2314 - accuracy: 0.91 - ETA: 0s - loss: 0.2313 - accuracy: 0.90 - 0s 999us/step - loss: 0.2335 - accuracy: 0.9090 - val_loss: 0.5496 - val_accuracy: 0.8330\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.84 - ETA: 0s - loss: 0.2387 - accuracy: 0.90 - ETA: 0s - loss: 0.2283 - accuracy: 0.90 - 0s 999us/step - loss: 0.2333 - accuracy: 0.9067 - val_loss: 0.5416 - val_accuracy: 0.8385\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.84 - ETA: 0s - loss: 0.2432 - accuracy: 0.90 - ETA: 0s - loss: 0.2250 - accuracy: 0.91 - ETA: 0s - loss: 0.2290 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9072 - val_loss: 0.5329 - val_accuracy: 0.8270\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.96 - ETA: 0s - loss: 0.2413 - accuracy: 0.90 - ETA: 0s - loss: 0.2319 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9072 - val_loss: 0.5595 - val_accuracy: 0.8280\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.78 - ETA: 0s - loss: 0.2090 - accuracy: 0.92 - ETA: 0s - loss: 0.2222 - accuracy: 0.91 - ETA: 0s - loss: 0.2241 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9108 - val_loss: 0.5353 - val_accuracy: 0.8350\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.84 - ETA: 0s - loss: 0.1923 - accuracy: 0.93 - ETA: 0s - loss: 0.2153 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9132 - val_loss: 0.5435 - val_accuracy: 0.8375\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.84 - ETA: 0s - loss: 0.2062 - accuracy: 0.91 - ETA: 0s - loss: 0.2155 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9103 - val_loss: 0.5757 - val_accuracy: 0.8320\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.90 - ETA: 0s - loss: 0.2304 - accuracy: 0.90 - ETA: 0s - loss: 0.2265 - accuracy: 0.90 - ETA: 0s - loss: 0.2288 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9067 - val_loss: 0.5621 - val_accuracy: 0.8315\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.87 - ETA: 0s - loss: 0.2222 - accuracy: 0.91 - ETA: 0s - loss: 0.2251 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9097 - val_loss: 0.5301 - val_accuracy: 0.8365\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.96 - ETA: 0s - loss: 0.2262 - accuracy: 0.91 - ETA: 0s - loss: 0.2207 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9150 - val_loss: 0.5620 - val_accuracy: 0.8335\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.90 - ETA: 0s - loss: 0.1923 - accuracy: 0.92 - ETA: 0s - loss: 0.2201 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9093 - val_loss: 0.5161 - val_accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.87 - ETA: 0s - loss: 0.2431 - accuracy: 0.90 - ETA: 0s - loss: 0.2316 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9092 - val_loss: 0.5410 - val_accuracy: 0.8350\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.90 - ETA: 0s - loss: 0.2102 - accuracy: 0.91 - ETA: 0s - loss: 0.2101 - accuracy: 0.91 - ETA: 0s - loss: 0.2108 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9125 - val_loss: 0.5285 - val_accuracy: 0.8315\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 1.00 - ETA: 0s - loss: 0.2176 - accuracy: 0.91 - ETA: 0s - loss: 0.2188 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9132 - val_loss: 0.5972 - val_accuracy: 0.8335\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 1.00 - ETA: 0s - loss: 0.2127 - accuracy: 0.91 - ETA: 0s - loss: 0.2230 - accuracy: 0.90 - ETA: 0s - loss: 0.2190 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9125 - val_loss: 0.5712 - val_accuracy: 0.8385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d8beb56014fb7dc9eac2ff61cbcdbaaf</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859000027179718</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.68 - ETA: 0s - loss: 0.5876 - accuracy: 0.80 - ETA: 0s - loss: 0.5659 - accuracy: 0.80 - ETA: 0s - loss: 0.5491 - accuracy: 0.79 - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7948 - val_loss: 0.4960 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4864 - accuracy: 0.78 - ETA: 0s - loss: 0.4937 - accuracy: 0.79 - ETA: 0s - loss: 0.4911 - accuracy: 0.79 - ETA: 0s - loss: 0.4877 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7948 - val_loss: 0.4740 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.75 - ETA: 0s - loss: 0.4623 - accuracy: 0.79 - ETA: 0s - loss: 0.4627 - accuracy: 0.79 - ETA: 0s - loss: 0.4658 - accuracy: 0.79 - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7948 - val_loss: 0.4687 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.75 - ETA: 0s - loss: 0.4752 - accuracy: 0.78 - ETA: 0s - loss: 0.4691 - accuracy: 0.78 - ETA: 0s - loss: 0.4698 - accuracy: 0.79 - ETA: 0s - loss: 0.4644 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7948 - val_loss: 0.4646 - val_accuracy: 0.7995\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.84 - ETA: 0s - loss: 0.4443 - accuracy: 0.79 - ETA: 0s - loss: 0.4485 - accuracy: 0.80 - ETA: 0s - loss: 0.4417 - accuracy: 0.80 - ETA: 0s - loss: 0.4507 - accuracy: 0.80 - ETA: 0s - loss: 0.4563 - accuracy: 0.79 - ETA: 0s - loss: 0.4593 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7948 - val_loss: 0.4606 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.93 - ETA: 0s - loss: 0.4436 - accuracy: 0.80 - ETA: 0s - loss: 0.4520 - accuracy: 0.80 - ETA: 0s - loss: 0.4492 - accuracy: 0.80 - ETA: 0s - loss: 0.4553 - accuracy: 0.79 - ETA: 0s - loss: 0.4557 - accuracy: 0.79 - ETA: 0s - loss: 0.4551 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7948 - val_loss: 0.4571 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.84 - ETA: 0s - loss: 0.4719 - accuracy: 0.77 - ETA: 0s - loss: 0.4563 - accuracy: 0.78 - ETA: 0s - loss: 0.4532 - accuracy: 0.79 - ETA: 0s - loss: 0.4526 - accuracy: 0.79 - ETA: 0s - loss: 0.4549 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7948 - val_loss: 0.4541 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.65 - ETA: 0s - loss: 0.4292 - accuracy: 0.80 - ETA: 0s - loss: 0.4446 - accuracy: 0.79 - ETA: 0s - loss: 0.4439 - accuracy: 0.80 - ETA: 0s - loss: 0.4536 - accuracy: 0.79 - ETA: 0s - loss: 0.4450 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7948 - val_loss: 0.4510 - val_accuracy: 0.7995\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.75 - ETA: 0s - loss: 0.4257 - accuracy: 0.80 - ETA: 0s - loss: 0.4372 - accuracy: 0.80 - ETA: 0s - loss: 0.4392 - accuracy: 0.79 - ETA: 0s - loss: 0.4403 - accuracy: 0.79 - ETA: 0s - loss: 0.4409 - accuracy: 0.79 - ETA: 0s - loss: 0.4427 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7948 - val_loss: 0.4479 - val_accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.81 - ETA: 0s - loss: 0.4291 - accuracy: 0.81 - ETA: 0s - loss: 0.4406 - accuracy: 0.79 - ETA: 0s - loss: 0.4428 - accuracy: 0.79 - ETA: 0s - loss: 0.4411 - accuracy: 0.79 - ETA: 0s - loss: 0.4416 - accuracy: 0.79 - ETA: 0s - loss: 0.4411 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7948 - val_loss: 0.4450 - val_accuracy: 0.7995\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.81 - ETA: 0s - loss: 0.4529 - accuracy: 0.78 - ETA: 0s - loss: 0.4344 - accuracy: 0.79 - ETA: 0s - loss: 0.4411 - accuracy: 0.79 - ETA: 0s - loss: 0.4404 - accuracy: 0.79 - ETA: 0s - loss: 0.4413 - accuracy: 0.79 - ETA: 0s - loss: 0.4370 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7948 - val_loss: 0.4424 - val_accuracy: 0.7995\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.71 - ETA: 0s - loss: 0.4477 - accuracy: 0.78 - ETA: 0s - loss: 0.4387 - accuracy: 0.78 - ETA: 0s - loss: 0.4343 - accuracy: 0.78 - ETA: 0s - loss: 0.4379 - accuracy: 0.79 - ETA: 0s - loss: 0.4327 - accuracy: 0.79 - ETA: 0s - loss: 0.4344 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7948 - val_loss: 0.4397 - val_accuracy: 0.7995\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3999 - accuracy: 0.81 - ETA: 0s - loss: 0.4439 - accuracy: 0.79 - ETA: 0s - loss: 0.4461 - accuracy: 0.78 - ETA: 0s - loss: 0.4492 - accuracy: 0.78 - ETA: 0s - loss: 0.4446 - accuracy: 0.78 - ETA: 0s - loss: 0.4357 - accuracy: 0.78 - ETA: 0s - loss: 0.4314 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7948 - val_loss: 0.4383 - val_accuracy: 0.7995\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.78 - ETA: 0s - loss: 0.4347 - accuracy: 0.79 - ETA: 0s - loss: 0.4253 - accuracy: 0.80 - ETA: 0s - loss: 0.4285 - accuracy: 0.79 - ETA: 0s - loss: 0.4293 - accuracy: 0.79 - ETA: 0s - loss: 0.4320 - accuracy: 0.79 - ETA: 0s - loss: 0.4291 - accuracy: 0.79 - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7948 - val_loss: 0.4357 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.78 - ETA: 0s - loss: 0.4315 - accuracy: 0.79 - ETA: 0s - loss: 0.4310 - accuracy: 0.79 - ETA: 0s - loss: 0.4292 - accuracy: 0.80 - ETA: 0s - loss: 0.4306 - accuracy: 0.80 - ETA: 0s - loss: 0.4285 - accuracy: 0.79 - ETA: 0s - loss: 0.4262 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7993 - val_loss: 0.4339 - val_accuracy: 0.8055\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.87 - ETA: 0s - loss: 0.4342 - accuracy: 0.79 - ETA: 0s - loss: 0.4450 - accuracy: 0.79 - ETA: 0s - loss: 0.4425 - accuracy: 0.79 - ETA: 0s - loss: 0.4300 - accuracy: 0.80 - ETA: 0s - loss: 0.4256 - accuracy: 0.80 - ETA: 0s - loss: 0.4233 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8045 - val_loss: 0.4325 - val_accuracy: 0.8075\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.81 - ETA: 0s - loss: 0.4100 - accuracy: 0.80 - ETA: 0s - loss: 0.4293 - accuracy: 0.79 - ETA: 0s - loss: 0.4288 - accuracy: 0.80 - ETA: 0s - loss: 0.4297 - accuracy: 0.80 - ETA: 0s - loss: 0.4254 - accuracy: 0.80 - ETA: 0s - loss: 0.4251 - accuracy: 0.80 - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8082 - val_loss: 0.4309 - val_accuracy: 0.8105\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.84 - ETA: 0s - loss: 0.4233 - accuracy: 0.80 - ETA: 0s - loss: 0.4066 - accuracy: 0.81 - ETA: 0s - loss: 0.4138 - accuracy: 0.81 - ETA: 0s - loss: 0.4169 - accuracy: 0.81 - ETA: 0s - loss: 0.4220 - accuracy: 0.80 - ETA: 0s - loss: 0.4223 - accuracy: 0.80 - 1s 3ms/step - loss: 0.4210 - accuracy: 0.8107 - val_loss: 0.4293 - val_accuracy: 0.8125\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.68 - ETA: 0s - loss: 0.4179 - accuracy: 0.81 - ETA: 0s - loss: 0.4267 - accuracy: 0.81 - ETA: 0s - loss: 0.4164 - accuracy: 0.81 - ETA: 0s - loss: 0.4181 - accuracy: 0.81 - ETA: 0s - loss: 0.4141 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8138 - val_loss: 0.4279 - val_accuracy: 0.8140\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.87 - ETA: 0s - loss: 0.4164 - accuracy: 0.81 - ETA: 0s - loss: 0.4087 - accuracy: 0.81 - ETA: 0s - loss: 0.4135 - accuracy: 0.81 - ETA: 0s - loss: 0.4147 - accuracy: 0.81 - ETA: 0s - loss: 0.4197 - accuracy: 0.81 - ETA: 0s - loss: 0.4166 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8160 - val_loss: 0.4265 - val_accuracy: 0.8150\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.93 - ETA: 0s - loss: 0.3897 - accuracy: 0.83 - ETA: 0s - loss: 0.4118 - accuracy: 0.82 - ETA: 0s - loss: 0.4165 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8183 - val_loss: 0.4252 - val_accuracy: 0.8150\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.84 - ETA: 0s - loss: 0.4388 - accuracy: 0.80 - ETA: 0s - loss: 0.4179 - accuracy: 0.81 - ETA: 0s - loss: 0.4146 - accuracy: 0.81 - ETA: 0s - loss: 0.4094 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8185 - val_loss: 0.4243 - val_accuracy: 0.8145\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.87 - ETA: 0s - loss: 0.4149 - accuracy: 0.81 - ETA: 0s - loss: 0.4144 - accuracy: 0.82 - ETA: 0s - loss: 0.4187 - accuracy: 0.81 - ETA: 0s - loss: 0.4155 - accuracy: 0.81 - ETA: 0s - loss: 0.4126 - accuracy: 0.81 - ETA: 0s - loss: 0.4121 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8190 - val_loss: 0.4231 - val_accuracy: 0.8160\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.75 - ETA: 0s - loss: 0.4273 - accuracy: 0.81 - ETA: 0s - loss: 0.4065 - accuracy: 0.82 - ETA: 0s - loss: 0.4077 - accuracy: 0.82 - ETA: 0s - loss: 0.4110 - accuracy: 0.81 - ETA: 0s - loss: 0.4102 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8217 - val_loss: 0.4216 - val_accuracy: 0.8180\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.84 - ETA: 0s - loss: 0.3900 - accuracy: 0.83 - ETA: 0s - loss: 0.3976 - accuracy: 0.82 - ETA: 0s - loss: 0.4089 - accuracy: 0.82 - ETA: 0s - loss: 0.4153 - accuracy: 0.81 - ETA: 0s - loss: 0.4088 - accuracy: 0.82 - ETA: 0s - loss: 0.4084 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8212 - val_loss: 0.4203 - val_accuracy: 0.8215\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.87 - ETA: 0s - loss: 0.3895 - accuracy: 0.84 - ETA: 0s - loss: 0.4016 - accuracy: 0.82 - ETA: 0s - loss: 0.4043 - accuracy: 0.82 - ETA: 0s - loss: 0.4075 - accuracy: 0.81 - ETA: 0s - loss: 0.4128 - accuracy: 0.82 - ETA: 0s - loss: 0.4066 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8228 - val_loss: 0.4190 - val_accuracy: 0.8195\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.81 - ETA: 0s - loss: 0.4121 - accuracy: 0.82 - ETA: 0s - loss: 0.4012 - accuracy: 0.83 - ETA: 0s - loss: 0.3982 - accuracy: 0.82 - ETA: 0s - loss: 0.3970 - accuracy: 0.83 - ETA: 0s - loss: 0.3970 - accuracy: 0.82 - ETA: 0s - loss: 0.4042 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8232 - val_loss: 0.4180 - val_accuracy: 0.8160\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.87 - ETA: 0s - loss: 0.4223 - accuracy: 0.80 - ETA: 0s - loss: 0.4123 - accuracy: 0.81 - ETA: 0s - loss: 0.4104 - accuracy: 0.81 - ETA: 0s - loss: 0.4090 - accuracy: 0.81 - ETA: 0s - loss: 0.4066 - accuracy: 0.82 - ETA: 0s - loss: 0.4051 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8263 - val_loss: 0.4173 - val_accuracy: 0.8205\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.87 - ETA: 0s - loss: 0.4084 - accuracy: 0.82 - ETA: 0s - loss: 0.3885 - accuracy: 0.82 - ETA: 0s - loss: 0.3979 - accuracy: 0.82 - ETA: 0s - loss: 0.3981 - accuracy: 0.83 - ETA: 0s - loss: 0.4031 - accuracy: 0.82 - ETA: 0s - loss: 0.4015 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8278 - val_loss: 0.4157 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.87 - ETA: 0s - loss: 0.3898 - accuracy: 0.83 - ETA: 0s - loss: 0.3973 - accuracy: 0.82 - ETA: 0s - loss: 0.4005 - accuracy: 0.82 - ETA: 0s - loss: 0.4033 - accuracy: 0.82 - ETA: 0s - loss: 0.4014 - accuracy: 0.82 - ETA: 0s - loss: 0.4004 - accuracy: 0.82 - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8268 - val_loss: 0.4143 - val_accuracy: 0.8220\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.81 - ETA: 0s - loss: 0.4214 - accuracy: 0.80 - ETA: 0s - loss: 0.4139 - accuracy: 0.81 - ETA: 0s - loss: 0.4106 - accuracy: 0.82 - ETA: 0s - loss: 0.4021 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8293 - val_loss: 0.4142 - val_accuracy: 0.8225\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.90 - ETA: 0s - loss: 0.3863 - accuracy: 0.82 - ETA: 0s - loss: 0.4028 - accuracy: 0.82 - ETA: 0s - loss: 0.3944 - accuracy: 0.82 - ETA: 0s - loss: 0.3974 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8293 - val_loss: 0.4134 - val_accuracy: 0.8220\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.81 - ETA: 0s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.3967 - accuracy: 0.82 - ETA: 0s - loss: 0.4002 - accuracy: 0.82 - 0s 1ms/step - loss: 0.3952 - accuracy: 0.8288 - val_loss: 0.4117 - val_accuracy: 0.8220\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.81 - ETA: 0s - loss: 0.4123 - accuracy: 0.81 - ETA: 0s - loss: 0.3942 - accuracy: 0.83 - ETA: 0s - loss: 0.3986 - accuracy: 0.82 - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8303 - val_loss: 0.4102 - val_accuracy: 0.8205\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.84 - ETA: 0s - loss: 0.3952 - accuracy: 0.82 - ETA: 0s - loss: 0.3933 - accuracy: 0.83 - ETA: 0s - loss: 0.3953 - accuracy: 0.82 - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8317 - val_loss: 0.4089 - val_accuracy: 0.8215\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.81 - ETA: 0s - loss: 0.4042 - accuracy: 0.82 - ETA: 0s - loss: 0.3992 - accuracy: 0.83 - ETA: 0s - loss: 0.3970 - accuracy: 0.82 - ETA: 0s - loss: 0.3899 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8323 - val_loss: 0.4084 - val_accuracy: 0.8230\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.75 - ETA: 0s - loss: 0.4009 - accuracy: 0.83 - ETA: 0s - loss: 0.4050 - accuracy: 0.82 - ETA: 0s - loss: 0.3969 - accuracy: 0.82 - ETA: 0s - loss: 0.3935 - accuracy: 0.82 - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8325 - val_loss: 0.4073 - val_accuracy: 0.8250\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.81 - ETA: 0s - loss: 0.3710 - accuracy: 0.83 - ETA: 0s - loss: 0.3738 - accuracy: 0.83 - ETA: 0s - loss: 0.3837 - accuracy: 0.83 - ETA: 0s - loss: 0.3873 - accuracy: 0.83 - ETA: 0s - loss: 0.3824 - accuracy: 0.83 - ETA: 0s - loss: 0.3868 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8340 - val_loss: 0.4056 - val_accuracy: 0.8235\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.84 - ETA: 0s - loss: 0.4040 - accuracy: 0.82 - ETA: 0s - loss: 0.4031 - accuracy: 0.82 - ETA: 0s - loss: 0.3933 - accuracy: 0.83 - ETA: 0s - loss: 0.3924 - accuracy: 0.83 - ETA: 0s - loss: 0.3850 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8372 - val_loss: 0.4047 - val_accuracy: 0.8250\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.84 - ETA: 0s - loss: 0.4110 - accuracy: 0.80 - ETA: 0s - loss: 0.3963 - accuracy: 0.82 - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.3890 - accuracy: 0.83 - ETA: 0s - loss: 0.3914 - accuracy: 0.83 - ETA: 0s - loss: 0.3871 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3850 - accuracy: 0.8353 - val_loss: 0.4051 - val_accuracy: 0.8270\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.93 - ETA: 0s - loss: 0.3879 - accuracy: 0.83 - ETA: 0s - loss: 0.3779 - accuracy: 0.84 - ETA: 0s - loss: 0.3927 - accuracy: 0.83 - ETA: 0s - loss: 0.3856 - accuracy: 0.83 - ETA: 0s - loss: 0.3839 - accuracy: 0.83 - ETA: 0s - loss: 0.3825 - accuracy: 0.83 - 1s 3ms/step - loss: 0.3841 - accuracy: 0.8365 - val_loss: 0.4023 - val_accuracy: 0.8275\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.81 - ETA: 0s - loss: 0.3746 - accuracy: 0.82 - ETA: 0s - loss: 0.3836 - accuracy: 0.83 - ETA: 0s - loss: 0.3813 - accuracy: 0.83 - ETA: 0s - loss: 0.3843 - accuracy: 0.83 - ETA: 0s - loss: 0.3875 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8382 - val_loss: 0.4014 - val_accuracy: 0.8285\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.90 - ETA: 0s - loss: 0.3697 - accuracy: 0.84 - ETA: 0s - loss: 0.3734 - accuracy: 0.84 - ETA: 0s - loss: 0.3826 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8373 - val_loss: 0.4002 - val_accuracy: 0.8260\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.71 - ETA: 0s - loss: 0.3711 - accuracy: 0.85 - ETA: 0s - loss: 0.3798 - accuracy: 0.84 - ETA: 0s - loss: 0.3790 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8392 - val_loss: 0.3997 - val_accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.71 - ETA: 0s - loss: 0.3971 - accuracy: 0.82 - ETA: 0s - loss: 0.3815 - accuracy: 0.83 - ETA: 0s - loss: 0.3828 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8393 - val_loss: 0.3988 - val_accuracy: 0.8290\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.87 - ETA: 0s - loss: 0.3828 - accuracy: 0.83 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - ETA: 0s - loss: 0.3778 - accuracy: 0.83 - ETA: 0s - loss: 0.3805 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8402 - val_loss: 0.3974 - val_accuracy: 0.8295\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.78 - ETA: 0s - loss: 0.3599 - accuracy: 0.85 - ETA: 0s - loss: 0.3682 - accuracy: 0.84 - ETA: 0s - loss: 0.3761 - accuracy: 0.83 - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8397 - val_loss: 0.3964 - val_accuracy: 0.8275\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.71 - ETA: 0s - loss: 0.3819 - accuracy: 0.83 - ETA: 0s - loss: 0.3684 - accuracy: 0.83 - ETA: 0s - loss: 0.3756 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8400 - val_loss: 0.3958 - val_accuracy: 0.8300\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.87 - ETA: 0s - loss: 0.3812 - accuracy: 0.84 - ETA: 0s - loss: 0.3810 - accuracy: 0.83 - ETA: 0s - loss: 0.3761 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8415 - val_loss: 0.3947 - val_accuracy: 0.8300\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.87 - ETA: 0s - loss: 0.3688 - accuracy: 0.84 - ETA: 0s - loss: 0.3759 - accuracy: 0.84 - ETA: 0s - loss: 0.3743 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8423 - val_loss: 0.3942 - val_accuracy: 0.8315\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.81 - ETA: 0s - loss: 0.3893 - accuracy: 0.83 - ETA: 0s - loss: 0.3768 - accuracy: 0.84 - ETA: 0s - loss: 0.3724 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8440 - val_loss: 0.3932 - val_accuracy: 0.8300\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.71 - ETA: 0s - loss: 0.3762 - accuracy: 0.83 - ETA: 0s - loss: 0.3687 - accuracy: 0.84 - ETA: 0s - loss: 0.3751 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8442 - val_loss: 0.3927 - val_accuracy: 0.8320\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.68 - ETA: 0s - loss: 0.3640 - accuracy: 0.84 - ETA: 0s - loss: 0.3655 - accuracy: 0.84 - ETA: 0s - loss: 0.3703 - accuracy: 0.84 - ETA: 0s - loss: 0.3694 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8442 - val_loss: 0.3920 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.78 - ETA: 0s - loss: 0.3789 - accuracy: 0.83 - ETA: 0s - loss: 0.3729 - accuracy: 0.84 - ETA: 0s - loss: 0.3655 - accuracy: 0.84 - ETA: 0s - loss: 0.3671 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8447 - val_loss: 0.3915 - val_accuracy: 0.8315\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.87 - ETA: 0s - loss: 0.3624 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3710 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8452 - val_loss: 0.3902 - val_accuracy: 0.8325\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.84 - ETA: 0s - loss: 0.3848 - accuracy: 0.83 - ETA: 0s - loss: 0.3602 - accuracy: 0.84 - ETA: 0s - loss: 0.3706 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.3901 - val_accuracy: 0.8335\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.75 - ETA: 0s - loss: 0.3633 - accuracy: 0.85 - ETA: 0s - loss: 0.3655 - accuracy: 0.84 - ETA: 0s - loss: 0.3635 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8460 - val_loss: 0.3887 - val_accuracy: 0.8295\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.78 - ETA: 0s - loss: 0.3527 - accuracy: 0.84 - ETA: 0s - loss: 0.3633 - accuracy: 0.84 - ETA: 0s - loss: 0.3634 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8468 - val_loss: 0.3879 - val_accuracy: 0.8335\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.81 - ETA: 0s - loss: 0.3582 - accuracy: 0.84 - ETA: 0s - loss: 0.3606 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8468 - val_loss: 0.3870 - val_accuracy: 0.8305\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.84 - ETA: 0s - loss: 0.3592 - accuracy: 0.84 - ETA: 0s - loss: 0.3597 - accuracy: 0.84 - 0s 986us/step - loss: 0.3621 - accuracy: 0.8475 - val_loss: 0.3865 - val_accuracy: 0.8320\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.65 - ETA: 0s - loss: 0.3705 - accuracy: 0.84 - ETA: 0s - loss: 0.3659 - accuracy: 0.84 - 0s 948us/step - loss: 0.3611 - accuracy: 0.8485 - val_loss: 0.3857 - val_accuracy: 0.8335\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2627 - accuracy: 0.90 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3611 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8488 - val_loss: 0.3848 - val_accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.87 - ETA: 0s - loss: 0.3401 - accuracy: 0.86 - ETA: 0s - loss: 0.3570 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8485 - val_loss: 0.3833 - val_accuracy: 0.8350\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.96 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3610 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8497 - val_loss: 0.3831 - val_accuracy: 0.8355\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.78 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3439 - accuracy: 0.85 - ETA: 0s - loss: 0.3573 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8495 - val_loss: 0.3822 - val_accuracy: 0.8350\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.78 - ETA: 0s - loss: 0.3642 - accuracy: 0.84 - ETA: 0s - loss: 0.3590 - accuracy: 0.84 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8508 - val_loss: 0.3813 - val_accuracy: 0.8355\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.84 - ETA: 0s - loss: 0.3395 - accuracy: 0.86 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - 0s 973us/step - loss: 0.3554 - accuracy: 0.8512 - val_loss: 0.3805 - val_accuracy: 0.8355\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.62 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8508 - val_loss: 0.3802 - val_accuracy: 0.8370\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.96 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8512 - val_loss: 0.3787 - val_accuracy: 0.8375\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.84 - ETA: 0s - loss: 0.3623 - accuracy: 0.84 - ETA: 0s - loss: 0.3576 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8522 - val_loss: 0.3788 - val_accuracy: 0.8385\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.90 - ETA: 0s - loss: 0.3612 - accuracy: 0.84 - ETA: 0s - loss: 0.3571 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8522 - val_loss: 0.3788 - val_accuracy: 0.8395\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 1.00 - ETA: 0s - loss: 0.3592 - accuracy: 0.85 - ETA: 0s - loss: 0.3594 - accuracy: 0.84 - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8525 - val_loss: 0.3775 - val_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.84 - ETA: 0s - loss: 0.3472 - accuracy: 0.84 - ETA: 0s - loss: 0.3419 - accuracy: 0.85 - ETA: 0s - loss: 0.3489 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8523 - val_loss: 0.3760 - val_accuracy: 0.8400\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.90 - ETA: 0s - loss: 0.3472 - accuracy: 0.86 - ETA: 0s - loss: 0.3486 - accuracy: 0.86 - ETA: 0s - loss: 0.3510 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8520 - val_loss: 0.3753 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.96 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3428 - accuracy: 0.85 - ETA: 0s - loss: 0.3400 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.84 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3476 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8522 - val_loss: 0.3745 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.84 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.85 - ETA: 0s - loss: 0.3362 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8538 - val_loss: 0.3737 - val_accuracy: 0.8390\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.84 - ETA: 0s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3473 - accuracy: 0.85 - ETA: 0s - loss: 0.3503 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3473 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8538 - val_loss: 0.3735 - val_accuracy: 0.8420\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.81 - ETA: 0s - loss: 0.3521 - accuracy: 0.83 - ETA: 0s - loss: 0.3326 - accuracy: 0.85 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8538 - val_loss: 0.3727 - val_accuracy: 0.8415\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.81 - ETA: 0s - loss: 0.3312 - accuracy: 0.85 - ETA: 0s - loss: 0.3439 - accuracy: 0.84 - ETA: 0s - loss: 0.3406 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8545 - val_loss: 0.3716 - val_accuracy: 0.8425\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.93 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3380 - accuracy: 0.86 - ETA: 0s - loss: 0.3418 - accuracy: 0.85 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - ETA: 0s - loss: 0.3410 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8543 - val_loss: 0.3713 - val_accuracy: 0.8465\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.93 - ETA: 0s - loss: 0.3490 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3350 - accuracy: 0.85 - ETA: 0s - loss: 0.3364 - accuracy: 0.85 - ETA: 0s - loss: 0.3437 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8547 - val_loss: 0.3702 - val_accuracy: 0.8415\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.84 - ETA: 0s - loss: 0.3412 - accuracy: 0.85 - ETA: 0s - loss: 0.3396 - accuracy: 0.85 - ETA: 0s - loss: 0.3405 - accuracy: 0.85 - ETA: 0s - loss: 0.3364 - accuracy: 0.85 - ETA: 0s - loss: 0.3347 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8557 - val_loss: 0.3703 - val_accuracy: 0.8410\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.84 - ETA: 0s - loss: 0.3296 - accuracy: 0.85 - ETA: 0s - loss: 0.3203 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.85 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - ETA: 0s - loss: 0.3407 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8567 - val_loss: 0.3692 - val_accuracy: 0.8440\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.81 - ETA: 0s - loss: 0.3239 - accuracy: 0.86 - ETA: 0s - loss: 0.3357 - accuracy: 0.85 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8570 - val_loss: 0.3684 - val_accuracy: 0.8465\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.84 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8575 - val_loss: 0.3674 - val_accuracy: 0.8470\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.87 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3366 - accuracy: 0.85 - 0s 936us/step - loss: 0.3382 - accuracy: 0.8585 - val_loss: 0.3675 - val_accuracy: 0.8425\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.84 - ETA: 0s - loss: 0.3182 - accuracy: 0.87 - ETA: 0s - loss: 0.3340 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8578 - val_loss: 0.3666 - val_accuracy: 0.8480\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.86 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3368 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8588 - val_loss: 0.3661 - val_accuracy: 0.8450\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.81 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3399 - accuracy: 0.85 - ETA: 0s - loss: 0.3365 - accuracy: 0.85 - 0s 990us/step - loss: 0.3362 - accuracy: 0.8583 - val_loss: 0.3654 - val_accuracy: 0.8480\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.75 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - ETA: 0s - loss: 0.3301 - accuracy: 0.85 - 0s 910us/step - loss: 0.3351 - accuracy: 0.8588 - val_loss: 0.3664 - val_accuracy: 0.8445\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.84 - ETA: 0s - loss: 0.3355 - accuracy: 0.85 - ETA: 0s - loss: 0.3344 - accuracy: 0.85 - 0s 942us/step - loss: 0.3351 - accuracy: 0.8588 - val_loss: 0.3651 - val_accuracy: 0.8465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.90 - ETA: 0s - loss: 0.3359 - accuracy: 0.85 - ETA: 0s - loss: 0.3371 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8595 - val_loss: 0.3651 - val_accuracy: 0.8510\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.96 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3367 - accuracy: 0.85 - 0s 904us/step - loss: 0.3336 - accuracy: 0.8593 - val_loss: 0.3642 - val_accuracy: 0.8505\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.87 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - 0s 990us/step - loss: 0.3333 - accuracy: 0.8587 - val_loss: 0.3644 - val_accuracy: 0.8535\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.87 - ETA: 0s - loss: 0.3206 - accuracy: 0.86 - ETA: 0s - loss: 0.3327 - accuracy: 0.85 - 0s 910us/step - loss: 0.3324 - accuracy: 0.8593 - val_loss: 0.3632 - val_accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.93 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - 0s 926us/step - loss: 0.3323 - accuracy: 0.8588 - val_loss: 0.3633 - val_accuracy: 0.8520\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.90 - ETA: 0s - loss: 0.3277 - accuracy: 0.85 - ETA: 0s - loss: 0.3320 - accuracy: 0.85 - 0s 926us/step - loss: 0.3319 - accuracy: 0.8605 - val_loss: 0.3631 - val_accuracy: 0.8505\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.93 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 841us/step - loss: 0.3312 - accuracy: 0.8603 - val_loss: 0.3625 - val_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.90 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - ETA: 0s - loss: 0.3233 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8608 - val_loss: 0.3625 - val_accuracy: 0.8510\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.96 - ETA: 0s - loss: 0.3209 - accuracy: 0.87 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - 0s 959us/step - loss: 0.3303 - accuracy: 0.8602 - val_loss: 0.3624 - val_accuracy: 0.8545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 7bfd122c924e27a28cc17c71a9fe611a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8544999957084656</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.7606 - accuracy: 0.31 - ETA: 0s - loss: 0.5812 - accuracy: 0.73 - ETA: 0s - loss: 0.5271 - accuracy: 0.76 - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7680 - val_loss: 0.4558 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5864 - accuracy: 0.75 - ETA: 0s - loss: 0.4484 - accuracy: 0.79 - ETA: 0s - loss: 0.4367 - accuracy: 0.80 - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8067 - val_loss: 0.4254 - val_accuracy: 0.8170\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.96 - ETA: 0s - loss: 0.4105 - accuracy: 0.81 - ETA: 0s - loss: 0.3994 - accuracy: 0.83 - 0s 920us/step - loss: 0.3998 - accuracy: 0.8313 - val_loss: 0.3983 - val_accuracy: 0.8310\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.90 - ETA: 0s - loss: 0.3664 - accuracy: 0.85 - ETA: 0s - loss: 0.3698 - accuracy: 0.85 - 0s 888us/step - loss: 0.3660 - accuracy: 0.8517 - val_loss: 0.3693 - val_accuracy: 0.8475\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.84 - ETA: 0s - loss: 0.3705 - accuracy: 0.84 - ETA: 0s - loss: 0.3559 - accuracy: 0.85 - 0s 909us/step - loss: 0.3481 - accuracy: 0.8558 - val_loss: 0.3658 - val_accuracy: 0.8480\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.84 - ETA: 0s - loss: 0.3439 - accuracy: 0.85 - ETA: 0s - loss: 0.3416 - accuracy: 0.85 - 0s 793us/step - loss: 0.3422 - accuracy: 0.8567 - val_loss: 0.3611 - val_accuracy: 0.8465\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.87 - ETA: 0s - loss: 0.3429 - accuracy: 0.85 - ETA: 0s - loss: 0.3393 - accuracy: 0.85 - 0s 777us/step - loss: 0.3390 - accuracy: 0.8595 - val_loss: 0.3606 - val_accuracy: 0.8465\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.90 - ETA: 0s - loss: 0.3328 - accuracy: 0.85 - ETA: 0s - loss: 0.3334 - accuracy: 0.86 - 0s 876us/step - loss: 0.3358 - accuracy: 0.8593 - val_loss: 0.3563 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.78 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3379 - accuracy: 0.85 - 0s 900us/step - loss: 0.3342 - accuracy: 0.8600 - val_loss: 0.3612 - val_accuracy: 0.8515\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.81 - ETA: 0s - loss: 0.3119 - accuracy: 0.86 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - 0s 798us/step - loss: 0.3324 - accuracy: 0.8615 - val_loss: 0.3572 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.90 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3282 - accuracy: 0.86 - 0s 864us/step - loss: 0.3287 - accuracy: 0.8625 - val_loss: 0.3581 - val_accuracy: 0.8535\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.90 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3323 - accuracy: 0.85 - 0s 920us/step - loss: 0.3287 - accuracy: 0.8625 - val_loss: 0.3567 - val_accuracy: 0.8520\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.90 - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - ETA: 0s - loss: 0.3198 - accuracy: 0.86 - 0s 858us/step - loss: 0.3267 - accuracy: 0.8623 - val_loss: 0.3552 - val_accuracy: 0.8580\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.87 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - ETA: 0s - loss: 0.3220 - accuracy: 0.86 - 0s 755us/step - loss: 0.3252 - accuracy: 0.8643 - val_loss: 0.3564 - val_accuracy: 0.8515\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.81 - ETA: 0s - loss: 0.3218 - accuracy: 0.86 - ETA: 0s - loss: 0.3234 - accuracy: 0.86 - 0s 755us/step - loss: 0.3230 - accuracy: 0.8643 - val_loss: 0.3528 - val_accuracy: 0.8555\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.87 - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - 0s 761us/step - loss: 0.3211 - accuracy: 0.8627 - val_loss: 0.3551 - val_accuracy: 0.8555\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.90 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - 0s 830us/step - loss: 0.3181 - accuracy: 0.8665 - val_loss: 0.3545 - val_accuracy: 0.8535\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.84 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - ETA: 0s - loss: 0.3131 - accuracy: 0.86 - 0s 819us/step - loss: 0.3178 - accuracy: 0.8663 - val_loss: 0.3562 - val_accuracy: 0.8560\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.96 - ETA: 0s - loss: 0.3207 - accuracy: 0.86 - ETA: 0s - loss: 0.3202 - accuracy: 0.86 - ETA: 0s - loss: 0.3188 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8677 - val_loss: 0.3544 - val_accuracy: 0.8535\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.84 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - 0s 841us/step - loss: 0.3148 - accuracy: 0.8683 - val_loss: 0.3533 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.84 - ETA: 0s - loss: 0.3148 - accuracy: 0.86 - ETA: 0s - loss: 0.3159 - accuracy: 0.86 - 0s 766us/step - loss: 0.3147 - accuracy: 0.8672 - val_loss: 0.3574 - val_accuracy: 0.8465\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.96 - ETA: 0s - loss: 0.3368 - accuracy: 0.86 - ETA: 0s - loss: 0.3177 - accuracy: 0.86 - 0s 776us/step - loss: 0.3134 - accuracy: 0.8723 - val_loss: 0.3596 - val_accuracy: 0.8530\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.90 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.86 - 0s 798us/step - loss: 0.3131 - accuracy: 0.8687 - val_loss: 0.3559 - val_accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.84 - ETA: 0s - loss: 0.3180 - accuracy: 0.86 - ETA: 0s - loss: 0.3112 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3111 - accuracy: 0.8693 - val_loss: 0.3533 - val_accuracy: 0.8565\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.90 - ETA: 0s - loss: 0.3005 - accuracy: 0.87 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - 0s 968us/step - loss: 0.3110 - accuracy: 0.8715 - val_loss: 0.3555 - val_accuracy: 0.8555\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.78 - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - ETA: 0s - loss: 0.3115 - accuracy: 0.87 - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8713 - val_loss: 0.3539 - val_accuracy: 0.8505\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.90 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3094 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8735 - val_loss: 0.3563 - val_accuracy: 0.8555\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.93 - ETA: 0s - loss: 0.2977 - accuracy: 0.88 - ETA: 0s - loss: 0.3025 - accuracy: 0.87 - 0s 947us/step - loss: 0.3107 - accuracy: 0.8725 - val_loss: 0.3558 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.81 - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - ETA: 0s - loss: 0.3103 - accuracy: 0.86 - 0s 952us/step - loss: 0.3081 - accuracy: 0.8720 - val_loss: 0.3560 - val_accuracy: 0.8515\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.93 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 910us/step - loss: 0.3066 - accuracy: 0.8745 - val_loss: 0.3594 - val_accuracy: 0.8490\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.84 - ETA: 0s - loss: 0.2881 - accuracy: 0.89 - ETA: 0s - loss: 0.2987 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8752 - val_loss: 0.3583 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.87 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - ETA: 0s - loss: 0.3039 - accuracy: 0.87 - 0s 851us/step - loss: 0.3055 - accuracy: 0.8730 - val_loss: 0.3547 - val_accuracy: 0.8520\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.87 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - 0s 798us/step - loss: 0.3038 - accuracy: 0.8745 - val_loss: 0.3560 - val_accuracy: 0.8535\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.96 - ETA: 0s - loss: 0.2902 - accuracy: 0.88 - ETA: 0s - loss: 0.2999 - accuracy: 0.87 - 0s 830us/step - loss: 0.3035 - accuracy: 0.8758 - val_loss: 0.3567 - val_accuracy: 0.8505\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.87 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - ETA: 0s - loss: 0.2971 - accuracy: 0.87 - 0s 787us/step - loss: 0.3018 - accuracy: 0.8773 - val_loss: 0.3666 - val_accuracy: 0.8545\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.87 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - ETA: 0s - loss: 0.3033 - accuracy: 0.87 - 0s 814us/step - loss: 0.3017 - accuracy: 0.8752 - val_loss: 0.3557 - val_accuracy: 0.8520\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.78 - ETA: 0s - loss: 0.3078 - accuracy: 0.87 - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - 0s 794us/step - loss: 0.3014 - accuracy: 0.8752 - val_loss: 0.3592 - val_accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.93 - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - 0s 806us/step - loss: 0.2989 - accuracy: 0.8780 - val_loss: 0.3640 - val_accuracy: 0.8520\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.87 - ETA: 0s - loss: 0.2781 - accuracy: 0.88 - ETA: 0s - loss: 0.2964 - accuracy: 0.88 - 0s 787us/step - loss: 0.3007 - accuracy: 0.8777 - val_loss: 0.3639 - val_accuracy: 0.8525\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.87 - ETA: 0s - loss: 0.2987 - accuracy: 0.87 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - ETA: 0s - loss: 0.2985 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8787 - val_loss: 0.3574 - val_accuracy: 0.8505\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.93 - ETA: 0s - loss: 0.2958 - accuracy: 0.87 - ETA: 0s - loss: 0.2921 - accuracy: 0.88 - 0s 888us/step - loss: 0.2977 - accuracy: 0.8813 - val_loss: 0.3623 - val_accuracy: 0.8530\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.90 - ETA: 0s - loss: 0.2935 - accuracy: 0.88 - ETA: 0s - loss: 0.2902 - accuracy: 0.88 - 0s 819us/step - loss: 0.2978 - accuracy: 0.8800 - val_loss: 0.3601 - val_accuracy: 0.8515\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.96 - ETA: 0s - loss: 0.2954 - accuracy: 0.87 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - 0s 797us/step - loss: 0.2970 - accuracy: 0.8797 - val_loss: 0.3582 - val_accuracy: 0.8535\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.87 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2941 - accuracy: 0.88 - 0s 830us/step - loss: 0.2977 - accuracy: 0.8787 - val_loss: 0.3655 - val_accuracy: 0.8515\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.90 - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - ETA: 0s - loss: 0.2976 - accuracy: 0.87 - 0s 835us/step - loss: 0.2955 - accuracy: 0.8793 - val_loss: 0.3618 - val_accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.78 - ETA: 0s - loss: 0.2897 - accuracy: 0.88 - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - 0s 809us/step - loss: 0.2955 - accuracy: 0.8808 - val_loss: 0.3606 - val_accuracy: 0.8505\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.93 - ETA: 0s - loss: 0.2914 - accuracy: 0.88 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - 0s 809us/step - loss: 0.2933 - accuracy: 0.8828 - val_loss: 0.3676 - val_accuracy: 0.8480\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.75 - ETA: 0s - loss: 0.2893 - accuracy: 0.88 - ETA: 0s - loss: 0.2945 - accuracy: 0.88 - 0s 926us/step - loss: 0.2948 - accuracy: 0.8795 - val_loss: 0.3705 - val_accuracy: 0.8455\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.90 - ETA: 0s - loss: 0.3021 - accuracy: 0.88 - ETA: 0s - loss: 0.2968 - accuracy: 0.88 - 0s 897us/step - loss: 0.2926 - accuracy: 0.8842 - val_loss: 0.3697 - val_accuracy: 0.8530\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.90 - ETA: 0s - loss: 0.2936 - accuracy: 0.88 - ETA: 0s - loss: 0.2911 - accuracy: 0.88 - 0s 814us/step - loss: 0.2935 - accuracy: 0.8807 - val_loss: 0.3651 - val_accuracy: 0.8540\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.93 - ETA: 0s - loss: 0.2892 - accuracy: 0.87 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - 0s 819us/step - loss: 0.2905 - accuracy: 0.8827 - val_loss: 0.3657 - val_accuracy: 0.8515\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.81 - ETA: 0s - loss: 0.2956 - accuracy: 0.87 - ETA: 0s - loss: 0.2944 - accuracy: 0.88 - 0s 803us/step - loss: 0.2912 - accuracy: 0.8827 - val_loss: 0.3777 - val_accuracy: 0.8430\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.84 - ETA: 0s - loss: 0.2931 - accuracy: 0.88 - ETA: 0s - loss: 0.2919 - accuracy: 0.88 - 0s 766us/step - loss: 0.2908 - accuracy: 0.8817 - val_loss: 0.3710 - val_accuracy: 0.8515\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.87 - ETA: 0s - loss: 0.2936 - accuracy: 0.87 - ETA: 0s - loss: 0.2904 - accuracy: 0.88 - 0s 830us/step - loss: 0.2893 - accuracy: 0.8835 - val_loss: 0.3741 - val_accuracy: 0.8505\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.87 - ETA: 0s - loss: 0.2967 - accuracy: 0.88 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - 0s 821us/step - loss: 0.2898 - accuracy: 0.8853 - val_loss: 0.3799 - val_accuracy: 0.8475\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.93 - ETA: 0s - loss: 0.2923 - accuracy: 0.88 - ETA: 0s - loss: 0.2858 - accuracy: 0.88 - 0s 756us/step - loss: 0.2895 - accuracy: 0.8837 - val_loss: 0.3697 - val_accuracy: 0.8465\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.93 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - 0s 788us/step - loss: 0.2880 - accuracy: 0.8845 - val_loss: 0.3779 - val_accuracy: 0.8445\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.84 - ETA: 0s - loss: 0.2846 - accuracy: 0.89 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - 0s 771us/step - loss: 0.2876 - accuracy: 0.8852 - val_loss: 0.3746 - val_accuracy: 0.8520\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.84 - ETA: 0s - loss: 0.2793 - accuracy: 0.88 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - 0s 777us/step - loss: 0.2864 - accuracy: 0.8863 - val_loss: 0.3750 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.93 - ETA: 0s - loss: 0.2983 - accuracy: 0.88 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - 0s 920us/step - loss: 0.2863 - accuracy: 0.8862 - val_loss: 0.3790 - val_accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.90 - ETA: 0s - loss: 0.2757 - accuracy: 0.89 - ETA: 0s - loss: 0.2849 - accuracy: 0.88 - 0s 803us/step - loss: 0.2843 - accuracy: 0.8855 - val_loss: 0.3784 - val_accuracy: 0.8495\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4118 - accuracy: 0.84 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.2858 - accuracy: 0.88 - 0s 798us/step - loss: 0.2837 - accuracy: 0.8848 - val_loss: 0.3825 - val_accuracy: 0.8485\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.87 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - ETA: 0s - loss: 0.2849 - accuracy: 0.88 - 0s 782us/step - loss: 0.2851 - accuracy: 0.8865 - val_loss: 0.3861 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.84 - ETA: 0s - loss: 0.2754 - accuracy: 0.88 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - 0s 915us/step - loss: 0.2838 - accuracy: 0.8848 - val_loss: 0.3769 - val_accuracy: 0.8430\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.90 - ETA: 0s - loss: 0.2707 - accuracy: 0.88 - ETA: 0s - loss: 0.2807 - accuracy: 0.88 - 0s 952us/step - loss: 0.2821 - accuracy: 0.8863 - val_loss: 0.3793 - val_accuracy: 0.8475\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.96 - ETA: 0s - loss: 0.2671 - accuracy: 0.89 - ETA: 0s - loss: 0.2793 - accuracy: 0.89 - 0s 761us/step - loss: 0.2806 - accuracy: 0.8888 - val_loss: 0.3745 - val_accuracy: 0.8495\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 1.00 - ETA: 0s - loss: 0.2624 - accuracy: 0.89 - ETA: 0s - loss: 0.2777 - accuracy: 0.88 - 0s 777us/step - loss: 0.2820 - accuracy: 0.8840 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 1.00 - ETA: 0s - loss: 0.2838 - accuracy: 0.88 - ETA: 0s - loss: 0.2792 - accuracy: 0.89 - 0s 771us/step - loss: 0.2809 - accuracy: 0.8893 - val_loss: 0.3866 - val_accuracy: 0.8430\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.84 - ETA: 0s - loss: 0.2792 - accuracy: 0.88 - ETA: 0s - loss: 0.2786 - accuracy: 0.88 - 0s 761us/step - loss: 0.2812 - accuracy: 0.8857 - val_loss: 0.3820 - val_accuracy: 0.8470\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.90 - ETA: 0s - loss: 0.2684 - accuracy: 0.89 - ETA: 0s - loss: 0.2784 - accuracy: 0.88 - 0s 772us/step - loss: 0.2792 - accuracy: 0.8878 - val_loss: 0.3851 - val_accuracy: 0.8530\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.96 - ETA: 0s - loss: 0.2769 - accuracy: 0.88 - ETA: 0s - loss: 0.2777 - accuracy: 0.88 - 0s 766us/step - loss: 0.2793 - accuracy: 0.8868 - val_loss: 0.3799 - val_accuracy: 0.8525\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.90 - ETA: 0s - loss: 0.2746 - accuracy: 0.89 - ETA: 0s - loss: 0.2736 - accuracy: 0.89 - 0s 756us/step - loss: 0.2788 - accuracy: 0.8880 - val_loss: 0.4006 - val_accuracy: 0.8435\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.84 - ETA: 0s - loss: 0.2771 - accuracy: 0.88 - ETA: 0s - loss: 0.2772 - accuracy: 0.88 - 0s 766us/step - loss: 0.2789 - accuracy: 0.8833 - val_loss: 0.3886 - val_accuracy: 0.8425\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.96 - ETA: 0s - loss: 0.2664 - accuracy: 0.89 - ETA: 0s - loss: 0.2779 - accuracy: 0.88 - 0s 787us/step - loss: 0.2781 - accuracy: 0.8870 - val_loss: 0.4001 - val_accuracy: 0.8435\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.96 - ETA: 0s - loss: 0.2809 - accuracy: 0.88 - ETA: 0s - loss: 0.2790 - accuracy: 0.88 - 0s 798us/step - loss: 0.2784 - accuracy: 0.8875 - val_loss: 0.3937 - val_accuracy: 0.8445\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.93 - ETA: 0s - loss: 0.2775 - accuracy: 0.89 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - 0s 766us/step - loss: 0.2763 - accuracy: 0.8882 - val_loss: 0.4010 - val_accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.96 - ETA: 0s - loss: 0.2739 - accuracy: 0.89 - ETA: 0s - loss: 0.2750 - accuracy: 0.88 - 0s 782us/step - loss: 0.2750 - accuracy: 0.8895 - val_loss: 0.3980 - val_accuracy: 0.8410\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.87 - ETA: 0s - loss: 0.2657 - accuracy: 0.89 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - 0s 761us/step - loss: 0.2767 - accuracy: 0.8868 - val_loss: 0.3983 - val_accuracy: 0.8455\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.96 - ETA: 0s - loss: 0.2723 - accuracy: 0.88 - ETA: 0s - loss: 0.2761 - accuracy: 0.88 - 0s 782us/step - loss: 0.2758 - accuracy: 0.8885 - val_loss: 0.3937 - val_accuracy: 0.8440\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.81 - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - ETA: 0s - loss: 0.2807 - accuracy: 0.88 - 0s 942us/step - loss: 0.2759 - accuracy: 0.8870 - val_loss: 0.4005 - val_accuracy: 0.8440\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.93 - ETA: 0s - loss: 0.2696 - accuracy: 0.89 - ETA: 0s - loss: 0.2763 - accuracy: 0.88 - 0s 809us/step - loss: 0.2741 - accuracy: 0.8898 - val_loss: 0.4070 - val_accuracy: 0.8420\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.78 - ETA: 0s - loss: 0.2659 - accuracy: 0.88 - ETA: 0s - loss: 0.2708 - accuracy: 0.88 - 0s 819us/step - loss: 0.2757 - accuracy: 0.8905 - val_loss: 0.3988 - val_accuracy: 0.8460\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.84 - ETA: 0s - loss: 0.2611 - accuracy: 0.89 - ETA: 0s - loss: 0.2750 - accuracy: 0.88 - 0s 825us/step - loss: 0.2743 - accuracy: 0.8895 - val_loss: 0.3980 - val_accuracy: 0.8440\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.90 - ETA: 0s - loss: 0.2708 - accuracy: 0.88 - ETA: 0s - loss: 0.2751 - accuracy: 0.88 - 0s 782us/step - loss: 0.2736 - accuracy: 0.8897 - val_loss: 0.3935 - val_accuracy: 0.8440\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.84 - ETA: 0s - loss: 0.2764 - accuracy: 0.88 - ETA: 0s - loss: 0.2754 - accuracy: 0.88 - 0s 777us/step - loss: 0.2745 - accuracy: 0.8897 - val_loss: 0.4031 - val_accuracy: 0.8420\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.87 - ETA: 0s - loss: 0.2736 - accuracy: 0.88 - ETA: 0s - loss: 0.2694 - accuracy: 0.89 - 0s 846us/step - loss: 0.2738 - accuracy: 0.8902 - val_loss: 0.3976 - val_accuracy: 0.8480\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.93 - ETA: 0s - loss: 0.2694 - accuracy: 0.89 - ETA: 0s - loss: 0.2717 - accuracy: 0.89 - 0s 830us/step - loss: 0.2718 - accuracy: 0.8903 - val_loss: 0.3971 - val_accuracy: 0.8445\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.90 - ETA: 0s - loss: 0.2899 - accuracy: 0.87 - ETA: 0s - loss: 0.2779 - accuracy: 0.88 - 0s 1ms/step - loss: 0.2711 - accuracy: 0.8888 - val_loss: 0.3995 - val_accuracy: 0.8460\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.87 - ETA: 0s - loss: 0.2818 - accuracy: 0.88 - ETA: 0s - loss: 0.2739 - accuracy: 0.88 - 0s 825us/step - loss: 0.2709 - accuracy: 0.8897 - val_loss: 0.4040 - val_accuracy: 0.8420\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.87 - ETA: 0s - loss: 0.2863 - accuracy: 0.88 - ETA: 0s - loss: 0.2685 - accuracy: 0.89 - 0s 862us/step - loss: 0.2722 - accuracy: 0.8905 - val_loss: 0.4044 - val_accuracy: 0.8420\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.90 - ETA: 0s - loss: 0.2717 - accuracy: 0.88 - ETA: 0s - loss: 0.2726 - accuracy: 0.88 - 0s 771us/step - loss: 0.2710 - accuracy: 0.8870 - val_loss: 0.4120 - val_accuracy: 0.8410\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.90 - ETA: 0s - loss: 0.2753 - accuracy: 0.88 - ETA: 0s - loss: 0.2714 - accuracy: 0.88 - 0s 825us/step - loss: 0.2716 - accuracy: 0.8903 - val_loss: 0.4026 - val_accuracy: 0.8420\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.87 - ETA: 0s - loss: 0.2643 - accuracy: 0.89 - ETA: 0s - loss: 0.2655 - accuracy: 0.89 - 0s 841us/step - loss: 0.2696 - accuracy: 0.8918 - val_loss: 0.4128 - val_accuracy: 0.8380\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.87 - ETA: 0s - loss: 0.2435 - accuracy: 0.89 - ETA: 0s - loss: 0.2670 - accuracy: 0.89 - 0s 777us/step - loss: 0.2703 - accuracy: 0.8908 - val_loss: 0.3980 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.90 - ETA: 0s - loss: 0.2704 - accuracy: 0.89 - ETA: 0s - loss: 0.2754 - accuracy: 0.88 - 0s 862us/step - loss: 0.2677 - accuracy: 0.8905 - val_loss: 0.4077 - val_accuracy: 0.8425\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.75 - ETA: 0s - loss: 0.2719 - accuracy: 0.89 - ETA: 0s - loss: 0.2696 - accuracy: 0.89 - 0s 819us/step - loss: 0.2680 - accuracy: 0.8923 - val_loss: 0.4083 - val_accuracy: 0.8430\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.93 - ETA: 0s - loss: 0.2478 - accuracy: 0.90 - ETA: 0s - loss: 0.2565 - accuracy: 0.89 - 0s 942us/step - loss: 0.2673 - accuracy: 0.8922 - val_loss: 0.4131 - val_accuracy: 0.8385\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.2537 - accuracy: 0.90 - ETA: 0s - loss: 0.2629 - accuracy: 0.89 - 0s 819us/step - loss: 0.2689 - accuracy: 0.8912 - val_loss: 0.4189 - val_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.87 - ETA: 0s - loss: 0.2526 - accuracy: 0.89 - ETA: 0s - loss: 0.2635 - accuracy: 0.89 - 0s 855us/step - loss: 0.2696 - accuracy: 0.8893 - val_loss: 0.4066 - val_accuracy: 0.8420\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.90 - ETA: 0s - loss: 0.2569 - accuracy: 0.89 - ETA: 0s - loss: 0.2662 - accuracy: 0.89 - 0s 878us/step - loss: 0.2671 - accuracy: 0.8913 - val_loss: 0.4129 - val_accuracy: 0.8415\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 12e74346c6635c6bf72c489eb230d346</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8579999804496765</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# we will split our training data into training (75%) and validation (0.25). Validation set will be used to validate the model in order to find best hyperparameters.\n",
    "tuner.search(X_train, y_train, epochs=100, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in directory1\\Project_Name1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 690055055f6b26574c0679b98b26b231</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8654999732971191</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 111e8a0254257662065566ec0086786e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8650000095367432</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 52cf32d73bb0b25148f810c53099e98d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8644999861717224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1cc22aa6771ff98e3ccae610dfe63031</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8634999990463257</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 06cc3c082e6391b4369c6f0f00766d5e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8634999990463257</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 22dc031d812dc49c4948b1637bf2df01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8619999885559082</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9a9b88ef9dc0a70657ae59a98c00516f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8600000143051147</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a4176dbd38f51a51d2bca2bc6686bab5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859499990940094</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 21</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ad5730a6d23b2cbcaaa03e629bc4c00d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859000027179718</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d8beb56014fb7dc9eac2ff61cbcdbaaf</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859000027179718</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-num_layers: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_0: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_2: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_4: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_5: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_6: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_7: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units_8: 26</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units_9: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a result summary from RandomSearch\n",
    "# it shows 10 best sorted trials  (hyperparameters and its score)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x2d7990c5d90>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x2d7990c5580>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x2d7990a6730>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 3 best models from RandomSearch (models with top 3 highest score)\n",
    "models = tuner.get_best_models(num_models=3)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x2d7990b75b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We must retrain the model on the full dataset after finding best hyperparameter since during hyperparameter tuning we splitted the training data into train and validation in order to validate the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.93 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - ETA: 0s - loss: 0.3315 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3498 - accuracy: 0.86 - ETA: 0s - loss: 0.3470 - accuracy: 0.86 - ETA: 0s - loss: 0.3486 - accuracy: 0.86 - 1s 1ms/step - loss: 0.3484 - accuracy: 0.8636 - val_loss: 0.3593 - val_accuracy: 0.8570\n",
      "Epoch 2/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.87 - ETA: 0s - loss: 0.3557 - accuracy: 0.84 - ETA: 0s - loss: 0.3363 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3295 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3376 - accuracy: 0.86 - 0s 970us/step - loss: 0.3364 - accuracy: 0.8644 - val_loss: 0.3527 - val_accuracy: 0.8595\n",
      "Epoch 3/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.87 - ETA: 0s - loss: 0.3304 - accuracy: 0.87 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - ETA: 0s - loss: 0.3385 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3382 - accuracy: 0.86 - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - 0s 970us/step - loss: 0.3367 - accuracy: 0.8648 - val_loss: 0.3560 - val_accuracy: 0.8620\n",
      "Epoch 4/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.93 - ETA: 0s - loss: 0.3532 - accuracy: 0.84 - ETA: 0s - loss: 0.3394 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.85 - ETA: 0s - loss: 0.3365 - accuracy: 0.85 - ETA: 0s - loss: 0.3375 - accuracy: 0.85 - ETA: 0s - loss: 0.3349 - accuracy: 0.86 - ETA: 0s - loss: 0.3389 - accuracy: 0.86 - 0s 921us/step - loss: 0.3395 - accuracy: 0.8602 - val_loss: 0.3457 - val_accuracy: 0.8625\n",
      "Epoch 5/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 1.00 - ETA: 0s - loss: 0.3358 - accuracy: 0.85 - ETA: 0s - loss: 0.3414 - accuracy: 0.85 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3271 - accuracy: 0.86 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - 0s 982us/step - loss: 0.3353 - accuracy: 0.8624 - val_loss: 0.3946 - val_accuracy: 0.8350\n",
      "Epoch 6/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.87 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3424 - accuracy: 0.86 - ETA: 0s - loss: 0.3442 - accuracy: 0.86 - ETA: 0s - loss: 0.3410 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3387 - accuracy: 0.86 - 0s 968us/step - loss: 0.3371 - accuracy: 0.8654 - val_loss: 0.3482 - val_accuracy: 0.8615\n",
      "Epoch 7/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.93 - ETA: 0s - loss: 0.3430 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.85 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3259 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3316 - accuracy: 0.86 - 0s 969us/step - loss: 0.3301 - accuracy: 0.8681 - val_loss: 0.3517 - val_accuracy: 0.8610\n",
      "Epoch 8/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 1.00 - ETA: 0s - loss: 0.3285 - accuracy: 0.86 - ETA: 0s - loss: 0.3331 - accuracy: 0.86 - ETA: 0s - loss: 0.3402 - accuracy: 0.86 - ETA: 0s - loss: 0.3432 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3443 - accuracy: 0.85 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - 0s 950us/step - loss: 0.3461 - accuracy: 0.8568 - val_loss: 0.3916 - val_accuracy: 0.8385\n",
      "Epoch 9/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.87 - ETA: 0s - loss: 0.3482 - accuracy: 0.84 - ETA: 0s - loss: 0.3396 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - ETA: 0s - loss: 0.3372 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3345 - accuracy: 0.86 - ETA: 0s - loss: 0.3366 - accuracy: 0.86 - 0s 918us/step - loss: 0.3331 - accuracy: 0.8664 - val_loss: 0.3610 - val_accuracy: 0.8570\n",
      "Epoch 10/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.87 - ETA: 0s - loss: 0.3460 - accuracy: 0.86 - ETA: 0s - loss: 0.3393 - accuracy: 0.86 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3365 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.86 - ETA: 0s - loss: 0.3413 - accuracy: 0.86 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - 0s 988us/step - loss: 0.3411 - accuracy: 0.8619 - val_loss: 0.3478 - val_accuracy: 0.8580\n",
      "Epoch 11/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.75 - ETA: 0s - loss: 0.3577 - accuracy: 0.86 - ETA: 0s - loss: 0.3508 - accuracy: 0.86 - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - ETA: 0s - loss: 0.3481 - accuracy: 0.86 - ETA: 0s - loss: 0.3458 - accuracy: 0.86 - ETA: 0s - loss: 0.3445 - accuracy: 0.86 - ETA: 0s - loss: 0.3431 - accuracy: 0.86 - 0s 951us/step - loss: 0.3416 - accuracy: 0.8635 - val_loss: 0.3449 - val_accuracy: 0.8655\n",
      "Epoch 12/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.93 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3266 - accuracy: 0.86 - ETA: 0s - loss: 0.3279 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3344 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.86 - 0s 936us/step - loss: 0.3335 - accuracy: 0.8643 - val_loss: 0.3637 - val_accuracy: 0.8640\n",
      "Epoch 13/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.87 - ETA: 0s - loss: 0.3318 - accuracy: 0.86 - ETA: 0s - loss: 0.3370 - accuracy: 0.86 - ETA: 0s - loss: 0.3359 - accuracy: 0.86 - ETA: 0s - loss: 0.3329 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3326 - accuracy: 0.86 - 0s 952us/step - loss: 0.3314 - accuracy: 0.8646 - val_loss: 0.3615 - val_accuracy: 0.8425\n",
      "Epoch 14/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 1.00 - ETA: 0s - loss: 0.3209 - accuracy: 0.86 - ETA: 0s - loss: 0.3268 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - ETA: 0s - loss: 0.3511 - accuracy: 0.86 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.86 - 0s 938us/step - loss: 0.3516 - accuracy: 0.8612 - val_loss: 0.3455 - val_accuracy: 0.8605\n",
      "Epoch 15/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.87 - ETA: 0s - loss: 0.3196 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.87 - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - 0s 950us/step - loss: 0.3323 - accuracy: 0.8673 - val_loss: 0.3486 - val_accuracy: 0.8620\n",
      "Epoch 16/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.81 - ETA: 0s - loss: 0.3518 - accuracy: 0.86 - ETA: 0s - loss: 0.3325 - accuracy: 0.87 - ETA: 0s - loss: 0.3358 - accuracy: 0.86 - ETA: 0s - loss: 0.3434 - accuracy: 0.86 - ETA: 0s - loss: 0.3361 - accuracy: 0.86 - ETA: 0s - loss: 0.3350 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - 0s 962us/step - loss: 0.3346 - accuracy: 0.8646 - val_loss: 0.3491 - val_accuracy: 0.8615\n",
      "Epoch 17/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.87 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - ETA: 0s - loss: 0.3222 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3253 - accuracy: 0.86 - ETA: 0s - loss: 0.3262 - accuracy: 0.86 - 0s 988us/step - loss: 0.3244 - accuracy: 0.8695 - val_loss: 0.3484 - val_accuracy: 0.8630\n",
      "Epoch 18/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.81 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3241 - accuracy: 0.87 - ETA: 0s - loss: 0.3226 - accuracy: 0.87 - ETA: 0s - loss: 0.3205 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - ETA: 0s - loss: 0.3251 - accuracy: 0.87 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - 0s 926us/step - loss: 0.3222 - accuracy: 0.8724 - val_loss: 0.3413 - val_accuracy: 0.8625\n",
      "Epoch 19/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.87 - ETA: 0s - loss: 0.3064 - accuracy: 0.88 - ETA: 0s - loss: 0.3135 - accuracy: 0.88 - ETA: 0s - loss: 0.3083 - accuracy: 0.88 - ETA: 0s - loss: 0.3160 - accuracy: 0.87 - ETA: 0s - loss: 0.3188 - accuracy: 0.87 - ETA: 0s - loss: 0.3205 - accuracy: 0.87 - ETA: 0s - loss: 0.3230 - accuracy: 0.87 - 0s 954us/step - loss: 0.3243 - accuracy: 0.8730 - val_loss: 0.3500 - val_accuracy: 0.8560\n",
      "Epoch 20/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.75 - ETA: 0s - loss: 0.3227 - accuracy: 0.88 - ETA: 0s - loss: 0.3144 - accuracy: 0.88 - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - ETA: 0s - loss: 0.3250 - accuracy: 0.87 - ETA: 0s - loss: 0.3250 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.87 - 0s 926us/step - loss: 0.3227 - accuracy: 0.8726 - val_loss: 0.3513 - val_accuracy: 0.8600\n",
      "Epoch 21/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 1.00 - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3228 - accuracy: 0.87 - ETA: 0s - loss: 0.3234 - accuracy: 0.87 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3233 - accuracy: 0.87 - 0s 944us/step - loss: 0.3225 - accuracy: 0.8726 - val_loss: 0.3408 - val_accuracy: 0.8610\n",
      "Epoch 22/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.87 - ETA: 0s - loss: 0.3195 - accuracy: 0.87 - ETA: 0s - loss: 0.3294 - accuracy: 0.86 - ETA: 0s - loss: 0.3258 - accuracy: 0.86 - ETA: 0s - loss: 0.3311 - accuracy: 0.86 - ETA: 0s - loss: 0.3275 - accuracy: 0.86 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.87 - 0s 976us/step - loss: 0.3211 - accuracy: 0.8708 - val_loss: 0.3434 - val_accuracy: 0.8620\n",
      "Epoch 23/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.93 - ETA: 0s - loss: 0.3030 - accuracy: 0.89 - ETA: 0s - loss: 0.3087 - accuracy: 0.88 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - ETA: 0s - loss: 0.3240 - accuracy: 0.87 - 0s 967us/step - loss: 0.3234 - accuracy: 0.8705 - val_loss: 0.3545 - val_accuracy: 0.8550\n",
      "Epoch 24/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 1.00 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3312 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3239 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - 0s 942us/step - loss: 0.3214 - accuracy: 0.8712 - val_loss: 0.3435 - val_accuracy: 0.8615\n",
      "Epoch 25/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.81 - ETA: 0s - loss: 0.3313 - accuracy: 0.86 - ETA: 0s - loss: 0.3204 - accuracy: 0.86 - ETA: 0s - loss: 0.3206 - accuracy: 0.87 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3160 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3212 - accuracy: 0.87 - 0s 999us/step - loss: 0.3204 - accuracy: 0.8710 - val_loss: 0.3464 - val_accuracy: 0.8600\n",
      "Epoch 26/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.93 - ETA: 0s - loss: 0.3078 - accuracy: 0.87 - ETA: 0s - loss: 0.3015 - accuracy: 0.88 - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3201 - accuracy: 0.87 - ETA: 0s - loss: 0.3198 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - 0s 969us/step - loss: 0.3217 - accuracy: 0.8724 - val_loss: 0.3529 - val_accuracy: 0.8630\n",
      "Epoch 27/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.81 - ETA: 0s - loss: 0.3464 - accuracy: 0.86 - ETA: 0s - loss: 0.3386 - accuracy: 0.86 - ETA: 0s - loss: 0.3264 - accuracy: 0.87 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3292 - accuracy: 0.86 - ETA: 0s - loss: 0.3257 - accuracy: 0.86 - ETA: 0s - loss: 0.3255 - accuracy: 0.86 - 1s 1ms/step - loss: 0.3244 - accuracy: 0.8701 - val_loss: 0.3465 - val_accuracy: 0.8670\n",
      "Epoch 28/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.87 - ETA: 0s - loss: 0.3236 - accuracy: 0.87 - ETA: 0s - loss: 0.3200 - accuracy: 0.87 - ETA: 0s - loss: 0.3232 - accuracy: 0.87 - ETA: 0s - loss: 0.3251 - accuracy: 0.87 - ETA: 0s - loss: 0.3244 - accuracy: 0.87 - ETA: 0s - loss: 0.3236 - accuracy: 0.87 - 0s 934us/step - loss: 0.3225 - accuracy: 0.8729 - val_loss: 0.3501 - val_accuracy: 0.8615\n",
      "Epoch 29/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.87 - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.2980 - accuracy: 0.87 - ETA: 0s - loss: 0.3077 - accuracy: 0.87 - ETA: 0s - loss: 0.3112 - accuracy: 0.86 - ETA: 0s - loss: 0.3162 - accuracy: 0.86 - ETA: 0s - loss: 0.3214 - accuracy: 0.86 - ETA: 0s - loss: 0.3189 - accuracy: 0.86 - 0s 970us/step - loss: 0.3173 - accuracy: 0.8709 - val_loss: 0.3587 - val_accuracy: 0.8575\n",
      "Epoch 30/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 1.00 - ETA: 0s - loss: 0.3343 - accuracy: 0.85 - ETA: 0s - loss: 0.3215 - accuracy: 0.86 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - ETA: 0s - loss: 0.3181 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - 0s 964us/step - loss: 0.3189 - accuracy: 0.8740 - val_loss: 0.3444 - val_accuracy: 0.8630\n",
      "Epoch 31/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.93 - ETA: 0s - loss: 0.3330 - accuracy: 0.85 - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - ETA: 0s - loss: 0.3199 - accuracy: 0.86 - ETA: 0s - loss: 0.3221 - accuracy: 0.87 - ETA: 0s - loss: 0.4152 - accuracy: 0.86 - ETA: 0s - loss: 0.4033 - accuracy: 0.86 - 0s 908us/step - loss: 0.4011 - accuracy: 0.8695 - val_loss: 0.3540 - val_accuracy: 0.8585\n",
      "Epoch 32/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.87 - ETA: 0s - loss: 0.2732 - accuracy: 0.89 - ETA: 0s - loss: 0.3042 - accuracy: 0.87 - ETA: 0s - loss: 0.3119 - accuracy: 0.87 - ETA: 0s - loss: 0.3180 - accuracy: 0.87 - ETA: 0s - loss: 0.3223 - accuracy: 0.87 - ETA: 0s - loss: 0.3266 - accuracy: 0.87 - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - 0s 960us/step - loss: 0.3215 - accuracy: 0.8711 - val_loss: 0.3505 - val_accuracy: 0.8605\n",
      "Epoch 33/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.93 - ETA: 0s - loss: 0.3674 - accuracy: 0.84 - ETA: 0s - loss: 0.3341 - accuracy: 0.86 - ETA: 0s - loss: 0.3297 - accuracy: 0.86 - ETA: 0s - loss: 0.3340 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.86 - ETA: 0s - loss: 0.3296 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - 0s 958us/step - loss: 0.3261 - accuracy: 0.8687 - val_loss: 0.3444 - val_accuracy: 0.8660\n",
      "Epoch 34/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.93 - ETA: 0s - loss: 0.3300 - accuracy: 0.86 - ETA: 0s - loss: 0.3353 - accuracy: 0.86 - ETA: 0s - loss: 0.3260 - accuracy: 0.86 - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3207 - accuracy: 0.87 - ETA: 0s - loss: 0.3198 - accuracy: 0.87 - 0s 934us/step - loss: 0.3168 - accuracy: 0.8736 - val_loss: 0.3624 - val_accuracy: 0.8635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.87 - ETA: 0s - loss: 0.2884 - accuracy: 0.87 - ETA: 0s - loss: 0.3009 - accuracy: 0.86 - ETA: 0s - loss: 0.3054 - accuracy: 0.86 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.86 - ETA: 0s - loss: 0.3098 - accuracy: 0.87 - ETA: 0s - loss: 0.3112 - accuracy: 0.87 - 0s 906us/step - loss: 0.3113 - accuracy: 0.8724 - val_loss: 0.3525 - val_accuracy: 0.8680\n",
      "Epoch 36/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8006 - accuracy: 0.62 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3035 - accuracy: 0.88 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.88 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - ETA: 0s - loss: 0.3122 - accuracy: 0.87 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - 0s 946us/step - loss: 0.3112 - accuracy: 0.8764 - val_loss: 0.3570 - val_accuracy: 0.8615\n",
      "Epoch 37/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.93 - ETA: 0s - loss: 0.2879 - accuracy: 0.88 - ETA: 0s - loss: 0.3117 - accuracy: 0.87 - ETA: 0s - loss: 0.3126 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3119 - accuracy: 0.87 - 0s 901us/step - loss: 0.3106 - accuracy: 0.8770 - val_loss: 0.3707 - val_accuracy: 0.8655\n",
      "Epoch 38/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.87 - ETA: 0s - loss: 0.3120 - accuracy: 0.87 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3152 - accuracy: 0.87 - ETA: 0s - loss: 0.3174 - accuracy: 0.87 - ETA: 0s - loss: 0.3147 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - 0s 920us/step - loss: 0.3106 - accuracy: 0.8764 - val_loss: 0.3550 - val_accuracy: 0.8610\n",
      "Epoch 39/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.93 - ETA: 0s - loss: 0.3256 - accuracy: 0.87 - ETA: 0s - loss: 0.3240 - accuracy: 0.86 - ETA: 0s - loss: 0.3189 - accuracy: 0.87 - ETA: 0s - loss: 0.3115 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - 0s 952us/step - loss: 0.3097 - accuracy: 0.8763 - val_loss: 0.3694 - val_accuracy: 0.8415\n",
      "Epoch 40/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.93 - ETA: 0s - loss: 0.3029 - accuracy: 0.85 - ETA: 0s - loss: 0.2850 - accuracy: 0.87 - ETA: 0s - loss: 0.2870 - accuracy: 0.88 - ETA: 0s - loss: 0.2931 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - ETA: 0s - loss: 0.3069 - accuracy: 0.87 - 0s 931us/step - loss: 0.3079 - accuracy: 0.8750 - val_loss: 0.3587 - val_accuracy: 0.8565\n",
      "Epoch 41/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.87 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.2966 - accuracy: 0.88 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - ETA: 0s - loss: 0.3084 - accuracy: 0.87 - 0s 939us/step - loss: 0.3086 - accuracy: 0.8776 - val_loss: 0.3812 - val_accuracy: 0.8645\n",
      "Epoch 42/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.93 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - ETA: 0s - loss: 0.3120 - accuracy: 0.87 - ETA: 0s - loss: 0.3140 - accuracy: 0.87 - ETA: 0s - loss: 0.3144 - accuracy: 0.87 - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - 0s 925us/step - loss: 0.3079 - accuracy: 0.8756 - val_loss: 0.4352 - val_accuracy: 0.8590\n",
      "Epoch 43/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.93 - ETA: 0s - loss: 0.2813 - accuracy: 0.89 - ETA: 0s - loss: 0.2894 - accuracy: 0.89 - ETA: 0s - loss: 0.2938 - accuracy: 0.88 - ETA: 0s - loss: 0.2980 - accuracy: 0.88 - ETA: 0s - loss: 0.3074 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - 0s 972us/step - loss: 0.3095 - accuracy: 0.8785 - val_loss: 0.3683 - val_accuracy: 0.8480\n",
      "Epoch 44/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.75 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - ETA: 0s - loss: 0.3104 - accuracy: 0.87 - ETA: 0s - loss: 0.3065 - accuracy: 0.87 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 935us/step - loss: 0.3077 - accuracy: 0.8752 - val_loss: 0.3539 - val_accuracy: 0.8630\n",
      "Epoch 45/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 1.00 - ETA: 0s - loss: 0.2905 - accuracy: 0.88 - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3045 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3082 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - 0s 946us/step - loss: 0.3082 - accuracy: 0.8775 - val_loss: 0.3528 - val_accuracy: 0.8600\n",
      "Epoch 46/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 1.00 - ETA: 0s - loss: 0.2985 - accuracy: 0.87 - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - ETA: 0s - loss: 0.2887 - accuracy: 0.88 - ETA: 0s - loss: 0.2936 - accuracy: 0.88 - ETA: 0s - loss: 0.2965 - accuracy: 0.88 - ETA: 0s - loss: 0.2994 - accuracy: 0.88 - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 978us/step - loss: 0.3053 - accuracy: 0.8789 - val_loss: 0.3586 - val_accuracy: 0.8650\n",
      "Epoch 47/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.87 - ETA: 0s - loss: 0.2702 - accuracy: 0.89 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - ETA: 0s - loss: 0.2870 - accuracy: 0.88 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - ETA: 0s - loss: 0.2992 - accuracy: 0.88 - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - 0s 950us/step - loss: 0.3076 - accuracy: 0.8774 - val_loss: 0.3659 - val_accuracy: 0.8650\n",
      "Epoch 48/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.93 - ETA: 0s - loss: 0.3157 - accuracy: 0.87 - ETA: 0s - loss: 0.3034 - accuracy: 0.88 - ETA: 0s - loss: 0.2902 - accuracy: 0.88 - ETA: 0s - loss: 0.3059 - accuracy: 0.87 - ETA: 0s - loss: 0.3035 - accuracy: 0.87 - ETA: 0s - loss: 0.3060 - accuracy: 0.87 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - 0s 980us/step - loss: 0.3067 - accuracy: 0.8760 - val_loss: 0.3603 - val_accuracy: 0.8665\n",
      "Epoch 49/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.93 - ETA: 0s - loss: 0.2948 - accuracy: 0.88 - ETA: 0s - loss: 0.3034 - accuracy: 0.87 - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 1.1875 - accuracy: 0.87 - ETA: 0s - loss: 1.0679 - accuracy: 0.87 - 0s 962us/step - loss: 1.0133 - accuracy: 0.8715 - val_loss: 0.3921 - val_accuracy: 0.8625\n",
      "Epoch 50/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 1.00 - ETA: 0s - loss: 0.3020 - accuracy: 0.88 - ETA: 0s - loss: 0.2910 - accuracy: 0.88 - ETA: 0s - loss: 0.3044 - accuracy: 0.88 - ETA: 0s - loss: 0.2979 - accuracy: 0.88 - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - ETA: 0s - loss: 0.3159 - accuracy: 0.87 - 0s 959us/step - loss: 0.3180 - accuracy: 0.8746 - val_loss: 0.3857 - val_accuracy: 0.8335\n",
      "Epoch 51/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.87 - ETA: 0s - loss: 0.3266 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3064 - accuracy: 0.88 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3119 - accuracy: 0.88 - ETA: 0s - loss: 0.3085 - accuracy: 0.88 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - 0s 991us/step - loss: 0.3141 - accuracy: 0.8786 - val_loss: 0.3691 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.87 - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - ETA: 0s - loss: 0.3054 - accuracy: 0.87 - ETA: 0s - loss: 0.3026 - accuracy: 0.88 - ETA: 0s - loss: 0.3065 - accuracy: 0.88 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3063 - accuracy: 0.87 - ETA: 0s - loss: 0.3337 - accuracy: 0.87 - 0s 960us/step - loss: 0.3344 - accuracy: 0.8761 - val_loss: 0.3584 - val_accuracy: 0.8550\n",
      "Epoch 53/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.93 - ETA: 0s - loss: 0.3163 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.88 - ETA: 0s - loss: 0.3040 - accuracy: 0.88 - ETA: 0s - loss: 0.3069 - accuracy: 0.87 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - ETA: 0s - loss: 0.3068 - accuracy: 0.87 - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 946us/step - loss: 0.3056 - accuracy: 0.8788 - val_loss: 0.3909 - val_accuracy: 0.8635\n",
      "Epoch 54/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.87 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3211 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3056 - accuracy: 0.87 - ETA: 0s - loss: 0.3021 - accuracy: 0.88 - 0s 958us/step - loss: 0.3029 - accuracy: 0.8789 - val_loss: 0.4141 - val_accuracy: 0.8555\n",
      "Epoch 55/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.87 - ETA: 0s - loss: 0.3095 - accuracy: 0.86 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - ETA: 0s - loss: 0.2992 - accuracy: 0.88 - ETA: 0s - loss: 0.3212 - accuracy: 0.87 - ETA: 0s - loss: 0.3242 - accuracy: 0.87 - ETA: 0s - loss: 0.3227 - accuracy: 0.87 - ETA: 0s - loss: 0.3200 - accuracy: 0.87 - 0s 947us/step - loss: 0.3203 - accuracy: 0.8761 - val_loss: 0.4269 - val_accuracy: 0.8520\n",
      "Epoch 56/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.87 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.87 - ETA: 0s - loss: 0.3062 - accuracy: 0.88 - ETA: 0s - loss: 0.3083 - accuracy: 0.87 - ETA: 0s - loss: 0.3261 - accuracy: 0.87 - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - ETA: 0s - loss: 0.3179 - accuracy: 0.87 - 0s 966us/step - loss: 0.3178 - accuracy: 0.8754 - val_loss: 0.4132 - val_accuracy: 0.8575\n",
      "Epoch 57/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.81 - ETA: 0s - loss: 0.3208 - accuracy: 0.86 - ETA: 0s - loss: 0.3115 - accuracy: 0.86 - ETA: 0s - loss: 0.3015 - accuracy: 0.87 - ETA: 0s - loss: 0.3080 - accuracy: 0.87 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.2987 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - 0s 989us/step - loss: 0.3051 - accuracy: 0.8750 - val_loss: 0.6956 - val_accuracy: 0.8515\n",
      "Epoch 58/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 1.00 - ETA: 0s - loss: 0.2836 - accuracy: 0.88 - ETA: 0s - loss: 0.3131 - accuracy: 0.88 - ETA: 0s - loss: 0.3086 - accuracy: 0.88 - ETA: 0s - loss: 0.3137 - accuracy: 0.87 - ETA: 0s - loss: 0.3218 - accuracy: 0.87 - ETA: 0s - loss: 0.3221 - accuracy: 0.86 - ETA: 0s - loss: 0.3207 - accuracy: 0.87 - 0s 947us/step - loss: 0.3230 - accuracy: 0.8700 - val_loss: 0.3753 - val_accuracy: 0.8495\n",
      "Epoch 59/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.93 - ETA: 0s - loss: 0.3290 - accuracy: 0.86 - ETA: 0s - loss: 0.3177 - accuracy: 0.87 - ETA: 0s - loss: 0.3131 - accuracy: 0.87 - ETA: 0s - loss: 0.3098 - accuracy: 0.87 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - ETA: 0s - loss: 0.3123 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - 0s 966us/step - loss: 0.3160 - accuracy: 0.8717 - val_loss: 0.3666 - val_accuracy: 0.8560\n",
      "Epoch 60/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.87 - ETA: 0s - loss: 0.3188 - accuracy: 0.87 - ETA: 0s - loss: 0.3053 - accuracy: 0.89 - ETA: 0s - loss: 0.3023 - accuracy: 0.88 - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3135 - accuracy: 0.87 - 0s 985us/step - loss: 0.3135 - accuracy: 0.8763 - val_loss: 0.3862 - val_accuracy: 0.8560\n",
      "Epoch 61/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.75 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3246 - accuracy: 0.86 - ETA: 0s - loss: 0.3147 - accuracy: 0.86 - ETA: 0s - loss: 0.3099 - accuracy: 0.87 - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3112 - accuracy: 0.87 - 0s 965us/step - loss: 0.3111 - accuracy: 0.8733 - val_loss: 0.3734 - val_accuracy: 0.8575\n",
      "Epoch 62/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.68 - ETA: 0s - loss: 0.3062 - accuracy: 0.87 - ETA: 0s - loss: 0.3055 - accuracy: 0.87 - ETA: 0s - loss: 0.2969 - accuracy: 0.87 - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.3063 - accuracy: 0.87 - ETA: 0s - loss: 0.3102 - accuracy: 0.87 - 0s 979us/step - loss: 0.3059 - accuracy: 0.8745 - val_loss: 0.3909 - val_accuracy: 0.8580\n",
      "Epoch 63/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.87 - ETA: 0s - loss: 0.3224 - accuracy: 0.86 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - ETA: 0s - loss: 0.3261 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.85 - ETA: 0s - loss: 0.3350 - accuracy: 0.85 - ETA: 0s - loss: 0.3367 - accuracy: 0.85 - ETA: 0s - loss: 0.3366 - accuracy: 0.85 - 0s 994us/step - loss: 0.3365 - accuracy: 0.8579 - val_loss: 0.3868 - val_accuracy: 0.8400\n",
      "Epoch 64/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - ETA: 0s - loss: 0.3577 - accuracy: 0.85 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - ETA: 0s - loss: 0.3264 - accuracy: 0.86 - ETA: 0s - loss: 0.3320 - accuracy: 0.86 - ETA: 0s - loss: 0.3330 - accuracy: 0.86 - ETA: 0s - loss: 0.3338 - accuracy: 0.86 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8619 - val_loss: 0.3882 - val_accuracy: 0.8575\n",
      "Epoch 65/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.87 - ETA: 0s - loss: 0.3276 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - ETA: 0s - loss: 0.3319 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3280 - accuracy: 0.86 - ETA: 0s - loss: 0.3322 - accuracy: 0.86 - ETA: 0s - loss: 0.3362 - accuracy: 0.85 - 0s 966us/step - loss: 0.3359 - accuracy: 0.8599 - val_loss: 0.3746 - val_accuracy: 0.8610\n",
      "Epoch 66/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.87 - ETA: 0s - loss: 0.3354 - accuracy: 0.86 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3284 - accuracy: 0.86 - ETA: 0s - loss: 0.3289 - accuracy: 0.86 - ETA: 0s - loss: 0.3256 - accuracy: 0.86 - ETA: 0s - loss: 0.3243 - accuracy: 0.86 - 0s 980us/step - loss: 0.3243 - accuracy: 0.8669 - val_loss: 0.3616 - val_accuracy: 0.8595\n",
      "Epoch 67/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.86 - ETA: 0s - loss: 0.3248 - accuracy: 0.86 - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - ETA: 0s - loss: 0.3145 - accuracy: 0.87 - ETA: 0s - loss: 0.3162 - accuracy: 0.87 - ETA: 0s - loss: 0.3138 - accuracy: 0.87 - 1s 1ms/step - loss: 0.3142 - accuracy: 0.8744 - val_loss: 0.3642 - val_accuracy: 0.8640\n",
      "Epoch 68/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.87 - ETA: 0s - loss: 0.2834 - accuracy: 0.89 - ETA: 0s - loss: 0.2950 - accuracy: 0.88 - ETA: 0s - loss: 0.2974 - accuracy: 0.88 - ETA: 0s - loss: 0.2990 - accuracy: 0.88 - ETA: 0s - loss: 0.2988 - accuracy: 0.88 - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - 0s 978us/step - loss: 0.3005 - accuracy: 0.8815 - val_loss: 0.3648 - val_accuracy: 0.8555\n",
      "Epoch 69/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.93 - ETA: 0s - loss: 0.2585 - accuracy: 0.90 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3054 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3152 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - 0s 984us/step - loss: 0.3101 - accuracy: 0.8745 - val_loss: 0.3808 - val_accuracy: 0.8595\n",
      "Epoch 70/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.81 - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - ETA: 0s - loss: 0.3010 - accuracy: 0.88 - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - ETA: 0s - loss: 0.2948 - accuracy: 0.88 - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - ETA: 0s - loss: 0.3023 - accuracy: 0.87 - 0s 992us/step - loss: 0.3023 - accuracy: 0.8784 - val_loss: 0.3610 - val_accuracy: 0.8630\n",
      "Epoch 71/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 1.00 - ETA: 0s - loss: 0.3136 - accuracy: 0.88 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - ETA: 0s - loss: 0.2957 - accuracy: 0.88 - ETA: 0s - loss: 0.2940 - accuracy: 0.88 - ETA: 0s - loss: 0.2959 - accuracy: 0.88 - ETA: 0s - loss: 0.2978 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - 0s 984us/step - loss: 0.2980 - accuracy: 0.8806 - val_loss: 0.3590 - val_accuracy: 0.8560\n",
      "Epoch 72/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 1.00 - ETA: 0s - loss: 0.2707 - accuracy: 0.89 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - ETA: 0s - loss: 0.3023 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.88 - ETA: 0s - loss: 0.2998 - accuracy: 0.88 - 0s 948us/step - loss: 0.3001 - accuracy: 0.8806 - val_loss: 0.3674 - val_accuracy: 0.8525\n",
      "Epoch 73/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.93 - ETA: 0s - loss: 0.2767 - accuracy: 0.88 - ETA: 0s - loss: 0.2904 - accuracy: 0.88 - ETA: 0s - loss: 0.2973 - accuracy: 0.87 - ETA: 0s - loss: 0.3087 - accuracy: 0.87 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - ETA: 0s - loss: 0.3014 - accuracy: 0.87 - ETA: 0s - loss: 0.3000 - accuracy: 0.87 - 0s 986us/step - loss: 0.3028 - accuracy: 0.8763 - val_loss: 0.3613 - val_accuracy: 0.8580\n",
      "Epoch 74/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.81 - ETA: 0s - loss: 0.2847 - accuracy: 0.88 - ETA: 0s - loss: 0.2952 - accuracy: 0.87 - ETA: 0s - loss: 0.3025 - accuracy: 0.87 - ETA: 0s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - ETA: 0s - loss: 0.3091 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - 0s 973us/step - loss: 0.3092 - accuracy: 0.8771 - val_loss: 0.3719 - val_accuracy: 0.8510\n",
      "Epoch 75/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5829 - accuracy: 0.81 - ETA: 0s - loss: 0.2979 - accuracy: 0.88 - ETA: 0s - loss: 0.2994 - accuracy: 0.88 - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - ETA: 0s - loss: 0.3000 - accuracy: 0.87 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - ETA: 0s - loss: 0.3033 - accuracy: 0.87 - 0s 935us/step - loss: 0.3044 - accuracy: 0.8777 - val_loss: 0.3687 - val_accuracy: 0.8500\n",
      "Epoch 76/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.81 - ETA: 0s - loss: 0.2875 - accuracy: 0.87 - ETA: 0s - loss: 0.2932 - accuracy: 0.87 - ETA: 0s - loss: 0.2935 - accuracy: 0.87 - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - ETA: 0s - loss: 0.2926 - accuracy: 0.88 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - ETA: 0s - loss: 0.2991 - accuracy: 0.87 - 0s 905us/step - loss: 0.3025 - accuracy: 0.8764 - val_loss: 0.3711 - val_accuracy: 0.8555\n",
      "Epoch 77/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.68 - ETA: 0s - loss: 0.3153 - accuracy: 0.87 - ETA: 0s - loss: 0.3213 - accuracy: 0.87 - ETA: 0s - loss: 0.3085 - accuracy: 0.87 - ETA: 0s - loss: 0.3051 - accuracy: 0.87 - ETA: 0s - loss: 0.2996 - accuracy: 0.87 - ETA: 0s - loss: 0.3044 - accuracy: 0.87 - ETA: 0s - loss: 0.2974 - accuracy: 0.88 - 0s 997us/step - loss: 0.3031 - accuracy: 0.8784 - val_loss: 0.3725 - val_accuracy: 0.8540\n",
      "Epoch 78/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.2619 - accuracy: 0.89 - ETA: 0s - loss: 0.2807 - accuracy: 0.88 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.2955 - accuracy: 0.87 - ETA: 0s - loss: 0.2975 - accuracy: 0.87 - ETA: 0s - loss: 0.2979 - accuracy: 0.87 - 0s 980us/step - loss: 0.2999 - accuracy: 0.8774 - val_loss: 0.3600 - val_accuracy: 0.8545\n",
      "Epoch 79/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 1.00 - ETA: 0s - loss: 0.3166 - accuracy: 0.86 - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - ETA: 0s - loss: 0.3065 - accuracy: 0.87 - ETA: 0s - loss: 0.3022 - accuracy: 0.87 - ETA: 0s - loss: 0.3051 - accuracy: 0.87 - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - 0s 936us/step - loss: 0.3030 - accuracy: 0.8785 - val_loss: 0.3883 - val_accuracy: 0.8495\n",
      "Epoch 80/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.93 - ETA: 0s - loss: 0.2810 - accuracy: 0.88 - ETA: 0s - loss: 0.3020 - accuracy: 0.88 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - ETA: 0s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.3019 - accuracy: 0.88 - ETA: 0s - loss: 0.3023 - accuracy: 0.88 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - 0s 929us/step - loss: 0.3035 - accuracy: 0.8789 - val_loss: 0.3695 - val_accuracy: 0.8565\n",
      "Epoch 81/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.81 - ETA: 0s - loss: 0.2852 - accuracy: 0.88 - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - ETA: 0s - loss: 0.3002 - accuracy: 0.88 - ETA: 0s - loss: 0.3030 - accuracy: 0.88 - ETA: 0s - loss: 0.3006 - accuracy: 0.88 - ETA: 0s - loss: 0.3047 - accuracy: 0.88 - ETA: 0s - loss: 0.3059 - accuracy: 0.87 - 0s 987us/step - loss: 0.3030 - accuracy: 0.8805 - val_loss: 0.3739 - val_accuracy: 0.8565\n",
      "Epoch 82/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.81 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.3034 - accuracy: 0.88 - ETA: 0s - loss: 0.3000 - accuracy: 0.88 - ETA: 0s - loss: 0.2961 - accuracy: 0.88 - ETA: 0s - loss: 0.2981 - accuracy: 0.88 - ETA: 0s - loss: 0.3016 - accuracy: 0.87 - ETA: 0s - loss: 0.3017 - accuracy: 0.87 - 0s 938us/step - loss: 0.3019 - accuracy: 0.8784 - val_loss: 0.3665 - val_accuracy: 0.8625\n",
      "Epoch 83/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.81 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - ETA: 0s - loss: 0.2893 - accuracy: 0.88 - ETA: 0s - loss: 0.2862 - accuracy: 0.88 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2937 - accuracy: 0.88 - ETA: 0s - loss: 0.3023 - accuracy: 0.87 - 0s 974us/step - loss: 0.3034 - accuracy: 0.8786 - val_loss: 0.3828 - val_accuracy: 0.8600\n",
      "Epoch 84/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.81 - ETA: 0s - loss: 0.2553 - accuracy: 0.90 - ETA: 0s - loss: 0.2700 - accuracy: 0.89 - ETA: 0s - loss: 0.2903 - accuracy: 0.88 - ETA: 0s - loss: 0.2891 - accuracy: 0.88 - ETA: 0s - loss: 0.2933 - accuracy: 0.88 - ETA: 0s - loss: 0.2932 - accuracy: 0.88 - ETA: 0s - loss: 0.2947 - accuracy: 0.88 - 0s 958us/step - loss: 0.2950 - accuracy: 0.8813 - val_loss: 0.3915 - val_accuracy: 0.8565\n",
      "Epoch 85/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - ETA: 0s - loss: 0.2584 - accuracy: 0.90 - ETA: 0s - loss: 0.2795 - accuracy: 0.89 - ETA: 0s - loss: 0.2803 - accuracy: 0.89 - ETA: 0s - loss: 0.2879 - accuracy: 0.88 - ETA: 0s - loss: 0.2935 - accuracy: 0.88 - ETA: 0s - loss: 0.2981 - accuracy: 0.88 - ETA: 0s - loss: 0.3003 - accuracy: 0.88 - 0s 977us/step - loss: 0.2972 - accuracy: 0.8826 - val_loss: 0.3850 - val_accuracy: 0.8585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.93 - ETA: 0s - loss: 0.2824 - accuracy: 0.88 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2872 - accuracy: 0.88 - ETA: 0s - loss: 0.2930 - accuracy: 0.88 - ETA: 0s - loss: 0.2911 - accuracy: 0.88 - ETA: 0s - loss: 0.2953 - accuracy: 0.88 - ETA: 0s - loss: 0.2926 - accuracy: 0.88 - 0s 978us/step - loss: 0.2933 - accuracy: 0.8845 - val_loss: 0.3846 - val_accuracy: 0.8600\n",
      "Epoch 87/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.2951 - accuracy: 0.87 - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - ETA: 0s - loss: 0.2978 - accuracy: 0.87 - 0s 967us/step - loss: 0.2969 - accuracy: 0.8796 - val_loss: 0.3831 - val_accuracy: 0.8575\n",
      "Epoch 88/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.93 - ETA: 0s - loss: 0.2938 - accuracy: 0.88 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.2936 - accuracy: 0.88 - ETA: 0s - loss: 0.3005 - accuracy: 0.88 - ETA: 0s - loss: 0.3007 - accuracy: 0.87 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - ETA: 0s - loss: 0.2985 - accuracy: 0.88 - 0s 919us/step - loss: 0.2987 - accuracy: 0.8820 - val_loss: 0.3854 - val_accuracy: 0.8440\n",
      "Epoch 89/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.93 - ETA: 0s - loss: 0.2822 - accuracy: 0.89 - ETA: 0s - loss: 0.2968 - accuracy: 0.88 - ETA: 0s - loss: 0.2950 - accuracy: 0.88 - ETA: 0s - loss: 0.2981 - accuracy: 0.88 - ETA: 0s - loss: 0.2962 - accuracy: 0.88 - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - ETA: 0s - loss: 0.2963 - accuracy: 0.88 - 0s 964us/step - loss: 0.2965 - accuracy: 0.8814 - val_loss: 0.3793 - val_accuracy: 0.8580\n",
      "Epoch 90/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.87 - ETA: 0s - loss: 0.3286 - accuracy: 0.86 - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - ETA: 0s - loss: 0.2994 - accuracy: 0.88 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.2974 - accuracy: 0.88 - ETA: 0s - loss: 0.2940 - accuracy: 0.88 - ETA: 0s - loss: 0.2948 - accuracy: 0.88 - 0s 961us/step - loss: 0.2954 - accuracy: 0.8826 - val_loss: 0.3630 - val_accuracy: 0.8610\n",
      "Epoch 91/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6581 - accuracy: 0.75 - ETA: 0s - loss: 0.2993 - accuracy: 0.87 - ETA: 0s - loss: 0.2974 - accuracy: 0.87 - ETA: 0s - loss: 0.2885 - accuracy: 0.88 - ETA: 0s - loss: 0.2929 - accuracy: 0.88 - ETA: 0s - loss: 0.2815 - accuracy: 0.88 - ETA: 0s - loss: 0.2876 - accuracy: 0.88 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.2916 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2915 - accuracy: 0.8856 - val_loss: 0.3855 - val_accuracy: 0.8595\n",
      "Epoch 92/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 1.00 - ETA: 0s - loss: 0.2996 - accuracy: 0.88 - ETA: 0s - loss: 0.2974 - accuracy: 0.88 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - ETA: 0s - loss: 0.2906 - accuracy: 0.88 - ETA: 0s - loss: 0.2900 - accuracy: 0.88 - ETA: 0s - loss: 0.2913 - accuracy: 0.88 - ETA: 0s - loss: 0.2954 - accuracy: 0.88 - 0s 963us/step - loss: 0.2967 - accuracy: 0.8827 - val_loss: 0.3655 - val_accuracy: 0.8570\n",
      "Epoch 93/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.93 - ETA: 0s - loss: 0.3127 - accuracy: 0.87 - ETA: 0s - loss: 0.2884 - accuracy: 0.88 - ETA: 0s - loss: 0.2906 - accuracy: 0.88 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - ETA: 0s - loss: 0.2832 - accuracy: 0.88 - ETA: 0s - loss: 0.2870 - accuracy: 0.88 - 0s 974us/step - loss: 0.2880 - accuracy: 0.8841 - val_loss: 0.3778 - val_accuracy: 0.8475\n",
      "Epoch 94/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.81 - ETA: 0s - loss: 0.2814 - accuracy: 0.89 - ETA: 0s - loss: 0.2842 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - ETA: 0s - loss: 0.2862 - accuracy: 0.88 - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - ETA: 0s - loss: 0.2867 - accuracy: 0.88 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - 0s 925us/step - loss: 0.2890 - accuracy: 0.8849 - val_loss: 0.3650 - val_accuracy: 0.8565\n",
      "Epoch 95/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 1.00 - ETA: 0s - loss: 0.2969 - accuracy: 0.88 - ETA: 0s - loss: 0.2937 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2776 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2871 - accuracy: 0.88 - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2868 - accuracy: 0.8852 - val_loss: 0.4074 - val_accuracy: 0.8550\n",
      "Epoch 96/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.81 - ETA: 0s - loss: 0.2939 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2853 - accuracy: 0.88 - ETA: 0s - loss: 0.2875 - accuracy: 0.88 - ETA: 0s - loss: 0.2905 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2839 - accuracy: 0.88 - 0s 968us/step - loss: 0.2843 - accuracy: 0.8830 - val_loss: 0.3778 - val_accuracy: 0.8560\n",
      "Epoch 97/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.75 - ETA: 0s - loss: 0.2797 - accuracy: 0.89 - ETA: 0s - loss: 0.2849 - accuracy: 0.88 - ETA: 0s - loss: 0.2789 - accuracy: 0.89 - ETA: 0s - loss: 0.2849 - accuracy: 0.88 - ETA: 0s - loss: 0.2897 - accuracy: 0.88 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - ETA: 0s - loss: 0.2910 - accuracy: 0.88 - 0s 952us/step - loss: 0.2935 - accuracy: 0.8838 - val_loss: 0.3935 - val_accuracy: 0.8475\n",
      "Epoch 98/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.93 - ETA: 0s - loss: 0.3066 - accuracy: 0.88 - ETA: 0s - loss: 0.3017 - accuracy: 0.87 - ETA: 0s - loss: 0.2972 - accuracy: 0.88 - ETA: 0s - loss: 0.2898 - accuracy: 0.88 - ETA: 0s - loss: 0.2941 - accuracy: 0.88 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - 0s 927us/step - loss: 0.2964 - accuracy: 0.8808 - val_loss: 0.3920 - val_accuracy: 0.8480\n",
      "Epoch 99/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.93 - ETA: 0s - loss: 0.2664 - accuracy: 0.89 - ETA: 0s - loss: 0.2661 - accuracy: 0.89 - ETA: 0s - loss: 0.2696 - accuracy: 0.89 - ETA: 0s - loss: 0.2739 - accuracy: 0.88 - ETA: 0s - loss: 0.2805 - accuracy: 0.88 - ETA: 0s - loss: 0.2830 - accuracy: 0.88 - 0s 925us/step - loss: 0.2872 - accuracy: 0.8839 - val_loss: 0.3908 - val_accuracy: 0.8410\n",
      "Epoch 100/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.87 - ETA: 0s - loss: 0.3004 - accuracy: 0.88 - ETA: 0s - loss: 0.2865 - accuracy: 0.88 - ETA: 0s - loss: 0.2934 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2864 - accuracy: 0.88 - ETA: 0s - loss: 0.2834 - accuracy: 0.88 - ETA: 0s - loss: 0.2873 - accuracy: 0.88 - 0s 946us/step - loss: 0.2866 - accuracy: 0.8863 - val_loss: 0.3913 - val_accuracy: 0.8580\n",
      "Epoch 101/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 1.00 - ETA: 0s - loss: 0.2397 - accuracy: 0.90 - ETA: 0s - loss: 0.2455 - accuracy: 0.90 - ETA: 0s - loss: 0.2656 - accuracy: 0.89 - ETA: 0s - loss: 0.2639 - accuracy: 0.89 - ETA: 0s - loss: 0.2758 - accuracy: 0.88 - ETA: 0s - loss: 0.2802 - accuracy: 0.88 - ETA: 0s - loss: 0.2834 - accuracy: 0.88 - 0s 926us/step - loss: 0.2828 - accuracy: 0.8845 - val_loss: 0.4251 - val_accuracy: 0.8520\n",
      "Epoch 102/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.87 - ETA: 0s - loss: 0.2734 - accuracy: 0.89 - ETA: 0s - loss: 0.2696 - accuracy: 0.89 - ETA: 0s - loss: 0.2682 - accuracy: 0.89 - ETA: 0s - loss: 0.2768 - accuracy: 0.88 - ETA: 0s - loss: 0.2808 - accuracy: 0.88 - ETA: 0s - loss: 0.2857 - accuracy: 0.88 - ETA: 0s - loss: 0.2869 - accuracy: 0.88 - 0s 957us/step - loss: 0.2869 - accuracy: 0.8846 - val_loss: 0.3800 - val_accuracy: 0.8560\n",
      "Epoch 103/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.87 - ETA: 0s - loss: 0.2743 - accuracy: 0.89 - ETA: 0s - loss: 0.2624 - accuracy: 0.89 - ETA: 0s - loss: 0.2745 - accuracy: 0.89 - ETA: 0s - loss: 0.2749 - accuracy: 0.89 - ETA: 0s - loss: 0.2808 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - 0s 880us/step - loss: 0.2919 - accuracy: 0.8819 - val_loss: 0.3676 - val_accuracy: 0.8595\n",
      "Epoch 104/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 1.00 - ETA: 0s - loss: 0.2855 - accuracy: 0.89 - ETA: 0s - loss: 0.2842 - accuracy: 0.89 - ETA: 0s - loss: 0.2970 - accuracy: 0.88 - ETA: 0s - loss: 0.2949 - accuracy: 0.88 - ETA: 0s - loss: 0.2992 - accuracy: 0.88 - ETA: 0s - loss: 0.3018 - accuracy: 0.88 - 0s 907us/step - loss: 0.2972 - accuracy: 0.8826 - val_loss: 0.4208 - val_accuracy: 0.8580\n",
      "Epoch 105/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.93 - ETA: 0s - loss: 0.2708 - accuracy: 0.89 - ETA: 0s - loss: 0.2776 - accuracy: 0.89 - ETA: 0s - loss: 0.2860 - accuracy: 0.88 - ETA: 0s - loss: 0.2847 - accuracy: 0.88 - ETA: 0s - loss: 0.2887 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - 0s 875us/step - loss: 0.2864 - accuracy: 0.8885 - val_loss: 0.3879 - val_accuracy: 0.8590\n",
      "Epoch 106/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.93 - ETA: 0s - loss: 0.2880 - accuracy: 0.88 - ETA: 0s - loss: 0.2955 - accuracy: 0.87 - ETA: 0s - loss: 0.2945 - accuracy: 0.88 - ETA: 0s - loss: 0.2897 - accuracy: 0.88 - ETA: 0s - loss: 0.2916 - accuracy: 0.88 - ETA: 0s - loss: 0.2884 - accuracy: 0.88 - 0s 879us/step - loss: 0.2861 - accuracy: 0.8864 - val_loss: 0.3895 - val_accuracy: 0.8575\n",
      "Epoch 107/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.81 - ETA: 0s - loss: 0.2621 - accuracy: 0.90 - ETA: 0s - loss: 0.2680 - accuracy: 0.89 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2801 - accuracy: 0.88 - ETA: 0s - loss: 0.2820 - accuracy: 0.88 - ETA: 0s - loss: 0.2844 - accuracy: 0.88 - 0s 878us/step - loss: 0.2861 - accuracy: 0.8842 - val_loss: 0.3656 - val_accuracy: 0.8605\n",
      "Epoch 108/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.93 - ETA: 0s - loss: 0.2897 - accuracy: 0.88 - ETA: 0s - loss: 0.2945 - accuracy: 0.88 - ETA: 0s - loss: 0.2866 - accuracy: 0.88 - ETA: 0s - loss: 0.2897 - accuracy: 0.88 - ETA: 0s - loss: 0.2917 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - 0s 952us/step - loss: 0.2816 - accuracy: 0.8849 - val_loss: 0.3916 - val_accuracy: 0.8525\n",
      "Epoch 109/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 1.00 - ETA: 0s - loss: 0.2575 - accuracy: 0.88 - ETA: 0s - loss: 0.2579 - accuracy: 0.89 - ETA: 0s - loss: 0.2671 - accuracy: 0.89 - ETA: 0s - loss: 0.2730 - accuracy: 0.89 - ETA: 0s - loss: 0.2780 - accuracy: 0.89 - ETA: 0s - loss: 0.2784 - accuracy: 0.89 - ETA: 0s - loss: 0.2808 - accuracy: 0.88 - 0s 989us/step - loss: 0.2816 - accuracy: 0.8889 - val_loss: 0.4050 - val_accuracy: 0.8560\n",
      "Epoch 110/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.87 - ETA: 0s - loss: 0.2754 - accuracy: 0.88 - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - ETA: 0s - loss: 0.2857 - accuracy: 0.88 - ETA: 0s - loss: 0.2896 - accuracy: 0.88 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.3214 - accuracy: 0.88 - 0s 980us/step - loss: 0.3188 - accuracy: 0.8832 - val_loss: 0.3753 - val_accuracy: 0.8595\n",
      "Epoch 111/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.87 - ETA: 0s - loss: 0.2721 - accuracy: 0.88 - ETA: 0s - loss: 0.2912 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - ETA: 0s - loss: 0.3027 - accuracy: 0.87 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - ETA: 0s - loss: 0.3000 - accuracy: 0.87 - ETA: 0s - loss: 0.2985 - accuracy: 0.87 - 1s 1ms/step - loss: 0.2969 - accuracy: 0.8796 - val_loss: 0.3747 - val_accuracy: 0.8570\n",
      "Epoch 112/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.87 - ETA: 0s - loss: 0.2795 - accuracy: 0.88 - ETA: 0s - loss: 0.2664 - accuracy: 0.89 - ETA: 0s - loss: 0.2710 - accuracy: 0.89 - ETA: 0s - loss: 0.2772 - accuracy: 0.88 - ETA: 0s - loss: 0.2814 - accuracy: 0.88 - ETA: 0s - loss: 0.2806 - accuracy: 0.88 - ETA: 0s - loss: 0.2822 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2859 - accuracy: 0.8846 - val_loss: 0.3825 - val_accuracy: 0.8495\n",
      "Epoch 113/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.81 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - ETA: 0s - loss: 0.2685 - accuracy: 0.89 - ETA: 0s - loss: 0.2681 - accuracy: 0.89 - ETA: 0s - loss: 0.2716 - accuracy: 0.89 - ETA: 0s - loss: 0.2751 - accuracy: 0.88 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2864 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2872 - accuracy: 0.8832 - val_loss: 0.3848 - val_accuracy: 0.8495\n",
      "Epoch 114/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.68 - ETA: 0s - loss: 0.2900 - accuracy: 0.88 - ETA: 0s - loss: 0.2885 - accuracy: 0.87 - ETA: 0s - loss: 0.2927 - accuracy: 0.87 - ETA: 0s - loss: 0.2867 - accuracy: 0.88 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - ETA: 0s - loss: 0.2813 - accuracy: 0.88 - ETA: 0s - loss: 0.2816 - accuracy: 0.88 - ETA: 0s - loss: 0.2873 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2871 - accuracy: 0.8860 - val_loss: 0.3869 - val_accuracy: 0.8410\n",
      "Epoch 115/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.93 - ETA: 0s - loss: 0.2722 - accuracy: 0.89 - ETA: 0s - loss: 0.2675 - accuracy: 0.89 - ETA: 0s - loss: 0.2622 - accuracy: 0.89 - ETA: 0s - loss: 0.2723 - accuracy: 0.89 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - ETA: 0s - loss: 0.2810 - accuracy: 0.88 - 0s 941us/step - loss: 0.2798 - accuracy: 0.8864 - val_loss: 0.4009 - val_accuracy: 0.8570\n",
      "Epoch 116/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.87 - ETA: 0s - loss: 0.2719 - accuracy: 0.88 - ETA: 0s - loss: 0.2816 - accuracy: 0.88 - ETA: 0s - loss: 0.2758 - accuracy: 0.89 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2863 - accuracy: 0.88 - ETA: 0s - loss: 0.2850 - accuracy: 0.88 - 0s 966us/step - loss: 0.2843 - accuracy: 0.8856 - val_loss: 0.4036 - val_accuracy: 0.8435\n",
      "Epoch 117/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 1.00 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.2848 - accuracy: 0.88 - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - ETA: 0s - loss: 0.2876 - accuracy: 0.88 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - ETA: 0s - loss: 0.2908 - accuracy: 0.88 - ETA: 0s - loss: 0.2919 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2904 - accuracy: 0.8831 - val_loss: 0.4211 - val_accuracy: 0.8595\n",
      "Epoch 118/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.81 - ETA: 0s - loss: 0.2852 - accuracy: 0.88 - ETA: 0s - loss: 0.2799 - accuracy: 0.88 - ETA: 0s - loss: 0.2844 - accuracy: 0.88 - ETA: 0s - loss: 0.2932 - accuracy: 0.87 - ETA: 0s - loss: 0.2966 - accuracy: 0.87 - ETA: 0s - loss: 0.2940 - accuracy: 0.88 - ETA: 0s - loss: 0.2917 - accuracy: 0.88 - 0s 956us/step - loss: 0.2925 - accuracy: 0.8827 - val_loss: 0.3713 - val_accuracy: 0.8645\n",
      "Epoch 119/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.93 - ETA: 0s - loss: 0.2803 - accuracy: 0.88 - ETA: 0s - loss: 0.2830 - accuracy: 0.88 - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - ETA: 0s - loss: 0.3021 - accuracy: 0.87 - ETA: 0s - loss: 0.2986 - accuracy: 0.87 - ETA: 0s - loss: 0.2894 - accuracy: 0.88 - ETA: 0s - loss: 0.2893 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2859 - accuracy: 0.8848 - val_loss: 0.4277 - val_accuracy: 0.8590\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.87 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.2876 - accuracy: 0.87 - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - ETA: 0s - loss: 0.2752 - accuracy: 0.88 - ETA: 0s - loss: 0.2754 - accuracy: 0.88 - ETA: 0s - loss: 0.2781 - accuracy: 0.88 - ETA: 0s - loss: 0.2795 - accuracy: 0.88 - 0s 972us/step - loss: 0.2793 - accuracy: 0.8863 - val_loss: 0.4005 - val_accuracy: 0.8555\n",
      "Epoch 121/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3967 - accuracy: 0.81 - ETA: 0s - loss: 0.2813 - accuracy: 0.88 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - ETA: 0s - loss: 0.2886 - accuracy: 0.88 - ETA: 0s - loss: 0.2850 - accuracy: 0.88 - ETA: 0s - loss: 0.2862 - accuracy: 0.88 - ETA: 0s - loss: 0.2807 - accuracy: 0.88 - ETA: 0s - loss: 0.2796 - accuracy: 0.88 - ETA: 0s - loss: 0.2774 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2760 - accuracy: 0.8906 - val_loss: 0.3964 - val_accuracy: 0.8595\n",
      "Epoch 122/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.87 - ETA: 0s - loss: 0.2704 - accuracy: 0.88 - ETA: 0s - loss: 0.2714 - accuracy: 0.89 - ETA: 0s - loss: 0.2673 - accuracy: 0.89 - ETA: 0s - loss: 0.2744 - accuracy: 0.89 - ETA: 0s - loss: 0.2753 - accuracy: 0.89 - ETA: 0s - loss: 0.2763 - accuracy: 0.89 - ETA: 0s - loss: 0.2771 - accuracy: 0.89 - ETA: 0s - loss: 0.2786 - accuracy: 0.89 - 1s 1ms/step - loss: 0.2786 - accuracy: 0.8907 - val_loss: 0.3893 - val_accuracy: 0.8590\n",
      "Epoch 123/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 1.00 - ETA: 0s - loss: 0.2541 - accuracy: 0.89 - ETA: 0s - loss: 0.2766 - accuracy: 0.89 - ETA: 0s - loss: 0.2923 - accuracy: 0.88 - ETA: 0s - loss: 0.2949 - accuracy: 0.88 - ETA: 0s - loss: 0.2865 - accuracy: 0.88 - ETA: 0s - loss: 0.2831 - accuracy: 0.88 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - ETA: 0s - loss: 0.2854 - accuracy: 0.88 - ETA: 0s - loss: 0.2846 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2831 - accuracy: 0.8866 - val_loss: 0.4238 - val_accuracy: 0.8515\n",
      "Epoch 124/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.93 - ETA: 0s - loss: 0.2688 - accuracy: 0.88 - ETA: 0s - loss: 0.2748 - accuracy: 0.88 - ETA: 0s - loss: 0.2770 - accuracy: 0.88 - ETA: 0s - loss: 0.2852 - accuracy: 0.87 - ETA: 0s - loss: 0.2840 - accuracy: 0.88 - ETA: 0s - loss: 0.2756 - accuracy: 0.88 - ETA: 0s - loss: 0.2790 - accuracy: 0.88 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - ETA: 0s - loss: 0.2764 - accuracy: 0.88 - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2796 - accuracy: 0.8866 - val_loss: 0.3775 - val_accuracy: 0.8465\n",
      "Epoch 125/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.81 - ETA: 0s - loss: 0.2603 - accuracy: 0.89 - ETA: 0s - loss: 0.2679 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.88 - ETA: 0s - loss: 0.2757 - accuracy: 0.88 - ETA: 0s - loss: 0.2728 - accuracy: 0.89 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - ETA: 0s - loss: 0.2809 - accuracy: 0.88 - ETA: 0s - loss: 0.2808 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2829 - accuracy: 0.8863 - val_loss: 0.3695 - val_accuracy: 0.8630\n",
      "Epoch 126/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.81 - ETA: 0s - loss: 0.2722 - accuracy: 0.88 - ETA: 0s - loss: 0.2673 - accuracy: 0.88 - ETA: 0s - loss: 0.2728 - accuracy: 0.88 - ETA: 0s - loss: 0.2681 - accuracy: 0.88 - ETA: 0s - loss: 0.2749 - accuracy: 0.88 - ETA: 0s - loss: 0.2770 - accuracy: 0.88 - ETA: 0s - loss: 0.2798 - accuracy: 0.88 - 0s 970us/step - loss: 0.2813 - accuracy: 0.8856 - val_loss: 0.4037 - val_accuracy: 0.8555\n",
      "Epoch 127/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 1.00 - ETA: 0s - loss: 0.2987 - accuracy: 0.88 - ETA: 0s - loss: 0.2874 - accuracy: 0.88 - ETA: 0s - loss: 0.2741 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2835 - accuracy: 0.88 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2821 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2821 - accuracy: 0.8886 - val_loss: 0.3892 - val_accuracy: 0.8580\n",
      "Epoch 128/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.93 - ETA: 0s - loss: 0.2251 - accuracy: 0.91 - ETA: 0s - loss: 0.2347 - accuracy: 0.91 - ETA: 0s - loss: 0.2503 - accuracy: 0.90 - ETA: 0s - loss: 0.2606 - accuracy: 0.89 - ETA: 0s - loss: 0.2655 - accuracy: 0.89 - ETA: 0s - loss: 0.2657 - accuracy: 0.89 - ETA: 0s - loss: 0.2738 - accuracy: 0.89 - ETA: 0s - loss: 0.2768 - accuracy: 0.89 - 1s 1ms/step - loss: 0.2771 - accuracy: 0.8900 - val_loss: 0.3944 - val_accuracy: 0.8500\n",
      "Epoch 129/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.93 - ETA: 0s - loss: 0.2715 - accuracy: 0.89 - ETA: 0s - loss: 0.2787 - accuracy: 0.89 - ETA: 0s - loss: 0.2895 - accuracy: 0.88 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - ETA: 0s - loss: 0.2998 - accuracy: 0.88 - ETA: 0s - loss: 0.3035 - accuracy: 0.87 - ETA: 0s - loss: 0.3051 - accuracy: 0.87 - 1s 1ms/step - loss: 0.3036 - accuracy: 0.8785 - val_loss: 0.3766 - val_accuracy: 0.8570\n",
      "Epoch 130/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.93 - ETA: 0s - loss: 0.3254 - accuracy: 0.86 - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - ETA: 0s - loss: 0.2955 - accuracy: 0.88 - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - ETA: 0s - loss: 0.2944 - accuracy: 0.87 - ETA: 0s - loss: 0.2986 - accuracy: 0.87 - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - 0s 909us/step - loss: 0.2994 - accuracy: 0.8783 - val_loss: 0.4741 - val_accuracy: 0.8485\n",
      "Epoch 131/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.93 - ETA: 0s - loss: 0.2942 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.87 - ETA: 0s - loss: 0.2975 - accuracy: 0.88 - ETA: 0s - loss: 0.2974 - accuracy: 0.88 - ETA: 0s - loss: 0.2941 - accuracy: 0.88 - ETA: 0s - loss: 0.2963 - accuracy: 0.88 - 0s 892us/step - loss: 0.2972 - accuracy: 0.8799 - val_loss: 0.3745 - val_accuracy: 0.8555\n",
      "Epoch 132/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.93 - ETA: 0s - loss: 0.2792 - accuracy: 0.88 - ETA: 0s - loss: 0.2759 - accuracy: 0.89 - ETA: 0s - loss: 0.2808 - accuracy: 0.89 - ETA: 0s - loss: 0.2847 - accuracy: 0.88 - ETA: 0s - loss: 0.2838 - accuracy: 0.88 - ETA: 0s - loss: 0.2829 - accuracy: 0.88 - ETA: 0s - loss: 0.2792 - accuracy: 0.88 - 0s 959us/step - loss: 0.2797 - accuracy: 0.8889 - val_loss: 0.3997 - val_accuracy: 0.8495\n",
      "Epoch 133/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.93 - ETA: 0s - loss: 0.2626 - accuracy: 0.90 - ETA: 0s - loss: 0.2475 - accuracy: 0.90 - ETA: 0s - loss: 0.2594 - accuracy: 0.89 - ETA: 0s - loss: 0.2672 - accuracy: 0.89 - ETA: 0s - loss: 0.2709 - accuracy: 0.89 - ETA: 0s - loss: 0.2736 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.88 - 0s 972us/step - loss: 0.2767 - accuracy: 0.8857 - val_loss: 0.3828 - val_accuracy: 0.8395\n",
      "Epoch 134/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.81 - ETA: 0s - loss: 0.2641 - accuracy: 0.89 - ETA: 0s - loss: 0.2742 - accuracy: 0.89 - ETA: 0s - loss: 0.2737 - accuracy: 0.89 - ETA: 0s - loss: 0.2740 - accuracy: 0.88 - ETA: 0s - loss: 0.2721 - accuracy: 0.89 - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - ETA: 0s - loss: 0.2765 - accuracy: 0.88 - 0s 943us/step - loss: 0.2767 - accuracy: 0.8881 - val_loss: 0.3983 - val_accuracy: 0.8490\n",
      "Epoch 135/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 1.00 - ETA: 0s - loss: 0.2921 - accuracy: 0.87 - ETA: 0s - loss: 0.2750 - accuracy: 0.88 - ETA: 0s - loss: 0.2735 - accuracy: 0.88 - ETA: 0s - loss: 0.2670 - accuracy: 0.89 - ETA: 0s - loss: 0.2625 - accuracy: 0.89 - ETA: 0s - loss: 0.2722 - accuracy: 0.88 - ETA: 0s - loss: 0.2755 - accuracy: 0.88 - 0s 949us/step - loss: 0.2773 - accuracy: 0.8864 - val_loss: 0.3917 - val_accuracy: 0.8380\n",
      "Epoch 136/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.93 - ETA: 0s - loss: 0.2723 - accuracy: 0.89 - ETA: 0s - loss: 0.2776 - accuracy: 0.88 - ETA: 0s - loss: 0.2764 - accuracy: 0.89 - ETA: 0s - loss: 0.2697 - accuracy: 0.89 - ETA: 0s - loss: 0.7274 - accuracy: 0.88 - ETA: 0s - loss: 0.6509 - accuracy: 0.88 - ETA: 0s - loss: 0.6009 - accuracy: 0.88 - 0s 942us/step - loss: 0.5880 - accuracy: 0.8835 - val_loss: 0.3853 - val_accuracy: 0.8510\n",
      "Epoch 137/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.68 - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - ETA: 0s - loss: 0.2845 - accuracy: 0.88 - ETA: 0s - loss: 0.2935 - accuracy: 0.88 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - ETA: 0s - loss: 0.2842 - accuracy: 0.88 - ETA: 0s - loss: 0.2856 - accuracy: 0.88 - ETA: 0s - loss: 0.2895 - accuracy: 0.88 - 0s 945us/step - loss: 0.2927 - accuracy: 0.8809 - val_loss: 0.3820 - val_accuracy: 0.8600\n",
      "Epoch 138/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.75 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - ETA: 0s - loss: 0.2820 - accuracy: 0.88 - ETA: 0s - loss: 0.2919 - accuracy: 0.88 - ETA: 0s - loss: 0.2933 - accuracy: 0.87 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.2923 - accuracy: 0.88 - ETA: 0s - loss: 0.2958 - accuracy: 0.88 - 0s 947us/step - loss: 0.2975 - accuracy: 0.8796 - val_loss: 0.3914 - val_accuracy: 0.8480\n",
      "Epoch 139/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.81 - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.2968 - accuracy: 0.88 - ETA: 0s - loss: 0.2949 - accuracy: 0.88 - ETA: 0s - loss: 0.3001 - accuracy: 0.87 - ETA: 0s - loss: 0.2993 - accuracy: 0.88 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - 0s 940us/step - loss: 0.3009 - accuracy: 0.8792 - val_loss: 0.4045 - val_accuracy: 0.8475\n",
      "Epoch 140/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.93 - ETA: 0s - loss: 0.2808 - accuracy: 0.89 - ETA: 0s - loss: 0.2830 - accuracy: 0.89 - ETA: 0s - loss: 0.2952 - accuracy: 0.88 - ETA: 0s - loss: 0.2975 - accuracy: 0.88 - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - ETA: 0s - loss: 0.3023 - accuracy: 0.87 - ETA: 0s - loss: 0.3025 - accuracy: 0.87 - 0s 929us/step - loss: 0.3049 - accuracy: 0.8769 - val_loss: 0.4008 - val_accuracy: 0.8400\n",
      "Epoch 141/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 1.00 - ETA: 0s - loss: 0.3006 - accuracy: 0.87 - ETA: 0s - loss: 0.2936 - accuracy: 0.88 - ETA: 0s - loss: 0.3004 - accuracy: 0.87 - ETA: 0s - loss: 0.3018 - accuracy: 0.87 - ETA: 0s - loss: 0.3013 - accuracy: 0.87 - ETA: 0s - loss: 0.3049 - accuracy: 0.87 - ETA: 0s - loss: 0.3066 - accuracy: 0.87 - 0s 956us/step - loss: 0.3074 - accuracy: 0.8725 - val_loss: 0.4013 - val_accuracy: 0.8355\n",
      "Epoch 142/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.93 - ETA: 0s - loss: 0.3064 - accuracy: 0.86 - ETA: 0s - loss: 0.3088 - accuracy: 0.86 - ETA: 0s - loss: 0.3037 - accuracy: 0.86 - ETA: 0s - loss: 0.3050 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.87 - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - 0s 966us/step - loss: 0.3050 - accuracy: 0.8740 - val_loss: 0.3990 - val_accuracy: 0.8375\n",
      "Epoch 143/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.93 - ETA: 0s - loss: 0.3136 - accuracy: 0.87 - ETA: 0s - loss: 0.3210 - accuracy: 0.86 - ETA: 0s - loss: 0.3120 - accuracy: 0.87 - ETA: 0s - loss: 0.3113 - accuracy: 0.87 - ETA: 0s - loss: 0.3120 - accuracy: 0.87 - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - 0s 909us/step - loss: 0.3132 - accuracy: 0.8716 - val_loss: 0.3988 - val_accuracy: 0.8420\n",
      "Epoch 144/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.88 - ETA: 0s - loss: 0.3021 - accuracy: 0.88 - ETA: 0s - loss: 0.3035 - accuracy: 0.88 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - 0s 952us/step - loss: 0.3010 - accuracy: 0.8780 - val_loss: 0.4245 - val_accuracy: 0.8475\n",
      "Epoch 145/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.93 - ETA: 0s - loss: 0.2768 - accuracy: 0.88 - ETA: 0s - loss: 0.2863 - accuracy: 0.88 - ETA: 0s - loss: 0.2784 - accuracy: 0.88 - ETA: 0s - loss: 0.2757 - accuracy: 0.88 - ETA: 0s - loss: 0.2812 - accuracy: 0.88 - ETA: 0s - loss: 0.2817 - accuracy: 0.88 - ETA: 0s - loss: 0.2889 - accuracy: 0.88 - 0s 985us/step - loss: 0.2895 - accuracy: 0.8840 - val_loss: 0.3930 - val_accuracy: 0.8455\n",
      "Epoch 146/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.81 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2983 - accuracy: 0.88 - ETA: 0s - loss: 0.2906 - accuracy: 0.88 - ETA: 0s - loss: 0.2909 - accuracy: 0.88 - ETA: 0s - loss: 0.2951 - accuracy: 0.88 - ETA: 0s - loss: 0.2936 - accuracy: 0.88 - ETA: 0s - loss: 0.2898 - accuracy: 0.88 - ETA: 0s - loss: 0.2907 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2919 - accuracy: 0.8846 - val_loss: 0.4135 - val_accuracy: 0.8355\n",
      "Epoch 147/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 1.00 - ETA: 0s - loss: 0.3078 - accuracy: 0.87 - ETA: 0s - loss: 0.3106 - accuracy: 0.86 - ETA: 0s - loss: 0.3089 - accuracy: 0.86 - ETA: 0s - loss: 0.3091 - accuracy: 0.86 - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - 1s 1ms/step - loss: 0.3042 - accuracy: 0.8741 - val_loss: 0.4009 - val_accuracy: 0.8375\n",
      "Epoch 148/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 1.00 - ETA: 0s - loss: 0.2936 - accuracy: 0.88 - ETA: 0s - loss: 0.3002 - accuracy: 0.87 - ETA: 0s - loss: 0.2955 - accuracy: 0.88 - ETA: 0s - loss: 0.2985 - accuracy: 0.87 - ETA: 0s - loss: 0.2988 - accuracy: 0.87 - ETA: 0s - loss: 0.2988 - accuracy: 0.87 - ETA: 0s - loss: 0.3006 - accuracy: 0.87 - ETA: 0s - loss: 0.3035 - accuracy: 0.87 - 1s 1ms/step - loss: 0.3034 - accuracy: 0.8748 - val_loss: 0.4527 - val_accuracy: 0.8430\n",
      "Epoch 149/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.81 - ETA: 0s - loss: 0.2641 - accuracy: 0.89 - ETA: 0s - loss: 0.2804 - accuracy: 0.88 - ETA: 0s - loss: 0.2843 - accuracy: 0.88 - ETA: 0s - loss: 0.2890 - accuracy: 0.88 - ETA: 0s - loss: 0.2871 - accuracy: 0.88 - ETA: 0s - loss: 0.2878 - accuracy: 0.88 - ETA: 0s - loss: 0.2942 - accuracy: 0.88 - 0s 961us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3995 - val_accuracy: 0.8350\n",
      "Epoch 150/150\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.87 - ETA: 0s - loss: 0.3193 - accuracy: 0.87 - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - ETA: 0s - loss: 0.2996 - accuracy: 0.87 - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - ETA: 0s - loss: 0.2971 - accuracy: 0.88 - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - 0s 962us/step - loss: 0.3014 - accuracy: 0.8783 - val_loss: 0.4020 - val_accuracy: 0.8370\n"
     ]
    }
   ],
   "source": [
    "# the model is already complied using RandomSearch\n",
    "best_model_history=best_model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 16, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.87 - 0s 556us/step - loss: 0.4020 - accuracy: 0.8370\n",
      "Test Loss : 0.40202948451042175\n",
      "Test Accuracy : 0.8370000123977661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      1595\n",
      "           1       0.61      0.56      0.58       405\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.75      0.73      0.74      2000\n",
      "weighted avg       0.83      0.84      0.83      2000\n",
      "\n",
      "AUC Score : 0.7338519292542282\n"
     ]
    }
   ],
   "source": [
    "# Model Performance on TEST SET\n",
    "\n",
    "print('.')\n",
    "loss_test, accuracy_test = best_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss : {loss_test}')\n",
    "print(f'Test Accuracy : {accuracy_test}')\n",
    "\n",
    "test_pred_prob = best_model.predict(X_test)\n",
    "test_pred = np.where(test_pred_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, test_pred)\n",
    "print(f'AUC Score : {auc_score_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
